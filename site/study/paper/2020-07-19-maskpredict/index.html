
<!DOCTYPE html>

<html class="no-js" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<link href="https://simonjisu.github.io/study/paper/2020-07-19-maskpredict/" rel="canonical"/>
<link href="../2020-03-12-deepinsidecnn/" rel="prev"/>
<link href="../2020-07-23-casm/" rel="next"/>
<link href="../../../assets/images/favicon.png" rel="icon"/>
<meta content="mkdocs-1.4.2, mkdocs-material-9.1.6+insiders-4.32.5" name="generator"/>
<title>Mask-Predict: Parallel Decoding of Conditional Masked Language Models - Soopace</title>
<link href="../../../assets/stylesheets/main.dc5b59cc.min.css" rel="stylesheet"/>
<link href="../../../assets/stylesheets/palette.6932e648.min.css" rel="stylesheet"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/>
<style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
<script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
<script id="__analytics">function __md_analytics(){function n(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],n("js",new Date),n("config","G-2D0S4P2SJ9"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&n("event","search",{search_term:this.value})}),document$.subscribe(function(){var a=document.forms.feedback;if(void 0!==a)for(var e of a.querySelectorAll("[type=submit]"))e.addEventListener("click",function(e){e.preventDefault();var t=document.location.pathname,e=this.getAttribute("data-md-value");n("event","feedback",{page:t,data:e}),a.firstElementChild.disabled=!0;e=a.querySelector(".md-feedback__note [data-md-value='"+e+"']");e&&(e.hidden=!1)}),a.hidden=!1}),location$.subscribe(function(e){n("config","G-2D0S4P2SJ9",{page_path:e.pathname})})});var e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=G-2D0S4P2SJ9",document.getElementById("__analytics").insertAdjacentElement("afterEnd",e)}</script>
<script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
<link href="../../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
            html.glightbox-open { overflow: initial; height: 100%; }
            .gslide-title { margin-top: 0px; user-select: text; }
            .gslide-desc { color: #666; user-select: text; }
            .gslide-image img { background: white; }
            
                .gscrollbar-fixer { padding-right: 15px; }
                .gdesc-inner { font-size: 0.75rem; }
                body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
                body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
                body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}
                </style><script src="../../../assets/javascripts/glightbox.min.js"></script></head>
<body data-md-color-accent="" data-md-color-primary="black" data-md-color-scheme="default" dir="ltr">
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" for="__drawer"></label>
<div data-md-component="skip">
<a class="md-skip" href="#mask-predict-parallel-decoding-of-conditional-masked-language-models">
          Skip to content
        </a>
</div>
<div data-md-component="announce">
</div>
<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
<nav aria-label="Header" class="md-header__inner md-grid">
<a aria-label="Soopace" class="md-header__button md-logo" data-md-component="logo" href="../../.." title="Soopace">
<img alt="logo" src="../../../img/logo/logo.png"/>
</a>
<label class="md-header__button md-icon" for="__drawer">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"></path></svg>
</label>
<div class="md-header__title" data-md-component="header-title">
<div class="md-header__ellipsis">
<div class="md-header__topic">
<span class="md-ellipsis">
            Soopace
          </span>
</div>
<div class="md-header__topic" data-md-component="header-topic">
<span class="md-ellipsis">
            
              Mask-Predict: Parallel Decoding of Conditional Masked Language Models
            
          </span>
</div>
</div>
</div>
<label class="md-header__button md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"></path></svg>
</label>
<div class="md-search" data-md-component="search" role="dialog">
<label class="md-search__overlay" for="__search"></label>
<div class="md-search__inner" role="search">
<form class="md-search__form" name="search">
<input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="search-query" name="query" placeholder="Search" required="" spellcheck="false" type="text"/>
<label class="md-search__icon md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"></path></svg>
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"></path></svg>
</label>
<nav aria-label="Search" class="md-search__options">
<button aria-label="Clear" class="md-search__icon md-icon" tabindex="-1" title="Clear" type="reset">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"></path></svg>
</button>
</nav>
</form>
<div class="md-search__output">
<div class="md-search__scrollwrap" data-md-scrollfix="">
<div class="md-search-result" data-md-component="search-result">
<div class="md-search-result__meta">
            Initializing search
          </div>
<ol class="md-search-result__list" role="presentation"></ol>
</div>
</div>
</div>
</div>
</div>
<div class="md-header__source">
<a class="md-source" data-md-component="source" href="https://github.com/simonjisu.github.io" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"></path></svg>
</div>
<div class="md-source__repository">
    GitHub
  </div>
</a>
</div>
</nav>
<nav aria-label="Tabs" class="md-tabs" data-md-component="tabs">
<div class="md-grid">
<ul class="md-tabs__list">
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../..">
        
  
    
  
  About

      </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../blog/">
          
  
    
  
  Blog

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link md-tabs__link--active" href="../../">
          
  
    
  
  Study

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../project/">
          
  
    
  
  Project

        </a>
</li>
</ul>
</div>
</nav>
</header>
<div class="md-container" data-md-component="container">
<main class="md-main" data-md-component="main">
<div class="md-main__inner md-grid">
<div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Navigation" class="md-nav md-nav--primary md-nav--lifted" data-md-level="0">
<label class="md-nav__title" for="__drawer">
<a aria-label="Soopace" class="md-nav__button md-logo" data-md-component="logo" href="../../.." title="Soopace">
<img alt="logo" src="../../../img/logo/logo.png"/>
</a>
    Soopace
  </label>
<div class="md-nav__source">
<a class="md-source" data-md-component="source" href="https://github.com/simonjisu.github.io" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"></path></svg>
</div>
<div class="md-source__repository">
    GitHub
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../..">
<span class="md-ellipsis">
    
  
    About
  

    
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../blog/">
<span class="md-ellipsis">
    
  
    Blog
  

    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_3" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../../">
<span class="md-ellipsis">
    
  
    Study
  

    
  </span>
</a>
<label class="md-nav__link" for="__nav_3">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="true" aria-labelledby="__nav_3_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_3">
<span class="md-nav__icon md-icon"></span>
            
  
    Study
  

          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_3_2" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../">
<span class="md-ellipsis">
    
  
    Paper
  

    
  </span>
</a>
<label class="md-nav__link" for="__nav_3_2">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="true" aria-labelledby="__nav_3_2_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_3_2">
<span class="md-nav__icon md-icon"></span>
            
  
    Paper
  

          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../2017-08-04-E2EMN/">
<span class="md-ellipsis">
    
  
    End-to-End Memory Network
  

    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../2018-04-04-nsmcbidreclstmselfattn/">
<span class="md-ellipsis">
    
  
    A Structured Self-Attentive Sentence Embedding
  

    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../2019-08-22-neuralnetworklm/">
<span class="md-ellipsis">
    
  
    A Neural Probabilistic Language Model
  

    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../2019-09-18-introxai/">
<span class="md-ellipsis">
    
  
    Explaining Explanations: An Overview of Interpretability of Machine Learning
  

    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../2020-01-14-attentionisallyouneed/">
<span class="md-ellipsis">
    
  
    Attention Is All You Need
  

    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../2020-03-12-deepinsidecnn/">
<span class="md-ellipsis">
    
  
    Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps
  

    
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--active">
<input class="md-nav__toggle md-toggle" id="__toc" type="checkbox"/>
<a class="md-nav__link md-nav__link--active" href="./">
<span class="md-ellipsis">
    
  
    Mask-Predict: Parallel Decoding of Conditional Masked Language Models
  

    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../2020-07-23-casm/">
<span class="md-ellipsis">
    
  
    Classifier-agnostic saliency map extraction
  

    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../2020-12-31-xaitutorial/">
<span class="md-ellipsis">
    
  
    Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI
  

    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../2021-04-12-spider/">
<span class="md-ellipsis">
    
  
    Spider: A Large-Scale Human-Labeled Dataset for Complex and Cross-Domain Semantic Parsing and Text-to-SQL Task
  

    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../2021-04-20-featurevisualization/">
<span class="md-ellipsis">
    
  
    Feature Visualization
  

    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../2021-05-14-bridge/">
<span class="md-ellipsis">
    
  
    Bridging Textual and Tabular Data for Cross-Domain Text-to-SQL Semantic Parsing
  

    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../2021-08-13-hybridranking/">
<span class="md-ellipsis">
    
  
    Hybrid Ranking Network for Text-to-SQL
  

    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../2021-11-21-nbdt/">
<span class="md-ellipsis">
    
  
    NBDT: Neural-Backed Decision Trees
  

    
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../tutorial/">
<span class="md-ellipsis">
    
  
    Tutorial
  

    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../project/">
<span class="md-ellipsis">
    
  
    Project
  

    
  </span>
</a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
</nav>
</div>
</div>
</div>
<div class="md-content" data-md-component="content">
<nav aria-label="Navigation" class="md-path">
<ol class="md-path__list">
<li class="md-path__item">
<a class="md-path__link" href="../../..">
<span class="md-ellipsis">
    About
  </span>
</a>
</li>
<li class="md-path__item">
<a class="md-path__link" href="../../">
<span class="md-ellipsis">
    Study
  </span>
</a>
</li>
<li class="md-path__item">
<a class="md-path__link" href="../">
<span class="md-ellipsis">
    Paper
  </span>
</a>
</li>
</ol>
</nav>
<article class="md-content__inner md-typeset">
<nav class="md-tags" hidden="">
<span class="md-tag">NLP</span>
<span class="md-tag">Decoding</span>
<span class="md-tag">Masked Language Models</span>
</nav>
<h1 id="mask-predict-parallel-decoding-of-conditional-masked-language-models">Mask-Predict: Parallel Decoding of Conditional Masked Language Models<a class="headerlink" href="#mask-predict-parallel-decoding-of-conditional-masked-language-models" title="Permanent link">¶</a></h1>
<p>Paper Link: <a href="https://arxiv.org/abs/1904.09324">Mask-Predict: Parallel Decoding of Conditional Masked Language Models</a></p>
<p>모두의 연구소에서 진행하는 "beyondBERT" 프로그램에서 참여하다가 본 논문을 정리해보려고 한다. 흥미롭게 생각했던 논문이라 중요 부분만 일단 정리했다.</p>
<p>기존의 기계번역등 작업을 진행할때 Seq2Seq 모델(with Attention)을 사용할 경우 보통 autoregressive하게 토큰을 하나씩 디코딩했다. 예를 들어, "내가 아이언맨이다."라는 문장을 번역하려면, Encoder에 다음과 같이 <code>source</code> 토큰들을 넣어주고, Decoder는 문장의 시작을 알리는 <code>&lt;SOS&gt;</code> 토큰으로 시작하여 <code>"I"</code>를 예측하고, 예측한 <code>"I"</code>로 <code>"am"</code>을 예측하고, 마지막에 <code>"&lt;EOS&gt;"</code> 토큰이 등장하면 끝나는 구조다. sudo-code로 다음과 같이 작성 할 수 있겠다.</p>
<div class="highlight"><pre><span></span><code><a href="#__codelineno-0-1" id="__codelineno-0-1" name="__codelineno-0-1"></a><span class="n">source</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"나는"</span> <span class="s2">"아이언맨"</span> <span class="s2">"이다"</span><span class="p">,</span> <span class="s2">"."</span><span class="p">]</span>
<a href="#__codelineno-0-2" id="__codelineno-0-2" name="__codelineno-0-2"></a><span class="n">target</span> <span class="o">=</span> <span class="p">[</span><span class="s2">"&lt;SOS&gt;"</span><span class="p">,</span> <span class="s2">"I"</span><span class="p">,</span> <span class="s2">"am"</span><span class="p">,</span> <span class="s2">"IronMan"</span><span class="p">,</span> <span class="s2">"."</span><span class="p">,</span> <span class="s2">"&lt;EOS&gt;"</span><span class="p">]</span>
<a href="#__codelineno-0-3" id="__codelineno-0-3" name="__codelineno-0-3"></a>
<a href="#__codelineno-0-4" id="__codelineno-0-4" name="__codelineno-0-4"></a><span class="n">hiddens</span> <span class="o">=</span> <span class="n">Encoder</span><span class="p">(</span> <span class="n">source</span> <span class="p">)</span>
<a href="#__codelineno-0-5" id="__codelineno-0-5" name="__codelineno-0-5"></a><span class="n">token</span> <span class="o">=</span> <span class="n">to_tensor</span><span class="p">(</span> <span class="s2">"&lt;EOS&gt;"</span> <span class="p">)</span>
<a href="#__codelineno-0-6" id="__codelineno-0-6" name="__codelineno-0-6"></a>
<a href="#__codelineno-0-7" id="__codelineno-0-7" name="__codelineno-0-7"></a><span class="k">while</span> <span class="n">token</span> <span class="o">==</span> <span class="s2">"&lt;EOS&gt;"</span><span class="p">:</span>
<a href="#__codelineno-0-8" id="__codelineno-0-8" name="__codelineno-0-8"></a>    <span class="n">predict</span> <span class="o">=</span> <span class="n">Decoder</span><span class="p">(</span> <span class="n">token</span><span class="p">,</span> <span class="n">hiddens</span> <span class="p">)</span>
<a href="#__codelineno-0-9" id="__codelineno-0-9" name="__codelineno-0-9"></a>    <span class="n">token</span> <span class="o">=</span> <span class="n">to_token</span><span class="p">(</span> <span class="n">predict</span> <span class="p">)</span>
</code></pre></div>
<p>이 논문에서는 non-autoregressive하게 decoding하는 방법을 제시했는데, 구체적인 방법은 <code>그림1</code>을 보면 단번에 이해가 되리라고 믿는다. </p>
<blockquote>
<ul>
<li>일부 스터디에서 나온 의견 및 개인 의견이 섞여서 들어가 있음을 밝힌다.</li>
<li>Model Distillation 부분은 비교군이 적절하지 않다고 스터디에서 나온 의견이 있어서 다루지 않았다.</li>
</ul>
</blockquote>
<hr/>
<h1 id="1-introduction">1. Introduction<a class="headerlink" href="#1-introduction" title="Permanent link">¶</a></h1>
<p>생략</p>
<h1 id="2-cmlmconditional-masked-language-models">2. CMLM(Conditional Masked Language Models)<a class="headerlink" href="#2-cmlmconditional-masked-language-models" title="Permanent link">¶</a></h1>
<ul>
<li>CMLM은 입력 토큰 <span class="arithmatex">\(X\)</span>와 일부 타겟 토큰 <span class="arithmatex">\(Y_{obs}\)</span>가 주어지면 마스크가 된 타겟 토큰 <span class="arithmatex">\(Y_{mask}\)</span>를 맞추는 문제다.</li>
<li>
<p>강한 가정: 마스크된 타겟 토큰들 <span class="arithmatex">\(Y_{mask}\)</span>은 입력데이터에 대해서 조건부 독립이다.</p>
<div class="arithmatex">\[\text{Predict: } P(y \vert X, Y_{obs}) \ \forall y \in Y_{mask}\]</div>
<p>이를 분해해보면 다음과 같다.</p>
<div class="arithmatex">\[\begin{aligned} P(Y_{mask} \vert X, Y_{obs}) &amp;= P(Y_{mask}^{K};Y_{mask}^{1:(K-1)} \vert X, Y_{obs}) P(Y_{mask}^{1:(K-1)} \vert X, Y_{obs}) \\ &amp;= P(Y_{mask}^{K};Y_{mask}^{1:(K-1)} \vert X, Y_{obs}) \cdots P(Y_{mask}^{2};Y_{mask}^{1} \vert X, Y_{obs}) P(Y_{mask}^{1} \vert X, Y_{obs}) \end{aligned} \\ \text{if } Y_{mask} \text{ is conditionally independent by each other } \rightarrow \\ \begin{aligned} P(Y_{mask} \vert X, Y_{obs}) &amp;\approx P(Y_{mask}^{K} \vert X, Y_{obs}) P(Y_{mask}^{K-1} \vert X, Y_{obs}) \cdots P(Y_{mask}^{2} \vert X, Y_{obs}) P(Y_{mask}^{1} \vert X, Y_{obs}) \end{aligned}\]</div>
<p>(beyondBERT 에서 나온 리뷰: 이러한 최종 예측파트에서는 가정이 맞지만, 훈련시킬때는 아닐 것이다)</p>
</li>
<li>
<p>추가로 마스크 개수는 정해져 있기 때문에 토큰 길이에 대한 제약도 명시적으로 달려있는 셈이다.</p>
</li>
</ul>
<h2 id="21-architecture">2.1 Architecture<a class="headerlink" href="#21-architecture" title="Permanent link">¶</a></h2>
<ul>
<li>클래식한 Transformer에 Decoder만 Masked-self attention을 제거하기로함</li>
<li>fair-style Transformer</li>
</ul>
<h2 id="22-training-objective">2.2 Training Objective<a class="headerlink" href="#22-training-objective" title="Permanent link">¶</a></h2>
<ul>
<li><span class="arithmatex">\(1\)</span>~<span class="arithmatex">\(N\)</span>(토큰길이) 만큼의 uniform distribution에서 랜덤하게 숫자를 고른다음에 그 개수만큼 <span class="arithmatex">\(Y_{mask}\)</span>를 선택</li>
<li>Cross-entropy Loss로 최적화, parallel하게 할 수 있는 이유는 이전의 <span class="arithmatex">\(Y_{mask}\)</span>에 취한 conditionally independent 가정 때문이다.</li>
</ul>
<h2 id="23-predicting-target-sequence-length">2.3 Predicting Target Sequence Length<a class="headerlink" href="#23-predicting-target-sequence-length" title="Permanent link">¶</a></h2>
<ul>
<li>전통적인 left-to-right 기계번역의 경우, 이전 예측 토큰이 다음 예측 토큰으로 들어가게 된다. 그리고 최종적으로 <code>EOS</code>이 나오면 종료가 되는 형태라서 자동적으로 문장의 길이를 알 수 있었지만 , CMLMs에서는 전체 시퀀스를 parallel하게 예측하기 때문에 타겟 문장 전체의 길이를 예측해야한다.</li>
<li>논문에서는 BERT 의 <code>CLS</code> 토큰처럼, <code>LENGTH</code> 토큰을 Encoder에 집어넣기로 한다. 해당 토큰의 loss도 마지막에 추가한다.</li>
</ul>
<hr/>
<h1 id="3-decoding-with-mask-predict">3. Decoding with Mask-Predict<a class="headerlink" href="#3-decoding-with-mask-predict" title="Permanent link">¶</a></h1>
<ul>
<li>요약하면 각 iteration마다 알고리즘은 토큰의 부분집합을 선택하여 masking하고, CMLM으로 예측한다.</li>
</ul>
<h2 id="31-formal-description">3.1 Formal Description<a class="headerlink" href="#31-formal-description" title="Permanent link">¶</a></h2>
<ul>
<li>타겟 시퀀스 <span class="arithmatex">\((y_1, \cdots, y_N)\)</span> 와 각 토큰의 확률 <span class="arithmatex">\((p_1, \cdots, p_N)\)</span>이라는 두 변수가 있고, 미러 정의된 <span class="arithmatex">\(T\)</span>번 동안 알고리즘을 돌린다(이는 상수거나 <span class="arithmatex">\(N\)</span>에 관련된 간단한 함수로 결정된다).</li>
<li>각 iteration마다 <code>mask</code> 작업을 수행하고, 예측(<code>predict</code>)한다.</li>
</ul>
<h3 id="mask"><strong>Mask</strong><a class="headerlink" href="#mask" title="Permanent link">¶</a></h3>
<ul>
<li>
<p>첫 iteration에는 모든 토큰을 마스킹한다. 그 이후부터는 가장 낮은 확률을 가진 <span class="arithmatex">\(n\)</span>개의 토큰을 masking한다.</p>
<div class="arithmatex">\[\begin{aligned} Y_{mask}^{(t)} &amp;= \arg \underset{i}{\min} (p_i, n) \\ Y_{obs}^{(t)} &amp;= Y \setminus Y_{mask}^{(t)}\end{aligned}\]</div>
</li>
<li>
<p><span class="arithmatex">\(n\)</span>은 <span class="arithmatex">\(t\)</span>의 함수이며 논문에서는 <span class="arithmatex">\(n=N \cdot \dfrac{T-t}{T}\)</span>를 사용했다(<span class="arithmatex">\(T\)</span>는 iteration 횟수).</p>
</li>
</ul>
<h3 id="predict"><strong>Predict</strong><a class="headerlink" href="#predict" title="Permanent link">¶</a></h3>
<ul>
<li>
<p>Masking후, CMLM은 주어진 입력<span class="arithmatex">\(X\)</span>와 masking 안된 <span class="arithmatex">\(Y_{obs}^{(t)}\)</span>를 기반으로 <span class="arithmatex">\(Y_{mask}^{(t)}\)</span>를 예측하는데, 각 마스킹된 토큰 <span class="arithmatex">\(y_i \in Y_{mask}^{(t)}\)</span>에 대해서 확률이 가장 높은 것을 예측값으로 선택한다.</p>
<div class="arithmatex">\[\begin{aligned} y_i^{(t)} &amp;= \arg \underset{w}{\max} P(y_i = w \vert X, Y_{obs}^{(t)} ) \\ p_i^{(t)} &amp;= \underset{w}{\max} P(y_i = w \vert X, Y_{obs}^{(t)} ) \end{aligned}\]</div>
</li>
<li>
<p>마스크가 안된 token들은 이전 스텝의 값을 그대로 따라간다.</p>
<div class="arithmatex">\[\begin{aligned} y_i^{(t)} &amp;=y_i^{(t-1)} \\ p_i^{(t)} &amp;= p_i^{(t-1)} \end{aligned}\]</div>
</li>
<li>
<p>특정 토큰의 확률이 계속 희박하여 이러한 휴리스틱한 작업에도 불구하고 잘 작동했다.</p>
</li>
</ul>
<h2 id="32-example">3.2 Example<a class="headerlink" href="#32-example" title="Permanent link">¶</a></h2>
<ul>
<li>그림으로 보면 조금더 이해가 쉬운데, 차후 3.3에서 이야기하는 Length predict 이후의 예시를 들은 것이다.</li>
<li>그림에서 나오는 용어들이 있다.<ul>
<li>각 <span class="arithmatex">\(t\)</span> 스텝 마다 <code>Mask &gt; Predict</code> 의 과정을 반복한다.</li>
<li><span class="arithmatex">\(t\)</span>: 현재 스텝</li>
<li><span class="arithmatex">\(n\)</span>: masking 해야할 토큰의 수</li>
<li><span class="arithmatex">\(probability\)</span>(보라색): 각 예측의 확률을 담는 container</li>
</ul>
</li>
</ul>
<p>{% include image.html id="12HUzuQzCWwkaO4B6H07EOkEIJlKpjMnv" desc="[그림1] Example of parallel decoding" width="100%" height="auto" %}</p>
<p><strong>장점</strong> </p>
<ul>
<li>마스킹되지 않았던 것들도 차후에 확률이 다른 토큰에 비해 상대적으로 낮아지면 다시 마스킹될 수도 있다. 즉, 초기에 잘못 예측했더라도, iteration을 통해 점차 바른 예측으로 고쳐질 수도 있다는 것</li>
</ul>
<p><strong>문제점: Multi-modality Problem</strong></p>
<p>{% include image.html id="1VSrcpclqKZ5KxqJF7yKAw-AP8u-hIuFQ" desc="[그림2] Paper Figure 1" width="100%" height="auto" %}</p>
<ul>
<li>논문의 Figure 1 처럼, t=0 인 상황에서 중복된 단어가 생성 될 수가 있음("completed") 이는 non-autoregressive 모델에서 자주 등장하는 문제다. 이는 <code>5.1</code>에서 자세히 다룬다.</li>
</ul>
<h2 id="33-deciding-target-sequence-length">3.3 Deciding Target Sequence Length<a class="headerlink" href="#33-deciding-target-sequence-length" title="Permanent link">¶</a></h2>
<ul>
<li>타켓 문장의 길이인 <code>LENGTH</code> 토큰을 예측하기 때문에 배치 연산을 할 수 있다.</li>
<li>확률이 가장 높은 길이를 여러개 뽑아서 배치 연산으로 3.2의 과정을 할 수 있다.</li>
</ul>
<p>{% include image.html id="1WPZ4xsitujEWF9yfeacc6V587DmjGZ2x" desc="[그림3] Length Predict" width="100%" height="auto" %}</p>
<ul>
<li>차후에 제일 높은 평균 로그 확률로 길이를 선택하게 된다(beam search 와 연관)</li>
</ul>
<div class="arithmatex">\[\dfrac{1}{N} \sum_i \log p_i^{(T)}\]</div>
<hr/>
<h1 id="experiments">Experiments<a class="headerlink" href="#experiments" title="Permanent link">¶</a></h1>
<h2 id="41-experimental-setup">4.1 Experimental Setup<a class="headerlink" href="#41-experimental-setup" title="Permanent link">¶</a></h2>
<h3 id="translation-benchmarks">Translation Benchmarks<a class="headerlink" href="#translation-benchmarks" title="Permanent link">¶</a></h3>
<ul>
<li>총 3개의 데이터 세트를 사용: WMT'14 EN-DE (4.5M sentence pairs), WMT'16 EN-RO (610k pairs), WMT'17 EN-ZH (20M pairs)</li>
<li>모든 데이터는 BPE로 인코딩했으며, 퍼포먼스는 BELU score를 계산했다.</li>
<li>EN-ZH 만 ScareBLEU를 사용했다.</li>
</ul>
<h3 id="hyperparameters">Hyperparameters<a class="headerlink" href="#hyperparameters" title="Permanent link">¶</a></h3>
<ul>
<li>Attention is All you Need 논문과 똑같이 각 stack마다 6개의 layer, 각 layer마다 8개의 attention heads, 모델 <span class="arithmatex">\(h_{model}, h_{ffn}\)</span> hidden size는 각 512, 2048로 진행했다.</li>
<li>가중치 초기화는 BERT 논문에서 진행한 <span class="arithmatex">\(\mathcal{N}(0, 0.02)\)</span>, bias는 0으로 초기화 했다.</li>
<li>LayerNorm은 <span class="arithmatex">\(\beta=0, \gamma=1\)</span></li>
<li>Regularization은 <span class="arithmatex">\(\text{dropout}=0.3, \text{weight decay}=0.01\)</span> 로 실험했다.</li>
<li>Smoothed CV Loss <span class="arithmatex">\(\varepsilon=0.1\)</span> </li>
<li>훈련은 Adam에 <span class="arithmatex">\(\beta=(0.9, 0.999), \varepsilon=10^{-6}\)</span>으로 진행, warm up 은 <span class="arithmatex">\(10000\)</span> 스텝에 <span class="arithmatex">\(5\cdot 10^{-4}\)</span>까지 피크로 가다가 역제곱근의 형태로 내려간다.</li>
<li>훈련 스텝은 300k 각 epoch 마다 validation 진행하고, 가장 좋은 5개의 checkpoint를 평균내서 최종모델을 만든다.</li>
<li>Decoding을 비교하기 위해서 autoregressive 모델에서 beam search(<span class="arithmatex">\(b=5\)</span>), 논문의 모델은 <span class="arithmatex">\(l=5\)</span>개의 후보를 사용해서 decoding했다.</li>
</ul>
<h2 id="42-translation-quality">4.2 Translation Quality<a class="headerlink" href="#42-translation-quality" title="Permanent link">¶</a></h2>
<p>{% include image.html id="1sdffQlPXdG9Fgs_O_xgE1xfn-kxIPKmL" desc="[그림4] Paper Table 1 &amp; 2" width="100%" height="auto" %}</p>
<ul>
<li>같은 non-autoregressive 방법들 중에서 논문의 모델이 가장 높은 BLEU score를 달성했다고 주장하고 있다.</li>
<li>다른 non-autoregressive 방법들을 확인 해봐야 더 자세히 알것 같다.<ul>
<li>NAT w/ Fertility (<a href="https://arxiv.org/abs/1802.06901">Gu et al., 2018</a>)</li>
<li>CTC Loss (<a href="https://arxiv.org/abs/1811.04719">Libovicky et al., 2018</a>)</li>
<li>Iterative Refinement(<a href="https://www.aclweb.org/anthology/D18-1149/">Lee et al., 2018</a>)</li>
</ul>
</li>
</ul>
<h2 id="43-decoding-speed">4.3 Decoding Speed<a class="headerlink" href="#43-decoding-speed" title="Permanent link">¶</a></h2>
<p>{% include image.html id="1pqAa4SEq-SNleVeUp0IUkcTrzQFqpjLr" desc="[그림5] Paper Figure 2" width="100%" height="auto" %}</p>
<ul>
<li>파란점은 논문저자들의 실험 결과며, <code>L2R b=1</code>는 beam search(b=1)를 사용한 Left-to-Right(autoregressive) 모델이다.</li>
<li>Decoding 스피드와 퍼포먼스간의 trade-off 를 이야기하면, <span class="arithmatex">\(T=4, l=2\)</span>인 경우 2 point의 퍼포먼스를 대가로 <code>L2R b=5</code>모델 보다 3배의 스피드를 끌어 올릴 수 있다고 주장한다.</li>
<li>beyondBERT에서 나온 리뷰중에 하나가 2 point BELU score 면 엄청나게 큰 점수라고 한다(quality 가 상당히 떨어질 수도?!).</li>
</ul>
<hr/>
<h1 id="5-analysis">5. Analysis<a class="headerlink" href="#5-analysis" title="Permanent link">¶</a></h1>
<h2 id="51-why-are-multiple-iterataions-necessary">5.1 Why Are Multiple Iterataions Necessary?<a class="headerlink" href="#51-why-are-multiple-iterataions-necessary" title="Permanent link">¶</a></h2>
<ul>
<li>Various non-autoregressive 모델에서는 각 예측 토큰들이 서로 조건부 독립이라는 큰 가정이 들어간다. 때문에 예측할때 서로 다른 토큰에 영향을 받지 않아서 다른 위치라도 높은 확률로 같은 토큰을 반복적으로 예측하는 문제가 생긴다.</li>
<li>이러한 문제를 Multi-modality 문제라고 <a href="https://arxiv.org/abs/1711.02281">Gu et al., 2018</a>의 논문에서 이야기 한적이 있다.</li>
<li>저자들은 예측한 토큰을 모델의 입력으로 사용하여, 반복적인 masking-predict 수행을 통해(multi-modal distribution을 uni-modal distribution으로 전환) 이 문제를 완화시키려고 했다.</li>
</ul>
<p>{% include image.html id="1G5DV3t-J1dp6-nOdx9Nh1Vwo-XXy6xpx" desc="[그림6] Paper Table 3" width="75%" height="auto" %}</p>
<ul>
<li>가설을 검증하기 위해서, Proxy Metric으로 중복 된 예측 토큰의 개수가 몇 퍼센트를 차지하는지 살펴보았다. 확실히 <span class="arithmatex">\(T\)</span>가 높아질 수록 해당 비율은 현저하게 줄어든다.</li>
<li><span class="arithmatex">\(T\)</span>가 작을 수록(중복된 토큰 예측이 많아질 수록) BLEU score가 현저하게 낮아지는 것도 이해가 된다.</li>
</ul>
<h2 id="52-do-longer-sequence-need-more-iterations">5.2 Do Longer Sequence Need More Iterations?<a class="headerlink" href="#52-do-longer-sequence-need-more-iterations" title="Permanent link">¶</a></h2>
<p>{% include image.html id="1qf97x-hNgWXtl8NbHJ-z7iUG0KZ-uNg2" desc="[그림7] Paper Table 4" width="75%" height="auto" %}</p>
<ul>
<li>긴 문장일 수록 더 많은 iteration이 도움이 되긴했다. 그러나 <span class="arithmatex">\(T\)</span>가 많아질 수록 연산비용이 많아지는 것을 고려해야 할 것이다.</li>
</ul>
<h2 id="53-do-more-length-candidates-help">5.3 Do More Length Candidates Help?<a class="headerlink" href="#53-do-more-length-candidates-help" title="Permanent link">¶</a></h2>
<p>{% include image.html id="127K3YP4LlTrPHEiu9XO5v7U_rlrByMlA" desc="[그림8] Paper Table 5" width="75%" height="auto" %}</p>
<ul>
<li>적당한 길이 후보(<span class="arithmatex">\(\mathcal{l}\)</span>)는 번역에 도움이 되지만 너무 많은 후보를 두면 도움이 안된다.</li>
<li>상식적으로 후보들이 비슷한 길이를 가진다면 예측에 도움이 되겠지만, 많은 후보들 중에 비슷하지 않은 길이들이 있다면, 번역의 품질이 떨어질 수밖에 없을 것 같다.</li>
</ul>
<hr/>
<h1 id="_1">개인적 리뷰 및 결론<a class="headerlink" href="#_1" title="Permanent link">¶</a></h1>
<ul>
<li>non-autoregressive 모델의 decoding은 실무에서 빠르게 decoding 할 수있기 때문에 앞으로 연구할 가치가 있는 분야인것 같다.</li>
<li>이런 분야도 있다는 것을 처음 접해서 신선한 decoding 방법이라고 생각했다. 다른 decoding 방법들(<a href="https://www.facebook.com/groups/ChatbotDevKR/permalink/1000241780393951/">챗봇 코리아 게시물</a>)도 참고하면 좋을 것 같다.</li>
<li>그러나 해결되지 않은 몇 가지 문제(multi-modality)를 해결할 필요가 있어 보인다.</li>
</ul>
<!-- Giscus -->
<h2 id="__comments">Comments</h2>
<script async="" crossorigin="anonymous" data-category="General" data-category-id="DIC_kwDOHRhxjc4CQSuI" data-emit-metadata="0" data-input-position="top" data-lang="ko" data-mapping="pathname" data-reactions-enabled="1" data-repo="simonjisu/comments_bot" data-repo-id="R_kgDOHRhxjQ" data-theme="light" src="https://giscus.app/client.js">
</script>
<!-- Synchronize Giscus theme with palette -->
<script>
    var giscus = document.querySelector("script[src*=giscus]")

    /* Set palette on initial load */
    var palette = __md_get("__palette")
    if (palette && typeof palette.color === "object") {
      var theme = palette.color.scheme === "slate" ? "dark" : "light"
      giscus.setAttribute("data-theme", theme) 
    }

    /* Register event handlers after documented loaded */
    document.addEventListener("DOMContentLoaded", function() {
      var ref = document.querySelector("[data-md-component=palette]")
      ref.addEventListener("change", function() {
        var palette = __md_get("__palette")
        if (palette && typeof palette.color === "object") {
          var theme = palette.color.scheme === "slate" ? "dark" : "light"

          /* Instruct Giscus to change theme */
          var frame = document.querySelector(".giscus-frame")
          frame.contentWindow.postMessage(
            { giscus: { setConfig: { theme } } },
            "https://giscus.app"
          )
        }
      })
    })
  </script>
</article>
</div>
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
</div>
<button class="md-top md-icon" data-md-component="top" hidden="" type="button">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"></path></svg>
            Back to top
          </button>
</main>
<footer class="md-footer">
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank">
      Material for MkDocs Insiders
    </a>
</div>
<div class="md-social">
<a class="md-social__link" href="https://github.com/simonjisu" rel="noopener" target="_blank" title="github.com">
<svg viewbox="0 0 496 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg>
</a>
</div>
</div>
</div>
</footer>
</div>
<div class="md-dialog" data-md-component="dialog">
<div class="md-dialog__inner md-typeset"></div>
</div>
<script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.tabs", "navigation.tabs.sticky", "navigation.indexes", "navigation.top", "toc.follow", "navigation.prune", "navigation.path", "content.tooltips", "content.code.annotate"], "search": "../../../assets/javascripts/workers/search.6c7302c4.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
<script src="../../../assets/javascripts/bundle.803ed251.min.js"></script>
<script src="../../../javascripts/mathjax.js"></script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script>document$.subscribe(() => {const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": false, "draggable": false, "openEffect": "none", "closeEffect": "none", "slideEffect": "slide"});})</script></body>
</html>