
<!DOCTYPE html>

<html class="no-js" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<link href="https://simonjisu.github.io/study/tutorial/reinforcement_learning/chapter8/" rel="canonical"/>
<link href="../chapter7/" rel="prev"/>
<link href="../../../../project/" rel="next"/>
<link href="../../../../assets/images/favicon.png" rel="icon"/>
<meta content="mkdocs-1.5.3, mkdocs-material-9.4.2+insiders-4.42.0" name="generator"/>
<title>8. Planning and Learning with Tabular Methods - Soopace</title>
<link href="../../../../assets/stylesheets/main.f2778614.min.css" rel="stylesheet"/>
<link href="../../../../assets/stylesheets/palette.46987102.min.css" rel="stylesheet"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/>
<style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
<script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
<script id="__analytics">function __md_analytics(){function n(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],n("js",new Date),n("config","G-2D0S4P2SJ9"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&n("event","search",{search_term:this.value})}),document$.subscribe(function(){var a=document.forms.feedback;if(void 0!==a)for(var e of a.querySelectorAll("[type=submit]"))e.addEventListener("click",function(e){e.preventDefault();var t=document.location.pathname,e=this.getAttribute("data-md-value");n("event","feedback",{page:t,data:e}),a.firstElementChild.disabled=!0;e=a.querySelector(".md-feedback__note [data-md-value='"+e+"']");e&&(e.hidden=!1)}),a.hidden=!1}),location$.subscribe(function(e){n("config","G-2D0S4P2SJ9",{page_path:e.pathname})})});var e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=G-2D0S4P2SJ9",document.getElementById("__analytics").insertAdjacentElement("afterEnd",e)}</script>
<script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
<link href="../../../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
            html.glightbox-open { overflow: initial; height: 100%; }
            .gslide-title { margin-top: 0px; user-select: text; }
            .gslide-desc { color: #666; user-select: text; }
            .gslide-image img { background: white; }
            
                .gscrollbar-fixer { padding-right: 15px; }
                .gdesc-inner { font-size: 0.75rem; }
                body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
                body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
                body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}
                </style><script src="../../../../assets/javascripts/glightbox.min.js"></script></head>
<body data-md-color-accent="indigo" data-md-color-primary="black" data-md-color-scheme="default" dir="ltr">
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" for="__drawer"></label>
<div data-md-component="skip">
<a class="md-skip" href="#planning">
          Skip to content
        </a>
</div>
<div data-md-component="announce">
</div>
<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
<nav aria-label="Header" class="md-header__inner md-grid">
<a aria-label="Soopace" class="md-header__button md-logo" data-md-component="logo" href="../../../.." title="Soopace">
<img alt="logo" src="../../../../img/logo/logo.png"/>
</a>
<label class="md-header__button md-icon" for="__drawer">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"></path></svg>
</label>
<div class="md-header__title" data-md-component="header-title">
<div class="md-header__ellipsis">
<div class="md-header__topic">
<span class="md-ellipsis">
            Soopace
          </span>
</div>
<div class="md-header__topic" data-md-component="header-topic">
<span class="md-ellipsis">
            
              8. Planning and Learning with Tabular Methods
            
          </span>
</div>
</div>
</div>
<label class="md-header__button md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"></path></svg>
</label>
<div class="md-search" data-md-component="search" role="dialog">
<label class="md-search__overlay" for="__search"></label>
<div class="md-search__inner" role="search">
<form class="md-search__form" name="search">
<input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="search-query" name="query" placeholder="Search" required="" spellcheck="false" type="text"/>
<label class="md-search__icon md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"></path></svg>
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"></path></svg>
</label>
<nav aria-label="Search" class="md-search__options">
<button aria-label="Clear" class="md-search__icon md-icon" tabindex="-1" title="Clear" type="reset">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"></path></svg>
</button>
</nav>
</form>
<div class="md-search__output">
<div class="md-search__scrollwrap" data-md-scrollfix="">
<div class="md-search-result" data-md-component="search-result">
<div class="md-search-result__meta">
            Initializing search
          </div>
<ol class="md-search-result__list" role="presentation"></ol>
</div>
</div>
</div>
</div>
</div>
<div class="md-header__source">
<a class="md-source" data-md-component="source" href="https://github.com/simonjisu.github.io" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"></path></svg>
</div>
<div class="md-source__repository">
    GitHub
  </div>
</a>
</div>
</nav>
<nav aria-label="Tabs" class="md-tabs" data-md-component="tabs">
<div class="md-grid">
<ul class="md-tabs__list">
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../..">
        
  
    
  
  About

      </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../blog/">
          
  
    
  
  Blog

        </a>
</li>
<li class="md-tabs__item md-tabs__item--active">
<a class="md-tabs__link" href="../../../">
          
  
    
  
  Study

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../../project/">
          
  
    
  
  Project

        </a>
</li>
</ul>
</div>
</nav>
</header>
<div class="md-container" data-md-component="container">
<main class="md-main" data-md-component="main">
<div class="md-main__inner md-grid">
<div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Navigation" class="md-nav md-nav--primary md-nav--lifted" data-md-level="0">
<label class="md-nav__title" for="__drawer">
<a aria-label="Soopace" class="md-nav__button md-logo" data-md-component="logo" href="../../../.." title="Soopace">
<img alt="logo" src="../../../../img/logo/logo.png"/>
</a>
    Soopace
  </label>
<div class="md-nav__source">
<a class="md-source" data-md-component="source" href="https://github.com/simonjisu.github.io" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"></path></svg>
</div>
<div class="md-source__repository">
    GitHub
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../..">
<span class="md-ellipsis">
    
  
    About
  

    
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_2" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../../../../blog/">
<span class="md-ellipsis">
    
  
    Blog
  

    
  </span>
</a>
<label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="false" aria-labelledby="__nav_2_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_2">
<span class="md-nav__icon md-icon"></span>
            
  
    Blog
  

          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../blog/archive/2020/">
<span class="md-ellipsis">
    
  
    Archive
  

    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../../blog/category/lifelog/">
<span class="md-ellipsis">
    
  
    Categories
  

    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_3" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../../../">
<span class="md-ellipsis">
    
  
    Study
  

    
  </span>
</a>
<label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="true" aria-labelledby="__nav_3_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_3">
<span class="md-nav__icon md-icon"></span>
            
  
    Study
  

          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../paper/">
<span class="md-ellipsis">
    
  
    Paper
  

    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_3_3" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../../">
<span class="md-ellipsis">
    
  
    Tutorial
  

    
  </span>
</a>
<label class="md-nav__link" for="__nav_3_3" id="__nav_3_3_label" tabindex="0">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="true" aria-labelledby="__nav_3_3_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_3_3">
<span class="md-nav__icon md-icon"></span>
            
  
    Tutorial
  

          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../algorithm/">
<span class="md-ellipsis">
    
  
    Algorithm
  

    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../deeplearning/">
<span class="md-ellipsis">
    
  
    Deeplearning
  

    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../gcp/">
<span class="md-ellipsis">
    
  
    Gcp
  

    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../math/">
<span class="md-ellipsis">
    
  
    Math
  

    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../mongodb/">
<span class="md-ellipsis">
    
  
    Mongodb
  

    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_3_3_7" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../">
<span class="md-ellipsis">
    
  
    Reinforcement learning
  

    
  </span>
</a>
<label class="md-nav__link" for="__nav_3_3_7" id="__nav_3_3_7_label" tabindex="0">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="true" aria-labelledby="__nav_3_3_7_label" class="md-nav" data-md-level="3">
<label class="md-nav__title" for="__nav_3_3_7">
<span class="md-nav__icon md-icon"></span>
            
  
    Reinforcement learning
  

          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../CS285_L19/">
<span class="md-ellipsis">
    
  
    CS 285: Lecture 19, Control as Inference
  

    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../CS285_L20/">
<span class="md-ellipsis">
    
  
    CS 285: Lecture 20, Inverse Reinforcement Learning
  

    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../chapter1/">
<span class="md-ellipsis">
    
  
    1. Introduction
  

    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../chapter2/">
<span class="md-ellipsis">
    
  
    2. Multi-armed Bandits
  

    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../chapter3/">
<span class="md-ellipsis">
    
  
    3. Finite Markov Decision Processes
  

    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../chapter4/">
<span class="md-ellipsis">
    
  
    4. Dynamic Programming
  

    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../chapter5/">
<span class="md-ellipsis">
    
  
    5. Monte Carlo Method
  

    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../chapter6/">
<span class="md-ellipsis">
    
  
    6. Temporal-Difference Learning
  

    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../chapter7/">
<span class="md-ellipsis">
    
  
    7. n-step Bootstrapping
  

    
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--active">
<input class="md-nav__toggle md-toggle" id="__toc" type="checkbox"/>
<label class="md-nav__link md-nav__link--active" for="__toc">
<span class="md-ellipsis">
    
  
    8. Planning and Learning with Tabular Methods
  

    
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<a class="md-nav__link md-nav__link--active" href="./">
<span class="md-ellipsis">
    
  
    8. Planning and Learning with Tabular Methods
  

    
  </span>
</a>
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#planning">
<span class="md-ellipsis">
      
        Planning
      
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#planning-learning">
<span class="md-ellipsis">
      
        Planning &amp; Learning
      
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#dyna-q-integrated-planning-and-learning">
<span class="md-ellipsis">
      
        Dyna-Q: Integrated Planning and Learning
      
    </span>
</a>
<nav aria-label="Dyna-Q: Integrated Planning and Learning" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#when-the-model-is-wrong">
<span class="md-ellipsis">
      
        When the Model is Wrong
      
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#dyna-q">
<span class="md-ellipsis">
      
        Dyna-Q+
      
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#prioritized-sweeping">
<span class="md-ellipsis">
      
        Prioritized Sweeping
      
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#trajectory-sampling">
<span class="md-ellipsis">
      
        Trajectory Sampling
      
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#real-time-dynamic-programming-rtdp">
<span class="md-ellipsis">
      
        Real-time Dynamic Programming (RTDP)
      
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#planning-at-decision-time">
<span class="md-ellipsis">
      
        Planning at Decision Time
      
    </span>
</a>
<nav aria-label="Planning at Decision Time" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#heuristic-search">
<span class="md-ellipsis">
      
        Heuristic Search
      
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#rollout-algorithms">
<span class="md-ellipsis">
      
        Rollout Algorithms
      
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#monte-carlo-tree-search-mcts">
<span class="md-ellipsis">
      
        Monte Carlo Tree Search (MCTS)
      
    </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--section md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_4" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../../../../project/">
<span class="md-ellipsis">
    
  
    Project
  

    
  </span>
</a>
</div>
<nav aria-expanded="false" aria-labelledby="__nav_4_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_4">
<span class="md-nav__icon md-icon"></span>
            
  
    Project
  

          </label>
<ul class="md-nav__list" data-md-scrollfix="">
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-component="toc" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#planning">
<span class="md-ellipsis">
      
        Planning
      
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#planning-learning">
<span class="md-ellipsis">
      
        Planning &amp; Learning
      
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#dyna-q-integrated-planning-and-learning">
<span class="md-ellipsis">
      
        Dyna-Q: Integrated Planning and Learning
      
    </span>
</a>
<nav aria-label="Dyna-Q: Integrated Planning and Learning" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#when-the-model-is-wrong">
<span class="md-ellipsis">
      
        When the Model is Wrong
      
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#dyna-q">
<span class="md-ellipsis">
      
        Dyna-Q+
      
    </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#prioritized-sweeping">
<span class="md-ellipsis">
      
        Prioritized Sweeping
      
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#trajectory-sampling">
<span class="md-ellipsis">
      
        Trajectory Sampling
      
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#real-time-dynamic-programming-rtdp">
<span class="md-ellipsis">
      
        Real-time Dynamic Programming (RTDP)
      
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#planning-at-decision-time">
<span class="md-ellipsis">
      
        Planning at Decision Time
      
    </span>
</a>
<nav aria-label="Planning at Decision Time" class="md-nav">
<ul class="md-nav__list">
<li class="md-nav__item">
<a class="md-nav__link" href="#heuristic-search">
<span class="md-ellipsis">
      
        Heuristic Search
      
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#rollout-algorithms">
<span class="md-ellipsis">
      
        Rollout Algorithms
      
    </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#monte-carlo-tree-search-mcts">
<span class="md-ellipsis">
      
        Monte Carlo Tree Search (MCTS)
      
    </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content" data-md-component="content">
<nav aria-label="Navigation" class="md-path">
<ol class="md-path__list">
<li class="md-path__item">
<a class="md-path__link" href="../../../..">
<span class="md-ellipsis">
    About
  </span>
</a>
</li>
<li class="md-path__item">
<a class="md-path__link" href="../../../">
<span class="md-ellipsis">
    Study
  </span>
</a>
</li>
<li class="md-path__item">
<a class="md-path__link" href="../../">
<span class="md-ellipsis">
    Tutorial
  </span>
</a>
</li>
<li class="md-path__item">
<a class="md-path__link" href="../">
<span class="md-ellipsis">
    Reinforcement learning
  </span>
</a>
</li>
</ol>
</nav>
<article class="md-content__inner md-typeset">
<nav class="md-tags" hidden="">
<span class="md-tag">reinforcement learning</span>
<span class="md-tag">planning</span>
</nav>
<h1>8. Planning and Learning with Tabular Methods</h1>
<blockquote>
<p>데이터사이언스 대학원 강화학습 수업을 듣고 정리한 내용입니다.</p>
</blockquote>
<p>지금까지는 model-based와 model-free 방법들을 다루어 보았다. </p>
<ul>
<li>Model-based (e.g., Dynamic Programming)은 planning에 초점이 맞춰져있다.</li>
<li>Model-free (e.g., Monte Carlo, Temporal Difference)은 learning에 초점이 맞춰져있다.</li>
</ul>
<h2 id="planning">Planning<a class="headerlink" href="#planning" title="Permanent link">¶</a></h2>
<p><strong>planning</strong>은 model을 입력으로하고 policy를 출력으로하는 어떤 계산 프로세스로 정의된다. </p>
<div class="arithmatex">\[\text{model} \xrightarrow[]{\text{planning}} \text{policy}\]</div>
<ul>
<li>State-space planning: state space에서 optimal policy를 찾는 과정. Actions는 state과 state 사이의 transition을 야기하며, value function는 state로 계산된다.</li>
<li>Plan-space planning: plan space를 찾는 과정. 하나의 plan에서 다른 plan으로 변경하는 연산(operators)을 찾는 것이다.</li>
</ul>
<p>우선 같은 structure을 공유하는 state-space planning만 알아본다. Policy를 개선하기 위해서 value function을 계산하고, simulated experiences가 value function을 계산하는데 근거가 되어준다.</p>
<div class="arithmatex">\[\text{model} \xrightarrow[]{} \text{simulated experience} \xrightarrow[]{\text{backups}} \text{values} \xrightarrow[]{} \text{policy}\]</div>
<h2 id="planning-learning">Planning &amp; Learning<a class="headerlink" href="#planning-learning" title="Permanent link">¶</a></h2>
<p>Planning과 Learning의 차이점은 학습에 사용되는 경험 종류다. Planning은 model에서 생성된 simulated experience를 사용하고, Learning은 환경에서 생성된 real experience를 사용한다. 보통 두 방법을 결합해서 사용하는데 대표적인 예로 "the planning method based on Q-learning"이 있다.</p>
<div class="admonition info">
<p class="admonition-title">random-sample one-step tabular Q-planning</p>
<div class="tabbed-set tabbed-alternate" data-tabs="1:1"><input checked="checked" id="__tabbed_1_1" name="__tabbed_1" type="radio"><div class="tabbed-labels"><label for="__tabbed_1_1">pseudo code</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p><img alt="HeadImg" class="skipglightbox" src="https://drive.google.com/uc?id=1B5ouTXjMSO0A2wJxkFeHP2UPL67MYe-E" width="100%"/></p>
<ul>
<li>2번에서 보통 real experience를 쓰지만, sample method가 사용되었다.</li>
</ul>
</div>
</div>
</input></div>
</div>
<h2 id="dyna-q-integrated-planning-and-learning">Dyna-Q: Integrated Planning and Learning<a class="headerlink" href="#dyna-q-integrated-planning-and-learning" title="Permanent link">¶</a></h2>
<table>
<thead>
<tr>
<th align="center">Dyna</th>
<th align="center">General Dyna</th>
</tr>
</thead>
<tbody>
<tr>
<td align="center"><img alt="HeadImg" class="skipglightbox" src="https://drive.google.com/uc?id=1BHRiar1J0oJMe0ZrHF9pKFO54I_7jPPp" width="100%"/></td>
<td align="center"><img alt="HeadImg" class="skipglightbox" src="https://drive.google.com/uc?id=1BMxCdEq2dTAnaD6dOgg1JwLWVJjSE0Qi" width="100%"/></td>
</tr>
</tbody>
</table>
<p><strong>Dyna-Q</strong>는 online planning agent의 주요 functions을 포함하는 간단한 아키텍쳐다. Online 상황에서 planning, acting, learning을 결합한 방법이다. </p>
<ul>
<li><strong>Model-Learning</strong>: real experience로 model을 학습하는 것으로, 환경을 조금 더 잘 정확하게 따라할 수 있도록 한다.</li>
<li><strong>Direct RL</strong>: 강화학습으로 value function과 policy 을 개선하는 과정.</li>
<li><strong>Indirect RL</strong>: model을 통해 value function과 policy를 개선하는 과정.</li>
<li><strong>Planning</strong>: model을 통해 simulated experience를 생성하고, 이를 통해 value function과 policy을 개선한다.</li>
<li><strong>Search Control</strong>: simulated experience를 생성하기 위해 starting state와 action을 선택해서 model에 입력하는 과정.</li>
</ul>
<div class="admonition info">
<p class="admonition-title">Tabular Dyna-Q</p>
<div class="tabbed-set tabbed-alternate" data-tabs="2:1"><input checked="checked" id="__tabbed_2_1" name="__tabbed_2" type="radio"><div class="tabbed-labels"><label for="__tabbed_2_1">pseudo code</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p><img alt="HeadImg" class="skipglightbox" src="https://drive.google.com/uc?id=1BOyzRDso-Lw8HrBjBIlxIhbH0YJL1Pb4" width="100%"/></p>
<ul>
<li>여기서 (e) 와 (f) 과정이 없으면 one-step tabular Q-learning과 동일하다.</li>
</ul>
</div>
</div>
</input></div>
</div>
<div class="admonition note">
<p class="admonition-title">Dyna Maze</p>
<p><img alt="HeadImg" class="skipglightbox" src="https://drive.google.com/uc?id=1BXGoERyTg6R1Q1YURb2rVxhCXFRIowd7" width="100%"/></p>
<p>미로 문제에서 Dyna-Q를 적용한 결과다. Dyna-Q는 planning을 통해 더 많은 경험을 얻어서 더 빠르게 optimal policy를 찾을 수 있다.</p>
<ul>
<li>모든 episode는 <span class="arithmatex">\(S\)</span>에서 시작한다. 미로의 밖같과 검은 장애물은 지나갈 수 없다.</li>
<li>Actions = 상, 하, 좌, 우</li>
<li>Reward = <span class="arithmatex">\(G\)</span>에 도착시 <span class="arithmatex">\(+1\)</span>, 나머지는 <span class="arithmatex">\(0\)</span>.</li>
</ul>
<p><img alt="HeadImg" class="skipglightbox" src="https://drive.google.com/uc?id=1BXQ7GQ__7ov2V_7RAP48kf6RRMRUOCfc" width="100%"/></p>
<p>위 그림은 두번째 episode에서 Planning 유무에 다른 policy 차이를 보여준다. Planning의 유무에 따라서 optimal policy를 찾는 속도가 달라진다.</p>
</div>
<h3 id="when-the-model-is-wrong">When the Model is Wrong<a class="headerlink" href="#when-the-model-is-wrong" title="Permanent link">¶</a></h3>
<p>Model이 항상 옳은 것은 아니다. 예를 들어, (1) 환경이 stochastic하고, 경험의 갯수가 충분치 않을 때, (2) 일반화가 잘 되지 않을 때, (3) 환경이 변했는데 model이 관찰하지 못하는 경우 등이 있다. 다음 예제를 한 번 보자. Dyna-Q+는 조금 있다 다룬다.</p>
<div class="admonition note">
<p class="admonition-title">Example: Blocking and Shorcut Maze</p>
<div class="tabbed-set tabbed-alternate" data-tabs="3:2"><input checked="checked" id="__tabbed_3_1" name="__tabbed_3" type="radio"><input id="__tabbed_3_2" name="__tabbed_3" type="radio"><div class="tabbed-labels"><label for="__tabbed_3_1">Blocking Maze</label><label for="__tabbed_3_2">Shortcut Maze</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p><img alt="HeadImg" class="skipglightbox" src="https://drive.google.com/uc?id=1BZ_NWxjrRoukE0kaZ1X7vKl3OgksSsAO" width="80%"/></p>
<p>간단한 미로이지만 1000 time steps 이후에 장벽으로 생긴 블록이 오른쪽으로 한칸 이동한다. 처음에 최적의 경로는 오른쪽으로 탐색하는 것이고 블록이 옮겨지면 왼쪽으로 찾는 것이 최적의 경로다. </p>
</div>
<div class="tabbed-block">
<p><img alt="HeadImg" class="skipglightbox" src="https://drive.google.com/uc?id=1BgPlwrHxWAv-Eni7UvGx0qO2Nrpk9tf3" width="80%"/></p>
<p>간단한 미로이지만 3000 time steps 이후에 장벽의 오른쪽이 뚫리며 숏컷이 생긴다. 처음에 최적의 경로는 왼쪽으로  탐색하는 것이고 블록이 사라지면 오른쪽으로 찾는 것이 최적의 경로다. 그러나 Dyna-Q는 블록이 사라지고 나서 최적의 경로를 찾지 못하고 이전의 경로에 만족하는 모습을 보인다(cumulateive reward의 기울기가 급격하게 상승하지 않는다). Exploration-exploitation trade-off가 존재한다.</p>
</div>
</div>
</input></input></div>
</div>
<h3 id="dyna-q">Dyna-Q+<a class="headerlink" href="#dyna-q" title="Permanent link">¶</a></h3>
<p>Dyna-Q+는 각 state-action 쌍이 지난번 시도 이후로 얼만큼 오랫동안 경과했는지 기록하는 휴리스틱한 방법이다. 시간이 오래되었을 수록 해당 state-action 쌍에 대한 모델의 지식이 잘못 되었다는 것을 알려주기 위함이다. 그래서 보상에 경과된 시간을 추가하여 업데이트 한다. </p>
<div class="arithmatex">\[Q(S, A) \leftarrow Q(S, A) + \alpha \left[ (R + \kappa \sqrt{\tau}) + \gamma \max_{a} Q(S', a) - Q(S, A) \right]\]</div>
<ul>
<li><span class="arithmatex">\(\kappa\)</span>는 경과된 시간에 대한 보상의 가중치이다. <span class="arithmatex">\(\kappa\)</span>가 크면 경과된 시간이 길어질수록 보상이 커지고, <span class="arithmatex">\(\kappa\)</span>가 작으면 경과된 시간이 길어질수록 보상이 작아진다.</li>
</ul>
<h2 id="prioritized-sweeping">Prioritized Sweeping<a class="headerlink" href="#prioritized-sweeping" title="Permanent link">¶</a></h2>
<p>Dyan-Q Planning 단계에서 랜덤하게(uniformly) 경험들을 선택해서 해당 state-action 쌍의 value를 업데이트 했다. Uniformly 하게 샘플링하지 말고 다른 방법으로 할 수 있다. </p>
<ul>
<li>Backward-focusing: value 가 업데이트 된 state-action 쌍부터 거꾸로 planning을 진행하는 방법</li>
<li>Prioritized Sweeping: value의 업데이트 변동성이 큰 state-action 쌍부터 planning을 진행하는 방법</li>
</ul>
<p>구체적으로 우선순위 큐(priority queue)를 사용하여 value의 변동량이 특정 값 <span class="arithmatex">\(\omega\)</span>를 넘기면 우선순위 큐에 넣는다. 그리고 해당 큐에서 dequeue해서 simulated experience를 생성하여 Q-Learning을 진행한다. 만약에 이 과정에서 value의 변동량이 또 <span class="arithmatex">\(\omega\)</span>를 넘으면 다시 큐에 넣는다.</p>
<div class="admonition info">
<p class="admonition-title">Prioritized Sweeping</p>
<div class="tabbed-set tabbed-alternate" data-tabs="4:1"><input checked="checked" id="__tabbed_4_1" name="__tabbed_4" type="radio"><div class="tabbed-labels"><label for="__tabbed_4_1">pseudo code</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p><img alt="HeadImg" class="skipglightbox" src="https://drive.google.com/uc?id=1BilaMm2xjjYc6AWijbrjXY1EVuQ0rYFT" width="100%"/></p>
</div>
</div>
</input></div>
</div>
<h2 id="trajectory-sampling">Trajectory Sampling<a class="headerlink" href="#trajectory-sampling" title="Permanent link">¶</a></h2>
<p>Dynamic Programming에서 모든 state를 방문해서 value를 업데이트 했는데 이를 <strong>exhaustive sweep</strong>이라고 한다. 일단 dynamics를 알아야 하지만, 모든 state를 탐색한다는 것은 현실에서 거의 불가능하다. 그래서 특정 분포를 가지는 state space를 샘플링하여 planning을 하게 된다. Dyna-Q에서는 Uniform sampling을 사용했다. <strong>Trajectory Sampling</strong>은 on-policy distribution에 따라 샘플링을 한다. 주어진 model로 state transitions와 rewards을 샘플링하고, 현재 policy를 기반으로 action을 샘플링한다. </p>
<p><img alt="HeadImg" class="skipglightbox" src="https://drive.google.com/uc?id=1BkvoAyyvO4KUHRdyH0fZ8fJha6Nqylvj" width="100%"/></p>
<p>위 그림에서 b는 branching factor이다.</p>
<blockquote>
<p>the branch factor refers to the number of possible actions that an agent can take at each state in the environment.</p>
</blockquote>
<p>On-policy distribution을 사용의 장단점은 다음과 같다. </p>
<ul>
<li>장점: 중요하지 않은 state 혹은 state-action 쌍을 무시할 수가 있다.</li>
<li>단점: model이 잘못되었을 때, 잘못된 state 혹은 state-action 쌍을 계속해서 샘플링하게 된다.</li>
</ul>
<h2 id="real-time-dynamic-programming-rtdp">Real-time Dynamic Programming (RTDP)<a class="headerlink" href="#real-time-dynamic-programming-rtdp" title="Permanent link">¶</a></h2>
<p><img align="left" alt="HeadImg" class="skipglightbox" src="https://drive.google.com/uc?id=1BlzjFO8mWgLr1wGgxZ6CYEWVOiwf6PIf" width="40%"/></p>
<p>Dynamic Programming에서 valute iteration을 on-policy trajectory sampling로 하는 방법이 <strong>Real-time Dynamic Programming (RTDP)</strong>이다. 다음 수식을 사용하여 state-action 쌍이 주어졌을 때(real experience 혹은 simulated experience) value를 업데이트 한다.</p>
<div class="arithmatex">\[v_{k+1}(s) = \underset{a}{\max} \sum_{s', r} p(s', r|s, a) \left[ r + \gamma v_k(s') \right]\]</div>
<p>좌측의 그림과 같이 지정된 시작 states에서 시작하여 도달가능한 state들(=유용한 states)을 업데이트 한다. Optimal policy를 찾기 위해서 필요없는 states, 즉 경로에 도달 할 수 없는 states는 업데이트 하지 않기 때문에, 필요없는 action을 선택할 필요가 없다. Optimal poilcy와 관련 없는 state에 대해서 임의의 action을 지정하거나 선택하지 않는 policy를 <strong>optimal partial policy</strong>라고 한다.</p>
<p>하지만 optimal partial policy를 찾기 위해서는 모든 state를 방문해야 할 수도 있다. 특정 문제에서 RTDP는 모든 state 방문없이 optimal policy를 찾을 수 있다.</p>
<h2 id="planning-at-decision-time">Planning at Decision Time<a class="headerlink" href="#planning-at-decision-time" title="Permanent link">¶</a></h2>
<p>지금까지 현재 state <span class="arithmatex">\(S_t\)</span>에서 선택한 action 뿐만 아니라 과거 경험 했던 state에서 action을 선택할 때에도 planning을 사용했다. 이러한 과정을 <strong>Background Planning</strong>이라고 한다.</p>
<p>그러나 <strong>Decision-time Planning</strong>에서는 현재 state <span class="arithmatex">\(S_t\)</span>에서 action을 선택하기 위해서만 planning을 사용한다. 그리고 State value를 사용할 수 있을 때만 planning을 진행하며, 각 state에서 model이 예측한 value를 기반으로 action을 선택한다.</p>
<ul>
<li>Decision-time Planning은 빠른 응답이 필요하지 않은 Environment에서 유용</li>
</ul>
<h3 id="heuristic-search">Heuristic Search<a class="headerlink" href="#heuristic-search" title="Permanent link">¶</a></h3>
<p><strong>Heuristic Search</strong>는 매 State 방문마다 tree를 생성하여 planning을 진행하는 방법이다. Tree의 리프 노드에 추정한 value function을 적용하고, 현재 state를 root node로 두어 리프 노드부터 루트까지 거꾸로 올라가는(Backup) 방식으로 탐색을 진행한다. 아래 그림은 DFS(Depth First Search)를 사용한 예시이다.</p>
<p><img alt="HeadImg" class="skipglightbox" src="https://drive.google.com/uc?id=1BnBuyRV43vfqBuWsBHqsEGhf-0zhOn8-" width="100%"/></p>
<h3 id="rollout-algorithms">Rollout Algorithms<a class="headerlink" href="#rollout-algorithms" title="Permanent link">¶</a></h3>
<p><strong>Rollout Algorithm</strong>은 현재 state에서 시작하여 simulated trajectory에 적용된 Monte Carlo Control을 기반으로 planning을 진행하는 방법이다. 현재 state의 가능한 action에서 주어진 policy를 따라 simulated trajactory의 reward 평균을 계산하여 action value를 추정한다. 추정한 action value가 충분히 정확하다고 판단되면 가장 높은 추정값을 갖는 action이 선택되고, 그 action의 결과로 생성된 다음 state에서 해당 과정이 반복된다.</p>
<h3 id="monte-carlo-tree-search-mcts">Monte Carlo Tree Search (MCTS)<a class="headerlink" href="#monte-carlo-tree-search-mcts" title="Permanent link">¶</a></h3>
<p><strong>Monte Carlo Tree Search (MCTS)</strong>는 Rollout Algorithm에 기반하지만 Monte Carlo simulations에서 얻은 value 추정값을 누적하여 확장한 버전이다. 시뮬레이션에서 보다 높은 reward를 받는 trajectory로 더 유도하기 위해서 고안되었다. </p>
<p>MCTS는 action을 선택하기 위해 새로운 state를 방문했을 때 실행된다. MCTS의 핵심 아이디어는 이전 시뮬레이션에서 높은 평가를 받은 trajectory의 초반부분을 확장하여 현재 state에서 연속적으로 여러 번의 시뮬레이션을 행할 수 있게 하는 것이다.</p>
<p>다음 그림으로 구체적인 MCTS의 과정을 살펴보자<sup id="fnref:1"><a class="footnote-ref" href="#fn:1">1</a></sup><sup id="fnref:2"><a class="footnote-ref" href="#fn:2">2</a></sup><sup id="fnref:3"><a class="footnote-ref" href="#fn:3">3</a></sup>.</p>
<div class="admonition note">
<p class="admonition-title">MCTS Illustration</p>
<div class="tabbed-set tabbed-alternate" data-tabs="5:2"><input checked="checked" id="__tabbed_5_1" name="__tabbed_5" type="radio"><input id="__tabbed_5_2" name="__tabbed_5" type="radio"><div class="tabbed-labels"><label for="__tabbed_5_1">Illustration</label><label for="__tabbed_5_2">Algorithm</label></div>
<div class="tabbed-content">
<div class="tabbed-block">
<p><img alt="HeadImg" class="skipglightbox" src="https://drive.google.com/uc?id=1BuR89m2TSROMwCo9FjUAjMWBUPUFbl9X" width="100%"/></p>
<ol>
<li><strong>Selection</strong>: 자식 노드 선택 policy를 재귀적으로 적용하여, Root 노드에서 가장 중요 확장 가능한(urgent expandable) 노드로 트리를 따라 내려간다. "확장 가능한"이란 노드가 비 종료 상태이고 방문하지 않은 자식들(unexpanded 포함)을 뜻한다. 여기서 leaf node는 제일 끝에 있는 노드가 아니라 확장 가능한 노드를 뜻한다.</li>
<li><strong>Expansion</strong>: 가능한 action에 따라 하나 이상의 자식노드가 추가되서 트리를 확장한다.</li>
<li><strong>Simulation</strong>: Rollout Policy에 따라 새 노드들에서 시뮬레이션을 실행하여 결과를 생성한다.</li>
<li><strong>Backup(Backpropagation)</strong>: 시뮬레이션 결과(backed up)를 사용하여 트리를 업데이트한다. Rollout Policy에 의해 Tree의 밖에서 방문한 state 및 action에 대한 정보는 저장하지 않는다(Expansion 단계에서 확장된게 아니면 저장하지 않음).</li>
</ol>
</div>
<div class="tabbed-block">
<p><a href="https://ieeexplore.ieee.org/document/6145622">https://ieeexplore.ieee.org/document/6145622</a> 참고</p>
<p><img alt="HeadImg" class="skipglightbox" src="https://drive.google.com/uc?id=1C3ETh5IGNWgjJ4_HfZdAS4RAm4W1NJ-W" width="100%"/></p>
<p><img alt="HeadImg" class="skipglightbox" src="https://drive.google.com/uc?id=1C8xzduGqj2YbjIE-ldjjoXT0NnC2BSgj" width="100%"/></p>
<p><img alt="HeadImg" class="skipglightbox" src="https://drive.google.com/uc?id=1CHVeW_dV2dCXMoTAKV02xe-paUSIlNPc" width="100%"/></p>
</div>
</div>
</input></input></div>
</div>
<div class="footnote">
<hr/>
<ol>
<li id="fn:1">
<p><a href="https://mongxmongx2.tistory.com/17">Monte Carlo Tree Search 알고리즘(MCTS)</a> <a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text">↩</a></p>
</li>
<li id="fn:2">
<p><a href="https://ieeexplore.ieee.org/document/6145622">A Survey of Monte Carlo Tree Search Methods</a> <a class="footnote-backref" href="#fnref:2" title="Jump back to footnote 2 in the text">↩</a></p>
</li>
<li id="fn:3">
<p><a href="https://gusals1620.tistory.com/3">몬테카를로 트리 서치 (Monte Carlo Tree Search)에 대한 정확한 정리</a> <a class="footnote-backref" href="#fnref:3" title="Jump back to footnote 3 in the text">↩</a></p>
</li>
</ol>
</div>
<!-- Giscus -->
<h2 id="__comments">Comments</h2>
<script async="" crossorigin="anonymous" data-category="General" data-category-id="DIC_kwDOHRhxjc4CQSuI" data-emit-metadata="0" data-input-position="top" data-lang="ko" data-mapping="pathname" data-reactions-enabled="1" data-repo="simonjisu/comments_bot" data-repo-id="R_kgDOHRhxjQ" data-theme="light" src="https://giscus.app/client.js">
</script>
<!-- Synchronize Giscus theme with palette -->
<script>
    var giscus = document.querySelector("script[src*=giscus]")

    /* Set palette on initial load */
    var palette = __md_get("__palette")
    if (palette && typeof palette.color === "object") {
      var theme = palette.color.scheme === "slate" ? "dark" : "light"
      giscus.setAttribute("data-theme", theme) 
    }

    /* Register event handlers after documented loaded */
    document.addEventListener("DOMContentLoaded", function() {
      var ref = document.querySelector("[data-md-component=palette]")
      ref.addEventListener("change", function() {
        var palette = __md_get("__palette")
        if (palette && typeof palette.color === "object") {
          var theme = palette.color.scheme === "slate" ? "dark" : "light"

          /* Instruct Giscus to change theme */
          var frame = document.querySelector(".giscus-frame")
          frame.contentWindow.postMessage(
            { giscus: { setConfig: { theme } } },
            "https://giscus.app"
          )
        }
      })
    })
  </script>
</article>
</div>
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
</div>
<button class="md-top md-icon" data-md-component="top" hidden="" type="button">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"></path></svg>
            Back to top
          </button>
</main>
<footer class="md-footer">
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank">
      Material for MkDocs Insiders
    </a>
</div>
<div class="md-social">
<a class="md-social__link" href="https://github.com/simonjisu" rel="noopener" target="_blank" title="github.com">
<svg viewbox="0 0 496 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg>
</a>
</div>
</div>
</div>
</footer>
</div>
<div class="md-dialog" data-md-component="dialog">
<div class="md-dialog__inner md-typeset"></div>
</div>
<script id="__config" type="application/json">{"base": "../../../..", "features": ["navigation.tabs", "navigation.tabs.sticky", "navigation.indexes", "navigation.top", "toc.follow", "navigation.prune", "navigation.path", "content.tooltips", "content.code.annotate"], "search": "../../../../assets/javascripts/workers/search.f2da59ea.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
<script src="../../../../assets/javascripts/bundle.65061dd4.min.js"></script>
<script src="../../../../javascripts/mathjax.js"></script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script>document$.subscribe(() => {const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": false, "draggable": false, "openEffect": "none", "closeEffect": "none", "slideEffect": "slide"});})</script></body>
</html>