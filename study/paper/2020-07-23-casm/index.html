
<!DOCTYPE html>

<html class="no-js" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<link href="https://simonjisu.github.io/study/paper/2020-07-23-casm/" rel="canonical"/>
<link href="../2020-07-19-maskpredict/" rel="prev"/>
<link href="../2020-12-31-xaitutorial/" rel="next"/>
<link href="../../../assets/images/favicon.png" rel="icon"/>
<meta content="mkdocs-1.4.2, mkdocs-material-9.0.12+insiders-4.30.2" name="generator"/>
<title>Classifier-agnostic saliency map extraction - Soopace</title>
<link href="../../../assets/stylesheets/main.b6d2c4d8.min.css" rel="stylesheet"/>
<link href="../../../assets/stylesheets/palette.2505c338.min.css" rel="stylesheet"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/>
<style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
<script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
<script id="__analytics">function __md_analytics(){function n(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],n("js",new Date),n("config","G-2D0S4P2SJ9"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&n("event","search",{search_term:this.value})}),document$.subscribe(function(){var a=document.forms.feedback;if(void 0!==a)for(var e of a.querySelectorAll("[type=submit]"))e.addEventListener("click",function(e){e.preventDefault();var t=document.location.pathname,e=this.getAttribute("data-md-value");n("event","feedback",{page:t,data:e}),a.firstElementChild.disabled=!0;e=a.querySelector(".md-feedback__note [data-md-value='"+e+"']");e&&(e.hidden=!1)}),a.hidden=!1}),location$.subscribe(function(e){n("config","G-2D0S4P2SJ9",{page_path:e.pathname})})});var e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=G-2D0S4P2SJ9",document.getElementById("__analytics").insertAdjacentElement("afterEnd",e)}</script>
<script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
<link href="../../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
            html.glightbox-open { overflow: initial; height: 100%; }
            .gslide-title { margin-top: 0px; user-select: text; }
            .gslide-desc { color: #666; user-select: text; }
            .gslide-image img { background: white; }
            
                .gscrollbar-fixer { padding-right: 15px; }
                .gdesc-inner { font-size: 0.75rem; }
                body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
                body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
                body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}
                </style><script src="../../../assets/javascripts/glightbox.min.js"></script></head>
<body data-md-color-accent="" data-md-color-primary="black" data-md-color-scheme="default" dir="ltr">
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" for="__drawer"></label>
<div data-md-component="skip">
<a class="md-skip" href="#1-introduction">
          Skip to content
        </a>
</div>
<div data-md-component="announce">
</div>
<header class="md-header md-header--lifted" data-md-component="header">
<nav aria-label="Header" class="md-header__inner md-grid">
<a aria-label="Soopace" class="md-header__button md-logo" data-md-component="logo" href="../../.." title="Soopace">
<img alt="logo" src="../../../img/logo/logo.png"/>
</a>
<label class="md-header__button md-icon" for="__drawer">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"></path></svg>
</label>
<div class="md-header__title" data-md-component="header-title">
<div class="md-header__ellipsis">
<div class="md-header__topic">
<span class="md-ellipsis">
            Soopace
          </span>
</div>
<div class="md-header__topic" data-md-component="header-topic">
<span class="md-ellipsis">
            
              Classifier-agnostic saliency map extraction
            
          </span>
</div>
</div>
</div>
<label class="md-header__button md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"></path></svg>
</label>
<div class="md-search" data-md-component="search" role="dialog">
<label class="md-search__overlay" for="__search"></label>
<div class="md-search__inner" role="search">
<form class="md-search__form" name="search">
<input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="search-query" name="query" placeholder="Search" required="" spellcheck="false" type="text"/>
<label class="md-search__icon md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"></path></svg>
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"></path></svg>
</label>
<nav aria-label="Search" class="md-search__options">
<button aria-label="Clear" class="md-search__icon md-icon" tabindex="-1" title="Clear" type="reset">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"></path></svg>
</button>
</nav>
</form>
<div class="md-search__output">
<div class="md-search__scrollwrap" data-md-scrollfix="">
<div class="md-search-result" data-md-component="search-result">
<div class="md-search-result__meta">
            Initializing search
          </div>
<ol class="md-search-result__list" role="presentation"></ol>
</div>
</div>
</div>
</div>
</div>
<div class="md-header__source">
<a class="md-source" data-md-component="source" href="https://github.com/simonjisu.github.io" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"></path></svg>
</div>
<div class="md-source__repository">
    GitHub
  </div>
</a>
</div>
</nav>
<nav aria-label="Tabs" class="md-tabs" data-md-component="tabs">
<div class="md-grid">
<ul class="md-tabs__list">
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../..">
        
  
    
  
  About

      </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../blog/">
          
  
    
  
  Blog

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link md-tabs__link--active" href="../../">
          
  
    
  
  Study

        </a>
</li>
<li class="md-tabs__item">
<a class="md-tabs__link" href="../../../project/">
          
  
    
  
  Project

        </a>
</li>
</ul>
</div>
</nav>
</header>
<div class="md-container" data-md-component="container">
<main class="md-main" data-md-component="main">
<div class="md-main__inner md-grid">
<div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Navigation" class="md-nav md-nav--primary md-nav--lifted" data-md-level="0">
<label class="md-nav__title" for="__drawer">
<a aria-label="Soopace" class="md-nav__button md-logo" data-md-component="logo" href="../../.." title="Soopace">
<img alt="logo" src="../../../img/logo/logo.png"/>
</a>
    Soopace
  </label>
<div class="md-nav__source">
<a class="md-source" data-md-component="source" href="https://github.com/simonjisu.github.io" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"></path></svg>
</div>
<div class="md-source__repository">
    GitHub
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../..">
<span class="md-ellipsis">
    
  
    About
  

    
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../blog/">
<span class="md-ellipsis">
    
  
    Blog
  

    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_3" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../../">
<span class="md-ellipsis">
    
  
    Study
  

    
  </span>
</a>
<label class="md-nav__link" for="__nav_3">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="true" aria-labelledby="__nav_3_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_3">
<span class="md-nav__icon md-icon"></span>
            
  
    Study
  

          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_3_2" type="checkbox"/>
<div class="md-nav__link md-nav__container">
<a class="md-nav__link" href="../">
<span class="md-ellipsis">
    
  
    Paper
  

    
  </span>
</a>
<label class="md-nav__link" for="__nav_3_2">
<span class="md-nav__icon md-icon"></span>
</label>
</div>
<nav aria-expanded="true" aria-labelledby="__nav_3_2_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_3_2">
<span class="md-nav__icon md-icon"></span>
            
  
    Paper
  

          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../2017-08-04-E2EMN/">
<span class="md-ellipsis">
    
  
    End-to-End Memory Network
  

    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../2018-04-04-nsmcbidreclstmselfattn/">
<span class="md-ellipsis">
    
  
    A Structured Self-Attentive Sentence Embedding
  

    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../2019-08-22-neuralnetworklm/">
<span class="md-ellipsis">
    
  
    A Neural Probabilistic Language Model
  

    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../2019-09-18-introxai/">
<span class="md-ellipsis">
    
  
    Explaining Explanations: An Overview of Interpretability of Machine Learning
  

    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../2020-01-14-attentionisallyouneed/">
<span class="md-ellipsis">
    
  
    Attention Is All You Need
  

    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../2020-03-12-deepinsidecnn/">
<span class="md-ellipsis">
    
  
    Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps
  

    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../2020-07-19-maskpredict/">
<span class="md-ellipsis">
    
  
    Mask-Predict: Parallel Decoding of Conditional Masked Language Models
  

    
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--active">
<input class="md-nav__toggle md-toggle" id="__toc" type="checkbox"/>
<a class="md-nav__link md-nav__link--active" href="./">
<span class="md-ellipsis">
    
  
    Classifier-agnostic saliency map extraction
  

    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../2020-12-31-xaitutorial/">
<span class="md-ellipsis">
    
  
    Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI
  

    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../2021-04-12-spider/">
<span class="md-ellipsis">
    
  
    Spider: A Large-Scale Human-Labeled Dataset for Complex and Cross-Domain Semantic Parsing and Text-to-SQL Task
  

    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../2021-04-20-featurevisualization/">
<span class="md-ellipsis">
    
  
    Feature Visualization
  

    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../2021-05-14-bridge/">
<span class="md-ellipsis">
    
  
    Bridging Textual and Tabular Data for Cross-Domain Text-to-SQL Semantic Parsing
  

    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../2021-08-13-hybridranking/">
<span class="md-ellipsis">
    
  
    Hybrid Ranking Network for Text-to-SQL
  

    
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../2021-11-21-nbdt/">
<span class="md-ellipsis">
    
  
    NBDT: Neural-Backed Decision Trees
  

    
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../tutorial/">
<span class="md-ellipsis">
    
  
    Tutorial
  

    
  </span>
<span class="md-nav__icon md-icon"></span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
<a class="md-nav__link" href="../../../project/">
<span class="md-ellipsis">
    
  
    Project
  

    
  </span>
</a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
</nav>
</div>
</div>
</div>
<div class="md-content" data-md-component="content">
<nav aria-label="Navigation" class="md-path">
<ol class="md-path__list">
<li class="md-path__item">
<a class="md-path__link" href="../../..">
<span class="md-ellipsis">
          About
        </span>
</a>
</li>
<li class="md-path__item">
<a class="md-path__link" href="../../">
<span class="md-ellipsis">
            Study
          </span>
</a>
</li>
<li class="md-path__item">
<a class="md-path__link" href="../">
<span class="md-ellipsis">
            Paper
          </span>
</a>
</li>
</ol>
</nav>
<article class="md-content__inner md-typeset">
<nav class="md-tags" hidden="">
<span class="md-tag">Saliency Map</span>
<span class="md-tag">XAI</span>
<span class="md-tag">Explainable AI</span>
</nav>
<p>Paper Link: <a href="https://arxiv.org/abs/1805.08249">Classifier-agnostic saliency map extraction</a></p>
<hr/>
<h1 id="1-introduction">1. Introduction<a class="headerlink" href="#1-introduction" title="Permanent link">¶</a></h1>
<ul>
<li>
<p>기존의 몇몇 논문에서 특정 클래스 점수에 대한 gradient가 네트워크의 내부 작동을 밝히는 수단으로 사용할 수 있다는 것을 증명했다.</p>
<ul>
<li><a href="https://arxiv.org/abs/1312.6034">Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps</a>(Simonyan et al., 2013): vanilla gradient를 사용한 saliency map 생성, 관련 논문 리뷰 <a href="https://simonjisu.github.io/paper/2020/03/12/deepinsidecnn.html">링크</a></li>
<li><a href="https://arxiv.org/abs/1412.6806">Striving for Simplicity: The All Convolutional Net</a>(Springenberg et al., 2014): guided backpropagation을 사용하여 정교한 saliency map 생성</li>
</ul>
</li>
<li>
<p>이러한 추세에 따라서 saliency map을 정교하게 만들기 위한 몇몇 테크닉이 적용되었다.</p>
<ul>
<li><a href="https://arxiv.org/abs/1610.02391">Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization</a>(Selvaraju et al., 2017): GradCAM 논문, 여러개의 saliency map을 평균내서 조금더 smooth 한 맵을 형성</li>
</ul>
</li>
<li>
<p>논문의 저자들은 이러한 트릭들은 유용한 증거를 가지고 있는 saliency map을 찾는데 원칙적인 방법이 아니라고 주장한다.</p>
</li>
<li>이 논문에서는 저자들의 목표는 분류에 도움이 되는 픽셀을 알려주는 saliency map을 찾는 것이다. 문제는 기존의 방법들이 분류기(훈련된 모델)에 너무 의존한다는 것이다. 이러한 문제점을 저자들은 해결하려고 했고, <strong>"class-agnostic saliency map extraction"</strong>이라는 것을 제시한다.</li>
<li>
<p>이 방법은 모델에 의존하지 않고 오직 입력데이터에만 더 집중할 수 있도록 했다. 결과는 Figure2 처럼 질적으로 더 좋은 saliency map을 생성함. 각 행이 어떤 그림을 그린건지는 파트5에서 설명한다.</p>
<p>{% include image.html id="1SJcqwn25JiuD4LHO-yPILhwvaxOi7Qp6" desc="Paper Figure 2" width="100%" height="auto" %}
- ImageNet 데이터로 weakly-supervised 방법중에서 SOTA를 달성, strongly supervised 모델과 비슷한 성과를 냈다고 주장한다. 심지어, 훈련하지 않은 class에 대해서 잘 작동하는 모습도 보여줬다.</p>
</li>
</ul>
<hr/>
<h1 id="2-related-work">2. Related work<a class="headerlink" href="#2-related-work" title="Permanent link">¶</a></h1>
<ul>
<li>생략</li>
</ul>
<hr/>
<h1 id="3-classifier-agnostic-saliency-map-extraction">3. Classifier-Agnostic Saliency Map Extraction<a class="headerlink" href="#3-classifier-agnostic-saliency-map-extraction" title="Permanent link">¶</a></h1>
<ul>
<li>
<p>이 논문에서 다루는 문제는 다음과 같이, 주어진 이미지에 해당하는 salient region을 추출하는 매핑(mapping)을 찾는 것이다. 이 매핑은 분류기(모델)에 도움이 되는 픽셀은 1을 유지하고 그렇지 않은 픽셀은 0으로 masking되어야 한다.</p>
<div class="arithmatex">\[m: \Bbb{R}^{W\times H\times3} \rightarrow [0, 1]^{W\times H} \text{ over } x \in \Bbb{R}^{W\times H\times3}\]</div>
</li>
</ul>
<h2 id="31-classifier-dependent-saliency-map-extraction">3.1 Classifier-Dependent Saliency Map Extraction<a class="headerlink" href="#31-classifier-dependent-saliency-map-extraction" title="Permanent link">¶</a></h2>
<ul>
<li>
<p>기존의 연구(<a href="https://arxiv.org/abs/1704.03296">Fong &amp; Vedaldi, 2017</a>과 <a href="https://arxiv.org/abs/1705.07857">Dabkowski &amp; Gal, 2017</a>)들은 주로 분류기 <span class="arithmatex">\(f\)</span> 가 주어진 상태에서 최적의 masking을 찾는 형태가 많았다.</p>
<div class="arithmatex">\[m = \arg \underset{m'}{\max} S(m', f) \qquad \cdots (1)\]</div>
<p>이러한 방법을 <strong>Classifier-Dependent Saliency Map Extraction</strong> 이라고 하며 자세한 방법은 다음과 같다.</p>
</li>
<li>
<p><span class="arithmatex">\(S\)</span>는 일종의 score function인데, 분류 오차와 연관이 있다.</p>
<div class="arithmatex">\[S(m, f) = \dfrac{1}{N} \sum_{n=1}^{N} \bigg[ l\Big( f\big( (1-m(x_n))\odot x_n \big), y_n \Big) + R\big(m(x_n)\big) \bigg] \qquad \cdots (2)\]</div>
</li>
<li>
<p>수식을 하나씩 보자. <span class="arithmatex">\(m(x_n)\)</span>는 마스크로 매핑된 값들이고, <span class="arithmatex">\(1-m(x_n)\)</span>은 자연스럽게 마스크로 지워지지 않은 지역이다. 여기어 <span class="arithmatex">\(\odot x_n\)</span>은 element-wise product로 입력 이미지에 덧씌움으로써 마스크 되지 않은 픽셀들을 가르킨다. 따라서 분류기 <span class="arithmatex">\(f\)</span> 의 입력으로 지워지지 않은 픽셀을 넣고, 그 예측값과 타겟을 비교한 Loss가 수식의 앞부분 <span class="arithmatex">\(l(f( * ), y_n)\)</span>이다(분류의 경우 보통 Cross-Entropy Loss 다). 뒤에 <span class="arithmatex">\(R( * )\)</span> 항목은 정규화 항목이다. </p>
</li>
<li>같은 입력에서 특정 분류기 <span class="arithmatex">\(f\)</span>로부터 생성된 매핑 <span class="arithmatex">\(m\)</span>은, 다른 분류기 <span class="arithmatex">\(f'\)</span> 로부터 생성된 <span class="arithmatex">\(m'\)</span>과 다를 수도 있다(심지어 같은 성능을 지녀도).</li>
<li>
<p>예를 들어, 다음 수식 <span class="arithmatex">\(L\)</span>을 성능으로 측정한다면, 마스크를 씌우지 않았을 경우 <span class="arithmatex">\(L(0, f) = L(0, f')\)</span>와 마스크가 씌워진 경우 <span class="arithmatex">\(L(m, f) = L(m', f')\)</span>의 성능이 같다고 해도, <span class="arithmatex">\(m\)</span>과 <span class="arithmatex">\(m'\)</span>은 다른 형태를 보여줄 수가 있다는 말이다.</p>
<div class="arithmatex">\[L(m, f) = \dfrac{1}{N} \sum_{n=1}^{N} l\Big( f\big( (1-m(x_n))\odot x_n \big), y_n \Big) \qquad \cdots (3)\]</div>
</li>
<li>
<p>이런 현상의 원인은 두 개의 성능은 동일하나 가중치가 완전히 다른 분류기들이, 같은 입력에 대해서 각자 이미지의 다른 부분집합(픽셀들)을 사용하여 분류할 가능성이 있기 때문이다.</p>
</li>
<li>
<p>극단적인 예시로 이미지의 너비를 반으로 줄이고 옆으로 복사해서 각기 다른 구조의 분류기에 넣는다면, 하나는 이미지의 왼쪽에 saliency map을 생성하고, 다른 분류기는 이미지의 오른쪽에 saliency map을 생성할 수도 있다는 것이다.</p>
<ul>
<li><strong>코멘트:</strong> 이 부분은 실험결과가 없어서 실제로 해봐야 할것 같다. 두 개다 탐지할 수도 있는것 아닌가?</li>
</ul>
</li>
</ul>
<h2 id="32-classifier-agnostic-saliency-map-extraction">3.2 Classifier-Agnostic Saliency Map Extraction<a class="headerlink" href="#32-classifier-agnostic-saliency-map-extraction" title="Permanent link">¶</a></h2>
<ul>
<li>
<p><code>2.1</code>에서 제기한 문제를 해결하려고 모든 분류기에 대한 사후확률의 평균을 최적화는 방식으로 전환하여, 수식(1)을 다음과 같이 변형했다.</p>
<div class="arithmatex">\[m = \arg \underset{m'}{\max} \Bbb{E}_f \big[ S(m', f) \big] \qquad \cdots (4)\]</div>
</li>
<li>
<p><strong>코멘트:</strong> 아래는 공부한 것을 토대로 풀어써봤는데, 틀릴 수도 있으니 주의..</p>
<p>사후확률 <span class="arithmatex">\(p(f \vert D, m')\)</span>은 masking된 이미지가 주어졌을 때, 해당하는 분류기의 확률이라고 생각할 수 있겠다.</p>
<ul>
<li>
<p><span class="arithmatex">\(D, m'\)</span> 부분은 <span class="arithmatex">\((1-m'(x_n))\odot x_n \text{ where } x_n \in D\)</span> 부분이라고 생각할 수 있다.</p>
</li>
<li>
<p>따라서 <span class="arithmatex">\(p(f \vert D, m') \propto p(f) p(D, m' \vert f) = p(f) \exp(-L(m', f))\)</span> 처럼 쓸 수 있다(아마 수식(3) 형태로 가져가려고 <span class="arithmatex">\(L\)</span>에서 입력 이미지 <span class="arithmatex">\(x_n\in D\)</span>는 생략한듯 하다).</p>
</li>
<li>
<p><span class="arithmatex">\(p(D, m' \vert f)\)</span>의 뜻은 특정 분류기 <span class="arithmatex">\(f\)</span>가 주어졌을 때, masking된 이미지를 생성할 확률이다. 이는 Classifier-Dependent Saliency Map Extraction의 목적함수를 확률로 표현한 것이다.</p>
</li>
<li><span class="arithmatex">\(p(D, m' \vert f) = \exp(-L(m', f))\)</span>로 쓸수 있는 이유는 해당 항이 Likelihood 인데,  <span class="arithmatex">\(\log\)</span>를 취하고 마이너스를 곱해줌으로써 Negative Log Likelihood로 바뀐다. <span class="arithmatex">\(-\log p(D, m' \vert f)\)</span>는 곧 수식(3)인 <span class="arithmatex">\(L(m',f)\)</span>와 일치한다.</li>
<li>수식(4)는 모든 가능한 분류기의 공간(the space of all possible classifiers)을 탐색하고, 그 중에서 잘 작동하는 매핑 <span class="arithmatex">\(m\)</span>을 찾는 과정이다. 모든 가능한 분류기의 공간은 모든 분류기의 파라미터(<span class="arithmatex">\(\theta_f\)</span>)의 공간과 동일하다.</li>
<li>이러한 과정을 저자들은 <strong>Classifier-Agnostic Saliency Map Extraction</strong>라고 부르기로 했다.</li>
</ul>
</li>
</ul>
<h2 id="33-algorithm">3.3 Algorithm<a class="headerlink" href="#33-algorithm" title="Permanent link">¶</a></h2>
<ul>
<li>수식(4)의 최적화 문제는 불행하게도 풀수가 없다(intractable). 특히 기댓값안에 있는 매핑 <span class="arithmatex">\(m\)</span>을 loop를 통해 최적화 해야한다는 것이 이 문제를 더 난해하게 만든다. 따라서 논문에서는 이 문제를 매핑 <span class="arithmatex">\(m\)</span>과 기댓값 목적함수를 동시에 추정함으로써 해결하려고 한다.</li>
<li>
<p>구체적인 알고리즘은 다음과 같다.</p>
<p>{% include image.html id="1xCajsDh2yozXxhMwYy82TzJ702BMv6BA" desc="Paper Algorithm 1" width="100%" height="auto" %}</p>
<ul>
<li>
<p>먼저  <span class="arithmatex">\(\theta_f\)</span> 대해 classification loss <span class="arithmatex">\(L\)</span>의 미분을 구함으로써, 사후확률 <span class="arithmatex">\(p(f \vert D, m^{(k-1)})\)</span>를 가지는 <span class="arithmatex">\(f^{(k)}\)</span>를 샘플링한다.</p>
<div class="arithmatex">\[\theta_{f^{(k)}} \leftarrow \theta_{f^{(k-1)}} - \eta_f \triangledown_{\theta_f} L(m^{(k-1)}, f^{(k-1)})\]</div>
<p>이러한 방법은 <a href="https://www.ics.uci.edu/~welling/publications/papers/stoclangevin_v6.pdf">Welling &amp; Teh, 2011</a>와 <a href="https://arxiv.org/abs/1704.04289">Mandt et al., 2017</a> 연구에서 SGD에 noise를 일부 주면  Bayesian Posterior Inference를 수행할 수 있다는 점에서 착안했다. <strong>공부가 더 필요한 부분..</strong></p>
<p>EM 알고리즘이랑 비슷한데, SGD로 한다는 점이 다른듯하다. 참고자료: <a href="http://norman3.github.io/prml/docs/chapter09/4.html">4. The EM Algorithm in General</a></p>
</li>
<li>
<p>업데이트된 파라미터 공간을 <span class="arithmatex">\(F^{(k-1)}\)</span>와 합친뒤에 <span class="arithmatex">\(F^{(k)}\)</span>에서 새로운 파라미터 <span class="arithmatex">\(f'\)</span>를 샘플링한다.</p>
</li>
<li>
<p>새로운 모델을 score function <span class="arithmatex">\(S\)</span>에 넣어서 다시 마스크 네트워크 <span class="arithmatex">\(\theta_{m^{(k-1)}}\)</span>값을 <span class="arithmatex">\(\theta_{m^{(k)}}\)</span>로 업데이트 한다.</p>
<div class="arithmatex">\[\theta_{m^{(k)}} \leftarrow \theta_{m^{(k-1)}} + \eta_m \triangledown_{\theta_m} S(m^{(k-1)}, f')\]</div>
</li>
</ul>
</li>
</ul>
<h3 id="score-function">Score Function<a class="headerlink" href="#score-function" title="Permanent link">¶</a></h3>
<ul>
<li>Score Function은 saliency map의 퀄리티를 측정하는 도구다.</li>
<li>
<p>또한, Precision 과 Recall의 조건을 동시에 만족하게 디자인 되어야한다.</p>
<div class="arithmatex">\[\text{precision} = \dfrac{TP}{TP + FP} \quad \text{recall}=\dfrac{TP}{TP+FN}\]</div>
<p>{% include image.html id="1OEpXqK1p1lwdTLJHzHbliw_EScvBBjO2" desc="Confusion Matrix" width="100%" height="auto" %}</p>
<ul>
<li>Precision: 마킹된 픽셀들 중에서 연관된 픽셀이 얼마나 있는지</li>
<li>Recall: 실제 연관된 픽셀들중에서 얼마나 정확하게 마킹되었는지</li>
<li>기존의 score 함수를 살펴보면, <span class="arithmatex">\(A\)</span>파트는 연관된 픽셀이 더 많이 마킹되게 만들어주는 항이다(high recall). 마스킹된 이미지를 넣어서 classification loss가 높아지면 분류에 도움되는 픽셀들을 잡아주고 있다는 뜻이고, 낮아지면 마스킹이 잘 안되고 있다는 뜻으로 해석할 수 있다.</li>
</ul>
<div class="arithmatex">\[S(m, f) = \dfrac{1}{N} \sum_{n=1}^{N} \bigg[ \underbrace{ l\Big( f\big( (1-m(x_n))\odot x_n \big), y_n \Big)}_{A} + \underbrace{ R\big(m(x_n)\big) }_{B}\bigg] \qquad \cdots (2)\]</div>
</li>
<li>
<p>하지만 단순히 <span class="arithmatex">\(A\)</span>파트를 쓰기에는 문제가 있는데, sampling할때 마스킹된 입력을 넣어서 파라미터 <span class="arithmatex">\(\theta_f\)</span>를 업데이트하기 때문에, 모델의 성능을 저하시킬 가능성이 있다. 변형된 파라미터에 같은 classification loss를 그대로 사용하는 것은 이치에 안맞을 수도 있다. </p>
</li>
<li>추가로 연관된 픽셀이 마스킹된 이미지를 분류기에게 넣었을 때, 정답 클래스가 아니라는 것만 판단해야지, 다른 클래스로 예측하면 안되기 때문에, classification loss를 그대로 사용하는 것은 문제가 있어 보인다. </li>
<li>따라서 저자들은 <span class="arithmatex">\(A\)</span>파트를 <span class="arithmatex">\(\mathcal{H}\big( f( (1-m(x)) \odot x_n) \big)\)</span> Entropy로 바꿨다. 즉, 마스킹을 찾아내는 작업은 정확도를 최소화하는 것이 아닌 불확실성(uncertainty)을 최대화하는 방향으로 진행해야한다.</li>
<li>또한, Entropy로 바꾸면서 ground-truth label의 필요성을 제거했다.</li>
<li><span class="arithmatex">\(B\)</span>파트는 정규화 항목인데, trivial solution을 배제하고 있다. 만약에 마스크 <span class="arithmatex">\(m\)</span>이 전부 1인 경우, 최대 recall 및 아주 낮은 precision을 달성할 수가 있다. 그래서 total variation(<a href="https://www.sciencedirect.com/science/article/abs/pii/016727899290242F">Rudin et al., 1992</a>)과 L1 Norm을 사용하기로 한다.<ul>
<li>임성빈님의 자료 참고: <a href="https://www.slideshare.net/ssuser7e10e4/wasserstein-gan-i">링크</a></li>
</ul>
</li>
<li>
<p>따라서 수식(2)는 다음과 같이 변한다</p>
<div class="arithmatex">\[S(m, f) = \dfrac{1}{N} \sum_{n=1}^{N} \bigg[ \mathcal{H}\Big( f\big( (1-m(x_n))\odot x_n \big) \Big) + \lambda_R \Vert m(x_n) \Vert_1 \bigg] \qquad \cdots (7)\]</div>
</li>
</ul>
<h3 id="thining">Thining<a class="headerlink" href="#thining" title="Permanent link">¶</a></h3>
<ul>
<li>알고리즘이 사후확률 분포에서 분류기 집합 <span class="arithmatex">\(f^{(k)}\)</span>을 저장해서 많은 양의 데이터를 수집하기 때문에, 그중 작은 부분집합만 보존하는 전략을 취하기로 했다.</li>
<li>고정된 크기 <span class="arithmatex">\(F^{(k)}\)</span>를 취하는 방식으로 다음과 같이 정한다.<ul>
<li><strong>F</strong>: 첫번째 분류기만 저장 <span class="arithmatex">\(F^{(k)} = \{ f^{(0)}\}\)</span></li>
<li><strong>L</strong>: 마지막 분류기만 저장 <span class="arithmatex">\(F^{(k)} = \{ f^{(k)}\}\)</span></li>
<li><strong>FL</strong>: 첫번째와 마지막 분류기만 저장 <span class="arithmatex">\(F^{(k)} = \{ f^{(0)}, f^{(k)}\}\)</span></li>
<li><strong>L1000</strong>: 1000번째 iteration 마다 저장하고, <span class="arithmatex">\(\vert F^{(k)} \vert =30\)</span> 을 넘어갈때, 랜덤하게 하나를 제거한다.</li>
<li><strong>L100</strong>: 100번째 iteration 마다 저장하고, <span class="arithmatex">\(\vert F^{(k)} \vert =30\)</span> 을 넘어갈때, 랜덤하게 하나를 제거한다.</li>
</ul>
</li>
</ul>
<h3 id="classification-loss">Classification loss<a class="headerlink" href="#classification-loss" title="Permanent link">¶</a></h3>
<ul>
<li>
<p>수식(3)처럼 classification loss를 정의해도 되지만 꼭 그럴 필요도 없다.</p>
<div class="arithmatex">\[L(m, f) = \dfrac{1}{N} \sum_{n=1}^{N} l\Big( f\big( (1-m(x_n))\odot x_n \big), y_n \Big) \qquad \cdots (3)\]</div>
</li>
<li>
<p>대신 <a href="https://arxiv.org/abs/1312.6199">Szegedy et al., 2013</a> 방식이 더 잘 됐다.</p>
<div class="arithmatex">\[L(m, f) = \dfrac{1}{2N} \sum_{n=1}^{N} \bigg[ l\Big( f\big( (1-m(x_n))\odot x_n \big), y_n \Big) + l\big( f(x_n), y_n \big) \bigg] \qquad \cdots (8)\]</div>
</li>
</ul>
<hr/>
<h1 id="4-training-and-evaluation-details">4. Training and evaluation details<a class="headerlink" href="#4-training-and-evaluation-details" title="Permanent link">¶</a></h1>
<h3 id="dataset">Dataset<a class="headerlink" href="#dataset" title="Permanent link">¶</a></h3>
<ul>
<li>Official ImageNet Training Set</li>
</ul>
<h3 id="classifier-f-and-mapping-m">Classifier <span class="arithmatex">\(f\)</span> and mapping <span class="arithmatex">\(m\)</span><a class="headerlink" href="#classifier-f-and-mapping-m" title="Permanent link">¶</a></h3>
<p>{% include image.html id="1FHVgUhAdmJqAlJ0UE1l55lbnna070zJq" desc="Paper Figure 1" width="100%" height="auto" %}</p>
<ul>
<li>모델 <span class="arithmatex">\(f\)</span>는 ResNet-50을 사용했다. 그리고 Encoder-Decoder 구조를 취해서 마스크 <span class="arithmatex">\(m\)</span>를 생성한다.</li>
<li>Encoder는 ResNet-50 구조를 사용하고, 가중치는 <span class="arithmatex">\(f\)</span>와 공유할 수도 있고 아닐수도 있다(실험결과 공유하는게 더 유리하다).</li>
<li>Decoder는 Deconvolutional Network를 사용하여 마스크를 생성한다.</li>
</ul>
<h3 id="regularization-coeffieient-lambda_r">Regularization coeffieient <span class="arithmatex">\(\lambda_R\)</span><a class="headerlink" href="#regularization-coeffieient-lambda_r" title="Permanent link">¶</a></h3>
<ul>
<li><a href="https://lld-workshop.github.io/2017/papers/LLD_2017_paper_64.pdf">Fan et al. 2017</a> 에서 최적의 <span class="arithmatex">\(\lambda_R\)</span>는 쉽게 찾을 수 없다고(not trivial)하다고 이야기하면서, adaptive 전략을 취해서 인위적인 <span class="arithmatex">\(\lambda_R\)</span>을 고르는 것을 배제했다.</li>
<li>저자들을 같은 방법을 사용하면 saliency map의 평균 크기를 제어하기가 어려워 <span class="arithmatex">\(f(x)\)</span>와 <span class="arithmatex">\(f((1-m(x)) \odot x)\)</span>간에 차이가 있을 때만 <span class="arithmatex">\(\lambda_R\)</span>를 적용했다.</li>
<li>각 실험에서 대략 50%의 픽셀이 연관되게 하도록 마스크 <span class="arithmatex">\(m\)</span>를 생성했다.</li>
</ul>
<h3 id="baseline-and-casm">Baseline and CASM<a class="headerlink" href="#baseline-and-casm" title="Permanent link">¶</a></h3>
<ul>
<li>Baseline 모델은 CASM과 같은 모델 구조를 가지지만 CDSM(classifier-dependent saliency mapping) 방법으로 훈련킨 모델이(Thinning은 <strong>F</strong>를 사용).</li>
</ul>
<h3 id="mask-discretization">Mask discretization<a class="headerlink" href="#mask-discretization" title="Permanent link">¶</a></h3>
<ul>
<li>
<p>마스크는 다음과 같이 생성한다. <span class="arithmatex">\(\bar{m}(x)\)</span>은 마스크의 평균값이고, <span class="arithmatex">\(\alpha\)</span>는 하이퍼파라미터다.</p>
<div class="arithmatex">\[b_{ij}(x) = \begin{cases} 1, \quad \text{if } m_{ij}(x) \geq \alpha \bar{m}(x) \\ 0, \quad \text{otherwise} \end{cases}\]</div>
</li>
<li>
<p><span class="arithmatex">\(\alpha\)</span>를 1로 설성하면 마스크 평균값이 그대로 binary mask를 생성한다.</p>
</li>
</ul>
<hr/>
<h1 id="5-qualitative-comparisons">5. Qualitative comparisons<a class="headerlink" href="#5-qualitative-comparisons" title="Permanent link">¶</a></h1>
<ul>
<li>논문의 그림에 대해서 설명한다. 각 행에 대하여 다음과 같은 visualization을 했다.<ol>
<li><strong>original image</strong>: 원본 이미지</li>
<li><strong>masked-in image</strong>( <span class="arithmatex">\(b(x) \odot x\)</span> ): 마스크안의 이미지</li>
<li><strong>masked-out image</strong>( <span class="arithmatex">\((1-b(x)) \odot x\)</span> ): 마스킹된 이미지</li>
<li><strong>inpainted masked-out image</strong>: inpainting 알고리즘 <a href="https://www.researchgate.net/publication/238183352_An_Image_Inpainting_Technique_Based_on_the_Fast_Marching_Method">Telea, 2004</a>을 사용해서 마스크 내부 이미지를 채웠다.</li>
</ol>
</li>
<li>Random 하게 7개의 연속된 그림을 골라서 visualization 했다.</li>
</ul>
<hr/>
<h1 id="6-evaluation">6. Evaluation<a class="headerlink" href="#6-evaluation" title="Permanent link">¶</a></h1>
<h2 id="61-basic-statistics">6.1 Basic statistics<a class="headerlink" href="#61-basic-statistics" title="Permanent link">¶</a></h2>
<ul>
<li>Validation Set로 saliency map을 만들었다.</li>
<li>CASM 모델로 마스크를 추출시 total variation이 더 낮았다( <span class="arithmatex">\(2.5 \times 10^3\)</span> vs <span class="arithmatex">\(7.0 \times 10 ^3\)</span> ). 즉, total variation 정규화를 적게 줘도 CASM이 더 많은 mask를 생성한다. &gt; 무슨말이냐</li>
<li>Entropy는 Baseline 보다 많이 작았는데( <span class="arithmatex">\(0.05\)</span> vs <span class="arithmatex">\(0.21\)</span> ), 이는 mask intensities가 거의 0과 1 사이의 값을 평균적으로 가진다는 것을 뜻한다.</li>
<li>masked out volume의 표준편차가 더 컸는데( <span class="arithmatex">\(0.19\)</span> vs <span class="arithmatex">\(0.14\)</span> ), 이를 통해 CASM이 입력 이미지에 따라서 더 다양한 크기의 saliency map을 생성할 수 있다는 것을 알 수 있다.</li>
</ul>
<h2 id="62-classification-by-multiple-classifiers">6.2 Classification by multiple classifiers<a class="headerlink" href="#62-classification-by-multiple-classifiers" title="Permanent link">¶</a></h2>
<p>{% include image.html id="11zPpcGsV3JDEPhvOBVGsIm9uO-mtIcGz" desc="Paper Figure 3" width="100%" height="auto" %}</p>
<ul>
<li>CASM이 정말로 classifier-agnostic인지 <code>torchvision.models</code>에 있는 모델들로 주장을 확인해봤다. 자신들이 기대한 것은 CASM을 통해 만든 inpainted masked-out 이미지로 해당 모델들의 정확도를 깎아 내리고, masked-in 이미지들은 좋은 성능을 내는거다. 그리고 그 기대는 맞아 떨어졌다.</li>
<li>
<p>Masked-out 이미지에서 Baseline 모델이 성능이 굉장히 낮게 나왔는데, 저자들이 어림짐작으로 보았을때 Baseline 모델이 생성한 saliency map의 적대적인 성질인것 겉다. 그 이유는 masked-out 이미지를 채운 inpainted masked-out 이미지와 비교했을 때, Baseline 모델은 성능이 드라마틱하게 향상하는데, CASM 모델은 그 혜택을 많이 못보기 때문이다.</p>
<ul>
<li><strong>코멘트</strong>: 기존에 완전한 이미지로 모델을 학습 할 때, 주변 사물등 다른 정보를 사용하여 물체를 분류했을 가능성이 있는데, Baseline 모델은 일부 연관된 물체도 지워버리니까 오히려 더 CASM 보다 성능이 하락하는 것 같음. 예를 들어, 아래 그림 처럼 나무를 아예 지워버리니까, 판별을 더 못하는 듯. 어떻게 생각하면 훈련 데이터가 다양하지 못했다는 것이, <code>f(나무 + 새) = 새</code> 라는 것이 되니까, 주변 사물이 분류기에 많은 영향을 끼치는 것을 알 수 있음.</li>
</ul>
<p>{% include image.html id="1UAR_h0c0RE4uLM5LK3SBu21qj3rcuQLL" desc="Comparing CASM vs Baseline" width="100%" height="auto" %}</p>
</li>
<li>
<p><strong>코멘트</strong>: 자신들이 만든 baseline과 비교한것도 좋지만, 다른 방법(CAM방식) 등 하고 비교해보았어도 괜찮을 것 같음</p>
</li>
</ul>
<h2 id="63-object-localization">6.3 Object localization<a class="headerlink" href="#63-object-localization" title="Permanent link">¶</a></h2>
<p>{% include image.html id="1WZ6W1xGCCfgnpA-8irC-_l-3Fljbe3aY" desc="Paper Table 1" width="100%" height="auto" %}</p>
<ul>
<li>saliency map으로 weakly supervised localization도 같이 수행했다.</li>
<li>
<p>3가지 metrics으로 localization을 계량했다.</p>
<ul>
<li><strong>OM</strong>: ImageNet Localization 챌린지에서 사용하는 official metric, 예측 bounding box와 정답 bounding box의 IOU가 0.5 이상이여야하고, 클래스를 맞춰야한다. 맞췄을 경우 0, 그렇지 않을 경우 1이 되서, OM이 낮을 수록 좋다.</li>
<li><strong>LE</strong>: OM방식은 분류기에 따라 다르다. 저자들은 분류기와 상관없이 훈련했기에 bounding box만 예측하는 "Localization Error"라는 다른 방법을 사용했다. (Cao et al. 2015, Fong &amp; Vedaldi 2017) 이 방법도 낮을 수록 좋다.</li>
<li>마지막으로 원본 saliency map을 conintious F1 score로 평가했다.<ul>
<li>
<p>Precision과 Recall은 다음과 같이 정해진다.</p>
<div class="arithmatex">\[P=\dfrac{\sum_{(i,j) \in B^*(x)} m_{ij}(x)}{\sum_{ij} m_{ij}(x)} \quad \text{and} \quad R=\dfrac{\sum_{(i,j) \in B^*(x)} m_{ij}(x)}{\vert B^*(x) \vert}\]</div>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>supervised 보다 성능이 대부분 뛰어났다고 주장, 다만 전제 자체가 조금 다르기에 적절한 비교가 힘들다고 함</p>
</li>
</ul>
<h3 id="thinning-strategies-score-function-sharing-the-encoder-and-classifier">Thinning strategies &amp; Score function &amp; Sharing the encoder and classifier<a class="headerlink" href="#thinning-strategies-score-function-sharing-the-encoder-and-classifier" title="Permanent link">¶</a></h3>
<p>{% include image.html id="1YPJ_KmdfPrHgIeZOSAB1m0ZDi97zsamg" desc="Paper Table 2" width="100%" height="auto" %}</p>
<ul>
<li><span class="arithmatex">\(S\)</span>: score function 의 선택 (E: entropy loss, C: classification loss)</li>
<li><span class="arithmatex">\(SHR\)</span>: Encoder와 Classifier를 공유 했는지 여부</li>
<li><span class="arithmatex">\(THIN\)</span>: Thinning 전략</li>
<li>Entropy 쓰고, parameter sharing하고, L100 thinning 전략인 E가 제일 좋음</li>
</ul>
<h2 id="64-unseen-classes">6.4 Unseen classes<a class="headerlink" href="#64-unseen-classes" title="Permanent link">¶</a></h2>
<p>{% include image.html id="1pyIiM1Np5OWJB85TAczggvXwdFl69pdX" desc="Paper Table 3" width="100%" height="auto" %}</p>
<ul>
<li>제안한 방법이 클래스의 정답을 필요로 하지 않기 때문에, 학습하지 않았던 데이터의 localization을 수행할 수 있다.</li>
<li>이를 테스트하기 위해서 1000개의 클래스를 5개(6개아닌가..?)의 서로소 부분집합(disjoint subset)으로 쪼갠다. 즉, 각각의 집합에 서로 다른 클래스가 들어가 있다. 그리고 각 집합에는 다음과 같은 크기의 데이터를 담고, 각각 해당하는 % 만큼 CASM 모델을 훈련시킨다(Thinning은 <strong>L</strong> 전략 사용).<ul>
<li>A: 50, B: 50, C: 100, D: 300, E: 300, F: 200</li>
<li>95%: B, C, D, E, F</li>
<li>90%: C, D, E, F</li>
<li>80%: D, E, F</li>
<li>50%: E, F</li>
<li>20%: F</li>
</ul>
</li>
<li>모든 모델들의 일반화가 좋은 편이었고, 정확도는 무시할정도 수준으로 작았다(20% 훈련한 모델을 제외).</li>
<li>seen과 unseen의 <strong>LE</strong> 차이는 훈련 데이터가 적어질 수록 높아졌다. 그러나 적당한 크기의 traning set 이라면 차이는 크게 나지 않는다.</li>
</ul>
<!-- Giscus -->
<h2 id="__comments">Comments</h2>
<script async="" crossorigin="anonymous" data-category="General" data-category-id="DIC_kwDOHRhxjc4CQSuI" data-emit-metadata="0" data-input-position="top" data-lang="ko" data-mapping="pathname" data-reactions-enabled="1" data-repo="simonjisu/comments_bot" data-repo-id="R_kgDOHRhxjQ" data-theme="light" src="https://giscus.app/client.js">
</script>
<!-- Synchronize Giscus theme with palette -->
<script>
    var giscus = document.querySelector("script[src*=giscus]")

    /* Set palette on initial load */
    var palette = __md_get("__palette")
    if (palette && typeof palette.color === "object") {
      var theme = palette.color.scheme === "slate" ? "dark" : "light"
      giscus.setAttribute("data-theme", theme) 
    }

    /* Register event handlers after documented loaded */
    document.addEventListener("DOMContentLoaded", function() {
      var ref = document.querySelector("[data-md-component=palette]")
      ref.addEventListener("change", function() {
        var palette = __md_get("__palette")
        if (palette && typeof palette.color === "object") {
          var theme = palette.color.scheme === "slate" ? "dark" : "light"

          /* Instruct Giscus to change theme */
          var frame = document.querySelector(".giscus-frame")
          frame.contentWindow.postMessage(
            { giscus: { setConfig: { theme } } },
            "https://giscus.app"
          )
        }
      })
    })
  </script>
</article>
</div>
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
</div>
<a class="md-top md-icon" data-md-component="top" hidden="" href="#">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"></path></svg>
            Back to top
          </a>
</main>
<footer class="md-footer">
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank">
      Material for MkDocs Insiders
    </a>
</div>
<div class="md-social">
<a class="md-social__link" href="https://github.com/simonjisu" rel="noopener" target="_blank" title="github.com">
<svg viewbox="0 0 496 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.2.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg>
</a>
</div>
</div>
</div>
</footer>
</div>
<div class="md-dialog" data-md-component="dialog">
<div class="md-dialog__inner md-typeset"></div>
</div>
<script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.tabs", "navigation.tabs.sticky", "navigation.indexes", "navigation.top", "toc.follow", "navigation.prune", "navigation.path", "content.tooltips", "content.code.annotate"], "search": "../../../assets/javascripts/workers/search.6c7302c4.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
<script src="../../../assets/javascripts/bundle.fbce390c.min.js"></script>
<script src="../../../javascripts/mathjax.js"></script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<script>document$.subscribe(() => {const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": false, "draggable": false, "openEffect": "none", "closeEffect": "none", "slideEffect": "slide"});})</script></body>
</html>