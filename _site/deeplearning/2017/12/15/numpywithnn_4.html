<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>NUMPY with NN - 4: Backpropagation</title>
  <meta name="description" content="Numpy로 짜보는 Neural Network Basic - 4">
  
  <meta name="author" content="Soo">
  <meta name="copyright" content="&copy; Soo 2018">
  

  <!-- External libraries -->
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css">
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css">
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/lightbox2/2.7.1/css/lightbox.css">

  <!-- Favicon and other icons (made with http://www.favicon-generator.org/) -->
  <link rel="shortcut icon" href="/assets/icons/favicon.ico" type="image/x-icon">
  <link rel="icon" href="/assets/icons/favicon.ico" type="image/x-icon">
  <link rel="apple-touch-icon" sizes="57x57" href="/assets/icons/apple-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="/assets/icons/apple-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/assets/icons/apple-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="/assets/icons/apple-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="/assets/icons/apple-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="/assets/icons/apple-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/assets/icons/apple-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/assets/icons/apple-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/assets/icons/apple-icon-180x180.png">
  <link rel="icon" type="image/png" sizes="192x192"  href="/assets/icons/android-icon-192x192.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/assets/icons/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="96x96" href="/assets/icons/favicon-96x96.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/icons/favicon-16x16.png">
  <link rel="manifest" href="/assets/icons/manifest.json">
  <meta name="msapplication-TileColor" content="#ffffff">
  <meta name="msapplication-TileImage" content="/assets/icons/ms-icon-144x144.png">
  <meta name="theme-color" content="#ffffff">

  
  <!-- Facebook OGP cards -->
  <meta property="og:description" content="Numpy로 짜보는 Neural Network Basic - 4" />
  <meta property="og:url" content="http://simonjisu.github.io" />
  <meta property="og:site_name" content="Soo" />
  <meta property="og:title" content="NUMPY with NN - 4: Backpropagation" />
  <meta property="og:type" content="website" />
  <meta property="og:image" content="http://simonjisu.github.io/assets/logo.png" />
  <meta property="og:image:type" content="image/png" />
  <meta property="og:image:width" content="612" />
  <meta property="og:image:height" content="605" />
  

  
  <!-- Twitter: card tags -->
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="NUMPY with NN - 4: Backpropagation">
  <meta name="twitter:description" content="Numpy로 짜보는 Neural Network Basic - 4">
  <meta name="twitter:image" content="http://simonjisu.github.io/assets/logo.png">
  <meta name="twitter:url" content="http://simonjisu.github.io">
  

  

  <!-- Site styles -->
  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://simonjisu.github.io/deeplearning/2017/12/15/numpywithnn_4.html">
  <link rel="alternate" type="application/rss+xml" title="Soo" href="http://simonjisu.github.io/feed.xml" />


  <!-- <script type="text/javascript"
          src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" ></script> -->

  <!-- Latex -->
  <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
      MathJax.Hub.Insert(MathJax.InputJax.TeX.Definitions.macros,{
        cancel: ["Extension","cancel"],
        bcancel: ["Extension","cancel"],
        xcancel: ["Extension","cancel"],
        cancelto: ["Extension","cancel"]
      });
    });
    MathJax.Hub.Config({
        TeX: {
            extensions: ["mhchem.js", "cancel.js"]
        },
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true,
            ignoreClass: "no-mathjax",
        },
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            // linebreaks: { automatic: true }
        },
        menuSettings: {
            zoom: "Click",
            zscale: "200%"
        }
    });
  </script>

  <!--lightSlider-->
  <link rel="stylesheet" href="/css/lightslider.css" />


</head>


  <body>

    <header class="navigation" role="banner">
  <div class="navigation-wrapper">
    <a href="/" class="logo">
      
      <img src="/assets/logo.png" alt="Soo">
      
    </a>
    <a href="javascript:void(0)" class="navigation-menu-button" id="js-mobile-menu">
      <i class="fa fa-bars"></i>
    </a>
    <nav role="navigation">
      <ul id="js-navigation-menu" class="navigation-menu show">
        
          
          <li class="nav-link"><a href="/about/">About</a>
          
        
          
        
          
        
          
        
          
          <li class="nav-link"><a href="/posts/">Posts</a>
          
        
          
        
          
        
          
        
          <li class="nav-link"><a href="https://github.com/simonjisu"> GitHub </a>
      </ul>
    </nav>
  </div>
</header>


    <div class="page-content">
        <div class="post">
<!-- <h1></h1>
 -->
<div class="post-header-container " >
  <div class="scrim ">
    <header class="post-header">
      <h1 class="title">NUMPY with NN - 4: Backpropagation</h1>
      <p class="info">by <strong>Soo</strong></p>
    </header>
  </div>
</div>

<div class="wrapper">

 <span class="page-divider">
  <span class="one"></span>
  <span class="two"></span>
</span>
 

<section class="post-meta">
  <div class="post-date">December 15, 2017</div>
  <div class="post-categories">
   in 
    
    <a href="/posts/#DeepLearning">Deeplearning</a>
    
  
  </div>
</section>

<article class="post-content">
  <h1 id="numpy--neural-network-basic---4">Numpy로 짜보는 Neural Network Basic - 4</h1>
<hr />

<h2 id="backpropagation">오차역전파(Backpropagation)</h2>

<h3 id="section">연쇄법칙의 원리</h3>
<p>합성 함수의 미분은 합성 함수를 구성하는 각 함수의 미분의 곱으로 나타낼 수 있다.</p>

<script type="math/tex; mode=display">\begin{cases} z = t^2 \\ t = x + y \end{cases}</script>

<p>위 식의 미분을 나타내면
<script type="math/tex">\frac{\partial{z}}{\partial{x}} = \frac{\partial{z}}{\partial{t}} \cdot \frac{\partial{t}}{\partial{x}}</script></p>

<p>따라서 $z$, $t$ 식을 미분하게 되면</p>

<p><script type="math/tex">\frac{\partial{z}}{\partial{t}} = 2t</script>
<script type="math/tex">\frac{\partial{t}}{\partial{x}}=1</script></p>

<script type="math/tex; mode=display">\therefore\  \frac{\partial{z}}{\partial{x}} = \frac{\partial{z}}{\partial{t}} \cdot \frac{\partial{t}}{\partial{x}} = 2t \cdot 1 = 2(x+y)</script>

<p>우리의 목적은 $L$ 에 대해서 $W$ 를 미분하여 조금씩 업데이트 하는 것임으로 아래와 같다고 할 수 있다.
<script type="math/tex">\frac{\partial{L}}{\partial{W}} = \frac{\partial{L}}{\partial{Y}} \cdot \frac{\partial{Y}}{\partial{W}}</script></p>

<h3 id="section-1">덧셈노드와 곱셈노드의 역전파</h3>

<p><img src="/assets/ML/nn/NN_add.png" alt="Drawing" style="width: 400px;" /></p>

<p>(그림출처: ratsgo님의 블로그[<a href="https://ratsgo.github.io/deep%20learning/2017/05/14/backprop/"><span style="color: #7d7ee8">링크</span></a>])</p>

<script type="math/tex; mode=display">\begin{cases} L(z) \\ z = x + y \end{cases}</script>

<p>각각 미분하게 되면</p>

<script type="math/tex; mode=display">\begin{cases}
    \dfrac{\partial{L}}{\partial{z}} \\
    \dfrac{\partial{z}}{\partial{x}} =
    \dfrac{\partial{z}}{\partial{y}} = 1
  \end{cases}</script>

<p>따라서 $L$ 을 각각 $x$ 와 $y$ 로 미분하려면</p>

<script type="math/tex; mode=display">\begin{cases}
    \dfrac{\partial{L}}{\partial{x}} = \dfrac{\partial{L}}{\partial{z}} \cdot \dfrac{\partial{z}}{\partial{x}} = \dfrac{\partial{L}}{\partial{z}} \cdot 1 \\
    \dfrac{\partial{L}}{\partial{y}} = \dfrac{\partial{L}}{\partial{z}} \cdot \dfrac{\partial{z}}{\partial{y}} = \dfrac{\partial{L}}{\partial{z}} \cdot 1
  \end{cases}</script>

<p>따라서 <strong>덧셈</strong> 노드는 들어온 신호($\frac{\partial{L}}{\partial{z}}$)를 <strong>그대로</strong> 보낸다.</p>

<p><img src="/assets/ML/nn/NN_multiply.png" alt="Drawing" style="width: 400px;" /></p>

<p>(그림출처: ratsgo님의 블로그[<a href="https://ratsgo.github.io/deep%20learning/2017/05/14/backprop/"><span style="color: #7d7ee8">링크</span></a>])</p>

<script type="math/tex; mode=display">\begin{cases} L(z) \\ z = x \times y \end{cases}</script>

<p>각각 미분하게 되면</p>

<script type="math/tex; mode=display">\begin{cases}
    \dfrac{\partial{L}}{\partial{z}} \\
    \dfrac{\partial{z}}{\partial{x}} = y \\
    \dfrac{\partial{z}}{\partial{y}} = x
  \end{cases}</script>

<p>따라서 $L$ 을 각각 $x$ 와 $y$ 로 미분하려면</p>

<script type="math/tex; mode=display">\begin{cases}
    \dfrac{\partial{L}}{\partial{x}} = \dfrac{\partial{L}}{\partial{z}} \cdot \dfrac{\partial{z}}{\partial{x}} = \dfrac{\partial{L}}{\partial{z}} \cdot y \\
    \dfrac{\partial{L}}{\partial{y}} = \dfrac{\partial{L}}{\partial{z}} \cdot \dfrac{\partial{z}}{\partial{y}} = \dfrac{\partial{L}}{\partial{z}} \cdot x
  \end{cases}</script>

<p>따라서 <strong>곱셈</strong> 노드는 들어온 신호에 서로 바뀐 입력신호 값을 <strong>곱해서</strong> 하류로 보낸다.</p>

<h2 id="sigmoid---">Sigmoid 계층의 순전파와 역전파</h2>

<script type="math/tex; mode=display">y = \frac{1}{1+\exp(-x)}</script>

<h3 id="forward">Forward</h3>

<p><img src="/assets/ML/nn/NN_sigmoid_forward.png" alt="Drawing" style="width: 600px;" /></p>

<h3 id="backward">Backward</h3>

<p><img src="/assets/ML/nn/NN_sigmoid_back.png" alt="Drawing" style="width: 600px;" /></p>

<p><img src="/assets/ML/nn/NN_sigmoid_back2.png" alt="Drawing" style="width: 600px;" /></p>

<blockquote>
  <h4 id="section-2">역전파 1단계 ( / )</h4>

  <p>”/” 연산은 입력변수 x를 $\dfrac{1}{x}$ 로 바꿔준다. 즉 $f_1(x) = \dfrac{1}{x}$ 가 된다.</p>

  <p>미분을 하게 되면 $\dfrac{\partial{f_1}}{\partial{x}} = -\dfrac{1}{x^2} = -y^2$가 되서 입력신호를 하류로 보낸다.</p>

  <h4 id="section-3">역전파 2단계 ( + )</h4>

  <p>”+” 연산은 신호를 그대로 하류로 흘러 보낸다</p>

  <h4 id="exp">역전파 3단계 (exp)</h4>

  <p>“exp”연산은 $f_2(x) = exp(x)$ 이며, 미분도 $\dfrac{\partial{f_2}}{\partial{x}} = exp(x)$ 로 그대로 곱해서 하류로 보낸다.</p>

  <h4 id="x-">역전파 4단계 ( x )</h4>

  <p>”$\times$”연산은 서로 바뀐 입력신호의 값을 곱해서 보낸다.</p>
</blockquote>

<p>따라서, 최종적으로 시그모이드의 역전파 출력값은 아래와 같다.</p>

<p><img src="/assets/ML/nn/NN_sigmoid_last.png" alt="Drawing" style="width: 400px;" /></p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned}
\dfrac{\partial{L}}{\partial{y}}y^{2}\exp(-x)
&= \dfrac{\partial{L}}{\partial{y}} \dfrac{1}{[1+\exp(-x)]^2}\exp(-x) \\
&= \dfrac{\partial{L}}{\partial{y}} \dfrac{1}{1+\exp(-x)} \dfrac{\exp(-x)}{1+\exp(-x)} \\
&= \dfrac{\partial{L}}{\partial{y}}y(1-y) \\
\end{aligned} %]]></script>

<p>이것을 코드로 구현하게 되면</p>

<div class="highlighter-rouge"><pre class="highlight"><code>class Sigmoid(object):
    def __init__(self):
        self.out = None  # 역전파시 곱해야 하기 때문에 저장해둔다

    def forward(self, x):
        out = 1 / (1 + np.exp(-x))
        self.out = out

        return out

    def backward(self, dout):
        dx = dout * self.out * (1 - self.out)
</code></pre>
</div>

<h2 id="affine--affine-transform">Affine 계층과 Affine Transform</h2>
<p>기하학에서 신경망 순전파 때 수행하는 행렬의 내적을 Affine Transform이라 하며, Affine 계층은 어파인 변환을 수행 처리하는 계층이다.</p>

<p>위키백과[<a href="https://ko.wikipedia.org/wiki/%EC%95%84%ED%95%80_%EB%B3%80%ED%99%98"><span style="color: #7d7ee8">링크</span></a>]</p>

<h3 id="forward-1">Forward</h3>

<p>$A = X \cdot W + B$</p>

<h3 id="backward-1">Backward</h3>

<p>$\begin{cases}
    \dfrac{\partial{L}}{\partial{X}} = \dfrac{\partial{L}}{\partial{A}} \cdot \dfrac{\partial{A}}{\partial{X}} = \dfrac{\partial{L}}{\partial{A}} \cdot W^T <br />
    \dfrac{\partial{L}}{\partial{W}} = \dfrac{\partial{L}}{\partial{A}} \cdot \dfrac{\partial{A}}{\partial{W}} = X^T \cdot \dfrac{\partial{L}}{\partial{A}} <br />
    \dfrac{\partial{L}}{\partial{B}} = 1
  \end{cases}$</p>

<div class="highlighter-rouge"><pre class="highlight"><code>class Affine(object):
    def __init__(self, W, b):
        self.W = W
        self.b = b
        self.x = None
        self.dW = None
        self.db = None

    def forward(self, x):
        self.x = x
        out = np.dot(self.x, self.W) + self.b

        return out

    def backward(self, dout):
        dx = np.dot(dout, self.W.T)
        self.dW = np.dot(self.x.T, dout)
        self.db = np.sum(self.b, axis=0)

        return dx
</code></pre>
</div>

<h2 id="backpropogation--">Backpropogation 사용한 학습구현</h2>

<div class="highlighter-rouge"><pre class="highlight"><code>import collections
from layers import *

class TwoLayer(object):
    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):
        self.params = {}
        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)
        self.params['b1'] = np.zeros(hidden_size)
        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)
        self.params['b2'] = np.zeros(hidden_size)

        # 계층 생성
        self.layers = collections.OrderedDict()
        self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])
        self.layers['ReLu1'] = ReLu()
        self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2'])

        self.lastLayer = SoftmaxWithLoss()

    def predict(self, x):
        for layer in self.layers.values():
            x = layer.forward(x)

        return x

    # x: 입력 데이터, t: 정답 데이터
    def loss(self, x, t):
        y = self.predict(x)
        return self.lastLayer.forward(y, t)

    def accuracy(self, x, t):
        y = self.predict(x)
        y = np.argmax(y, axis=1)
        if t.ndim != 1: t = np.argmax(t, axis=1)

        acc = np.sum(y == t) / float(x.shape[0])
        return acc

    def gradient(self, x, t):
        # forward
        self.loss(x, t)

        # backward
        dout = 1
        dout = self.lastLayer.backward(dout)

        layers = list(self.layers.values())
        layers.reverse()

        for layer in layers:
            dout = layer.backward(dout)

        # save
        grads = {}
        grads['W1'] = self.layers['Affine1'].dW
        grads['b1'] = self.layers['Affine1'].db
        grads['W2'] = self.layers['Affine2'].dW
        grads['b2'] = self.layers['Affine2'].db

        return grads
</code></pre>
</div>

<p>TwoLayer Neural Network 를 생성하는 객체는 따로 파일에 저장하고 불러내는 것이 좋다. OrderedDict은 dictionary 형태로 입력 순서를 기억해주는 좋은 함수다.</p>

<div class="highlighter-rouge"><pre class="highlight"><code>from dataset.mnist import load_mnist
from two_layer_nn import TwoLayer

# data_loading
(x_train, y_train), (x_test, y_test) = load_mnist(normalize=True, one_hot_label=True)

train_loss_list = []
train_acc_list = []
test_acc_list = []

#highper parameter
epoch_num = 10000
train_size = x_train.shape[0]
batch_size = 100
alpha = 0.01  # learning rate
epsilon = 1e-6

# 1에폭당 반복 수
iter_per_epoch = max(train_size / batch_size, 1)

start = time.time()
nn = TwoLayer(input_size=784, hidden_size=100, output_size=10, weight_init_std=0.01)
for epoch in range(epoch_num):
    # get mini batch:
    batch_mask = np.random.choice(train_size, batch_size) # shuffle 효과
    x_batch = x_train[batch_mask]
    y_batch = y_train[batch_mask]

    # gradient 계산
    grad = nn.gradient(x_batch, y_batch)

    # update
    for key in ['W1', 'b1', 'W2', 'b2']:
        nn.params[key] = nn.params[key] - alpha * grad[key]

    # record
    loss = nn.loss(x_batch, y_batch)
    train_loss_list.append(loss)

    # 1에폭당 정확도 계산
    if epoch % iter_per_epoch == 0:
        train_acc = nn.accuracy(x_train, y_train)
        test_acc = nn.accuracy(x_test, y_test)
        train_acc_list.append(train_acc)
        test_acc_list.append(test_acc)
        print('# {0} | trian acc: {1:.5f} | test acc: {2:.5f}'.format(epoch, train_acc, test_acc))

end = time.time()
print('total time:', (end - start))

# 결과
# 0 | trian acc: 0.10775 | test acc: 0.10700
# 600 | trian acc: 0.10775 | test acc: 0.10700
# 1200 | trian acc: 0.10775 | test acc: 0.10700
# 1800 | trian acc: 0.10775 | test acc: 0.10700
# 2400 | trian acc: 0.10775 | test acc: 0.10700
# 3000 | trian acc: 0.10775 | test acc: 0.10700
# 3600 | trian acc: 0.10775 | test acc: 0.10700
# 4200 | trian acc: 0.10775 | test acc: 0.10700
# 4800 | trian acc: 0.10775 | test acc: 0.10700
# 5400 | trian acc: 0.10775 | test acc: 0.10700
# 6000 | trian acc: 0.10775 | test acc: 0.10700
# 6600 | trian acc: 0.10775 | test acc: 0.10700
# 7200 | trian acc: 0.10775 | test acc: 0.10700
# 7800 | trian acc: 0.10775 | test acc: 0.10700
# 8400 | trian acc: 0.10775 | test acc: 0.10700
# 9000 | trian acc: 0.10775 | test acc: 0.10700
# 9600 | trian acc: 0.10775 | test acc: 0.10700
# total time: 61.07117795944214
</code></pre>
</div>

<p>학습은 전혀 안되지만 수치 미분보다 더 빠르게 진행된다는 것을 알 수 있다.</p>

<p>왜 학습이 안됐을까에 대해서는 담은 시간에 이야기 하겠다.</p>

</article>



<section class="rss">
  <p class="rss-subscribe text"><strong>Subscribe <a href="/feed.xml">via RSS</a></strong></p>
</section>

<section class="share">
  <span>Share: </span>
  
    
    
      <a href="//www.facebook.com/sharer.php?t=NUMPY+with+NN+-+4%3A+Backpropagation&u=http%3A%2F%2Fsimonjisu.github.io%2Fdeeplearning%2F2017%2F12%2F15%2Fnumpywithnn_4.html"
        onclick="window.open(this.href, 'facebook-share', 'width=550,height=255');return false;">
        <i class="fa fa-facebook-square fa-lg"></i>
      </a>
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
</section>



  

  

  

  

  

  

  

  
    
    <!-- <h2 id="DeepLearning">6</h2> -->
    <!-- <h2 id="DeepLearning">/deeplearning/2018/01/13/numpywithnn_5.html</h2> -->
    
    <!-- <h2 id="DeepLearning">8</h2> -->
    <!-- <h2 id="DeepLearning">/deeplearning/2017/12/10/numpywithnn_3.html</h2> -->
    



  
	<section class="post-navigation">
		<span class="prev-post">
			
				<a href="/deeplearning/2017/12/10/numpywithnn_3.html">
					<span class="fa-stack fa-lg">
						<i class="fa fa-square fa-stack-2x"></i>
						<i class="fa fa-angle-double-left fa-stack-1x fa-inverse"></i>
					</span>
					<span class="page-number">NUMPY with NN - 3: Loss Function</span>
				</a>
			
		</span>
		<span class="next-post">
			
				<a href="/deeplearning/2018/01/13/numpywithnn_5.html">
					<span class="page-number">NUMPY with NN - 5: Optimizer</span>
					<span class="fa-stack fa-lg">
						<i class="fa fa-square fa-stack-2x"></i>
						<i class="fa fa-angle-double-right fa-stack-1x fa-inverse"></i>
					</span>
				</a>
			
		</span>
	</section>




  
  <section class="disqus">
    <div id="disqus_thread"></div>
    <script type="text/javascript">
      var disqus_shortname = 'soopace';

      /* * * DON'T EDIT BELOW THIS LINE * * */
      (function() {
          var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
          dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
          (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
  </section>
  


</div>
</div>

    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h3 class="footer-heading">Soo</h3>

    <div class="site-navigation">

      <p><strong>Site Map</strong></p>
      <ul class="pages">
        
        
          <li class="nav-link"><a href="/about/">About</a>
        
        
        
        
        
        
        
        
        
          <li class="nav-link"><a href="/posts/">Posts</a>
        
        
        
        
        
        
        
        
      </ul>
    </div>

    <div class="site-contact">

      <p><strong>Contact</strong></p>
      <ul class="social-media-list">
        <li>
          <a href="mailto:simonjisu@gmail.com">
            <i class="fa fa-envelope-o"></i>
            <span class="username">simonjisu@gmail.com</span>
          </a>
        </li>

        
          
          <li>
            <a href="https://www.facebook.com/simonjisu" title="Friend me on Facebook">
              <i class="fa fa-facebook"></i>
              <span class="username">simonjisu</span>
            </a>
          </li>
          
        
          
          <li>
            <a href="https://github.com/simonjisu" title="Fork me on GitHub">
              <i class="fa fa-github"></i>
              <span class="username">simonjisu</span>
            </a>
          </li>
          
        
          
        
          
        

      </ul>
    </div>

    <div class="site-signature">
      <p class="rss-subscribe text"><strong>Subscribe <a href="/feed.xml">via RSS</a></strong></p>
      <p class="text">My Blog
</p>
    </div>

  </div>
</footer>

<!-- Scripts -->
<script src="//code.jquery.com/jquery-1.11.2.min.js"></script>

<!-- Mathjax -->
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/lightbox2/2.7.1/js/lightbox.min.js"></script>
<script type="text/javascript">
$(document).ready(function() {
  // Default syntax highlighting
  hljs.initHighlightingOnLoad();
  $("code").addClass("python")
  // Header
  var menuToggle = $('#js-mobile-menu').unbind();
  $('#js-navigation-menu').removeClass("show");
  menuToggle.on('click', function(e) {
    e.preventDefault();
    $('#js-navigation-menu').slideToggle(function(){
      if($('#js-navigation-menu').is(':hidden')) {
        $('#js-navigation-menu').removeAttr('style');
      }
    });
  });
});
$("code").addClass("python")
</script>

<!--lightSlider-->
<script src="/js/lightslider.js"></script>
<script src='/js/multi_slider.js' type="text/javascript"></script>





    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-102691608-1', 'auto');
  ga('send', 'pageview');
</script>


  </body>

</html>
