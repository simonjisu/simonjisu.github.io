<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Soopace</title>
    <description>Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.
</description>
    <link>https://simonjisu.github.io/</link>
    <atom:link href="https://simonjisu.github.io/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sat, 28 Aug 2021 14:47:32 +0900</pubDate>
    <lastBuildDate>Sat, 28 Aug 2021 14:47:32 +0900</lastBuildDate>
    <generator>Jekyll v4.2.0</generator>
    
      <item>
        <title>Machine Learning: Evaluation</title>
        <description>&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1rxOWFSNawoCtGJQLLpQzE90tYWCAtEEI&quot; alt=&quot;Reference: Pixabay&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Reference: Pixabay&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h1 id=&quot;confusion-matrix&quot;&gt;Confusion Matrix&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Confusion Matrix&lt;/strong&gt; 는 보통 supervised learning 관련 머신러닝 알고리즘의 퍼포먼스를 측정하기 위한 도구로 사용된다. 자주 사용되는 것인데 계속 잊어버려서 한 번 정리해보고 어떤 상황에서 사용되는지 알아보자.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;개념&quot;&gt;개념&lt;/h1&gt;

&lt;p&gt;분류 문제에서 정확도를 평가지표로 사용할 때, 클래스의 불균형 문제가 있으면 잘못된 결과를 낳다. 예를 들어, 개/고양이를 분류하는 문제에서 95개의 고양이와 5개의 개 사진이 있고, 어떤 모델이 전부 고양이를 예측했다. 최종 정확도는 95%지만, 고양이의 검출율 은 100% (95개 중 95개 예측)이고 개의 검출율를 0% (5개 중 0개 예측)이다.&lt;/p&gt;

&lt;p&gt;정확도로 탐지할 수 없는 모델의 문제점을 정보(informedness)로 표현을 하게되자 어떤 문제가 있는지 알게 되었다. 이 예시에서는 모델이 항상 고양이만 예측한다는 것이다.&lt;/p&gt;

&lt;p&gt;두 개의 클래스가 있을 때 Confusion Matrix는 다음과 같이 정의 된다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;Predicted&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;Positive&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;Negative&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Actual&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;Positive&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;True Positive&lt;/td&gt;
      &lt;td&gt;False Negative&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;Negative&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;False Positive&lt;/td&gt;
      &lt;td&gt;True Negative&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;여기서 행은 실제(Actual) 데이터의 레이블이고, 칼럼은 모델이 예측(Predict)한 레이블을 뜻한다. 표의 내용은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(앞)진위여부 (뒤)예측&lt;/code&gt;과 같이 해석하는게 좋다. 즉, True Positive는 예측(Predicted)는 Positive인데 실제(Actual)로 Positive라서 진위 여부는 True다. 하나더 예를 보면 False Negative면 예측은 Negative인데 실제로 Negative라 진위 여부는 False다.&lt;/p&gt;

&lt;p&gt;Confusion Matrix에서 파생되는 여러가지 지표들이 있는데 지금부터 알아보겠다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;지표&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;공식&lt;/th&gt;
      &lt;th&gt;설명&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Accuracy&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$\dfrac{(TP + TN)}{(TP + TN + FN + FP)}$&lt;/td&gt;
      &lt;td&gt;전체 맞게 예측한 비율&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Precision&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$\dfrac{TP}{(TP + FP)}$&lt;/td&gt;
      &lt;td&gt;예측한 Positive 중에 맞게(True) 예측한 비율&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Recall / Sensitivity&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$\dfrac{TP}{(TP + FN)}$&lt;/td&gt;
      &lt;td&gt;실제 Positive 중에 맞게(True) 예측한 비율&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Fall-out&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$\dfrac{FP}{(FP + TN)}$&lt;/td&gt;
      &lt;td&gt;실제 Negative 중에 틀리게(False) 예측한 비율&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;F1 Score&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$\dfrac{2}{(1/Precision + 1/Recall)} = \dfrac{2\times Precision\times Recall}{Precision + Recall}$&lt;/td&gt;
      &lt;td&gt;Precision 과 Recall의 조화 평균, 데이터 분포가 불균형 일때 사용, 큰 비중이 끼치는 bias 가 줄어듦&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;예시&quot;&gt;예시&lt;/h1&gt;

&lt;p&gt;예를 들어, 쇼핑몰의 머신러닝 개발자가 조금더 편한 태깅을 위해, 의류 사진를 보고 어떤 종류인지 예측해서 분류하는 머신러닝 모델을 만들었다고 생각해보자. 의류는 총 3가지 class 이며 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;cls_dict&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;상의&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;하의&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;신발&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그리고 신규 물품 사진에 대한 모델의 에측 결과를 다음과 같이 저장했다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
    &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 상의 6개
&lt;/span&gt;    &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 하의 10개
&lt;/span&gt;    &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 신발 9개
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그러면 Confusion matrix를 다음과 같이 만들 수 있다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unique&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;confusion_matrix&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;confusion_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;confusion_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#         Predict
#        [[4 1 1]
# Target  [6 2 2]
#         [3 0 6]]
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;accuracy&quot;&gt;Accuracy&lt;/h2&gt;

&lt;p&gt;정확도는 전체에서 옳게 맞춘 비율임으로 다음과 같이 계산된다.&lt;/p&gt;

\[\text{Accuracy} =\dfrac{4+2+6}{25}\]

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;total&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;true_positive&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eye&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;confusion_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;true_positive&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;total&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 0.48
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;precision&quot;&gt;Precision&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;정밀도(Precision)&lt;/strong&gt; 는 Positive라고 예측한 것들 중에서 실제로 맞게 예측한 비율임으로 다음과 같이 계산된다.&lt;/p&gt;

\[\begin{aligned} \text{Class 0} &amp;amp;= \dfrac{4}{4+6+3} \\ \text{Class 1} &amp;amp;= \dfrac{2}{1+2+0} \\ \text{Class 2} &amp;amp;= \dfrac{6}{1+2+6} \end{aligned}\]

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;predicted&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;confusion_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;precisions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;true_positive&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predicted&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;precisions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Macro Precision &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;precisions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;precisions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# [0.3077 0.6667 0.6667]
# Macro Precision 0.5470
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;recall--sensitivity&quot;&gt;Recall / Sensitivity&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;재현율(Recall/Sensitivity)&lt;/strong&gt; 은 실제 Positive 인것들 중에서 맞게 예측한 비율임으로 다음과 같이 계산된다.&lt;/p&gt;

\[\begin{aligned} \text{Class 0} &amp;amp;= \dfrac{4}{4+1+1} \\ \text{Class 1} &amp;amp;= \dfrac{2}{6+2+2} \\ \text{Class 2} &amp;amp;= \dfrac{6}{3+0+6} \end{aligned}\]

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;actual_count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;confusion_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;recalls&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;true_positive&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;actual_count&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recalls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Macro Recall &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recalls&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recalls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# [0.6667 0.2    0.6667]
# Macro Recall 0.5111
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;fallout&quot;&gt;Fallout&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Fallout&lt;/strong&gt; 은 Negative라고 예측했는데 실제로 Positive라고 맞춘 비율임으로 다음과 같이 계산된다.&lt;/p&gt;

\[\begin{aligned} \text{Class 0} &amp;amp;= \dfrac{6+3}{6+2+2+3+0+6} \\ \text{Class 1} &amp;amp;= \dfrac{1+0}{4+1+1+3+0+6} \\ \text{Class 2} &amp;amp;= \dfrac{1+2}{4+1+1+6+2+2} \end{aligned}\]

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;itertools&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;combinations&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;fallouts&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cls_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;neg_idx&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;reversed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;combinations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;false_positive&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;confusion_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;neg_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cls_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;negative&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;confusion_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;neg_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;fpr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;false_positive&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;negative&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;fallouts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fpr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
&lt;span class=&quot;n&quot;&gt;fallouts&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fallouts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fallouts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Macro Fallout &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fallouts&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fallouts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# [0.4737 0.0667 0.1875]
# Macro Fallout 0.2426
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;f1-score&quot;&gt;F1 Score&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;F1 Score&lt;/strong&gt; 는 다음과 같이 계산된다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;f1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;precisions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;recalls&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;precisions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;recalls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Total F1 &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# [0.4211 0.3077 0.6667]
# Total F1 0.4651
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;scikit-learn&quot;&gt;Scikit-Learn&lt;/h1&gt;

&lt;p&gt;Scikit-learn 패키지중 이를 한번에 구해주는 패키지가 있다. 이 표를 보고 모델의 성능을 한번 평가해보자.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.metrics&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;classification_report&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;classification_report&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target_names&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;상의&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;하의&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;신발&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#               precision    recall  f1-score   support
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#         상의       0.31      0.67      0.42         6
#         하의       0.67      0.20      0.31        10
#         신발       0.67      0.67      0.67         9
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#     accuracy                           0.48        25
#    macro avg       0.55      0.51      0.47        25
# weighted avg       0.58      0.48      0.46        25
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;precision-1&quot;&gt;Precision&lt;/h3&gt;

&lt;p&gt;정밀도는 Type-I Error와 연관있다. Type-I Error는 실제 Negative를 Positive라고 예측한 경우인데, 예를 들어 재판의 경우 죄를 짓지 않았는데 유죄 판결을 내리는 경우 피고인은 무고할 수가 있다.  Precision이 높을 수록 Type-I Error를 줄일 수 있다.&lt;/p&gt;

&lt;p&gt;의류분류기 모델의 경우 “상의”에 대해서는 상의가 아닌데 상의라고 판별할 가능성이 높다는 것이다.&lt;/p&gt;

&lt;h3 id=&quot;recall&quot;&gt;Recall&lt;/h3&gt;

&lt;p&gt;재현율은 Type-II Error와 연관있다. Type-II Error는 실제 Positive를 Negative라고 예측한 경우인데, 암 판정의 예시를 들면, 암이 있는데 암이 없다고 판정한 것이며, 이는 환자에게 치명적일 수가 있다. Recall이 높을 수록 Type-II Error를 줄 일 수 있다.&lt;/p&gt;

&lt;p&gt;의류분류기 모델의 경우 “하의”에 대해서는 실제로 “하의”인데 다른 클래스라고 판별할 가능성이 높다는 것이다.&lt;/p&gt;

&lt;h3 id=&quot;f1-score-1&quot;&gt;F1 Score&lt;/h3&gt;

&lt;p&gt;조화 평균인 F1 Score은 데이터 분포가 불균형 일때 사용되는데, 큰 비중이 끼치는 bias 가 줄어들게 된다. 예를 들어 recall이 $0.9$ 이고 precision이 $0.01$ 인 경우, 일반 평균을 구하면 $(0.9+0.01)/2 = 0.455$가 나오지만 조화 평균을 사용하게 되면, $2\times 0.9 \times 0.01 / (0.9 + 0.01) = 0.020$으로 굉장히 낮게 나온다.&lt;/p&gt;

&lt;p&gt;의류분류기 모델의 경우 “신발”의 성능이 상대적으로 “하의”, “상의”보다는 더 나은 퍼포먼스를 보인다.&lt;/p&gt;
</description>
        <pubDate>Sat, 28 Aug 2021 12:13:01 +0900</pubDate>
        <link>https://simonjisu.github.io/machinelearning/2021/08/28/mleval.html</link>
        <guid isPermaLink="true">https://simonjisu.github.io/machinelearning/2021/08/28/mleval.html</guid>
        
        
        <category>machinelearning</category>
        
      </item>
    
      <item>
        <title>[NLP] Hybrid Ranking Network for Text-to-SQL</title>
        <description>&lt;p&gt;Paper Link: &lt;a href=&quot;https://arxiv.org/abs/2008.04759&quot;&gt;https://arxiv.org/abs/2008.04759&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;문제를 column-wise ranking, decoding 그리고 column-wise 결과물을 SQL 룰에 따라서 모으는 것으로 나눴다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;1-introduction&quot;&gt;1. Introduction&lt;/h1&gt;

&lt;p&gt;Relational database는 실제 세상에서 널리 사용되고 있다. SQL은 많이 사용되고 있으나 보통 이를 마스터하기엔 어렵다. 자연어를 통해서 데이터베이스와 소통하는 방법을 오랫동안 연구되어 왔다. 이를 일반화 하면 &lt;strong&gt;“Natural Language Interface to Databases(NLIDBs)”&lt;/strong&gt; 라는 분야다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/cmp-lg/9503016&quot;&gt;Natural Language Interfaces to Databases – An Introduction&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;최근에 딥러닝 기반의 방법들이 이를 해결해보고자 했는데 이를 “NL-to-SQL” 혹은 “Text-to-SQL”이라고 하는데, 이 논문에선 Text-to-SQL 문제를 WikiSQL 데이터로 실험한 것에 대해서만 다룬다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;WikiSQL: &lt;a href=&quot;https://github.com/salesforce/WikiSQL&quot;&gt;https://github.com/salesforce/WikiSQL&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;제약 조건: 테이블의 내용을 알고 각 질의(Question)는 하나의 테이블만 해당함&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;WikiSQL데이터에서 이전에 제안된 연구들은 여러 난관이 있었다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;NL question과 table schema 정보를 어떻게 &lt;strong&gt;조합(fuse)&lt;/strong&gt; 할 것인가?&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;실행가능&lt;/strong&gt;하고 &lt;strong&gt;정확한&lt;/strong&gt; SQL문을 어떻게 생성할 것인가?&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;pre-trained language model&lt;/strong&gt;을 어떻게 활용할 것인가?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이 논문의 동기는 3번 문제였으나 이전의 다른 접근 방법들(Hwang et al, 2019; He et al, 2019)이 language model의 힘을 이끌어 내지 못한다는 점을 주장한다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Encoding 단계에서 전체 테이블 스키마를 자연어 질의와 합쳐서 BERT에 전달한다.&lt;/li&gt;
  &lt;li&gt;Decoding 단게에서 각 칼럼의 hidden representation을 필요로 한다. 이때 칼럼 토큰들을 adhoc pooling을 하게 된다. 이 ad-hoc pooling이 정보손실을 야기하고 불필요하게 복잡도를 올린다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;따라서 이러한 문제를 해결하기 위해 하나의 칼럼만 인코딩하는 방법을 선택했다. 그리고 Decoding 단게에서 multiple sub-tasks를 수행하게 된다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Sub-Tasks: SELECT &amp;amp; WHERE column ranking, condition operator 그리고 condition value span 진행&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그리고 Decoder가 SQL문을 바로 생성하는 것은 아니기 때문에, 직관적인 룰을 사용하여 결과를 합친다. 이를 통해 다음과 같은 효과를 얻을 수 있다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;먼저, question과 column pair 형태가 BERT 혹은 RoBERTa와 sentence pair training task와 유사하기 때문에 효율적으로 이용할 수 있다.&lt;/li&gt;
  &lt;li&gt;둘째, 하나의 칼럼을 인코딩에 사용하기 때문에 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[CLS]&lt;/code&gt; 토큰 벡터에는 모든 정보(question과 column)를 포함하고 있다. 따라서 더 이상 추가 pooling 혹은 더 복잡한 layer를 추가할 필요가 없다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;2-related-work&quot;&gt;2. Related Work&lt;/h1&gt;

&lt;p&gt;생략&lt;/p&gt;

&lt;h1 id=&quot;3-approach&quot;&gt;3. Approach&lt;/h1&gt;

&lt;h2 id=&quot;31-input-representation&quot;&gt;3.1 Input Representation&lt;/h2&gt;

&lt;p&gt;질문 $q$ 와 column 후보 $c_1, c_2, \cdots, c_k$ 가 주어졌을 때, 입력 정보쌍를 다음과 같이 구성할 수 있다.&lt;/p&gt;

\[\big( \text{Concat}(\phi_{c_i}, t_{c_i}, c_i), q \big)\]

&lt;p&gt;여기서 $\phi_{c_i}$는 column $c_i$의 타입 정보(string, real, integer 등), $\text{Concat}$함수는 blank space로 토큰을 하나의 string으로 합친다. 따라서, 입력은 tokenizer에 의해서 다음과 같이 토큰화 된다.&lt;/p&gt;

\[\text{[CLS]}, x_1, x_2, \cdots, x_m, \text{[SEP]}, y_1, y_2, \cdots, y_n, \text{[SEP]}\]

&lt;p&gt;여기서 $x_1, x_2, \cdots, x_m$은 $\text{Concat}(\phi_{c_i}, t_{c_i}, c_i)$을 토큰화 한 것, $y_1, y_2, \cdots, y_n$는 질문 $q$에 대해 토큰화 한 것이다.&lt;/p&gt;

&lt;h2 id=&quot;32-sql-query-representation-and-tasks&quot;&gt;3.2 SQL Query Representation and Tasks&lt;/h2&gt;

&lt;p&gt;이 논문에서 SQL은 nested 구조가 아니기 때문에 다음과 같은 폼을 가진다(WikiSQL 데이터 세트의 제약조건).&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;s&quot;&gt;&quot;sql&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;select&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;agg1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scol1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;agg2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scol2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...],&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;from&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;table1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;table2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...],&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;where&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wcol1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;op1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wcol2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;op2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;SQL를 2개의 Task(Object)으로 분류 할 수 있다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;구체적 칼럼이 필요한 Task: aggregation operator, value text span&lt;/li&gt;
  &lt;li&gt;구체적 칼럼이 필요하지 않은 Global Task: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;select_num&lt;/code&gt;(SELECT 구문의 갯수), &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;where_num&lt;/code&gt;(WHERE 조건문의 갯수)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;각 칼럼-질문 입력쌍 $(c_i, q)$에 대해서 1번 목적은 sentence pair classification과 question answering task로 도식화 할 수 있다. 그 전에 각 토큰에 해당하는 벡터를 다음과 같이 표현한다.&lt;/p&gt;

\[h_{\text{[CLS]}}, h_{x_1}, h_{x_2}, \cdots, h_{x_m}, h_{\text{[SEP]}}, h_{y_1}, h_{y_2}, \cdots, h_{y_n}, h_{\text{[SEP]}}\]

&lt;p&gt;&lt;strong&gt;구체적 칼럼이 필요한 Task&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;aggregation operator&lt;/strong&gt; $a_j$: $P(a_j \vert c_i, q) = \text{softmax}(W^{agg}[j, :] \cdot h_{\text{[CLS]}})$로 정의한다. Training 때, SELECT 구문에 속하지 않는 칼럼은 mask out 한다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;condition operator&lt;/strong&gt; $o_j$:  $P(o_j \vert c_i, q) = \text{softmax}(W^{op}[j, :] \cdot h_{\text{[CLS]}})$로 정의한다. Training 때, WHERE 구문에 속하지 않는 칼럼은 mask out한다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;value&lt;/strong&gt; &lt;strong&gt;start &amp;amp; end index&lt;/strong&gt;: $P(y_j=\text{start} \vert c_i, q) = \text{softmax}(W^{\text{start}} \cdot h_j^q)$와 $P(y_j=\text{end} \vert c_i, q) = \text{softmax}(W^{\text{end}} \cdot h_j^q)$로 정의한다. Training 때, WHERE 구문에 속하지 않는 칼럼에 대해서 시작과 끝 인덱스는 0으로 세팅한다(BERT QA 세팅과 비슷).&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;구체적 칼럼이 필요하지 않은 Global Task&lt;/strong&gt;&lt;/p&gt;

\[P(z \vert q) = \sum_{c_i} P(z \vert c_i, q)P(c_i \vert q)\]

&lt;ul&gt;
  &lt;li&gt;$P(z \vert c_i, q)$: Sentence pair classification&lt;/li&gt;
  &lt;li&gt;$P(c_i \vert q)$: 칼럼과 질문의 유사도, 계산 방법은 다음 세션에서 소개&lt;/li&gt;
  &lt;li&gt;SELECT 구문의 개수 $n_s$에 대해서는 $P(n_s \vert q) = \sum_{c_i} P(n_s \vert c_i, q) P(c_i \vert q)$로 정의&lt;/li&gt;
  &lt;li&gt;WHERE 구문의 개수 $n_w$에 대해서는 $P(n_w \vert q) = \sum_{c_i} P(n_w \vert c_i, q) P(c_i \vert q)$로 정의&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;33-column-ranking&quot;&gt;3.3 Column Ranking&lt;/h2&gt;

&lt;p&gt;각 질문 $q$에 대해서 $\mathcal{S}_q$를 SELECT 구문과 연관된 칼럼, $\mathcal{W}_q$를 WHERE 구문과 연관된 칼럼이라고 하면, 쿼리문에 나온 칼럼들을 $\mathcal{R}_q \doteq \mathcal{S}_q \cup \mathcal{R}_q$ 로 정의할 수 있다. 마지막으로 후보 칼럼 집합을 $\mathcal{C}_q = \lbrace c_1, c_2, \cdots, c_k \rbrace$이라고 정의 할 수 있으며, 당연하게도 $\mathcal{R}_q \subseteq \mathcal{C}_q$ 관계가 성립된다.&lt;/p&gt;

&lt;p&gt;이에 따라 3개의 &lt;strong&gt;Ranking Tasks&lt;/strong&gt;를 정의할 수 있다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT-Rank&lt;/code&gt;: $q$ 와 연관된 쿼리에서 SELECT 구문에 포함된 칼럼 $c_i \in C_q$을 랭킹, $c_i \in \mathcal{S}_q$&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WHERE-Rank&lt;/code&gt;: $q$ 와 연관된 쿼리에서 WHERE 구문에 포함된 칼럼 $c_i \in C_q$을 랭킹, $c_i \in \mathcal{W}_q$&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Relevance-Rank&lt;/code&gt;: $q$ 와 연관된 쿼리에서 SQL 쿼리 포함된 칼럼 $c_i \in C_q$을 랭킹, $c_i \in \mathcal{R}_q$&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;BERT는 ranking tasks에서 강력한 파워를 보여준다. &lt;a href=&quot;https://arxiv.org/abs/1904.07531&quot;&gt;Qiao et al, 2019&lt;/a&gt;에서 $w \cdot h_{\text{[CLS]}}$를 ranking score로 간주해서 fine-tuning을 하게 된다. 그러면 각 Ranking Tasks에서 Ranking Score는 다음과 같이 정의 할 수 있다.&lt;/p&gt;

\[\begin{aligned} 
P(c_i \in \mathcal{S}_q \vert q) &amp;amp;= \text{sigmoid}(w_{sc} \cdot h_{\text{[CLS]}}) \\ P(c_i \in \mathcal{W}_q \vert q) &amp;amp;= \text{sigmoid}(w_{wc} \cdot h_{\text{[CLS]}}) \\ P(c_i \in \mathcal{R}_q \vert q) &amp;amp;= \text{sigmoid}(w_{rc} \cdot h_{\text{[CLS]}})
\end{aligned}\]

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT-Rank&lt;/code&gt; Score $P(c_i \in \mathcal{S}_q \vert q)$에서 가장 가능성이 높은 후보를 선택한다. 다만 SELECT 구문의 칼럼 갯수 $n_s$를 유지하기 위해서 다음과 같이 결정할 수 있다.&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;특정 threshold 보다 높은 확률을 가진 칼럼 후보만 선택&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;3.2에서 제안한 $n_s$를 직접 예측하기&lt;/p&gt;

\[\hat{n}_s = \underset{n_s}{\arg \max} P(n_s \vert q) = \sum_{c_i \in \mathcal{C}_q} P(n_s \vert c_i, q) P(c_i \in \mathcal{R}_q \vert q)\]

        &lt;p&gt;이번 논문에서는 2번째 방법을 사용했다.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WHERE-Rank&lt;/code&gt; Score $P(c_i \in \mathcal{W}_q \vert q)$ 도 마찬가지로 직접 $n_w$를 예측 한다.&lt;/p&gt;

\[\hat{n}_w = \underset{n_w}{\arg \max} P(n_w \vert q) = \sum_{c_i \in \mathcal{C}_q} P(n_s \vert c_i, q) P(c_i \in \mathcal{R}_q \vert q)\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;34-training-and-inference&quot;&gt;3.4 Training and Inference&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Training&lt;/strong&gt; 단계에서 labeled samples를 먼저 $n_i$ column-question samples 로 바꾼다.&lt;/p&gt;

\[\begin{aligned}
\text{labeled samples} &amp;amp;: (q_i, \mathcal{R}_{q_i}), \mathcal{C}_{q_i} = \lbrace c_{q_i1}, c_{q_i2}, \cdots c_{q_in_i} \rbrace \\
\text{column-question samples} &amp;amp;: (c_{q_i1}, q_i), (c_{q_i2}, q_i), \cdots, (c_{q_in_i}, q_i)
\end{aligned}\]

&lt;p&gt;SQL 쿼리 레이블 $(q_i, \mathcal{C}_{q_i})$은 column-question samples와 함께 3.2와 3.3의 Task를 수행하게 되며, 이 문제의 Optimization Object는 모든 샘플에 대해서 $(c_{q_1}, q_1), (c_{q_2}, q_2), \cdots, (c_{q_n}, q_n)$, 모든 Task의 cross-entropy loss를 줄이는 것이다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Inference&lt;/strong&gt; 단계에서는 각 Task의 class labels를 예측한다. 그리고 다음 스텝으로 쿼리문이 만들어진다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;select_num&lt;/code&gt; $n_{s}$ 과 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;where_num&lt;/code&gt; $n_w$를 예측한다.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$c_i \in \mathcal{C}_q$ 의 랭킹을 통해 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT-Rank&lt;/code&gt; Score를 구하고 상위 $\hat{n}_s$  개의 칼럼($\hat{sc}_1, \hat{sc}_2, \cdots, \hat{sc}_{\hat{n}_s}$) 을 선택한다 따라서 SELECT 구문은 다음과 같으며, $\hat{agg}_i$ 는 예측된 $\hat{sc}_i$ ($i = 1, 2, \cdots, \hat{n}_s$)의 aggregation operator다&lt;/p&gt;

\[[(\hat{agg}_1, \hat{sc}_1), (\hat{agg}_2, \hat{sc}_2), \cdots, (\hat{agg}_{\hat{n}_s}, \hat{sc}_{\hat{n}_s})]\]
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$c_i \in \mathcal{W}_q$의 랭킹을 통해 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WHERE-Rank&lt;/code&gt; Score를 구하고 상위 $\hat{n}_w$ 개의 칼럼($\hat{wc}_1, \hat{wc}_2, \cdots, \hat{wc}_{\hat{n}_w}$) 을 선택한다 따라서 WHERE 구문은 다음과 같으며, $\hat{op}_i, \hat{val}_i$ 는 예측된 $\hat{wc}_i$ ($i = 1, 2, \cdots, \hat{n}_s$)의 condition operator와 value text다.&lt;/p&gt;

\[[(\hat{wc}_1, \hat{op}_1, \hat{val}_1), (\hat{wc}_2, \hat{op}_2, \hat{val}_2), \cdots, (\hat{wc}_{\hat{n}_s}, \hat{op}_{\hat{n}_s}, \hat{val}_{\hat{n}_s})]\]
  &lt;/li&gt;
  &lt;li&gt;$\hat{\mathcal{T}} = \lbrace \hat{t}_1, \hat{t}_2, \cdots, \hat{t}_{n_t} \rbrace$를 모든 예측된 칼럼 $\hat{sc}_i, \hat{wc}_i$의 테이블 집합이라고 정의하면, FROM 구문은 $[\hat{t}_1, \hat{t}_2, \cdots, \hat{t}_{n_t}]$에 해당된다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;35-execution-guided-decoding&quot;&gt;3.5 Execution-guided decoding&lt;/h2&gt;

&lt;p&gt;Neural Network 모델은 입력 질문, column-value 관계에서 추출된 syntactic과 semantic 정보로 SQL 쿼리를 예측한다. 하지만, 런타임에서 좋은 예측을 못내고 있는데 그 이유는 다음과 같다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;데이터베이스의 값과 칼럼들은 이산적인 관계를 가지며 특별한 제약도 없다. 따라서 매핑된 칼럼들은 값이나 성격이 수시로 바뀔 수 있다. 훈련된 모델은 최신 데이터베이스 정보를 놓쳐서 예전 정보를 기반으로 예측할 가능성이 있다.&lt;/li&gt;
  &lt;li&gt;각 Task에 해당하는 모델의 출력들은 독립적으로 예측한 것이다. 따라서 말이 안되는 조합을 생성할 수 도 있다. string-type의 칼럼에 aggregation operator, greater-than이라는 condition operator를 예측하는 등을 예로 들 수 있다. 이런 케이스들은 가능성을 원천적으로 제거해야한다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이러한 이슈를 해결하기 위해 &lt;a href=&quot;https://arxiv.org/abs/1807.03100&quot;&gt;Wang et al. 2018&lt;/a&gt;에서는 Execution-guided decoding(EG)를 제안했다. 이 논문에서는 SQL 쿼리문 생성시, 만약 데이터베이스 엔진이 런타임 에러가 나거나 빈 출력을 반환 시, 수정을 해주는 아이디어를 제안했다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1NJelQlAmhTJdr62nH40QwTDul3kkUMY5&quot; alt=&quot;Execution Guided Decoding 알고리즘&quot; width=&quot;75%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Execution Guided Decoding 알고리즘&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h1 id=&quot;4-experiment&quot;&gt;4. Experiment&lt;/h1&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1KwHiNi20fOvrP3Cf7TzhlEmZjHf68jlN&quot; alt=&quot;Table 1&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Table 1&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;Logical form accuracy를 봤을 때, WikiSQL 데이터 세트에서 우수함을 보인다.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1WT043OhVRZ5ARrv81DZJZhLuLzsctFUp&quot; alt=&quot;Table 2&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Table 2&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;execution accuracy에서 볼 수 있듯이, HydraNet은 generalization에서도 더 우수함을 보였다.&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Fri, 13 Aug 2021 22:00:01 +0900</pubDate>
        <link>https://simonjisu.github.io/paper/2021/08/13/hybridranking.html</link>
        <guid isPermaLink="true">https://simonjisu.github.io/paper/2021/08/13/hybridranking.html</guid>
        
        
        <category>paper</category>
        
      </item>
    
      <item>
        <title>[글또 6기] 포스트 작성계획 및 다짐</title>
        <description>&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1qmObbD3KqGx2x-PDhXjQzDJQirST_MiC&quot; alt=&quot;그림출처: Pixabay, 그리스가 가고싶어서 넣은 그림&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;그림출처: Pixabay, 그리스가 가고싶어서 넣은 그림&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h1 id=&quot;글또-6기-참여를-시작하며&quot;&gt;글또 6기 참여를 시작하며&lt;/h1&gt;

&lt;p&gt;지난 글또 3, 4기 이후 잠깐 대학원 생활 한다고 1회 쉬었던 글또를 다시 참여하게 됐다. 이번에는 무려 131 명이라고 한다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;글또 페이스북: https://www.facebook.com/groups/geultto/&lt;/li&gt;
  &lt;li&gt;글또 노션 페이지: https://bit.ly/geultto&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;지난 번에 실행할 수 있는 계획을 쓰는게 중요하다고 생각해서 &lt;a href=&quot;https://simonjisu.github.io/others/2020/02/19/geultto4.html&quot;&gt;4기 때 썼던 다짐&lt;/a&gt;을 다시 보니, 그래도 나름 글을 꾸준히 쓴것 같다(12회/13회 글 작성, 패스 1회 사용, 피드백 1회 미달). 나름 시리즈로 기본적인 알고리즘에 대한 글도 써서 사람들에게 도움이 되서 나름 뿌듯했다.&lt;/p&gt;

&lt;p&gt;그러나 사람은 목표를 높게 잡아야하는 법, 이번에는 패스를 한 번도 사용하지 않고, 매 회자마다 글을 작성해보려고 한다. 사실 지원할 때부터 미리 생각해둔 주제들이 있어서 어떤 글을 쓸지는 이미 정해져있는데, 대학원 마지막 학기라 시간 관리를 잘 해야한다고 생각된다. 이번에도 잘 해보자!&lt;/p&gt;

&lt;h1 id=&quot;포스트-작성-계획&quot;&gt;포스트 작성 계획&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Semantic Parsing&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;대학원 학위 논문을 이 분야로 정해서 공부한 것을 잘 정리해보려고 한다. 나는 어떤 기술이던 사람에게 도움이 되어야 한다고 생각한다. 아무리 좋은 기술이라도, 현실에서 쓰이지 못하면 그것은 그림의 떡이라고 생각된다(물론 아직 어플리케이션 연구가 덜 되서 그런 것일 수도 있다).&lt;/p&gt;

&lt;p&gt;Text2SQL은 쿼리문을 잘 모르는 사람들에게 분명 유용한 기술이 될 것이라 생각한다. 주변 일반 회사를 다니는 사람들의 이야기를 들어보면 데이터 분석이 대세여서 해보려고 하는데, 데이터를 DB에서 불러오는 것 부터가 문제라고 한다. 매번 사내 개발자에게 도움을 청할 수도 없는 노릇이고 학원에 가서 SQL를 듣자니 흥미가 크게 나지 않는다고 한다.&lt;/p&gt;

&lt;p&gt;나는 Text2SQL이 이런 사람들을 위한 기술이라 생각한다. 뿐만 아니라 조금 긴 시각으로 보면 Board Meeting 같은 곳에서 필요한 예측을 자연어로 질의하고 이에대한 추론을 해낼 수만 있다면, 더 효율적인 미팅이 되지 않을까 생각한다. 그래서 이 기술을 제대로 연구해 보고 싶다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Background Semantic Parsing &amp;amp; Text2SQL&lt;/li&gt;
  &lt;li&gt;Datasets in Text2SQL&lt;/li&gt;
  &lt;li&gt;Data Agumentation in NLP&lt;/li&gt;
  &lt;li&gt;Models: Hybrid Ranking Network for Text-to-SQL&lt;/li&gt;
  &lt;li&gt;Models: RYANSQL: Recursively Applying Sketch-based Slot Fillings for Complex Text-to-SQL in Cross-Domain Databases&lt;/li&gt;
  &lt;li&gt;Beam Search decoding: Execution-Guided Neural Program Decoding&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Machine Learning &amp;amp; Computer Science&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;기본기를 항상 다지자고 했는데 막상 정리할 시간이 없었다. 다행이도 이번에 논문 자격시험을 통해 이를 한 번에 훑어볼 기회가 생겨서 이를 다시 정리해보려고 한다. 지식을 정리하는 이유는 인간은 기억력은 나약해서 항상 잊기 때문이고 나중에 정리 한 것을 보면 금방 떠오르기 때문이다.&lt;/p&gt;

&lt;p&gt;면접에 갔을 때, 어떤 질문을 물어보면 한 번에 잘 대답한 적이 있는가? 정리를 한 번 했던 경우와 그렇지 않은 경우는 그 대답의 수준이 천지차이다. 정리를 한 경우, 부분 부분 나눠서 기억하고 있던 지식이 상위 계층으로 축약이 되면서, 두괄식 답변을 할 수 있게 만든다(물론 말 하는 스킬에도 연관이 있지만 도움이 되는 것은 사실). 두괄식으로 대답하지 못하는 경우는 해당 지식에 대해서 부분적으로 알고 있다는 반증이기도 하다. 그래서 나는 이번에 머신러닝 지식을 정리하고 이를 한 마디로 요약하는 연습을 해보려고 한다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Bagging: Random Forest&lt;/li&gt;
  &lt;li&gt;Evaluation Metrics Summary&lt;/li&gt;
  &lt;li&gt;Loss Functions&lt;/li&gt;
  &lt;li&gt;Linear &amp;amp; Logistic Regression&lt;/li&gt;
  &lt;li&gt;Data structure summary&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Others&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;취업 할 준비가 되서 그런지, 요즘 회사에 지원 이력서를 쓰고 있는데, 이번 글또에서 사람들과 이런 경험을 같이 공유해봤으면 좋겠다. 나는 어떤 사람인지를 스스로 생각해보고, 내가 잘하는게 무엇인지를 잘 알아보면 좋을 것 같다. 이런 생각을 공유하면서 사람들은 어떤 생각을 가지고 있는지 내가 배울만한 점은 더 있는지 알아보고 싶다. 그리고 내가 생각했던 회사의 모습 혹은 회사가 내 이력서를 보고 생각한 나의 모습을 회사지원하면서 직접 경험하고, 취업을 준비한 사람들과 공유하면서 간접적으로 경험하고 싶다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;나를 뒤돌아 보는 연습: 메타인지&lt;/li&gt;
  &lt;li&gt;나는 어떤 일을 하고 싶은가?&lt;/li&gt;
  &lt;li&gt;채용 공고에서 회사가 원하는 사람, 세세한 차이를 구별해낼 수 있을까? 채용공고 분석하기&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;여기까지 쓰는데 한 시간 딱 걸렸다. OT발표에서 이수진님이 말씀한대로, 매일 한 시간 정도 할애해서 한번 시도 해보는 것도 좋을 것 같다.&lt;/p&gt;
</description>
        <pubDate>Mon, 19 Jul 2021 17:49:01 +0900</pubDate>
        <link>https://simonjisu.github.io/others/2021/07/19/geultto.html</link>
        <guid isPermaLink="true">https://simonjisu.github.io/others/2021/07/19/geultto.html</guid>
        
        
        <category>others</category>
        
      </item>
    
      <item>
        <title>[XAI] Feature Visualization</title>
        <description>&lt;p&gt;&lt;a href=&quot;https://distill.pub/2017/feature-visualization/&quot;&gt;Feature Visualization&lt;/a&gt; 논문을 보면서 정리한다는게 통째로 번역을 해버렸다(물론 부족한 번역이지만…). 하지만 배운 점이 많았는데 그중에 하나로 attribution 방법과 상당히 다른 방향을 지향한다는 점이다. 링크된 페이지를 방문하면 interactive하게 결과물을 보면서 감상할 수 있다.&lt;/p&gt;

&lt;p&gt;기회가 되면 다른 논문인 &lt;a href=&quot;https://distill.pub/2018/building-blocks/&quot;&gt;The Building Blocks of Interpretability&lt;/a&gt;도 한번 쭉 보면서 정리해보겠다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;인간이 신경망을 해석 할 수 있어야한다는 인식이 점차 커지고 있는 가운데 neural network interpretability 분야가 점점 발전하고 있다. 특히 비전분야에서 feature visualization 와 attribution 두 가지 방법이 많이 연구되고 있다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1Ra-1t_qmuJKc9zmqhx5uiFMJMyi9_QkG&quot; alt=&quot;Feature Visualization VS Attribution&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Feature Visualization VS Attribution&lt;/figcaption&gt;&lt;/figure&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;feature-visualization-by-optimization&quot;&gt;Feature Visualization by Optimization&lt;/h1&gt;

&lt;p&gt;Reference: &lt;a href=&quot;https://www.researchgate.net/publication/265022827_Visualizing_Higher-Layer_Features_of_a_Deep_Network&quot;&gt;Visualizing higher-layer features of a deep networ&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;신경망은 대체로 입력에 대해 미분가능하다. 따라서 모델의 특정 행동(내부 뉴런값 혹은 마지막 층의 출력값등)의 원인이 입력의 어떤 부분인지 보고 싶다면 도함수를 사용해 점진적으로 목표에 다다르도록 조정 할 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;optimization-objectives&quot;&gt;Optimization Objectives&lt;/h2&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1x6MT8wNRMAVAiWWTrZsA1wVF0JP1Jkrl&quot; alt=&quot;Different Optimization Objectives&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Different Optimization Objectives&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;목적에 따라서 전혀 다른 해석을 가질 수 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;특정 위치의 한 뉴런 혹은 전체 채널: Neuron, Channel&lt;/li&gt;
  &lt;li&gt;특정 층: Layer/DeepDream&lt;/li&gt;
  &lt;li&gt;특정 클래스: Class Logits, Class Probability&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;why-visualize-by-optimization&quot;&gt;Why visualize by optimization?&lt;/h2&gt;

&lt;p&gt;optimization 기법은 모델이 정말로 무엇을 보고 있는지 알 수 있는 강력한 방법이다. 왜냐면 모델의 특정 행동을 일이키는 원인과 단순히 연관된(correlate)것을 분리할 수 있기 때문이다.&lt;/p&gt;

&lt;p&gt;또한 optimization 기법은 유연하다는 장점이 있다. 예를 들어서 뉴런들어 어떻게 결합되어 표현(jointly represent)되는지 보고 싶다면, 추가 뉴런이 활성화되기 위해 특정한 예가 어떻게 달라져야 하는지 알아 볼 수 있다. 이런 유연함은 네트워크 피처가 어떻게 훈련과정에서 발전하는지를 보여주는 시각화에 도움이 된다.&lt;/p&gt;

&lt;p&gt;장점도 있는 반면 어려운 점들도 있다. 다음 섹션에서는 다양한 시각화 기법들을 이해해본다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;diversity&quot;&gt;Diversity&lt;/h1&gt;

&lt;p&gt;optimization을 통해 예시를 만들때 주의해야할 점은 전체 그림을 생성하는지의 여부다. 왜냐면 이런 특별한 예시들은 피처 표현의 한 단면만 보여주기 때문에, 인지의 오해를 불러 일으킬 수 있다.&lt;/p&gt;

&lt;p&gt;데이터 세트로부터 예시를 생성하면 각기 다른 방면으로 활성화된 뉴런의 전체 스펙트럼을 볼 수 있다.&lt;/p&gt;

&lt;p&gt;아래 그림을 예로 들어 본다. Positive optimized는 특정 뉴런 A을 최대화하게 optimization 과정을 거친 이미지라면, Maximum activation example은 데이터 세트 이미지를 모델에게 입력으로 넣어서, 우리가 optimization을 진행한 뉴런 A을 제일 크게 만드는 이미지만 골라내는 것이다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1sH6G1DatWGtZvoHpFSLPLIHfvIeVfZhG&quot; alt=&quot;Different optimization method in Inception Model&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Different optimization method in Inception Model&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 id=&quot;achieving-diversity-with-optimization&quot;&gt;Achieving Diversity with Optimization&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1507.02379&quot;&gt;Understanding Intra-Class Knowledge Inside CNN(Wei et al. 2015)&lt;/a&gt; 에서는 전체 훈련데이터세트의 활성화 값을 기록하면서, 이들을 클러스터링하고, 클러스터링된 중심값(cluster centroids)으로 부터 optimization하면서, 클래스 간(“intra-class”)의 다양성을 증명했다.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1602.03616&quot;&gt;Multifaceted feature visualization: Uncovering the different types of features learned by each neuron in deep neural networks(Nguyen et al. 2016)&lt;/a&gt; 에서는 하나의 뉴런이 아닌 다양한 방면을 표현하는 피처로부터 optimization을 시작함으로써 다양성을 증명한다.&lt;/li&gt;
  &lt;li&gt;최근 연구인 &lt;a href=&quot;https://arxiv.org/abs/1612.00005&quot;&gt;Plug &amp;amp; play generative networks: Conditional iterative generation of images in latent space(Nguyen et al. 2017)&lt;/a&gt; 에서는 generative model를 결합해서 다양한 예시를 샘플링한다. generative model 접근법이 꽤 잘 되는 편인데, learned priors에서 이를 더 다루기로 한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;diversity를 이루는 방법은 “diversity” 항을 목적함수에 추가함으로써 심플하게 달성할 수 있다. diversity 항은 다양하게 구성할 수 있으며, 그 예시로 다른 클래스 데이터와의 cosine similarity를 패널티로 부여하여 달성 할 수 있다. 다른 예로는 style transfer(&lt;a href=&quot;https://arxiv.org/abs/1508.06576&quot;&gt;A neural algorithm of artistic style, Gatys et al. 2015&lt;/a&gt;)에서 보여준 피처로하여금 다른 스타일을 강제하는 방법이 있다.&lt;/p&gt;

&lt;p&gt;[expand]summary: add “diversity” term 👈&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1eAqOW5e_zGMMRCfdrhbC-owHqpVl9hHs&quot; alt=&quot;원문&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;원문&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;artistic style transfer로부터 영감을 얻음. Gram matrix $G$의 채널들로부터 계산을 시작한다. $G_{i,j}$는 flatten된 필터 $i$와 필터 $j$의 dot product다.&lt;/p&gt;

&lt;p&gt;$G_{i,j} = \sum_{x,y} \text{layer}_n\text{[x, y, i]} \cdot \text{layer}_n\text{[x, y, j]}$&lt;/p&gt;

&lt;p&gt;여기서 diversity term을 계산할 수 있다. the negative pairwise cosine similarity of pairs of visualizations.&lt;/p&gt;

&lt;p&gt;$C_{\text{diversity}} = - \sum_{a} \sum_{b\neq a} \dfrac{\text{vec}(G_a) \cdot \text{vec}(G_b)}{\Vert\text{vec}(G_a)\Vert \Vert\text{vec}(G_b)\Vert}$&lt;/p&gt;

&lt;p&gt;이 후에 $C_{\text{diversity}}$를 optimization 목적함수에 패널티 항으로 추가하여 학습한다.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;낮은 차원의 뉴런들에서 diversity 항은 표현된 피처(feature representations)의 다양한 방면을 보여줄 수 있다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1VSLv-i9JG5uDZa2h4WSY4ECi3AsilOwE&quot; alt=&quot;diversity term reveals different curvy facets&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;diversity term reveals different curvy facets&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;다양한 피처 시각화는 무엇이 뉴런을 활성화하는지 자세히 들여다 볼 수 있게 해준다. 특히 데이터 세트로 본다면, 어떤 입력이 뉴런을 활성화 시키는지 더 다양하게 관찰하고 예측 할 수 있다. 예를 들어 다음 한 장의 optimization결과를 살펴본다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=19yqLldmhfok_rt3pYP6L5fbu2S2jz_yd&quot; alt=&quot;Simple optimization&quot; width=&quot;50%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Simple optimization&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;위 그림을 개의 머리 부분이 뉴런을 활성화 시킨 것으로 보인다. 그림의 일부를 보자면 개의 눈과 아래로 향하는 곡선으로 추측할 수 있다. 그러나 어떤 부분에서는 눈이 포함 안될 때도 있고, 아래로 향하는 곡선뿐만 아니라 위로 향하는 곡선도 있다. 따라서 이 뉴런이 활성화하는 것이 주로 모피 텍스처에 관한 것으로 가설을 세울 수 있다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1Hx7DEAK6jpHXmbTUeHPmGZ51D_ADUqJ6&quot; alt=&quot;Optimization with diversity&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Optimization with diversity&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;이 가설을 데이터 세트 예제를 통해 생성한 결과로 비교해 보면, 대체로 가설이 맞는 것으로 나타난다. 개의 털과 비슷한 질감의 색상과 텍스처를 활성화 했다는 점을 주목해야한다.&lt;/p&gt;

&lt;p&gt;다양함의 효과는 더 높은 층의 뉴런에서 두드러진다. 뉴런을 통해 다양한 물체 종류를 시뮬레이션 할 수 있다. 예를 들어, 다음 그림과 같이 다양한 종류의 볼들이 생성된 것을 볼 수 있다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1GjxqNJ7uwvONizNoTp7_CiZ4HIOXP5Ij&quot; alt=&quot;Optimization with diversity term reveals multiple types of balls&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Optimization with diversity term reveals multiple types of balls&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;이러한 접근법에도 단점이 있다. 예시를 다르게 만드려는 강압적인 방법 때문에 오히려 연관이 없는 물체가 생성 될 수도 있다. 추가로 optimization을 통해서 예시를 다르게 생성하는 것은 부자연스러운 방법이다. 예를 들어, 위 그림의 경우, 누군가는 다른 공들은 제외하고 깨끗한 축구공의 예시를 보고 싶었을 것이다. 데이터 세트에 기반한 기법들(&lt;a href=&quot;https://arxiv.org/abs/1507.02379&quot;&gt;Wei et al. 2015&lt;/a&gt;)은 이와 다르게 조금 더 자연스럽게 피처를 분리할 수 있지만, 각기 다른 데이터들이 어떻게 모델에서 동작하는 지를 이해하는 것에 크게 도움이 안될 수 있다.&lt;/p&gt;

&lt;p&gt;또 다른 근본적인 문제가 있다면, 다양함은 일관된 예시를 보여줄 수도 있지만 그렇지 않을 수 도 있다는 점이다. 아래 예시는 두 동물의 얼굴 그리고 차체의 결과다. 이러한 결과들로부터 우리는 뉴럴넷을 이해하는데 있어서, 하나의 뉴런이 꼭 정확한 의미론적(semantic) 단위는 아니라는 것을 알 수 있다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=153l1TwIixnPAIatf2TD3nqD1EhgMBIDb&quot; alt=&quot;Optimization with diversity term show cats, foxes, but also cars&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Optimization with diversity term show cats, foxes, but also cars&lt;/figcaption&gt;&lt;/figure&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;interaction-between-neurons&quot;&gt;Interaction between Neurons&lt;/h1&gt;

&lt;p&gt;만약에 뉴런이 뉴럴넷을 이해하는데 적절하지 않은 방법이라면, 도대체 무엇이 적절한 방법일까? 실제로 뉴럴넷에서는 여러 뉴런의 조합으로 이미지를 표현한다. 이에 도움이 되는 해석방법은 지리적(geometrically)으로 조합하는 것이다.&lt;/p&gt;

&lt;p&gt;예를 들어 &lt;strong&gt;활성화 공간(activation space)&lt;/strong&gt;이라는 것을 정의해 보자, 그렇다면 개별 활성화된 뉴런은 활성화 공간의 &lt;strong&gt;기저 벡터(basis vectors)&lt;/strong&gt;로 생각할 수 있다. 반대로, 활성화된 뉴런들의 조합들이 곧 활성화 공간이 된다.&lt;/p&gt;

&lt;p&gt;[expand]summary: 선형 대수에서 기저(basis)란? 👈&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://ko.wikipedia.org/wiki/%EA%B8%B0%EC%A0%80_(%EC%84%A0%ED%98%95%EB%8C%80%EC%88%98%ED%95%99)&quot;&gt;https://ko.wikipedia.org/wiki/기저_(선형대수학)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;선형대수학에서, 어떤 벡터 공간의 기저(基底, 영어: basis)는 그 벡터 공간을 선형생성하는 선형독립인 벡터들이다. 달리 말해, 벡터 공간의 임의의 벡터에게 선형결합으로서 유일한 표현을 부여하는 벡터들이다.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;이러한 프레임은 “활성화 공간의 벡터”로서 “뉴런”과 “뉴런의 조합”개념을 통합한다. 그러면 다음과 같은 질문을 할 수 있다. “특정 방향을 가지는 기저 벡터들이 다른 방향을 가지는 기저 벡터들보다 더 나은 해석가능함을 나타낼 수 있을까?”&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1312.6199&quot;&gt;Intriguing properties of neural networks(Szegedy et al. 2014)&lt;/a&gt;에서 저자들은 랜덤한 방향도 충분히 기저 벡터들의 방향만큼 의미가 있다는 것을 주장했다.&lt;/p&gt;

&lt;p&gt;[expand]summary: Intriguing properties of neural networks 👈&lt;/p&gt;

&lt;p&gt;Reference: &lt;a href=&quot;https://3ffr3s.github.io/2020-02-10-Intriguing_properties_of_neural_networks/&quot;&gt;https://3ffr3s.github.io/2020-02-10-Intriguing_properties_of_neural_networks/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;이전 연구에서는 이미지 데이터 집합 $I$에 속한 이미지 $x$가 주어졌을 때, 단일 피처의 activation을 최대화하는 입력 $x^{‘}$을 찾았다. $e_i$는 $i$번째 hidden unit에 관련된 natural basis vector를 뜻한다. 예: $e_i = 1 \text{ if i-th neuron else } 0$&lt;/p&gt;

\[x^{&apos;} = \underset{x \in I}{\arg \max} \text{&amp;lt;}\phi(x), e_i \text{&amp;gt;}\]

&lt;p&gt;하지만 저자들은 랜덤한 벡터 $v \in \Bbb{R}^{n}$ 로 해도 비슷한 해석이 가능하다는 것을 밝혀냈다.&lt;/p&gt;

\[x^{&apos;} = \underset{x \in I}{\arg \max} \text{&amp;lt;}\phi(x), v \text{&amp;gt;}\]

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1L0A9ZvvQe2UzsWcHTK3UJyUVxrXFG59J&quot; alt=&quot;Mnist에 대한 실험 결과&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Mnist에 대한 실험 결과&lt;/figcaption&gt;&lt;/figure&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1C55n-ng_wxzPLlH9qsSn6jDQE-xbXF29&quot; alt=&quot;ImageNet에 대한 실험결과&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;ImageNet에 대한 실험결과&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;여러 분석을 통해 뉴럴넷 $\phi(x)$의 특성을 살펴보는데 natural basis vector가 random vector와 큰 차이가 없다는 것을 뜻한다. 입력 분포의 특정 부분 집합에 대해서 불변성(invariance)을 띄는 $\phi$의 능력을 설명할 수 있지만, 나머지 도메인에 대해서 $\phi$의 행동을 설명 할 수가 없다.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1704.05796&quot;&gt;Network Dissection: Quantifying Interpretability of Deep Visual Representations(Zhou et al.)&lt;/a&gt;에서는 랜덤한 방향보다 basis vector의 방향이 더 해석가능하다고 밝혔다.&lt;/p&gt;

&lt;p&gt;우리의 실험에서는 두 가지 주장에 대체로 일치한다. 랜덤한 방향은 어느 때에는 더 해석가능하지만, basis 방향보다는 약간의 낮은 수치를 기록하고 있다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1gEssEqwLEh_Cdl9PWq56BdcOey2PmbbD&quot; alt=&quot;Dataset examples and optimized examples of random directions&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Dataset examples and optimized examples of random directions&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;우리는 활성화 공간에서 뉴런에 대해 약간의 산수를 통해 조금 더 흥미로운 방향을 정의할 수 있다. 예를 들어, “검정과 하양”을 “모자이크” 뉴런에 더하면, 검정고 하얀 모자이크를 얻을 수 있었다. 마치 Word2Vec의 의미론적 단어 임베딩과 비슷하다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1cNO3z_mtgocM0d0ggTIEE-llzqAxOt9Q&quot; alt=&quot;Jointly optimizing two neurons&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Jointly optimizing two neurons&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;위 그림의 예시는 뉴런들이 조건부 결합으로 표현된 이미지다. 이 둘 사이에 보간법을 적용해 뉴런들의 상호작용을 더 잘 이해하게 만들 수있다. 생성 모델(generative models)에서 latent space에 보간법을 적용하는 것과 비슷하다.&lt;/p&gt;

&lt;p&gt;[expand]summary: 생성모델에서 latent space애 보간법 적용하는 방법 👈&lt;/p&gt;

&lt;p&gt;간단히 0.1만큼 선형 보간법을 적용한다면 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt; 

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;interpolate_points&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_steps&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
    p1, p2: shape of (hidden_dim) vector
    &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# interpolate ratios between the points
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;ratios&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_steps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# linear interpolate vectors
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;vectors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ratio&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ratios&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ratio&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ratio&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p2&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;vectors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vectors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;정확히 말하자면, 전체 optimization의 목적은 개별 채널의 목적함수의 선형 보간과 같다. 보간법을 더 잘 하기 위해서, 낮은 활성화 층과 비슷하도록 작은 alignment 목표를 추가한다. 더 쉽게 optimization을 달성하기 위해서, 분리되고 공유된 이미지의 매개변수 조합을 사용했다(랜덤하게 주어도 되지만).&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1ugBFfZq4HhAtBuAQEJBz1iJFQrj33C8W&quot; alt=&quot;Interploation&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Interploation&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;이 부분은 뉴런들이 어떻게 상호작용하는지 알아가는 시작 단계일 뿐이다. 우리도 어떻게 의미있는 방향을 선택하는지 아니면 실제로 의미가 있는 방향이 존재하는 지를 아직 모르겠다. 방향을 찾는 것과 별개로 방향들간에 서로 어떻게 작용하지에 대한 의문도 있다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;the-enemy-of-feature-visualization&quot;&gt;The Enemy of Feature Visualization&lt;/h1&gt;

&lt;p&gt;불행하게도, 단순히 최적화를 한다고해서 피처를 시각화 할 수 없다. 단순 최적화를 하면 어떤 착시 현상 - noise로 가득차고, 무의미한 &lt;strong&gt;고주파 패턴(high-frequency patterns)&lt;/strong&gt;만을 얻을 것이다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=14QbrkQC29NRJVA4XTzKVO7IFc0nx-wBr&quot; alt=&quot;Optimization results with noise&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Optimization results with noise&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;이는 실제 생활에서 일어나지 않을 법한 패턴이다. 만약에 충분이 오랬동안 최적화를 진행한다면, 일부 뉴런이 특출나게 어떤 것을 탐지해내지만, 이미지는 고주파 패턴으로 도배될 것이다. 이러한 패턴들은 &lt;a href=&quot;https://arxiv.org/abs/1312.6199&quot;&gt;Intriguing properties of neural networks(Szegedy et al. 2014)&lt;/a&gt;에서 언급한 &lt;strong&gt;적대적 예시의 현상(phenomenon of adversarial examples)&lt;/strong&gt;으로 보인다.&lt;/p&gt;

&lt;p&gt;왜 이런 고주파 패턴 현상이 발생하는지 100% 이해할 수는 없지만, strided convolutions 과 pooling 연산에서 이러한 현상을 야기시킨다는 것을 발견할 수 있었다(&lt;a href=&quot;https://distill.pub/2016/deconv-checkerboard/&quot;&gt;Deconvolution and checkerboard artifacts&lt;/a&gt; 글 참고 - up sampling시 resize-convolution 활용: interpolation 후에 Conv Layer 통과).&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1vndh70zXGkfumkWigTbm36Ty3boFo0hn&quot; alt=&quot;Reason why causes the hight frequency patterns&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Reason why causes the hight frequency patterns&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;고주파 패턴을 통해 우리는 최적화 기반의 시각화에서 제약으로부터 자유로울수록 매력적이지만, 이는 양날의 검이기도 하다는 것을 알 수 있다. 아무런 제약이 없다면 적대적 예시를 결과로 얻을 것이다.&lt;/p&gt;

&lt;h2 id=&quot;the-spectrum-of-regularization&quot;&gt;The Spectrum of Regularization&lt;/h2&gt;

&lt;p&gt;고주파 노이즈를 다루는 것이 곧 이 분야에서 주요 과제가 되었다. 유용한 시각화 결과를 얻기 위해서, 학습된 사전 분포(prior), 정규항(regularizer)이나 제약(constraint)등이 추가되어야 한다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;정규화(regularization)&lt;/strong&gt;는 최근 피처 시각화 연구에서 확인 할 수 있는 주요 포인트다. 이를 하나의 스펙트럼으로 나눌 수 있을 것이다. 극단적으로 아예 정규화를 하지 않으면, 적대적 예시를 얻고, 너무 강한 정규화를 하게 되면 오해를 부르는 연관성을 야기할 수 있다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1jOkkAiLo4I_Ui-OJbGRcYe4JpLN335s1&quot; alt=&quot;여러 방법론 정리&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;여러 방법론 정리&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 id=&quot;three-families-of-regularization&quot;&gt;Three Families of Regularization&lt;/h2&gt;

&lt;h3 id=&quot;frequency-penalization&quot;&gt;Frequency penalization&lt;/h3&gt;

&lt;p&gt;Frequency penalization는 고주파 노이즈를 직접 없에는 것을 목표로 한다. 명시적으로 근접 픽셀(total variation, &lt;a href=&quot;https://arxiv.org/abs/1412.0035v1&quot;&gt;Understanding deep image representations by inverting them(Mahendran, Vedaldi, 2014)&lt;/a&gt;)에 패널티를 부여하거나, 암묵적으로 이미지를 각 최적화 스텝마다 블러 처리를 하는 방법(&lt;a href=&quot;https://arxiv.org/abs/1412.1897&quot;&gt;Deep neural networks are easily fooled: High confidence predictions for unrecognizable images(Nguyen et al. 2014)&lt;/a&gt;)등이 있다. 안타깝게도 이러한 접근법들은 노이즈가 더해진 엣지같은 높은 주파수를 가지는 피처를 억제한다(즉, 엣지를 없엔다). 이는 bilateral filter를 활용하면 약간 해소할 수 있다(&lt;a href=&quot;https://mtyka.github.io/deepdream/2016/02/05/bilateral-class-vis.html&quot;&gt;Class visualization with bilateral filters, M. Tyka. 2016&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;[expand]summary: 블러 처리에 대한 주석 👈&lt;/p&gt;

&lt;p&gt;푸리에 공간에서 블러 처리를 한다면, 스케일링된 L2 정규항을 목적함수에 추가하는 것과 같다. 즉, 주파수에 기반해 각 푸리에 요소에 패널티를 부여하는 것과 같다.&lt;/p&gt;

&lt;p&gt;If we think about blurring in Fourier space, it is equivalent to adding a scaled L2 penalty to the objective, penalizing each Fourier-component based on its frequency.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;특정 연구(&lt;a href=&quot;https://www.auduno.com/2015/07/29/visualizing-googlenet-classes/&quot;&gt;Visualizing GoogLeNet Classes &lt;strong&gt;(&lt;/strong&gt;A. Øygard. 2015)&lt;/a&gt;, &lt;a href=&quot;https://www.tensorflow.org/tutorials/generative/deepdream?hl=ko&quot;&gt;DeepDreaming with TensorFlow (A. Mordvintsev. 2016)&lt;/a&gt;)에서는 시각화에서 특정 결과로 모으기 전에, 위에서 서술한 기술을 사용해 경사에서 높은 주파수를 제거하는 용도로 사용한다. 이는 약간 비슷하면서도 본질적으로 다른 면이 있는데 Preconditioning and Parameterization 파트에서 설명한다.&lt;/p&gt;

&lt;p&gt;아래 그림에서 높은 패널티를 줄 수록 고주파 패턴이 사라지고 선명해지는 경향이 있다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1_cTAnFiCtXB2D-zaYVBgAoH494JUaBhn&quot; alt=&quot;블러처리와 패널티&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;블러처리와 패널티&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h3 id=&quot;transformation-robustness&quot;&gt;Transformation robustness&lt;/h3&gt;

&lt;p&gt;Transformation robustness는 약간의 변형이 있어도 계속 최적화 타겟을 활성화 시키는 예시을 찾는 것을 목표로 한다. &lt;a href=&quot;https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html&quot;&gt;Inceptionism: Going deeper into neural networks(Google Research Blog. 2015)&lt;/a&gt; 에서 말하길 아주 작은 값이라도 이미지에서는 큰 효과를 가져온다. 특히, 높은 주파수가 결합된 일반적인 정규항에서 더 효과적이다(&lt;a href=&quot;https://www.auduno.com/2015/07/29/visualizing-googlenet-classes/&quot;&gt;Visualizing GoogLeNet Classes &lt;strong&gt;(&lt;/strong&gt;A. Øygard. 2015)&lt;/a&gt;, &lt;a href=&quot;https://www.tensorflow.org/tutorials/generative/deepdream?hl=ko&quot;&gt;DeepDreaming with TensorFlow (A. Mordvintsev. 2016)&lt;/a&gt;). 구체적으로 최적화 스텝을 진행하기 전에 확률적으로 이미지를 지터링(jitter), 회전(rotate) 또는 스케일링(scale) 한다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=10VzBQqtUVnPGIuGCUBSd2vgcQLr66L-O&quot; alt=&quot;Stochastically transforming the image&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Stochastically transforming the image&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h3 id=&quot;learned-priors&quot;&gt;Learned priors&lt;/h3&gt;

&lt;p&gt;이전에 이야기한 정규화항은 예제를 합리적으로 유지하기 위해 매우 간단하고 휴리스틱한 방법을 사용했다. 자연스럽데 다음 단계로 실제 데이터로부터 모델을 학습하고 이를 적용하는 것이다. 강력한 모델을 사용하면, 데이터 세트에서 검색하는 것과 비슷해진다. 이러한 접근법은 가장 사실적인 시각화를 제공하지만, 어떤 것이 모델로부터 시각화 되었고, 어떤 것이 사전 분포로부터 온것인지 모르는 단점이 있다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;잠재 공간(latent space)&lt;/strong&gt;으로 부터 예시를 매핑하는 &lt;strong&gt;생성기(generator)&lt;/strong&gt;를 학습하는 것이 하나의 방법이다. GAN, VAE와 같은 모델을 학습하고 잠재공간을 최적화 하는 방법이다(&lt;a href=&quot;https://arxiv.org/abs/1605.09304&quot;&gt;Synthesizing the preferred inputs for neurons in neural networks via deep generator networks(Nguyen et al. 2016)&lt;/a&gt;). 다른 접근 법으로는 확률의 경사를 얻을 수 있는 사전 분포를 학습하는 것이다. 이를 이용하면 목적에 따라 사전 분포를 조건부로 최적화 할 수 있다(&lt;a href=&quot;https://arxiv.org/abs/1612.00005&quot;&gt;Plug &amp;amp; play generative networks: Conditional iterative generation of images in latent space(Nguyen et al. 2016)&lt;/a&gt;, &lt;a href=&quot;https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html&quot;&gt;Inceptionism: Going deeper into neural networks(Google Research Blog. 2015)&lt;/a&gt;). 하나는 특정 클래스의 확률값과 사전 분포를 최적화하고, 다른 하나는 특정 클래스를 조건부로 생성 모델에서 데이터를 복구하는 것이다. 마지막으로 &lt;a href=&quot;https://arxiv.org/abs/1507.02379&quot;&gt;Understanding Intra-Class Knowledge Inside CNN(Wei et al. 2015)&lt;/a&gt; 에서는 생성 모델의 사전 분포를 대략 추정한다. 적어도 칼러 분포에서, 출력 이미지 패치들과 근처 패치들의 거리에 패널티를 부여하는 방법을 사용하는데, 여기서 근처 패치들은 훈련 데이터에서 수집한 이미지 패치 데이터베이스에서 검색하는 방식이다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;preconditioning-and-parameterization&quot;&gt;Preconditioning and Parameterization&lt;/h1&gt;

&lt;p&gt;이전 섹션에서 특정 방법들은 고주파 패턴을 시각화 자체에서 줄이는게 아니라 경사에 적용한다고 했었다(&lt;a href=&quot;https://www.auduno.com/2015/07/29/visualizing-googlenet-classes/&quot;&gt;Visualizing GoogLeNet Classes &lt;strong&gt;(&lt;/strong&gt;A. Øygard. 2015)&lt;/a&gt;, &lt;a href=&quot;https://www.tensorflow.org/tutorials/generative/deepdream?hl=ko&quot;&gt;DeepDreaming with TensorFlow (A. Mordvintsev. 2016)&lt;/a&gt;). 이러한 방법이 정규화항(regularizer)인지는 명확하지 않다. 높은 주파수를 억제하나, 경사에서 이를 계속 보낼 경우 높은 주파수의 형성을 허용하게 된다. 만약에 정규화항이 아니라면, 경사의 변화는 어떤 역할을 하는 것일까?&lt;/p&gt;

&lt;p&gt;경사를 변화시키는 것은 꽤나 강력한 도구이며, optimization에서 “&lt;strong&gt;preconditioning”&lt;/strong&gt;이라고 부르며, 같은 목적함수를 가장 가파른 경사로 최적화 하는데, 다른 파라미티 공간과 거리 조건 하에서 최적화를 한다고 생각할 수 있다. 경사를 얼마나 가파르게 변화하거나, 해당 방향으로 얼마나 빠르게 변화를 줘도, 최소가 되는 지점은 변함이 없다. local minima가 많아도, 경사를 수축/확장하면서 벗어날 수 있다. 따라서 적절한 &lt;strong&gt;preconditioning&lt;/strong&gt;은 최적화 문제를 조금 더 쉽게 만들어 준다.&lt;/p&gt;

&lt;p&gt;그러면 어떤 조건이 좋을까? 먼저 데이터와 연관을 줄이는 방향(decorrelated and whitened)으로 시도 해볼 수 있다. 이미지의 경우, 같은 에너지를 가지도록 주파를 스케일링하는 Fourier basis로 경사 하강법을 실행하는 것이다.&lt;/p&gt;

&lt;p&gt;다음 그림을 보면 거리 조절 방법에 따라서 경사의 방향이 달라진다. $L^2$ 정규화는 $L^{\infty}$ 와 decorrelated space와 확연한 차이를 보인다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1w5oDxg5cMQuTlFUgbKb08YPBGV5RQhNi&quot; alt=&quot;Three directions of steepest descent under different notions of distance&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Three directions of steepest descent under different notions of distance&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;위에서 서술한 모든 방향들은 다 유효한 경사 방향이지만,  결과물을 보면 근본적으로 다르다. decorrelated space로 최적화시, 높은 주파수를 줄일 수 있으며,  $L^{\infty}$ 방법은 오히려 반대로 이를 증가시킨다.&lt;/p&gt;

&lt;p&gt;decorrelated 경사 방향을 사용하면 꽤나 다른 시각화 결과를 얻을 수 있다. 이는 hyperparameter를 조절해야하기 때문에 공평한 비교가 힘들지만, 시각화 결과는 훨씬 더 좋으며, 더 빠르게 얻을 수 있다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1FCCHjI1N6DhzOXz5JebyIeVUjdlgC94b&quot; alt=&quot;Combining the preconditioning and transformation robustness&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Combining the preconditioning and transformation robustness&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;preconditioner가 단순 최적화를 가속 시키는 것인지? 즉, 같은 조건에 평범한 경사를 사용하여 오랜 시간 기다리면, preconditioner을 사용한 것과 같은 결과를 얻을지? 정규화를 함으로써 local minima를 피할 수 있는 것인지? 이는 아직 확실하게 말하기 어렵다. 한편으로 만약에 충분히 오랜 스텝동안 경사하강법을 진행한다면, 느리지만 결국에 수렴하게 된다. 또 다른 한편으로 정규화를 하지 않으면 preconditioner가 높은 주파스 패턴을 줄여준다.&lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;뉴런 시각화는 지난 몇년 동안 많은 발전을 이뤘다. 우리는 강력한 시각화를 만들 수 있는 원칙적인 방법을 개발했다. 그리고 여러 가지 중요한 과제를 계획하고 해결 방법을 찾았습니다.&lt;/p&gt;

&lt;p&gt;신경망을 해석가능하게 만들기 위해, 피처 시각화는 가장 유망하고 발전된 연구 방향 중 하나로 눈에 띈다. 피처 시각화 자체로는 완벽한 이해를 얻을 수 없다. 우리는 이를 다른 툴과 함께 사용하여, 인간이 시스템을 이해하기 위한 근본 요소중 하나로 보고있다.&lt;/p&gt;

&lt;p&gt;피처 시각화에는 아직 많은 해야할 일이 남아 있다. 뉴런의 상호작용을 이해하기, 활성화된 신경망을 이애하기 위해 가장 의미가 유닛을 찾기, 그리고 피처를 다방면으로 살펴보는 문제들이 바로 앞으로 해결해야할 문제들이다.&lt;/p&gt;

&lt;h1 id=&quot;appendix-inception-module&quot;&gt;Appendix: Inception Module&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://distill.pub/2017/feature-visualization/appendix/&quot;&gt;Feature Visualization - Appendix&lt;/a&gt;&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1_61451LmD03-WIxRI2z6Auy5nRs6TauO&quot; alt=&quot;Inception 모델에 대한 Layer 번호 설명&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Inception 모델에 대한 Layer 번호 설명&lt;/figcaption&gt;&lt;/figure&gt;
</description>
        <pubDate>Tue, 20 Apr 2021 22:00:01 +0900</pubDate>
        <link>https://simonjisu.github.io/paper/2021/04/20/featurevisualization.html</link>
        <guid isPermaLink="true">https://simonjisu.github.io/paper/2021/04/20/featurevisualization.html</guid>
        
        
        <category>paper</category>
        
      </item>
    
      <item>
        <title>FARM tutorial</title>
        <description>&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1hbtUClFoXg45IbViZoFRLnnDGVlr9Dlb&quot; alt=&quot;&quot; width=&quot;50%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h1 id=&quot;farm&quot;&gt;FARM&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Framework for Adapting Representation Models&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이 패키지를 한 마디로 요약하면 Fine-tuning에 최적화된 도구다.&lt;/p&gt;

&lt;p&gt;최근의 자연어처리 분야는 Transformer와 그 변형의 등장으로 인해, 보통 2단계로 나눠서 학습이 진행된다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Pretrained Language Modeling&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;대량의 텍스트 데이터를 이용해 비지도학습(unsupervised learning)으로 언어 모델링은 진행한다. 언어 모델링이란 인간의 언어를 컴퓨터로 모델링하는 과정이다. 쉽게 말하면, 모델에게 단어들을 입력했을 때, 제일 말이 되는 단어(토큰)을 뱉어내게 하는 것이다. 과거에는 단어(토큰)의 순서가 중요했었다. 즉, 일정 단어들의 시퀀스 $x_{1:t-1}$가 주어지면, $t$번째 단어인 $x_t$를 잘 학습시키는 것이었다. 이를 &lt;strong&gt;Auto Regressive Modeling&lt;/strong&gt;이라고도 한다. 그러나, &lt;strong&gt;Masked Language Modeling&lt;/strong&gt; 방법이 등장했는데, 이는 랜덤으로 맞춰야할 단어를 가린 다음에 가려진 단어 $x_{mask}$가 포함된 시퀀스 $x_{1:t}$ 를 모델에게 입력하여 맞추는 학습 방법이다. 이러한 방법이 좋은 성과를 거두면서, 최근에는 모든 언어모델링 기법들이 MLM을 기반으로 하고 있다.&lt;/p&gt;

    &lt;p&gt;다만, 얼만큼의 확률로 적절하게 가릴지, transformer가 가지고 있는 태생적인 단점인 처리할 수 있는 토큰의 개수 제약 등 해결하려는 시도가 많이 있고, 앞으로도 해결해야할 문제들이다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Fine-tuning&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;&lt;strong&gt;PLM(Pretrained Language Model)&lt;/strong&gt;을 만들고 나면, 각기 다른 downstream task에 따라서 fine-tuning을 하게 된다. Downstream task은 구체적으로 풀고 싶은 문제를 말하며, 주로 다음과 같은 문제들이다.&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;텍스트 분류 Text Classification&lt;/strong&gt; - 예시: 영화 댓글 긍정/부정 분류하기&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;개체명인식 NER(Named Entity Recognition)&lt;/strong&gt; - 예시: 특정 기관명, 인명 및 시간 날짜 등 토큰에 알맞는 태그로 분류하기&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;질의응답 Question and Answering&lt;/strong&gt; - 예시: 특정 지문과 질의(query)가 주어지면 대답하기&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;오늘 소개할 FARM 패키지는 2번째 단계인 Fine-tuning을 보다 손쉽게 만들어 놓은 패키지다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Tutorial github:&lt;/strong&gt; &lt;a href=&quot;https://github.com/simonjisu/FARM_tutorial&quot;&gt;https://github.com/simonjisu/FARM_tutorial&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Colab Tutorial:&lt;/strong&gt; &lt;a href=&quot;https://colab.research.google.com/github/simonjisu/FARM_tutorial/blob/main/notebooks/FARM_colab.ipynb&quot;&gt;링크&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;core-features&quot;&gt;Core Features&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Easy fine-tuning of language models&lt;/strong&gt; to your task and domain language&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Speed&lt;/strong&gt;: AMP(Automatic Mixed Precision) optimizers (~35% faster) and parallel preprocessing (16 CPU cores =&amp;gt; ~16x faster)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Modular design&lt;/strong&gt; of language models and prediction heads&lt;/li&gt;
  &lt;li&gt;Switch between heads or combine them for &lt;strong&gt;multitask learning&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Full Compatibility&lt;/strong&gt; with HuggingFace Transformers’ models and model hub&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Smooth upgrading&lt;/strong&gt; to newer language models&lt;/li&gt;
  &lt;li&gt;Integration of &lt;strong&gt;custom datasets&lt;/strong&gt; via Processor class&lt;/li&gt;
  &lt;li&gt;Powerful &lt;strong&gt;experiment tracking&lt;/strong&gt; &amp;amp; execution&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Checkpointing &amp;amp; Caching&lt;/strong&gt; to resume training and reduce costs with spot instances&lt;/li&gt;
  &lt;li&gt;Simple &lt;strong&gt;deployment&lt;/strong&gt; and &lt;strong&gt;visualization&lt;/strong&gt; to showcase your model&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[expand]summary:What is AMP? 👈&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Reference&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/NVIDIA/apex&quot;&gt;https://github.com/NVIDIA/apex&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://forums.fast.ai/t/mixed-precision-training/20720&quot;&gt;https://forums.fast.ai/t/mixed-precision-training/20720&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;mixed precision training이란&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;처리 속도를 높이기 위한 FP16(16bit floating point)연산과 정확도 유지를 위한 FP32 연산을 섞어 학습하는 방법&lt;/li&gt;
  &lt;li&gt;Tensor Core를 활용한 FP16연산을 이용하면 FP32연산 대비 절반의 메모리 사용량과 8배의 연산 처리량 &amp;amp; 2배의 메모리 처리량 효과가 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;nsmc-데이터로-farm-알아보기&quot;&gt;NSMC 데이터로 FARM 알아보기&lt;/h1&gt;

&lt;h2 id=&quot;nsmc-데이터&quot;&gt;NSMC 데이터&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;NSMC(Naver Sentiment Movie Corpus)&lt;/strong&gt;는 한국어로 된 영화 댓글 데이터 세트다. 해당 Task는 타겟 값이 긍정(1)/부정(0)이 되는 Binary Text Classification 문제로 볼 수 있다. &lt;a href=&quot;https://github.com/e9t/nsmc&quot;&gt;https://github.com/e9t/nsmc&lt;/a&gt;에서 받을 수 있다(아래 그림은 label을 bad와 good으로 처리해놓은 상태).&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1FIGIBtZxtuKD5Prps5vPOPldBb0xHwzH&quot; alt=&quot;[그림1] NSMC Dataset&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;[그림1] NSMC Dataset&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 id=&quot;fine-tuning-process&quot;&gt;Fine-tuning Process&lt;/h2&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1j9pn8Lpg7sy6S8Ubvq3E7JLWf28KvRt4&quot; alt=&quot;[그림2] Fine-tuning Process&quot; width=&quot;50%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;[그림2] Fine-tuning Process&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;Fine-tuning Process는 위 그림과 같이 진행된다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Load Data: 데이터를 알맞는 형식(json, csv 등)으로 불러온다.&lt;/li&gt;
  &lt;li&gt;Create Dataset: 데이터세트(Dataset) 만들기
    &lt;ul&gt;
      &lt;li&gt;Tokenization: 텍스트를 토큰으로 나누고, 단어장(vocab)을 생성한다.&lt;/li&gt;
      &lt;li&gt;ToTensor: vocab에 해당하는 단어를 수치화하는 과정 (transformers 패키지 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;input_ids&lt;/code&gt;에 해당)&lt;/li&gt;
      &lt;li&gt;Attention Mask: 패딩계산을 피하기 위해 Attention 해야할 토큰만 masking(transformers 패키지 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;attention_mask&lt;/code&gt; 에 해당)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Create Dataloader: 훈련, 평가시 배치크기 단위로 데이터를 불러오는 객체&lt;/li&gt;
  &lt;li&gt;Create Model:
    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Pretrained Language Model: 대량의 텍스트 데이터로 사전에 훈련된 모델&lt;/p&gt;

\[\underset{\theta}{\arg \max} P(x_{mask} \vert x_{1:t})\]
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Fine-tuninig Layer: Downstream Task에 맞춰서 학습한다.&lt;/p&gt;

\[\underset{\theta}{\arg \max}P(y\vert x_{1:t})\]

        &lt;p&gt;예를 들어, 영화 긍정/부정 분류 문제의 경우&lt;/p&gt;

\[\underset{\theta}{\arg \max} P(y=\text{긍정/부정} \vert x_{1:t})\]
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Train Model: 모델 훈련&lt;/li&gt;
  &lt;li&gt;Eval Model: 모델 평가&lt;/li&gt;
  &lt;li&gt;Inference: 모델 서비스&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;processor--data-silo&quot;&gt;Processor &amp;amp; Data Silo&lt;/h2&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1XCc0AJpPBMFcC81NW0A6w0mpswZ2KU7h&quot; alt=&quot;[그림3] Fine-tuning Process&quot; width=&quot;90%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;[그림3] Fine-tuning Process&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Processor&lt;/strong&gt;는 file 혹은 request를 PyTorch Datset로 만들어 주는 역할이다. 자세한 인자값은 다음 코드 블록에서 설명한다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Data Silo&lt;/strong&gt;는 train, dev, test sets를 관리하고, Processor의 function들 이용해 각 set를 DataLoader로 변환한다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Processor&lt;/strong&gt;는 각 데이터를 처리할 때, &lt;strong&gt;Samples&lt;/strong&gt;, &lt;strong&gt;SampleBasket&lt;/strong&gt;에 담게 되는데, 이들은 raw document를 관리하는 객체이며 tokenized, features등 데이터와 각 샘플을 관리하는 id를 저장하고 있다. 이렇게 하는 이유는 하나의 소스 텍스트(raw text)에서 여러개의 샘플을 생성할 수도 있기 때문이다
여담이지만 huggingface의 SquadProcessor는 512개 토큰이 넘어가면, 뒤에서 부터 512토큰을 세서 하나의 데이터를 두 개의 샘플로 만든다.
    &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;dataset_from_dicts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...)&lt;/span&gt;
      &lt;span class=&quot;c1&quot;&gt;# ...
&lt;/span&gt;      &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_ids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;segment_ids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokens&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;dicts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_ids_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;segment_ids_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding_masks_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokens_batch&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
          &lt;span class=&quot;c1&quot;&gt;# ...
&lt;/span&gt;          &lt;span class=&quot;c1&quot;&gt;# Add Basket to self.baskets
&lt;/span&gt;          &lt;span class=&quot;n&quot;&gt;curr_sample&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
              &lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;clear_text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;tokenized&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenized&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;feat_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;curr_basket&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SampleBasket&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;id_internal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;raw&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;id_external&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;samples&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;curr_sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
          &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;baskets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;curr_basket&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

      &lt;span class=&quot;c1&quot;&gt;# ...
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;사용하는 방법은 다음과 같다.&lt;/p&gt;

&lt;p&gt;[expand]summary: 코드보기 👈&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Reference: https://github.com/Beomi/KcBERT
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;PRETRAINED_MODEL_NAME_OR_PATH&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;beomi/kcbert-base&quot;&lt;/span&gt;  
&lt;span class=&quot;n&quot;&gt;MAX_LENGTH&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;150&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;LABEL_LIST&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;bad&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;good&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;TRAIN_FILE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;train.tsv&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;TEST_FILE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;test.tsv&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;TASK_TYPE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;text_classification&quot;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Tokenizer
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pretrained_model_name_or_path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;PRETRAINED_MODEL_NAME_OR_PATH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;do_lower_case&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Processor
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;processor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TextClassificationProcessor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# tokenizer 
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;train_filename&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TRAIN_FILE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# training data 파일명
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;dev_filename&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# development data 파일명, 없으면, dev_split 비율만큼 training data에서 자른다 
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;test_filename&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TEST_FILE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# test data 파일명
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;dev_split&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# development data로 설정할 비율
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;header&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# csv, tsv, excel 등 tabular형태 데이터에서 첫행(보통은 컬럼명)의 위치
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MAX_LENGTH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 문장의 최대 길이
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;data_dir&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DATA_PATH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 데이터의 디렉토리
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;label_list&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LABEL_LIST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 레이블 리스트(string 필요)
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;metric&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;acc&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 평가지표
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;label_column_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;label&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# tabular형태 데이터에서 레이블의 컬럼명
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;text_column_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;document&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# tabular형태 데이터에서 텍스트의 컬럼명
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;delimiter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;data_silo&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DataSilo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;processor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;processor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;eval_batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;caching&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;코드 실행 후, 다음과 같이 tokenization 되며, sample 객체에 저장된다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1DVPT_Rjv_SI4ggJZzqfPh0MgsMa1Q9El&quot; alt=&quot;[그림4] 실행화면&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;[그림4] 실행화면&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;하나를 확대해서 살펴보면 Sample객체 안에 다양한 정보들이 들어 있다.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;03/28/2021 22:12:15 - INFO - farm.data_handler.processor -   

      .--.        _____                       _      
    .&apos;_\/_&apos;.     / ____|                     | |     
    &apos;. /\ .&apos;    | (___   __ _ _ __ ___  _ __ | | ___ 
      &quot;||&quot;       \___ \ / _` | &apos;_ ` _ \| &apos;_ \| |/ _ \ 
       || /\     ____) | (_| | | | | | | |_) | |  __/
    /\ ||//\)   |_____/ \__,_|_| |_| |_| .__/|_|\___|
   (/\||/                             |_|           
______\||/___________________________________________                     

ID: 437-0
Clear Text: 
 	text_classification_label: good
 	text: 이 영화를 보고 두통이 나았습니다. ㅠ ㅠ
Tokenized: 
 	tokens: [&apos;이&apos;, &apos;영화를&apos;, &apos;보고&apos;, &apos;두&apos;, &apos;##통이&apos;, &apos;나&apos;, &apos;##았습니다&apos;, &apos;.&apos;, &apos;[UNK]&apos;, &apos;[UNK]&apos;]
 	offsets: [0, 2, 6, 9, 10, 13, 14, 18, 20, 22]
 	start_of_word: [True, True, True, True, False, True, False, False, True, True]
Features: 
 	input_ids: [2, 2451, 25833, 8198, 917, 11765, 587, 21809, 17, 1, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
 	padding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
 	segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
 	text_classification_label_ids: [1]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;modeling-layers-adaptivemodel--languagemodel--predictionhead&quot;&gt;Modeling Layers: AdaptiveModel = LanguageModel + PredictionHead&lt;/h2&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1OLWdr8rh7ucpF9t55gzVeMawMBJbRiEC&quot; alt=&quot;[그림5] Modeling Layers&quot; width=&quot;90%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;[그림5] Modeling Layers&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;LanguageModel&lt;/strong&gt;은 pretrained language models(BERT, XLNet …)의 표준 클래스&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;PredictionHead&lt;/strong&gt;는 모든 down-stream tasks(NER, Text classification, QA …)를 표준 클래스&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;AdaptiveModel&lt;/strong&gt;은 위 두 가지 모들의 결합, 하나의 LanguageModel과 여러 개의 PredictionHead를 결합할 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[expand]summary: 코드보기 👈&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# LanguageModel: Build pretrained language model
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EMBEDS_DROPOUT_PROB&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;TASK_NAME&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;text_classification&quot;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;language_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LanguageModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;PRETRAINED_MODEL_NAME_OR_PATH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;language&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;korean&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# PredictionHead: Build predictor layer
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prediction_head&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TextClassificationHead&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;num_labels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LABEL_LIST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;class_weights&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_silo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;calculate_class_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;task_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TASK_NAME&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AdaptiveModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;language_model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;language_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;prediction_heads&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prediction_head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;embeds_dropout_prob&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EMBEDS_DROPOUT_PROB&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;lm_output_types&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;per_sequence&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;실제 모델의 구성을 살펴보면 classification을 위한 bert와 유사하게 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PredictionHead&lt;/code&gt;에서는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pooler&lt;/code&gt;에서 나온 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pooled_output&lt;/code&gt;을 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dropout&lt;/code&gt;층을 통과한 후에 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FeedForwardBlock&lt;/code&gt;으로 보내서 최종 logits을 생성한다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AdaptiveModel&lt;/code&gt; class에서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;embeds_dropout_prob&lt;/code&gt;를 바꾸면, dropout 확률을 조절할 수 있다.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;h2 id=&quot;train--eval--inference&quot;&gt;Train &amp;amp; Eval &amp;amp; Inference&lt;/h2&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1bD54igqAn7T96gDCFZ2uxzFHpZIL5GOh&quot; alt=&quot;[그림6] Modeling Layers&quot; width=&quot;90%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;[그림6] Modeling Layers&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;여타 다른 패키지와 마찬가지로 Trainer는 모델과 분리되어 있다. FARM에는 EarlyStopping callback을 지원한다. 훈련 진행도중 정해진 스텝마다 평가를 하는데, 이때 callback이 작동한다.&lt;/p&gt;

&lt;h3 id=&quot;train--eval&quot;&gt;Train &amp;amp; Eval&lt;/h3&gt;

&lt;p&gt;[expand]summary: 코드보기 👈&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;LEARNING_RATE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;2e-5&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;N_EPOCHS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;N_GPU&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;checkpoint_path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;./ckpt/NSMC&quot;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Initialize Optimizer
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr_schedule&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialize_optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LEARNING_RATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;n_batches&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_silo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loaders&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;train&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;n_epochs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N_EPOCHS&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# EarlyStopping
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;earlymetric&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;f1&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;task_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;question_answering&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;acc&quot;&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;max&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;task_name&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;text_classification&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;question_answering&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;min&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;earlystop&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;EarlyStopping&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;save_dir&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;checkpoint_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;metric&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;earlymetric&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;patience&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Trainer
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trainer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Trainer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;lr_schedule&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr_schedule&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;data_silo&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_silo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;early_stopping&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;earlystop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;evaluate_every&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;checkpoints_to_keep&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;checkpoint_root_dir&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;checkpoint_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;checkpoint_every&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N_EPOCHS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;n_gpu&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N_GPU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# now train!
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trainer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;훈련 과정에 계속 Log가 찍히고, Processor단계에서 입력해둔 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;test_filename&lt;/code&gt;로 평가도 해준다. 다음 그림은 430개의 배치 데이터(&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;batch_size=256&lt;/code&gt;)를 돌렸을 때 earlystopping한 결과다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1m1K9CjBNulC4dzSxC1vKjLb94p9BQu26&quot; alt=&quot;[그림7] logging 내용&quot; width=&quot;90%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;[그림7] logging 내용&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h3 id=&quot;inference&quot;&gt;Inference&lt;/h3&gt;

&lt;p&gt;실제 네이버 영화 두 곳에서 각기 다른 평점을 가져와서 테스트 해보았다.&lt;/p&gt;

&lt;p&gt;[expand]summary: 코드보기 👈&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;termcolor&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;farm.infer&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Inferencer&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pprint&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PrettyPrinter&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# https://movie.naver.com/movie/bi/mi/basic.nhn?code=161967
# https://movie.naver.com/movie/bi/mi/point.nhn?code=196051
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;basic_texts&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;text&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;비에 젖지 않는 고급 장난감 텐트와, 비에 젖다 못해 잠겨버리는 반지하 가구&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 161967 / 평점 10
&lt;/span&gt;    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;text&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;남들이 난해하단거 보고 혼자 이해했다며 심오한척 하고플때나 보면 딱인 영화. 통찰도 시사점도 재미도 의미도 감동도 없는... 
진정한 킬링타임. 가난한 사람들 다 기생충에 비유한거야? 그렇다면 감독 개똥철학 완전꽝이고...&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 161967 / 평점 1
&lt;/span&gt;    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;text&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;와 이거 안보면 인생 절반 후회한겁니다 여러분&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 196051 / 평점 10
&lt;/span&gt;    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;text&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;절레절레 돈주고 보지마셈ㅋㅋㅋㅋ&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 196051 / 평점 1
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;infer_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Inferencer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model_name_or_path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;./ckpt/best_nsmc&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;task_type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;text_classification&quot;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;infer_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inference_from_dicts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dicts&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;basic_texts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;star&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;predictions&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;161967&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;161967&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;196051&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;196051&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;context&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;label&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;probability&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;probability&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;star&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;termcolor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;colored&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;star&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;blue&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attrs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;bold&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;bad&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;termcolor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;colored&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;red&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attrs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;bold&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;termcolor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;colored&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;green&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attrs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;bold&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;termcolor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;colored&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;[Movie: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mid&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;] Context:&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attrs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;bold&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Probability &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;probability&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;% | Predict: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; | Real Star: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;star&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1fI8ME4YexqN75CumIcCO32jUWl3BB86U&quot; alt=&quot;[그림8] 테스트 결과&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;[그림8] 테스트 결과&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;두 영화는 봉준호 감독님의 ‘기생충(id=161967)’, 최근 인기가도를 달리고 있는 ‘극장판 귀멸의 칼날: 무한열차편(id=196051)’를 선정했다. 하나를 제외하고 잘 맞춘 모습을 보여줬는데, 첫번째 샘플의 경우 사실 영화의 장면을 묘사한 것으로, 그만큼 인상깊었던 장면들을 달면서 평점은 10점으로 달았다. 사람으로써 이 영화을 본 관객이라면 이 평가가 10점에 알맞는 평점(혹은 긍정)이지만, 기계에게는 아직 어려운 점 중에 하나라고 생각한다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;mlflow&quot;&gt;MLflow&lt;/h1&gt;

&lt;p&gt;MLflow를 이용하 빠르고 쉽게 실험을 관리하고, 관련 평가지표도 함께 볼 수 있다. 다음 그림들은 TITAN RTX 4대에서 배치크기를 256으로 훈련 시킨 결과다(440 batches 에서 Early Stopping했다.).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;public mlflow(&lt;a href=&quot;https://public-mlflow.deepset.ai/#/experiments/313/runs/05e7e3d4945642f9ab3e296637d57c26&quot;&gt;링크&lt;/a&gt;)에서 확인하기&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=13Cg8eziHBgA3JLwZJ3Bo8YzeySWPRmiP&quot; alt=&quot;[그림9] Parameters&quot; width=&quot;50%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;[그림9] Parameters&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;Train과 Dev 세트의 loss는 다음과 같다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1cpFWVvjkSqshvN0hS_CuPk4RjyEyM0AV&quot; alt=&quot;[그림10] Loss Graph&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;[그림10] Loss Graph&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;Dev 세트의 정확도는 다음과 같다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1VPso9Gx60V8_dgE4as054n7kymCoQ9w5&quot; alt=&quot;[그림11] Dev Accuracy Graph&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;[그림11] Dev Accuracy Graph&lt;/figcaption&gt;&lt;/figure&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;task-supported&quot;&gt;TASK Supported&lt;/h1&gt;

&lt;p&gt;현재 지원되는 모델과 SubTask는 다음과 같다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Task&lt;/th&gt;
      &lt;th&gt;BERT&lt;/th&gt;
      &lt;th&gt;RoBERTa*&lt;/th&gt;
      &lt;th&gt;XLNet&lt;/th&gt;
      &lt;th&gt;ALBERT&lt;/th&gt;
      &lt;th&gt;DistilBERT&lt;/th&gt;
      &lt;th&gt;XLMRoBERTa&lt;/th&gt;
      &lt;th&gt;ELECTRA&lt;/th&gt;
      &lt;th&gt;MiniLM&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Text classification&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;NER&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Question Answering&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Language Model Fine-tuning&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Text Regression&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Multilabel Text classif.&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Extracting embeddings&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;LM from scratch&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Text Pair Classification&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Passage Ranking&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Document retrieval (DPR)&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;compare-to-others&quot;&gt;Compare to others&lt;/h1&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1TZoRpza8-o4wSTr0s16f8hHQRroLQg30&quot; alt=&quot;[그림12] 다른 패키지와의 비교&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;[그림12] 다른 패키지와의 비교&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;다른 모델과 비교해보면 FARM은 조금 더 huggingface와 pytorch-lightning의 합본 축약 버전이라고 생각할 수 있다. 마치 Tensorflow v1과 keras의 차이 느낌이다.&lt;/p&gt;

&lt;h2 id=&quot;farm-장단점&quot;&gt;FARM 장단점&lt;/h2&gt;

&lt;p&gt;장점:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;데이터 세트만 준비되어 있으면, 다른 패키지에 비해 상대적으로 설정 할 것이 적음&lt;/li&gt;
  &lt;li&gt;훈련 속도가 빠르고, 실험 기록 및 관리이 편리해서 빠르게 실험해 볼 수 있음(텐서보드 대신 mlflow 사용 가능)&lt;/li&gt;
  &lt;li&gt;멀티 GPU 설정을 해줄 필요가 없음&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;단점:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;customization이 상대적으로 힘듦&lt;/li&gt;
  &lt;li&gt;아직 발전 중이라 불안정하고 documentaton이 잘 안되어 있음&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Wed, 31 Mar 2021 01:30:01 +0900</pubDate>
        <link>https://simonjisu.github.io/nlp/2021/03/31/farm.html</link>
        <guid isPermaLink="true">https://simonjisu.github.io/nlp/2021/03/31/farm.html</guid>
        
        
        <category>nlp</category>
        
      </item>
    
      <item>
        <title>Jekyll Blog Collapsible Block 만들기</title>
        <description>&lt;h1 id=&quot;지킬블로그-텍스트-확장-블록-만들기&quot;&gt;지킬블로그 텍스트 확장 블록 만들기&lt;/h1&gt;

&lt;p&gt;지킬에서 블로그를 쓰다보면 가끔 아주 긴 부연설명에 대한 텍스트를 넣고 싶거나, 긴 코드블록을 숨겨서 이쁘게 꾸미고 싶을 때가 있다. 그런데 내가 인터넷에서 나오는 expand 모듈들은 markdown 내에 html 태그를 길게 써야되서 불편했다. 그래서 기존에 인터넷에 있던 코드를 기반으로 새로 만들었다. 그렇게 썩 깔끔한 코드는 아니지만, 해당기능이 필요한 사람들에게 잘 사용됐으면 좋겠다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;세팅법&quot;&gt;세팅법&lt;/h1&gt;

&lt;p&gt;제일먼저 세팅해야할 것은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_config.yml&lt;/code&gt; 에서 마크다운이 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;kramdown&lt;/code&gt; 인지 확인 하는 것이다. 그 이유는 collapsible block을 만들기 위해서는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;details&amp;gt;&lt;/code&gt; 태그를 사용해야하는데,  &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;kramdown&lt;/code&gt;이 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;details&amp;gt;&lt;/code&gt;를 지원하는 것으로 알고 있다.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# _config.yml&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;markdown&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;kramdown&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;[expand]summary:열어서 text-expander 코드 복사하기 👈&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://gist.github.com/simonjisu/43c789bf44e9f8171be440b46f0948a5&quot;&gt;여기&lt;/a&gt;에서 다운로드 하거나, 아래 코드를 복사한다.&lt;/p&gt;

&lt;div class=&quot;language-html highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;&amp;lt;!-- Author: https://github.com/simonjisu
Change `div.article-content` to your article container in jekyll blog
Put your file into `_include/text-expand.html`
--&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;script&amp;gt;&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;elements&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;document&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;querySelectorAll&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;div.article-content&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;childNodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// 수정1 &lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;addContent&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;contentsToAdd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[];&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;expandtags&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;detailText&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;detailsTag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;summaryTag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;detailsContent&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;elements&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;el&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;elements&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;el&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;innerHTML&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;[/expand]&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;addContent&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;detailsContent&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;document&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;createElement&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;div&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;detailsContent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;className&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;collaspe-content&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;detailsContent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;setAttribute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;markdown&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;el&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;parentNode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;removeChild&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;el&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;el&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;innerHTML&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;[expand]&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;el&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;nodeName&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;el&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;innerHTML&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;includes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;[expand]summary:&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;addContent&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;expandtags&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;el&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;innerHTML&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;summary:&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;expandtags&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
            &lt;span class=&quot;nx&quot;&gt;detailText&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;Details&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nx&quot;&gt;detailText&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;expandtags&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;detailsTag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;document&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;createElement&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;details&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;detailsTag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;className&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;collaspe-article&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;summaryTag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;document&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;createElement&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;summaryTag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;appendChild&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;document&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;createTextNode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;detailText&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;detailsTag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;appendChild&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;summaryTag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;contentsToAdd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nx&quot;&gt;detailsContent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;appendChild&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;contentsToAdd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;detailsTag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;appendChild&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;detailsContent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;el&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;parentNode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;replaceChild&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;detailsTag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;el&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;contentsToAdd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;addContent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nx&quot;&gt;contentsToAdd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;push&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;el&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/script&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;그 다음 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_include&lt;/code&gt; 폴더내에 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;text-expand.html&lt;/code&gt; 파일을 만들고 다음 코드를 복사해서 붙여넣기 하자. 여기서 수정할 부분은 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;elements&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;document&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;querySelectorAll&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;div.article-content&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;childNodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;div.article-content&lt;/code&gt; 부분을 수정해야하는데 자신의 jekyll 구조를 파악해서 글의 내용이 어느 컨테이너에 있는지 확인해야한다. 자신의 블로그에서 마우스 오른쪽 버튼을 누르고 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;검사&lt;/code&gt;를 통해 구조를 파악하거나, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_layout&lt;/code&gt;폴더의 파일들 중 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;body&amp;gt;&lt;/code&gt; 태그 사이를 잘 살펴보면 된다. 내 블로그의 경우 구조가 다음과 같은데, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;div class=&quot;article-content&quot;&amp;gt;&lt;/code&gt; 가 글에 해당하는 내용이다.&lt;/p&gt;

&lt;div class=&quot;language-html highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;&amp;lt;!DOCTYPE html&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;html&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;head&amp;gt;&lt;/span&gt; ... &lt;span class=&quot;nt&quot;&gt;&amp;lt;/head&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;body&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;div&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;class=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;page-content&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;div&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;class=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;container&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;div&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;class=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;three columns&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;header&amp;gt;&lt;/span&gt; ... &lt;span class=&quot;nt&quot;&gt;&amp;lt;/header&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;/div&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;div&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;class=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;nine columns&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;style=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;z-index:100;&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;div&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;class=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;wrapper&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;article&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;class=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;post&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;header&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;class=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;post-header&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
              &lt;span class=&quot;nt&quot;&gt;&amp;lt;h1&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;class=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;post-title&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt; ... &lt;span class=&quot;nt&quot;&gt;&amp;lt;/h1&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;/header&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;div&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;class=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;article-content&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
                content   &lt;span class=&quot;c&quot;&gt;&amp;lt;!-- 포스트의 내용이 담김 곳 --&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;/div&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;/article&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;/div&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;/div&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;/div&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;footer&amp;gt;&lt;/span&gt; ... &lt;span class=&quot;nt&quot;&gt;&amp;lt;/footer&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/div&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;/body&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/html&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그 다음 스텝으로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_layout&lt;/code&gt; 폴더에서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;/body&amp;gt;&lt;/code&gt; 태그가 들어간 파일을 찾아, 이전에 다음과 같이 liquid 문법으로 아까 만든 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;text-expand.html&lt;/code&gt;을 포함시킨다.&lt;/p&gt;

&lt;div class=&quot;language-html highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{% include text-expand.html %}
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/body&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;마지막으로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_sass&lt;/code&gt; 폴더의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_layout.scss&lt;/code&gt; 파일에 관련 css만 추가해주면 끝난다.&lt;/p&gt;

&lt;div class=&quot;language-scss highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;// _sass/_layout.scss &lt;/span&gt;
&lt;span class=&quot;nc&quot;&gt;.collaspe-article&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nl&quot;&gt;padding-top&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;10px&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;nl&quot;&gt;padding-bottom&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;10px&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;nc&quot;&gt;.collaspe-content&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nl&quot;&gt;padding-top&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;5px&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;nc&quot;&gt;.collaspe-content&lt;/span&gt;&lt;span class=&quot;nd&quot;&gt;:before&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nl&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;nl&quot;&gt;display&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;nl&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;100%&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;nl&quot;&gt;border-bottom&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1px&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;solid&lt;/span&gt; &lt;span class=&quot;mh&quot;&gt;#bcbcbc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;nc&quot;&gt;.collaspe-content&lt;/span&gt;&lt;span class=&quot;nd&quot;&gt;:after&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nl&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;nl&quot;&gt;display&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;nl&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;100%&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;nl&quot;&gt;border-bottom&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1px&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;solid&lt;/span&gt; &lt;span class=&quot;mh&quot;&gt;#bcbcbc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;사용법&quot;&gt;사용법&lt;/h1&gt;

&lt;p&gt;마크다운에서 다음과 같이 쓰면 된다. 주의할 점은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[expand]&lt;/code&gt;사이에 새 줄만 잘 띄어주면 된다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[expand]&lt;/code&gt;뒤에는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;summary:&lt;/code&gt;를 붙여서 설명하고 싶은 내용을 적을 수 있다. 만약에 없으면 기본으로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Details&lt;/code&gt;가 들어간다.&lt;/p&gt;

&lt;p&gt;예를 들면, 다음 코드는 아래처럼 바뀐다.&lt;/p&gt;

&lt;p&gt;[expand]summary:원하는 블록 요약 쓰기&lt;/p&gt;

&lt;p&gt;내용을 써주세요. [expand] 사이에 마크다운 문법이 가능합니다.&lt;/p&gt;

\[1 + 1 = 3\]

&lt;p&gt;설명을 위해 코드블록을 일부러 띄워 썼습니다. 실제로 쓸때는 밑에 띄어쓴 칸을 지우세요!&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;div class=&quot;language-markdown highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
[expand]summary:원하는 블록 요약 쓰기

내용을 써주세요. [expand] 사이에 마크다운 문법이 가능합니다.

$$1 + 1 = 3$$

설명을 위해 코드블록을 일부러 띄워 썼습니다. 실제로 쓸때는 밑에 띄어쓴 칸을 지우세요!
    
    &lt;span class=&quot;p&quot;&gt;```&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;python
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;```&lt;/span&gt;

[/expand]

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;기본원리&quot;&gt;기본원리&lt;/h1&gt;

&lt;p&gt;짧게 설명하면, Markdown에서 Collapsible block의 문법은 다음과 같으며, 원하면 자신만의 코드로 커스텀해서 사용해볼 수 있다.&lt;/p&gt;

&lt;div class=&quot;language-html highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;details&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;summary&amp;gt;&lt;/span&gt; 표기할것 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/summary&amp;gt;&lt;/span&gt;
내용쓰기
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/details&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
</description>
        <pubDate>Sun, 07 Mar 2021 18:28:01 +0900</pubDate>
        <link>https://simonjisu.github.io/programming/2021/03/07/jekyllexpand.html</link>
        <guid isPermaLink="true">https://simonjisu.github.io/programming/2021/03/07/jekyllexpand.html</guid>
        
        
        <category>programming</category>
        
      </item>
    
      <item>
        <title>Tree-based Ensemble: Boosting</title>
        <description>&lt;h1 id=&quot;references&quot;&gt;References&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://ko.wikipedia.org/wiki/%EA%B2%B0%EC%A0%95_%ED%8A%B8%EB%A6%AC_%ED%95%99%EC%8A%B5%EB%B2%95&quot;&gt;위키백과: 결정 트리 학습법&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://brunch.co.kr/@snobberys/137&quot;&gt;Xgboost 사용하기&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://brunch.co.kr/@chris-song/98&quot;&gt;Ensemble: bagging, boosting&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://3months.tistory.com/368&quot;&gt;Gradient Boosting Algorithm의 직관적 이해&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/rpmcruz/machine-learning/blob/master/ensemble/boosting/gboost.py&quot;&gt;rpmcruz의 gboost코드&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ensemble&quot;&gt;Ensemble&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;앙상블(Ensemble)&lt;/strong&gt;의 사전적 의미는 2인 이상의 노래나 연주를 뜻하는데, 머신러닝에서 앙상블 학습이란 하나의 학습 알고리즘 보다 더 좋은 성능을 내기 위해 다수의 약한 성능을 가진 학습 알고리즘을 합쳐서 사용하는 방법이다. 이때, 약한 성능을 가진 학습 알고리즘을 &lt;strong&gt;약한 학습자(Weak Learner)&lt;/strong&gt;라고 부른다. 앙상블 학습은 일반적으로 &lt;strong&gt;배깅(Bagging)&lt;/strong&gt; 과 &lt;strong&gt;부스팅(Boosting)&lt;/strong&gt; 두 가지의 유형으로 나눌 수 있다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Bagging(Bootstrap Aggregation): 샘플을 여러번 뽑아(Bootstrap)서 여러 개의 약한 학습자를 병렬적으로 학습시켜 결과물을 집계(Aggregration)하는 방법. 결과물을 집계하는 방법으로 회귀 문제의 경우 평균을 내거나, 분류 문제의 경우 가장 많이 나온 클래스로 투표(Hard Voting) 혹은 클래스의 확률을 평균화해서 가장 높은 확률로 도출(Soft Voting)한다. 모델의 variance를 줄이는 방향을 원한다면 배깅방법이 적합하다.&lt;/li&gt;
  &lt;li&gt;Boosting: 훈련 데이터를 샘플링하여 순차적으로 약한 학습자를 하나씩 추가시키면서 학습한다. 각 약한 학습자들은 가중치로 연결된다는 것이 특징이다. 다만 이전 약한 학습자가 틀린 데이터의 샘플링이 더 잘 되게 가중치를 부여하여 훈련 데이터를 생성하고 다시 학습한다. 모델의 bias를 줄이는 방향을 생각하고 있다면, 부스팅 방법이 적합하다.&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;boosting-ensemble&quot;&gt;Boosting Ensemble&lt;/h1&gt;

&lt;p&gt;앙상블 방법론중 부스팅 방법에는 &lt;strong&gt;적응형 부스팅(Adaptive Boosting)&lt;/strong&gt;, &lt;strong&gt;경사 부스팅(Gradient Boosting)&lt;/strong&gt;이 있다. 이번 글에서는 Gradient Boosting을 중점적으로 다뤄본다.&lt;/p&gt;

&lt;h2 id=&quot;gradient-boosting&quot;&gt;Gradient Boosting&lt;/h2&gt;

&lt;p&gt;Gradient Boosting을 한마디로 하면 Pseudo-Residual Fitting이라고 할 수 있다. 예를 들어, 약한 학습자 $A$로 데이터($Y, X$)를 학습시킨 결과를 다음 수식으로 표현해본다.&lt;/p&gt;

\[Y = A(X) + \epsilon_1\]

&lt;p&gt;여기서 $\epsilon_1$은 &lt;strong&gt;오차(error)&lt;/strong&gt; 혹은 &lt;strong&gt;잔차(residual)&lt;/strong&gt;이라고 부른다. 그러면 남은 $\epsilon_1$에 대해서 다른 약한 학습자 $B$를 예측을 잘하게 학습시켜서 $Y$를 예측한다.&lt;/p&gt;

\[\epsilon_1 = B(X) + \epsilon_2\]

&lt;p&gt;이렇게 계속 잔차를 줄여나가면서 여러 개의 약한 학습자를 연결시키는 것이 Gradient Boosting이다.&lt;/p&gt;

&lt;h3 id=&quot;negative-gradient&quot;&gt;Negative Gradient&lt;/h3&gt;

&lt;p&gt;그렇다면 왜 Gradient가 들어가는가? 그 해답은 손실함수(loss function)와 연결된다.&lt;/p&gt;

&lt;p&gt;예를 들어, Mean Squared Error를 손실함수로 설정하면, 다음과 같이 예측 값에 대해 경사(gradient)를 구할 수 있다.&lt;/p&gt;

\[\begin{aligned} 
\text{Loss} &amp;amp;= L \big(Y, f(X) \big) = \dfrac{1}{2} \big( Y - f(X) \big)^2 \\
\text{gradient} &amp;amp;= \dfrac{\partial L}{\partial f(X)} = \dfrac{1}{2} \times 2 \big( Y - f(X) \big) \times (-1) = -\big( Y - f(X) \big) \\
\text{residual} &amp;amp;= -\dfrac{\partial L}{\partial f(X)} = - \text{gradient}
\end{aligned}\]

&lt;p&gt;이때의 잔차는 음의 경사값이 되는 것을 알 수 있다. 이는 우리가 데이터를 남은 잔차에 대해서 학습하는 방법이 곧 전체 손실값을 줄이는 것과 같다는 이야기다.&lt;/p&gt;

&lt;p&gt;[expand]summary:부연 설명보기 👈&lt;/p&gt;

&lt;p&gt;부연 설명하자면, 두 개의 약한 학습자를 예로 들면 다음과 같다.&lt;/p&gt;

\[\begin{aligned}
\text{fitting: } Y &amp;amp;= f_1(X) + \epsilon_1 \\
L_1 &amp;amp;= L\big(Y, f_1(X) \big) = \dfrac{1}{2}\big( Y - f_1(X)\big)^2 \\
\dfrac{\partial L_1}{\partial f_1(X)} &amp;amp;= - \big( Y - f_1(X)\big) = - \epsilon_1 \\
\\
\text{fitting: } \epsilon_1 &amp;amp;= f_2(X) + \epsilon_2 \\
L_2 &amp;amp;= L\big(\epsilon_1, f_2(X) \big) = \dfrac{1}{2}\big( \epsilon_1 - f_2(X)\big)^2 \\
\dfrac{\partial L_2}{\partial f_2(X)} &amp;amp;= - \big( \epsilon_1 - f_2(X)\big) = - \epsilon_2 \\
\end{aligned}\]

&lt;p&gt;여기서 $\epsilon_1$을 $L_2$ 에 넣어보면&lt;/p&gt;

\[\begin{aligned}
L_2 &amp;amp;= \dfrac{1}{2}\big( Y - f_1(X) - f_2(X)\big)^2 \\
\dfrac{\partial L_2}{\partial f_2(X)} &amp;amp;= - \big( Y - f_1(X) - f_2(X)\big) = - \epsilon_2
\end{aligned}\]

&lt;p&gt;가 되고, $F(X) = f_1(X) + f_2(X)$ 라고 하면, 약한 학습자를 여러 개를 더한 모델($f_1(X) + f_2(X)$)을 최적화 하는 것과 하나의 잘 예측하는 모델($F(X)$)를 최적화하는 것과 같다는 것을 알 수 있다(말장난 같지만, 이유는 같은 잔차$\epsilon_2$ 가 남기 때문).&lt;/p&gt;

\[\begin{aligned}
L &amp;amp;= \dfrac{1}{2}\big( Y - F(X)\big)^2 \\
\dfrac{\partial L}{\partial F(X)} &amp;amp;= - \big( Y - F(X)\big) = - \epsilon_2
\end{aligned}\]

&lt;p&gt;또한, 원래 잔차를 구하려면 학습된 모델에 예측을 하고, 타겟값에 예측값을 빼줘야하는데, 미분으로 잔차를 구할 수 있으니 더 빠르게 학습이 가능하다.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;결국에는 negative gradient가 잔차와 일치하기 때문에 Gradient 용어가 들어가는 것이다.&lt;/p&gt;

&lt;p&gt;알고리즘은 다음과 같이 진행한다(&lt;a href=&quot;https://github.com/rpmcruz/machine-learning/blob/master/ensemble/boosting/gboost.py&quot;&gt;rpmcruz의 gboost코드&lt;/a&gt;를 빌려 약간의 변형후 해석해본다).&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# self.first_estimator = 더미모델
# self.base_estimator = 약한 학습자
# self.loss = residual 함수, 여기서는 y - y_pred
# self.eta = Loss(y, y_pred)를 최소로 하는 eta값을 구하는데,
# 여기서는 생략하고 하나의 값으로 통일
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first_estimator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# step 0
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first_estimator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# step 1
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;M&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# step 2
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;R&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# step 3
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;clone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base_estimator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;R&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# step 4
&lt;/span&gt;        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;f0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]],&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Step 0.&lt;/strong&gt; dummy 모델(예를 들어 모든 예측값이 0인 모델)로 초기화 한다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Step 1.&lt;/strong&gt; 모델의 개수 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;M&lt;/code&gt; 만큼 진행하며 항상 첫 스텝에 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;X&lt;/code&gt;에 대한 예측을 한다. 예측은 현재까지 저장해둔 약한 학습자의 예측값과 가중치(&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;self.eta&lt;/code&gt;)를 곱해서 합한 값으로 한다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Step 2.&lt;/strong&gt; 예측값(&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;y_pred&lt;/code&gt;)과 타겟값(&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;y&lt;/code&gt;)을 이용해 잔차(&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;R&lt;/code&gt;)을 구한다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Step 3.&lt;/strong&gt; 약한 학습자를 타겟값이 아닌 잔차값에 대해서 학습한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;tree-based-ensemble--cart&quot;&gt;Tree-Based Ensemble &amp;amp; CART&lt;/h1&gt;

&lt;p&gt;의사결정 나무 계열의 앙상블중 부스팅 방법을 사용하는 패키지들은 많이 있으나, 그중에서 XGBoost를 소개하려고 한다. 그 전에 의사결정 나무의 &lt;strong&gt;CART(Classification And Regression Tree)&lt;/strong&gt; 알고리즘을 소개하고 넘어간다.&lt;/p&gt;

&lt;p&gt;CART 알고리즘은 이름에서도 알 수 있듯이 분류와 회귀를 둘다 가능케하는 알고리즘이다. 분류의 경우 지니 계수(Gini Index)를 사용하고, 회귀의 경우 실제값과 예측값의 오차(MSE)를 사용해서 분기를 정한다. 일반적인 의사결정 나무와 다르게, 리프 노드(leaf node)에는 실제값 대신 결정값(decision values)을 보존하고 있다.&lt;/p&gt;

&lt;p&gt;예를 들어, 다음 그림과 같이 가족원 5명중 컴퓨터 게임을 좋아할 만한 사람을 분류하는 모델을 만들면 최종 리프 노드에는 해당 조건에 부합할 경우 양의 점수가 저장되고 그렇지 않으면 음의 점수가 저장된다. 이러한 결정값을 저장함으로써 더 유연한 비교와 추론을 할 수가 있다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=15_gKUfmzAV-oZaJ17uYDajhmGjIQc4Sc&quot; alt=&quot;출처: XGBoost Documentation&quot; width=&quot;80%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;출처: XGBoost Documentation&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;보통 하나의 의사결정 나무 모델을 쓰지 않고, 앙상블 학습법을 많이 쓰기 때문에, 예를 들어, 다음과 같이 두 개의 의사 결정나무를 예시로 어떻게 진행되는지 살펴보자.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1APEjS1gHrcfJXR_W7BC29mV6dNIteVe9&quot; alt=&quot;출처: XGBoost Documentation&quot; width=&quot;80%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;출처: XGBoost Documentation&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;각 샘플(가족원)의 최종 점수를 계산하려면 샘플이 속한 스코어를 전부 더하면 된다. 파란 옷을 입은 아들의 경우, 첫번째 모델에서 $+2$ 그리고 두번째 모델에서 $+0.9$의 결정값을 가짐으로 최종 결정값은 $+2.9$가 된다. 점수가 높을 수록 게임을 더 좋아한다는 뜻임으로, 아들은 게임을 좋아한다고 분류할 수 있다.&lt;/p&gt;

&lt;p&gt;여기에는 두 의사결정 나무 모델이 같은 가중치를 가지고 있다고 가정하고 있다. 물론 가중치를 다르게 줘서, 나이가 더 중요하다고 생각하면 첫번째 모델에 더 가중치를 줘서 높은 결정값을 가지게 할 수도 있다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;xgboost&quot;&gt;XGBoost&lt;/h1&gt;

&lt;p&gt;Gradient Boosting 알고리즘에서 가장 유명한 패키지는 &lt;a href=&quot;https://xgboost.readthedocs.io/en/latest/index.html&quot;&gt;&lt;strong&gt;XGBoost&lt;/strong&gt;&lt;/a&gt;이다. XGBoost는 Extreme Gradient Boosting 의 약자로써, 말그대로 엄청나게 빠른 Boosting 학습을 지원한다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;설치방법과 사용방법은 따로 다루지 않으며 아래 링크를 참고하길 바란다.
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://xgboost.readthedocs.io/en/latest/parameter.html&quot;&gt;XGBoost 공식문서&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://brunch.co.kr/@snobberys/137&quot;&gt;브런치: Xgboost 사용하기&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://eagle705.github.io/articles/2018-06/XGBoost-정리&quot;&gt;eagle705님의 블로그: XGBoost-정리&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;특징&quot;&gt;특징&lt;/h2&gt;

&lt;p&gt;정규화(regularization)를 도입해서 과적합을 피하고 있다. 목적함수에 의사결정 나무의 복잡도($\Omega$)를 구하여 이를 억제하는 방식으로 훈련한다.&lt;/p&gt;

\[\begin{aligned}
\text{Loss}^{(t)} = \sum_{i=1}^n L(y_i, y_i^{(t)}) + \sum_{j=1}^{t} \Omega(f_j)
\end{aligned}\]

&lt;p&gt;의사결정 나무를 (1)식과 같이 정의하면, 복잡도은 (2)식 처럼 정의할 수 있다. 여기서 $w$는 리프노드의 결정값 벡터이고, $q$는 각 데이터를 해당하는 $T$개의 모델의 리프노드에 배분하는 함수다. 모델 복잡도에서 $\gamma$는 정보획득(information gain)에 관한 변수이며, 정보획득량이 $\gamma$보다 낮은 경우 약한 학습자를 더하지 않는다. $\lambda$는 결정값에 관한 변수이며, 해당 값이 높을수록 결정값이 커지지 않게 더 큰 제약을 준다.&lt;/p&gt;

\[\begin{aligned}
f_t(x) &amp;amp;= w_{q(x)}, w \in R^T , q: R^d \rightarrow \{ 1, 2, \cdots, T\} &amp;amp; \cdots (1)\\
\Omega(f) &amp;amp;= \gamma T + \dfrac{1}{2} \lambda \sum_{j=1}^T w_j^2 &amp;amp; \cdots (2)
\end{aligned}\]

&lt;h2 id=&quot;xgboost의-병렬처리&quot;&gt;XGBoost의 병렬처리&lt;/h2&gt;

&lt;p&gt;원칙적으로 Boosting방법은 Additive 학습 방법이기 때문에, 학습 방법 자체는 병렬이 불가능한 구조다. 하지만, 의사결정 나무를 만드는 과정을 병렬화(하나의 모델 내에서 openMP로 개별 코어에게 분배해서 하위 브랜치를 만듦)함으로써 더 빠르게 학습을 완료시킬 수 있었다. 아래 레퍼런스를 참고하자.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://m.blog.naver.com/nicolechae0627/221811579005&quot;&gt;XGBoost vs GBM&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://machinelearningkorea.com/2019/07/25/xgboost-의-병렬처리가-어떻게-가능할까/&quot;&gt;XGBoost의 병렬처리&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://stackoverflow.com/questions/34151051/how-does-xgboost-do-parallel-computation&quot;&gt;How does XGBoost do parallel computation?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sun, 07 Mar 2021 17:13:01 +0900</pubDate>
        <link>https://simonjisu.github.io/machinelearning/2021/03/07/treeboosting.html</link>
        <guid isPermaLink="true">https://simonjisu.github.io/machinelearning/2021/03/07/treeboosting.html</guid>
        
        
        <category>machinelearning</category>
        
      </item>
    
      <item>
        <title>Decision Tree</title>
        <description>&lt;p&gt;가장 고전적인 머신러닝 모델이지만 정확하게 알고 넘어가야할 것 같아 정리한다.&lt;/p&gt;

&lt;h1 id=&quot;references&quot;&gt;References&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://ko.wikipedia.org/wiki/%EA%B2%B0%EC%A0%95_%ED%8A%B8%EB%A6%AC_%ED%95%99%EC%8A%B5%EB%B2%95&quot;&gt;위키백과: 결정 트리 학습법&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://ratsgo.github.io/machine%20learning/2017/03/26/tree/&quot;&gt;ratsgo blog: 의사결정나무(Decision Tree)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://m.blog.naver.com/laonple/220861527086&quot;&gt;라온피플 blog: Decision Tree&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://scikit-learn.org/stable/modules/tree.html&quot;&gt;Scikit-Learn: Decision Tree&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://scikit-learn.org/stable/auto_examples/tree/plot_cost_complexity_pruning.html&quot;&gt;Scikit-Learn: Post Pruning&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://scikit-learn.org/stable/modules/permutation_importance.html&quot;&gt;Scikit-Learn: Permutation feature importance&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://hwi-doc.tistory.com/entry/Feature-selection-feature-importance-vs-permutation-importance&quot;&gt;Feature selection : feature importance vs permutation importance&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;의사결정-나무decision-tree&quot;&gt;의사결정 나무(Decision Tree)&lt;/h1&gt;

&lt;p&gt;의사결정 나무는 분류 및 회귀에 사용되는 전통적인 &lt;strong&gt;비모수(non-parametric)&lt;/strong&gt; 지도학습 방법이다. 이 알고리즘의 목적은 입력 데이터 피처(features)로부터 타겟 데이터를 유추할 수 있는 간단한 규칙을 학습하는 것이다. 위키백과에 나온 타이타닉 탑승객 생존 여부를 나태내는 트리로 예를 들면 다음과 같다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1U_uzhLK2KzUYOyxjCLoHcVjzVneLOQBn&quot; alt=&quot;출처: 위키백과&quot; width=&quot;50%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;출처: 위키백과&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;리프 노드(leaf node)가 아닌 노드들(마름모 모양)은 각 입력 데이터 피처에 대한 규칙을 나타내고 있으며, 이 그림에서는 위에서 부터&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;성별&lt;/li&gt;
  &lt;li&gt;나이&lt;/li&gt;
  &lt;li&gt;탑승한 배우자와 자녀의 수&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이다. 반면 리프 노드(생존/사망)는 각 규칙에 이어지는 경로를 따랐을 때, 타겟 데이터의 값이다. 이 그림에서는&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;생존 확률 = 해당 리프 노드에 속하는 생존 수 / 해당 클래스에 속하는 전체 승객 수&lt;/li&gt;
  &lt;li&gt;리프노드에 해당할 확률 = 사망 혹은 생존 수 / 전체 탑승객 수&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;을 나타내고 있다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;학습의-기준-불확실성&quot;&gt;학습의 기준: 불확실성&lt;/h2&gt;

&lt;p&gt;학습의 기준은 불확실성을 나타내는 &lt;strong&gt;엔트로피(entropy)&lt;/strong&gt; 혹은 &lt;strong&gt;불순도(impurity)&lt;/strong&gt;가 최대로 감소하는 방향으로 진행된다(엔트로피 함수 혹은 Gini계수를 쓰지만 여기서는 엔트로피를 사용한다). 이전 단계와 현재 단계의 불확실성의 차이를 &lt;strong&gt;정보획득(information gain, 이하 IG)&lt;/strong&gt;이라고 하며, 정보획득이 많은 방향으로 학습을 진행한다고 말 할 수 있다.&lt;/p&gt;

&lt;p&gt;예를 들어 아래 그림처럼, 특정 영역내에 두 색상의 공을 분류하는 문제가 있고, 사각형의 수평 혹은 수직 변에서 특정 지점을 기준으로 반으로 나누는 것을 규칙이라고 해보자. 우리의 목적은 10개의 공을 잘 나누는 규칙들을 학습하는 것이며, 빨간공을 1, 초록공을 2로 표기한다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=17jk7c6NbX0ckSKhZqebV5M7m-a3bHyeV&quot; alt=&quot;영역 A&quot; width=&quot;50%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;영역 A&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;이를 나누는 기준 엔트로피는 다음과 같으며 특정 영역 $A$의 불확실성을 나타낸다. 여기서 $p_k$는 특정 k 클래스에 속할 확률을 나타낸다($p_k$ = &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;k-class 공의 개수&lt;/code&gt; / &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;전체 공의 개수&lt;/code&gt;).&lt;/p&gt;

\[Entropy(A)= - \sum_{k=1}^{K} p_k \log_{2}(p_k)\]

&lt;p&gt;현재 상태의 엔트로피를 계산하면, 다음과 같다.&lt;/p&gt;

\[Entropy(A)= - \Big( \dfrac{6}{10}\log_{2}(\dfrac{6}{10}) + \dfrac{4}{10}\log_{2}(\dfrac{4}{10}) \Big) = 0.9710\]

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;calculate_entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;log&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;pks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# A: p_red, p_greem
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;entropy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;calculate_entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Entropy is &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Entropy is 0.9710
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=133G4Y4HmuHBGTeSisfZw76h3CoXhD-5B&quot; alt=&quot;좌우 영역 A1, A2 나눌 경우&quot; width=&quot;50%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;좌우 영역 A1, A2 나눌 경우&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;이제 가로변의 임의로 한 곳을 나눠서 두 개의 영역(좌: $A_1$, 우: $A_2$)으로 나눠본다. 이때의 엔트로피는 두 엔트로피의 가중합으로 계산할 수 있으며, 다음과 같다.&lt;/p&gt;

\[\begin{aligned} Entropy(A) &amp;amp;= \sum_{i=1}^{m} \dfrac{1}{m} Entropy(A_m) = \dfrac{1}{2} Entropy(A_1) + \dfrac{1}{2} Entropy(A_2) \\
&amp;amp;= - \sum_{i=1}^{2} \dfrac{1}{2} \sum_{k=1}^K p_k^{(i)} \log_2 (p_k^{(i)}) \\
&amp;amp;= - \dfrac{1}{2} \Big( \dfrac{5}{6}\log_{2}(\dfrac{5}{6}) + \dfrac{1}{6}\log_{2}(\dfrac{1}{6}) \Big) - \dfrac{1}{2} \Big( \dfrac{1}{4}\log_{2}(\dfrac{1}{4}) + \dfrac{3}{4}\log_{2}(\dfrac{3}{4}) \Big) \\
&amp;amp;= 0.7307
\end{aligned}\]

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;calculate_entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ndim&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;pks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expand_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;log&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1e-10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;entropy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;pks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# A_1: p_red, p_greem
&lt;/span&gt;    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# A_2: p_red, p_greem
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;entropy2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;calculate_entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Entropy is &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;entropy2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Entropy is 0.7307
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이제 우리는 정보획득(IG)을 계산할 수 있게 된다. 이전 단계과 현재 상태의 불확실성 차이인 $IG_1 = 0.9710 - 0.7307 = 0.2403$가 정보획득량이라고 할 수 있다.&lt;/p&gt;

&lt;p&gt;그렇다면 다른 경우에는 어떨까? 예를 들어 가로로 선을 그어 두 영역(상: $A_1$, 하: $A_2$)을 나눠보고 정보획득량을 계산해보자.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1VvzOYsLNMEoM2mOtCi9FbHxIo5e-bUVM&quot; alt=&quot;상하 영역 A1, A2 나눌 경우&quot; width=&quot;50%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;상하 영역 A1, A2 나눌 경우&lt;/figcaption&gt;&lt;/figure&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;pks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# A_1: p_red, p_greem
&lt;/span&gt;    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# A_2: p_red, p_greem
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;entropy3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;calculate_entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Entropy is &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;entropy3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Entropy is 0.8464
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;계산해보니 정보획득량은 $IG_2 = 0.9710 - 0.8464 = 0.1246$이 되기 때문에, 세로로 선을 긋는 방법 보다 선호하지 않는 규칙이 될 것이다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;학습-방법-재귀적-분기--가지치기&quot;&gt;학습 방법: 재귀적 분기 &amp;amp; 가지치기&lt;/h2&gt;

&lt;h3 id=&quot;재귀적-분기recursive-partitioning&quot;&gt;재귀적 분기(recursive partitioning)&lt;/h3&gt;

&lt;p&gt;예를 들어 대출 심사를 하는 데이터가 있다면, 어떻게 진행되는지 알아본다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;자동차 소유&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;소득&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;보유 대출 건수&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;대출여부&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;650&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yes&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;200&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;700&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;500&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;425&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;900&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yes&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;먼저 처음 시점의 엔트로피를 구하면 다음과 같다.&lt;/p&gt;

\[Entropy(A)= - \Big( \dfrac{4}{6}\log(\dfrac{4}{6}) + \dfrac{2}{6}\log(\dfrac{2}{6}) \Big) = 0.9183\]

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;pks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;entropy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;calculate_entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Entropy is &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Entropy is 0.9183
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그 후 특정 피처를 선정해서 정렬 후에 각 분기점에서 한번씩 엔트로피를 계산하고 IG를 구한다. 예를 들어 다음 표처럼 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;소득 &amp;lt;= 200&lt;/code&gt;을 기준으로 나눠서 계산하고, 다음 기준을 선정해서 계속 계산한다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;자동차 소유&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;소득&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;보유 대출 건수&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;대출여부&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;span style=&quot;color: #7d7ee8&quot;&gt;0&lt;/span&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;span style=&quot;color: #7d7ee8&quot;&gt;200&lt;/span&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;span style=&quot;color: #7d7ee8&quot;&gt;0&lt;/span&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;span style=&quot;color: #7d7ee8&quot;&gt;no&lt;/span&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;425&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;500&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;650&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yes&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;700&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;900&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yes&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Colname&lt;/th&gt;
      &lt;th&gt;Value&lt;/th&gt;
      &lt;th&gt;MaxIG&lt;/th&gt;
      &lt;th&gt;ClsCount&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;income&lt;/td&gt;
      &lt;td&gt;700&lt;/td&gt;
      &lt;td&gt;0.677653&lt;/td&gt;
      &lt;td&gt;{False: {0: 0, 1: 1}, True: {0: 4, 1: 1}}&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;existloan&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0.594646&lt;/td&gt;
      &lt;td&gt;{False: {0: 1, 1: 0}, True: {0: 3, 1: 2}}&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;car&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;-0.018797&lt;/td&gt;
      &lt;td&gt;{False: {0: 1, 1: 1}, True: {0: 3, 1: 1}}&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;[expand]summary:전체코드 보기 👈&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;calculate_entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;counts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;counts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ndim&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;counts&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expand_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;counts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;counts&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;counts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepdims&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;log&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1e-10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_info_gain&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;E_base&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reset_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;drop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;unique_x_values&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unique&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;[Start] Processing column: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_col&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unique_x_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;IG_candidates&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;IG_counts&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;unique_x_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;group&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;counts&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;groupby&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;group&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;loan&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unstack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fill_value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;E_x_col&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;calculate_entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;counts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;E_x_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;counts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;counts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;E_x_col&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;E_x_col&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;E_x_col&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;E_x_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;info_gain&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;E_base&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;E_x_col&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;IG_candidates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;info_gain&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;IG_counts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;counts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;  Testing Value &amp;lt;= &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; | Entropy: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;E_x_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; | IG: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;info_gain&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;  Counts:&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;counts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;IG_candidates&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IG_candidates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;IG_max&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IG_candidates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;idx_IG_max&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IG_candidates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;IG_value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx_IG_max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;[Result] Max information gain is &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IG_max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; value: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IG_value&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;del&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;group&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IG_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IG_max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IG_counts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx_IG_max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;car&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;income&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;650&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;700&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;425&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;900&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;existloan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;E_base&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;calculate_entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;loan&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value_counts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;IGs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_col&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;car&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;income&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;existloan&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;IG_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IG_max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IG_counts&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_info_gain&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;E_base&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;IGs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IG_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IG_max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IG_counts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df_res&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Colname&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Value&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;MaxIG&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;ClsCount&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IGs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))})&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df_res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;MaxIG&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ascending&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# [Start] Processing column: car: [0, 1]
# 0.9370927078645052
#   Testing Value &amp;lt;= 0 | Entropy: 0.9371 | IG: -0.0188
#   Counts: {False: {0: 1, 1: 1}, True: {0: 3, 1: 1}}
# [Result] Max information gain is -0.0188 value: 0
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# [Start] Processing column: income: [200, 425, 500, 650, 700, 900]
# 0.6473003960626632
#   Testing Value &amp;lt;= 200 | Entropy: 0.6473 | IG: 0.2710
#   Counts: {False: {0: 3, 1: 2}, True: {0: 1, 1: 0}}
# 0.6666666664262174
#   Testing Value &amp;lt;= 425 | Entropy: 0.6667 | IG: 0.2516
#   Counts: {False: {0: 2, 1: 2}, True: {0: 2, 1: 0}}
# 0.6121972224625437
#   Testing Value &amp;lt;= 500 | Entropy: 0.6122 | IG: 0.3061
#   Counts: {False: {0: 1, 1: 2}, True: {0: 3, 1: 0}}
# 0.9370927078645052
#   Testing Value &amp;lt;= 650 | Entropy: 0.9371 | IG: -0.0188
#   Counts: {False: {0: 1, 1: 1}, True: {0: 3, 1: 1}}
# 0.2406426981034281
#   Testing Value &amp;lt;= 700 | Entropy: 0.2406 | IG: 0.6777
#   Counts: {False: {0: 0, 1: 1}, True: {0: 4, 1: 1}}
# [Result] Max information gain is 0.6777 value: 700
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# [Start] Processing column: existloan: [0, 1, 3]
# 0.6666666664262174
#   Testing Value &amp;lt;= 0 | Entropy: 0.6667 | IG: 0.2516
#   Counts: {False: {0: 2, 1: 2}, True: {0: 2, 1: 0}}
# 0.32365019795919686
#   Testing Value &amp;lt;= 1 | Entropy: 0.3237 | IG: 0.5946
#   Counts: {False: {0: 1, 1: 0}, True: {0: 3, 1: 2}}
# [Result] Max information gain is 0.5946 value: 0
&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;위 코드와 표는 각 입력 피처로 하나씩 규칙을 찾은 결과다. 살펴보면 최대 정보획등량(MaxIG)은 $0.068056$ 으로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;소득 &amp;lt;= 700&lt;/code&gt; 기준으로 나누는 첫번째 노드의 규칙이 된다. 만약 소득이 규칙인 700보다 작은 값이면, 대출여부가 0인 값은 4개, 1인 값은 1개가 되고, 700 보다 크다면 대출여부가 0인 값은 0개, 1인 값은 1개가 된다. 다시 풀어서 말하면, 만약에 당신의 소득이 700 보다 적다면, 학습된 데이터를 기반으로 보았을 때, 대출가능한 확률은 20%(1/5) 정도가 될것이다.&lt;/p&gt;

&lt;p&gt;이렇게 첫번째 규칙이 정해지면, 사람이 정한 하이퍼파라미터인 나무의 최대 깊이(max depth)에 따라서 계속 찾을 것인지 아니면 멈출지를 결정한다. 그리고 엔트로피가 0이 되면 학습을 최대 깊이가 아니더라도 알아서 멈추게 된다. 다만, 의사결정 나무 모델이 깊게 들어갈 수록 과적합(overfitting)될 가능성이 높다.&lt;/p&gt;

&lt;p&gt;scikit-learn 패키지를 활용하면 손쉽게 의사결정 나무를 학습시킬 수 있다. 다만 피처의 정렬하여 특정값을 기준값으로 정하지 않고 약간 다르게 적용한다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tree&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;car&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;income&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;650&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;700&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;425&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;900&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;existloan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;clf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tree&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DecisionTreeClassifier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;entropy&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_depth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;clf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;clf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;만약 graphviz를 설치했다면, 의사결정 나무 모델을 시각화 해볼 수도 있다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;graphviz&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dot_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tree&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;export_graphviz&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;clf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_file&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;feature_names&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;car&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;income&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;existloan&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;class_names&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;대출 불가능&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;대출 가능&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;filled&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rounded&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;special_characters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;graph&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;graphviz&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Source&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;graph&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1B8ZxPjkeFn_TCkG-ll5JSPu0JBGsLuHQ&quot; alt=&quot;Graphviz로 의사결정 나무 모델 시각화&quot; width=&quot;90%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Graphviz로 의사결정 나무 모델 시각화&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;이 모델 그래프에 따르면 대출이 가능한 사람은 수입(income)이 575 이상이어야 하고, 대출 보유 대출 건수(existloan)가 2개 이하여야 대출이 가능하다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;가지치기pruning&quot;&gt;가지치기(pruning)&lt;/h3&gt;

&lt;p&gt;과적합을 피하기 위해 다양한 방법이 있다. scikit-learn을 기준으로 설명하면 다음과 같다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;min_samples_leaf&lt;/code&gt;: 리프 노드가 되기 위한 최소 샘플의 개수를 말하며, 이 값이 커질 수록 모델이 간결해지나, 학습 데이터가 부족할 경우, 전체 정확도가 떨어질 수가 있다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max_depth&lt;/code&gt;: 최대 깊이, 깊이를 작게 만들어 모델을 간결하게 만들 수 있지만 정확도가 떨어질 가능성이 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;여기서 말하는 가지치기(purning)는 &lt;strong&gt;비용복잡도 가지치기(Cost Complexity Pruning)&lt;/strong&gt;을 말하며, 복잡도 파라미터라고 불리는 $\alpha$로 조절 할 수 있다. 의사결정 나무 모델 $T$가 주어 졌을 때, 비용복잡도 함수$R_{\alpha}(T)$는 다음과 같이 결정된다.&lt;/p&gt;

\[R_{\alpha}(T) = R(T) + \alpha \vert \hat{T} \vert\]

&lt;p&gt;여기서 $\vert \hat{T} \vert$는 리프 노드의 개수, $R(T)$는 전체 리프 노드에서 계산된 오분류율이다. Scikit-learn에서는 $R(T)$를 전체 샘플로 가중치화된 리프 노드의 불순도(impurity)로 대신 계산한다. $\alpha$값이 올라 갈 수록, 훈련 데이터에서 의사 결정 나무 모델의 깊이와 노드의 개수가 점점 떨어진다. 따라서, $\alpha$값을 잘 조절하면, 검증 데이터에서 좋은 성능을 낼 수 있는 최적의 모델을 만들 수 있다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1Q_0g6iCs1sS7dvG1c7OA451PPrDUIMEF&quot; alt=&quot;Alpha값에 따른 Train/Test 데이터에서 정확도 변화&quot; width=&quot;90%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Alpha값에 따른 Train/Test 데이터에서 정확도 변화&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;feature-importance&quot;&gt;Feature Importance&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;피처 중요도(Feature Improtance)&lt;/strong&gt;란 의사결정 나무를 만드는데 기여한 피처의 정량적 평가라고 볼 수 있다. 재귀적 분리와 가지치기를 통해 의사결정 나무를 생성할 때, 불순도를 가장 많이 줄이는 피처가 곧 모델을 생성하는데 큰 공헌을 새운 피처라고 할 수 있으며, 중요도가 높다고 말 할 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;feature-importance-구하는-방법&quot;&gt;Feature Importance 구하는 방법&lt;/h3&gt;

&lt;p&gt;일반적인 Feature Importance를 구하는 방법은, 다름 의사결정 나무를 보고 계산하면서 알아보자.&lt;/p&gt;

&lt;p&gt;[expand]summary:전체코드 보기 👈&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tree&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;graphviz&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;car&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;income&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;650&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;700&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;425&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;900&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;550&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;existloan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;clf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tree&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DecisionTreeClassifier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;entropy&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_depth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;clf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;clf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;dot_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tree&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;export_graphviz&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;clf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_file&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;feature_names&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;car&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;income&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;existloan&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;class_names&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;대출 불가능&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;대출 가능&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;filled&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rounded&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;special_characters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;graph&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;graphviz&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Source&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1KZS2M8IQDzULdVkRTIbkK1SlkkGBUWQu&quot; alt=&quot;새로운 Tree&quot; width=&quot;90%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;새로운 Tree&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;$i$번째 가지(feature)에서 노드가 $L$과 $R$로 분리 되었 다면 information gain 은 다음과 같이 구한다. 여기서 $N$은 전체 샘플의 개수, $N_i$는 분리 이전의 해당 노드에서 보유하고 있는 샘플의 개수, $N_{(i, L)}$는 좌측으로 분리된 샘플의 개수, $N_{(i, R)}$은 우측으로 분리된 샘플의 개수, $E_i$는 분리 이전의 엔트로피, $E_{(i, L)}$과, $E_{(i, R)}$은 각각 좌측과 우측의 엔트로피다.&lt;/p&gt;

\[IG_{i} = \dfrac{N_i}{N} E_{i} - \dfrac{N_{(i, L)}}{N_i} E_{(i, L)} - \dfrac{N_{(i, R)}}{N_i} E_{(i, R)}\]

&lt;p&gt;지금 그래프는 두 개의 피처(income, existloan)으로 인해 나눠졌고, 먼저 income의 정보획득량을 구해보면 다음과 같다.&lt;/p&gt;

\[\begin{aligned}
IG_{income} &amp;amp;= \dfrac{N_{income}}{N} E_{income} - \dfrac{N_{(income, L)}}{N_{income}} E_{(income, L)} - \dfrac{N_{(income, R)}}{N_{income}} E_{(income, R)} \\
&amp;amp;= \dfrac{7}{7} \times 0.9852 - \dfrac{3}{7} \times 0.0 - \dfrac{4}{7} \times 0.8113 \\
&amp;amp;= 0.5216
\end{aligned}\]

&lt;p&gt;나머지 existloan의 정보획득량은 다음과 같다.&lt;/p&gt;

\[\begin{aligned}
IG_{existloan} &amp;amp;= \dfrac{N_{existloan}}{N} E_{existloan} - \dfrac{N_{(existloan, L)}}{N_{existloan}} E_{(existloan, L)} - \dfrac{N_{(existloan, R)}}{N_{existloan}} E_{(existloan, R)} \\
&amp;amp;= \dfrac{4}{7} \times 0.8113 - \dfrac{1}{4} \times 0.0 - \dfrac{3}{4} \times 0.0 \\
&amp;amp;= 0.4636
\end{aligned}\]

&lt;p&gt;car 칼럼은 쓰이지 않았기 때문에 피처 중요도는 0이 된다. 따라서 각각의 피처 중요도를 일반화(normalize) 시키면 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(car, income, existloan) = (0, 0.5295, 0.4705)&lt;/code&gt;가 된다.&lt;/p&gt;

&lt;p&gt;[expand]summary:계산코드 보기 👈&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scipy.stats&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;entropy&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;calculate_ig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;e_base&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;e_left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;e_right&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;IG&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e_base&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e_left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e_right&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;E Base: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e_base&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; | E Left &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e_left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; | E Right &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e_right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Information Gain = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IG&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IG&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Income
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;[Feature] Income&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x_income&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x_income_left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x_income_right&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;IG_income&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;calculate_ig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_income&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_income_left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_income_right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Existloan
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;[Feature] Existloan&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x_existloan&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x_existloan_left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x_existloan_right&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;IG_existloan&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;calculate_ig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_existloan&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_existloan_left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_existloan_right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;[Feature Importance] Normalized (Car, Income, Existloan)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;IG_car&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IG_car&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IG_income&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IG_existloan&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;normed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;[Feature Importance] in scikit-learn&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;clf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;feature_importances_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# [Feature] Income
# E Base: 0.9852 | E Left 0.0000 | E Right 0.8113
# Information Gain = 0.5216
# [Feature] Existloan
# E Base: 0.8113 | E Left 0.0000 | E Right 0.0000
# Information Gain = 0.4636
# [Feature Importance] Normalized (Car, Income, Existloan)
# [0.     0.5295 0.4705]
# [Feature Importance] in scikit-learn
# [0.     0.5295 0.4705]
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;h3 id=&quot;사용시-주의할-점&quot;&gt;사용시 주의할 점&lt;/h3&gt;

&lt;p&gt;사용시에 주의할 점이 있는데, 피처 중요도를 절대적인 지표로 사용하면 안 된다. 그 이유는 훈련 데이터에 최적화된 모델에서 보여주는 중요도이기 때문에, 특정 피처가 중요하지 않다고 할 수 없다. 위에서 설명한 자동차 보유 여부인 피처 car의 경우 모델에 고려되지 않았다고 해서 대출의 중요한 척도가 아니다. 실제로 어떤 사람이 차를 소유했다면, 보통은 그 유지비용을 감당할 수 있어서(즉, 어느정도의 현금 흐름이 있다)차를 샀다고 생각하기 때문에 중요하지 않다고 보기는 힘들다. 하지만 상대적으로 중요하다고는 말 할 수 있기 때문에 모델을 만들고 분석시에 유용하게 쓰인다.&lt;/p&gt;

&lt;h2 id=&quot;permutation-feature-importance&quot;&gt;Permutation Feature Importance&lt;/h2&gt;

&lt;p&gt;Permutation Feature Importance는 feature의 값을 임의로 치환했을 때 성능의 변화를 본다. 만약 해당 feature가 모델에서 크게 중요한 역할을 하고 있다면 값을 치환했을 때 성능이 크겍 떨어진다는 아이디어에서 시작한다. 입력 데이터 $X$, 타겟 데이터 $y$, 모델 $f$과 손실함수 $L$로 주어 졌을 때, 주요 알고리즘은 다음과 같다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;현재 모델의 성능 측정: $e^{original} = L\big(y, f(X)\big)$&lt;/li&gt;
  &lt;li&gt;데이터의 각 피처 $j$에 대해서
    &lt;ol&gt;
      &lt;li&gt;$K$번 반복한다. ($k = 1, \cdots, K$)
        &lt;ol&gt;
          &lt;li&gt;랜덤하게 피처 $j$의 데이터를 셔플하여 새로운 변형된 데이터 세트 $\hat{X}^{(j)}_k$를 만든다&lt;/li&gt;
          &lt;li&gt;변형된 데이터 세트로 성능을 측정한다. $e^{(j)}_k = L\big(y, f(\hat{X}^{(j)}_k)\big)$&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;피처 $k$의 중요도 $I^{(j)}$를 계산한다. $I^{(j)} = e^{original} - \dfrac{1}{K} \sum_{k=1}^{K} e^{(j)}_k$&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Scikit-learn에서 다음과 같이 제공하고 있다. 다만 모델이 커질 경우 실행시간이 꽤 오래 걸린다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.inspection&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;permutation_importance&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;permutation_importance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;clf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_repeats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;importances_mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argsort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()[::&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;importances_mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; +/- &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;importances_std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# income  0.462 +/- 0.180
# existloan  0.195 +/- 0.078
# car  0.000 +/- 0.000
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;장단점&quot;&gt;장단점&lt;/h1&gt;

&lt;p&gt;어떤 문제를 해결할 때, 왜 이 모델을 사용하려고 하는지 이해하고 쓰는 것이 중요하기에, 의사결정 나무 모델의 장단점을 요약해서 정리해보았다.&lt;/p&gt;

&lt;h2 id=&quot;장점&quot;&gt;장점&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;사람이 해석하고, 이해하기 쉽게 시각화가 가능하다.&lt;/li&gt;
  &lt;li&gt;일반화(normalization), 더미변수(dummy variables), 결측치(missing values)에 대한 전처리가 거의 필요없다.&lt;/li&gt;
  &lt;li&gt;수치형과 범주형 데이터를 다룰 수가 있다.&lt;/li&gt;
  &lt;li&gt;조절해야할 하이퍼파라미터가 상대적으로 적긱 때문에, 빠르게 실험해 볼 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;단점&quot;&gt;단점&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;조절을 못하면 과적합된 모델을 생성할 가능성이 크다.&lt;/li&gt;
  &lt;li&gt;데이터의 작은 변동으로 인해 완전히 다른 트리가 생성될 수 있기 때문에 의사 결정 트리는 불안정할 수 있다. 이 문제는 앙상블 내에서 의사결정 트리를 사용함으로써 완화할 수 있다.&lt;/li&gt;
  &lt;li&gt;예측값이 매끄럽지도 않고 연속적이지도 않고 단편적으로 일정한 근사치이다. 보외법(extrapolation)을 수행하기가 어렵다. 즉, 일반화가 안될 수 있다.&lt;/li&gt;
  &lt;li&gt;특정 클래스의 값에 지배적으로 편향되는 경우, 편향된 트리를 만든다. 따라서 학습 전에 균형 있는 데이터 세트를 만드는 것이 중요하다.&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Thu, 04 Mar 2021 00:00:01 +0900</pubDate>
        <link>https://simonjisu.github.io/machinelearning/2021/03/04/decision_tree.html</link>
        <guid isPermaLink="true">https://simonjisu.github.io/machinelearning/2021/03/04/decision_tree.html</guid>
        
        
        <category>machinelearning</category>
        
      </item>
    
      <item>
        <title>[XAI] Explainable Artificial Intelligence (XAI) - 2 </title>
        <description>&lt;h1 id=&quot;explainable-artificial-intelligence-xai-concepts-taxonomies-opportunities-and-challenges-toward-responsible-ai&quot;&gt;Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI&lt;/h1&gt;

&lt;p&gt;Paper Link: &lt;a href=&quot;https://arxiv.org/abs/1910.10045&quot;&gt;https://arxiv.org/abs/1910.10045&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;XAI에 대한 전반적인 소개를 정리한 논문이 나와서 차근 차근 요약 정리해보려고 한다(무려 115페이지, reference만 6페이지). 약간의 번역 어투와 생략된 것도 있으니 영어 원문을 참고하길 바란다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://simonjisu.github.io/paper/2020/12/31/xaitutorial1.html&quot;&gt;Introduction&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://simonjisu.github.io/paper/2021/01/14/xaitutorial2.html&quot;&gt;&lt;span style=&quot;color:#e25252&quot;&gt;Explainability: What, why, what for and how?(이번편)&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://simonjisu.github.io/paper/2021/01/23/xaitutorial3.html&quot;&gt;Transparent machine learning models&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Post-hoc explainability techniques for machile learning models: Taxonomy, shallow models and deep learning&lt;/li&gt;
  &lt;li&gt;XAI: Opportunities, challenges and future research needs&lt;/li&gt;
  &lt;li&gt;Toward responsible AI: Principles of artificial intelligence, fairness, privacy and data fusion&lt;/li&gt;
  &lt;li&gt;Conclusions and outlook&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;2-explainability-what-why-what-for-and-how&quot;&gt;2. Explainability: What, Why, What For and How?&lt;/h1&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;Before proceeding with our literature study, it is convenient to first establish a common point of understanding on what the term explainability stands for in the context of AI and, more specifically, ML. This is indeed the purpose of this section, namely, to pause at the numerous definitions that have been done in regards to this concept (what?), to argue why explainability is an important issue in AI and ML (why? what for?) and to introduce the general classification of XAI approaches that will drive the literature study thereafter (how?).&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; 시작하기 전에 &lt;strong&gt;설명가능성(explainability)&lt;/strong&gt;이라는 용어가 AI 혹은 ML의 맥락에서 무엇을 뜻하는지, 공통의 이해점을 확립해야한다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;What? 이 개념에 대한 정립된 수 많은 정의들을 정리&lt;/li&gt;
  &lt;li&gt;Why? What for? 왜 설명가능성이 AI와 ML에서 중요한 이슈인지&lt;/li&gt;
  &lt;li&gt;How? 이후 연구할 XAI 접근 방식의 일반적인 분류방식들 소개&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;21-terminology-clarification&quot;&gt;2.1 Terminology Clarification&lt;/h2&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;One of the issues that hinders the establishment of common grounds is the interchangeable misuse of interpretability and explainability in the literature. There are notable differences among these concepts. To begin with, interpretability refers to a passive characteristic of a model referring to the level at which a given model makes sense for a human observer. This feature is also expressed as transparency. By contrast, explainability can be viewed as an active characteristic of a model, denoting any action or procedure taken by a model with the intent of clarifying or detailing its internal functions.&lt;/p&gt;

&lt;p&gt;To summarize the most commonly used nomenclature, in this section we clarify the distinction and similarities among terms often used in the ethical AI and XAI communities.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Understandability (or equivalently, intelligibility) denotes the characteristic of a model to make a human understand its function – how the model works – without any need for explaining its internal structure or the algorithmic means by which the model processes data internally [18].&lt;/li&gt;
  &lt;li&gt;Comprehensibility: When conceived for ML models, comprehensibility refers to the ability of a learning algorithm to represent its learned knowledge in a human understandable fashion [19], [20], [21]. This notion of model comprehensibility stems from the postulates of Michalski [22], which stated that &lt;em&gt;“the results of computer induction should be symbolic descriptions of given entities, semantically and structurally similar to those a human expert might produce observing the same entities. Components of these descriptions should be comprehensible as single ‘chunks’ of information, directly interpretable in natural language, and should relate quantitative and qualitative concepts in an integrated fashion”&lt;/em&gt;. Given its difficult quantification, comprehensibility is normally tied to the evaluation of the model complexity [17].&lt;/li&gt;
  &lt;li&gt;Interpretability: It is defined as the ability to explain or to provide the meaning in understandable terms to a human.&lt;/li&gt;
  &lt;li&gt;Explainability: Explainability is associated with the notion of explanation as an interface between humans and a decision maker that is, at the same time, both an accurate proxy of the decision maker and comprehensible to humans [17].&lt;/li&gt;
  &lt;li&gt;Transparency: A model is considered to be transparent if by itself it is understandable. Since a model can feature different degrees of understandability, transparent models in Section 3 are divided into three categories: simulatable models, decomposable models and algorithmically transparent models [5].&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color:#aaa&quot;&gt; 참고: 용어가 한국어로 거의다 비슷해서 최대한 의미를 붙여서 추가함 &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; 공통의 이해점 확립을 방해하는 요소중 하나는 &lt;strong&gt;설명가능성(explainability)&lt;/strong&gt;과 &lt;strong&gt;해석가능성(interpretability)&lt;/strong&gt;용어의 혼용이다. 이 둘의 개념읜 차이점이 있다. 결론부터 말하자면&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;해석가능성(Interpretability):&lt;/strong&gt; 모델이 인간에게 맞춰서 설명하는 &lt;u&gt;모델의 수동적 특성&lt;/u&gt;, 투명성(transparency)과 같은 말&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;설명가능성(Explainability):&lt;/strong&gt; 모델의 내부 기능을 명확히 하거나 자세히 설명할 목적으로, 수행된 모든 행동 또는 절차를 나타내는 &lt;u&gt;모델의 능동적 특성&lt;/u&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;가장 일반적으로 사용되는 명명법을 이야기하고자 ethical AI 및 XAI 커뮤니티에서 자주 사용되는 용어 간의 구별과 그 유사성을 명확히한다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;이해가능성(Understandability)&lt;/strong&gt; 혹은 &lt;strong&gt;명료성(Intelligibility):&lt;/strong&gt; 모델 구조 혹은 내부의 알고리즘 기능의 부가 설명 없이도 인간이 바로 이해할 수 있는 모델의 특성 &lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S1051200417302385&quot;&gt;[18]&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;포괄적 이해가능성(Comprehensibility):&lt;/strong&gt; 모델이 학습한 지식을 인간의 이해방식으로 나타내는 능력 &lt;a href=&quot;https://scholar.google.com/scholar?q=Evolutionary%20fuzzy%20systems%20for%20explainable%20artificial%20intelligence:%20Why,%20when,%20what%20for,%20and%20where%20to&quot;&gt;[19]&lt;/a&gt;, &lt;a href=&quot;https://scholar.google.com/scholar_lookup?title=A%20framework%20for%20considering%20comprehensibility%20in%20modeling&amp;amp;publication_year=2016&amp;amp;author=M.%20Gleicher&quot;&gt;[20]&lt;/a&gt;, &lt;a href=&quot;https://scholar.google.com/scholar_lookup?title=Extracting%20comprehensible%20models%20from%20trained%20neural%20networks&amp;amp;publication_year=1996&amp;amp;author=M.W.%20Craven&quot;&gt;[21]&lt;/a&gt;. 이 개념은 Michalski&lt;a href=&quot;https://scholar.google.com/scholar_lookup?title=A%20theory%20and%20methodology%20of%20inductive%20learning&amp;amp;publication_year=1983&amp;amp;author=R.S.%20Michalski&quot;&gt;[22]&lt;/a&gt;의 가정에서 비롯됐다.&lt;/p&gt;

    &lt;p&gt;“컴퓨터 유도 결과는 주어진 실체에 대한 상징적 설명이어야 하며, 인간 전문가가 동일한 실체를 관찰하는 것과 의미론적이고 구조적으로 유사해야 한다. 이러한 설명의 구성요소는 자연어로 직접 해석할 수 있는 정보의 단일 ‘청크’로 이해할 수 있어야 하며, 통합된 방식으로 양적 및 질적 개념을 연관시켜야 한다.”&lt;/p&gt;

    &lt;p&gt;정량화가 어렵다는 점을 고려했을 때, 포괄적 이해가능성은 일반적으로 모델 복잡도 평가와 연관된다&lt;a href=&quot;https://scholar.google.com/scholar_lookup?title=A%20survey%20of%20methods%20for%20explaining%20black%20box%20models&amp;amp;publication_year=2018&amp;amp;author=R.%20Guidotti&amp;amp;author=A.%20Monreale&amp;amp;author=S.%20Ruggieri&amp;amp;author=F.%20Turini&amp;amp;author=F.%20Giannotti&amp;amp;author=D.%20Pedreschi&quot;&gt;[17]&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;해석가능성(Interpretability)&lt;/strong&gt;: 인간이 이해할 수 있는 용어로 의미를 설명하거나 제공하는 능력&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;설명가능성(Explainability):&lt;/strong&gt; 사람과 모델간의 “인터페이스(interface)” 역할로서 설명(explanation)과 연관되어 있다. 설명은 모델이 내린 의사결정의 정확한 대리이자 인간이 이해할 수 있는 것이어야 한다&lt;a href=&quot;https://scholar.google.com/scholar_lookup?title=A%20survey%20of%20methods%20for%20explaining%20black%20box%20models&amp;amp;publication_year=2018&amp;amp;author=R.%20Guidotti&amp;amp;author=A.%20Monreale&amp;amp;author=S.%20Ruggieri&amp;amp;author=F.%20Turini&amp;amp;author=F.%20Giannotti&amp;amp;author=D.%20Pedreschi&quot;&gt;[17]&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;투명성(Transparency):&lt;/strong&gt; 모델은 자신이 스스로 이해가능하다면 투명한 것으로 간주된다. 모델은 정도에 따라 이해력를 다르게 제공할 수 있기 때문에, 투명성 있는 모델은 section 3에서 3가지 항목(시뮬레이션 가능한 모델, 분해가능한 모델 그리고 알고리즘 자체가 투명한 모델)으로 나눌 것이다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;In all the above definitions, understandability emerges as the most essential concept in XAI. Both transparency and interpretability are strongly tied to this concept: while transparency refers to the characteristic of a model to be, on its own, understandable for a human, understandability measures the degree to which a human can understand a decision made by a model. Comprehensibility is also connected to understandability in that it relies on the capability of the audience to understand the knowledge contained in the model. All in all, understandability is a two-sided matter: model understandability and human understandability. This is the reason why the definition of XAI given in Section 2.2 refers to the concept of audience, as the cognitive skills and pursued goal of the users of the model have to be taken into account jointly with the intelligibility and comprehensibility of the model in use. This prominent role taken by understandability makes the concept of audience the cornerstone of XAI, as we next elaborate in further detail.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; 위의 모든 정의에서 이해가능성(understandability)은 XAI에서 가장 필수적인 개념이다. 투명성(transparency)과 해석가능성(interpretability)은 모두 이 개념과 강하게 연관되어 있다. 투명성(transparency)은 인간에게는 이해가능해야 하고, 모델 스스로는 이해할 수 있는 특성이지만, 이해가능성(interpretability)은 모델의 결정을 인간이 얼만큼 이해가능한지 측정한다.&lt;/p&gt;

&lt;p&gt;또한 포괄적 이해가능성(comprehensibility)은 &lt;strong&gt;청중&lt;/strong&gt;(audience, &lt;span style=&quot;color:#aaa&quot;&gt;[주] 설명을 듣는 사람&lt;/span&gt;)이 얼만큼 모델에 포함된 지식을 이해하는 지를 측정한다는 점에서 이해가능성(understandability)과 연결된다.&lt;/p&gt;

&lt;p&gt;대체로, 이해가능성(understandability)은 “모델”과 “인간”의 이해가능성으로 나눌 수 있다. 모델 이용자의 인지능력 및 추구목표는 모델의 명료성과 포괄적 이해가능성이 함께 고려되어야 하기 때문에, Section 2.2에서는 XAI개념을 정의할 때, &lt;strong&gt;청중&lt;/strong&gt;&lt;span style=&quot;color:#aaa&quot;&gt;([주] 모델을 사용하는 인간)&lt;/span&gt;의 개념을 먼저 이야기하려고 한다. 이해가능성은 XAI의 초석이 되는 청중의 개념을 만드는 역할을 한다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;22-what&quot;&gt;2.2 What?&lt;/h2&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;Although it might be considered to be beyond the scope of this paper, it is worth noting the discussion held around general theories of explanation in the realm of philosophy [23]. Many proposals have been done in this regard, suggesting the need for a general, unified theory that approximates the structure and intent of an explanation. However, nobody has stood the critique when presenting such a general theory. For the time being, the most agreed-upon thought blends together different approaches to explanation drawn from diverse knowledge disciplines. A similar problem is found when addressing interpretability in AI. It appears from the literature that there is not yet a common point of understanding on what interpretability or explainability are. However, many contributions claim the achievement of interpretable models and techniques that empower explainability.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; 철학의 영역에서 설명(explanation)에 대해 토의에 주목할 필요가 있다&lt;a href=&quot;https://scholar.google.com/scholar_lookup?title=General%20theories%20of%20explanation%3A%20buyer%20beware&amp;amp;publication_year=2013&amp;amp;author=J.%20D%C3%ADez&amp;amp;author=K.%20Khalifa&amp;amp;author=B.%20Leuridan&quot;&gt;[23]&lt;/a&gt;. 왜냐면 일반적이고 통일된 설명 이론의 구조와 의도를 근사하게나마 제시했기 때문이다. 그렇지만 튼튼한 이론은 아니였다. 그래서 그동안 다양한 지식 분야에서 도출된 설명에 대한 접근 박싱을 혼합한 정의를 사용했다. AI에서 해석가능성(interpretability)을 다룰 때도 비슷한 문제가 발견됐다. 해석가능성(interpretability)이나 설명가능성(explainability)의 공통점을 찾지 못했으나, 많은 연구자들은 해석가능한 모델의 생성과 모델 설명력을 강화했다는 연구성과를 주장해왔다.&lt;/p&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;To shed some light on this lack of consensus, it might be interesting to place the reference starting point at the definition of the term Explainable Artificial Intelligence (XAI) given by D. Gunning in [7]:
&lt;br /&gt;
‘XAI will create a suite of machine learning techniques that enables human users to understand, appropriately trust, and effectively manage the emerging generation of artificially intelligent partners.’
&lt;br /&gt;
This definition brings together two concepts (understanding and trust) that need to be addressed in advance. However, it misses to consider other purposes motivating the need for interpretable AI models, such as causality, transferability, informativeness, fairness and confidence [5], [24], [25], [26]. We will later delve into these topics, mentioning them here as a supporting example of the incompleteness of the above definition.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; 부족한 공감대를 어느 정도 형성하기 위해서 D. Gunning이 제시한 Explainable Artificial Intelligence(XAI) 용어의 정의를 기준점으로 시작할 수 있을 것 같다. &lt;a href=&quot;https://scholar.google.com/scholar?q=Explainable%20artificial%20intelligence&quot;&gt;[7]&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“인간이 이해할 수 있고, 적절하게 신뢰할 수 있으며, 효과적으로 세로운 세대의 인공지능 파트너를 관리할 수 있는 머신러닝 기법 제품군을 XAI는 만들어 낼 것이다”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이 정의는 다루어야 할 두 가지 개념(이해와 신뢰)을 담았다. 그러나 해석가능한 AI 모델에 필요한 인과성(causality), 전이성(transferability), 정보성(informativeness), 공정성(fairness)과 확실성(confidence) 등을 담지 않았다&lt;a href=&quot;https://scholar.google.com/scholar_lookup?title=The%20mythos%20of%20model%20interpretability&amp;amp;publication_year=2018&amp;amp;author=Z.C.%20Lipton&quot;&gt;[5]&lt;/a&gt;, &lt;a href=&quot;https://scholar.google.com/scholar?q=D.%20Doran,%20S.%20Schulz,%20T.R.%20Besold,%20What%20does%20explainable%20AI%20really%20mean%20a%20new%20conceptualization%20of%20perspectives,%202017.&quot;&gt;[24]&lt;/a&gt;, &lt;a href=&quot;https://scholar.google.com/scholar?q=F.%20Doshi-Velez,%20B.%20Kim,%20Towards%20a%20rigorous%20science%20of%20interpretable%20machine%20learning,%202017.&quot;&gt;[25]&lt;/a&gt;, &lt;a href=&quot;https://scholar.google.com/scholar_lookup?title=Making%20machine%20learning%20models%20interpretable.&amp;amp;publication_year=2012&amp;amp;author=A.%20Vellido&amp;amp;author=J.D.%20Mart%C3%ADn-Guerrero&amp;amp;author=P.J.%20Lisboa&quot;&gt;[26]&lt;/a&gt;. 언급한 주제들은 D. Gunning의 정의에 대한 불완전성을 뒷받침하는 사례로 여기 언급하면서, 나중에 이 주제들을 파헤칠 것이다.&lt;/p&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;As exemplified by the definition above, a thorough, complete definition of explainability in AI still slips from our fingers. A broader reformulation of this definition (e.g. ‘An explainable Artificial Intelligence is one that produces explanations about its functioning’) would fail to fully characterize the term in question, leaving aside important aspects such as its purpose. To build upon the completeness, a definition of explanation is first required.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; 위 예시와 같이, 설명가능성에 대한 완벽한 정의를 내리기 어렵다. 예를 들어, “설명 가능한 인공지능은 그에 대한 기능을 설명하는 것이다” 경우, 설명가능성의 목적성 측면만 이야기한다. 따라서, 먼저 설명(explanation)에 대한 정의가 필요하다.&lt;/p&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;As extracted from the Cambridge Dictionary of English Language, an explanation is ‘the details or reasons that someone gives to make something clear or easy to understand’ [27]. In the context of an ML model, this can be rephrased as: ‘the details or reasons a model gives to make its functioning clear or easy to understand’. It is at this point where opinions start to diverge. Inherently stemming from the previous definitions, two ambiguities can be pointed out. First, the details or the reasons used to explain, are completely dependent of the audience to which they are presented. Second, whether the explanation has left the concept clear or easy to understand also depends completely on the audience. Therefore, the definition must be rephrased to reflect explicitly the dependence of the explainability of the model on the audience. To this end, a reworked definition could read as: ‘Given a certain audience, explainability refers to the details and reasons a model gives to make its functioning clear or easy to understand.’&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; 케임브릿지 영어사전을 인용하면, 설명(explanation)은 “어떤 것을 명백하게 혹은 이해하기 쉽게 만들어주기 위해 누군가가 밝혀주는 세부 사항이나 이유”다&lt;a href=&quot;https://scholar.google.com/scholar?q=Cambridge%20advanced%20learners%20dictionary&quot;&gt;[27]&lt;/a&gt;. &lt;span style=&quot;color:#aaa&quot;&gt;([주] 네이버 국어사전의 경우, “어떤 일이나 대상의 내용을 상대편이 잘 알 수 있도록 밝혀 말함. 또는 그런 말.”) &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;Machine learning의 맥락 상, “모델이 자신의 기능을 명백히 하거나 이해하기 쉽게 세부사항 혹은 이유를 밝히는 것”으로 바꿀수 있다. 여기에서 의견이 갈리기 시작한다. 본질적으로 이전 정의에서 비롯 된것으로 두 가지 애매모호한 점이 있다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;설명에 관한 세부 사항이나 이유는 이를 듣는 청중(audience)과 가장 연관이 있다.&lt;/li&gt;
  &lt;li&gt;설명이 명료하게 혹은 알기 쉽게 되었는지의 여부도 완전히 청중에게 달려있다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;따라서, 두 가지를 반영해 다시 정의하면 다음과 같다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;“특정 청중에게 모델이 자신의 기능을 명백하게 혹은 이해하기 쉽게 밝히는 세부사항/이유를 설명가능성이라고 말한다.”&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;Since explaining, as argumenting, may involve weighting, comparing or convincing an audience with logic-based formalizations of (counter) arguments [28], explainability might convey us into the realm of cognitive psychology and the psychology of explanations [7], since measuring whether something has been understood or put clearly is a hard task to be gauged objectively. However, measuring to which extent the internals of a model can be explained could be tackled objectively. Any means to reduce the complexity of the model or to simplify its outputs should be considered as an XAI approach. How big this leap is in terms of complexity or simplicity will correspond to how explainable the resulting model is. An underlying problem that remains unsolved is that the interpretability gain provided by such XAI approaches may not be straightforward to quantify: for instance, a model simplification can be evaluated based on the reduction of the number of architectural elements or number of parameters of the model itself (as often made, for instance, for DNNs). On the contrary, the use of visualization methods or natural language for the same purpose does not favor a clear quantification of the improvements gained in terms of interpretability. The derivation of general metrics to assess the quality of XAI approaches remain as an open challenge that should be under the spotlight of the field in forthcoming years. We will further discuss on this research direction in Section 5.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; 어떤 것이 분명하게 이해되었는지는 객관적으로 측정하기 어렵기 때문에, 설명가능성은 인지 심리학영역을 끌어들일 수도 있다.&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color:#aaa&quot;&gt;([주] 주관적인 해석이 섞여 있습니다.)&lt;/span&gt; 그러나 모델의 내부가 어느 정도까지 설명될 수 있는지는 객관적으로 측정가능하다. 모델의 복잡성/결과의 단순화 수단들을 XAI 접근법으로 생각할 수 있다. 단순화 정도를 측정하하여, 그 성과를 설명가능성으로 계량하는 것이다. &lt;span style=&quot;color:#aaa&quot;&gt;(왜? … 적절한 예시가 떠오르지 않는다…)&lt;/span&gt; 하지만 해결되지 않은 근본적인 문제는 이러한 접근 방식으로 제공하는 해석가능성이 직관적으로 정량화하기가 쉽지 않을 수 있다.&lt;/p&gt;

&lt;p&gt;예를들어, 모델의 단순화(simplification)는 아키텍쳐를 간소화 하거나 매개변수(parameters) 수를 줄임으로서 달성할 수 있다. 반면, 시각화 벙법들이나 자연어 설명은 해석가능성을 계량하기에 좋은 방법은 아니다.
XAI 방법들의 퀄리티를 평가하기 위한 일반적인 측정지표의 도출은 향후 몇 년간 과제로 남아있다. 이를 Section 5에서 논의 할 것이다.&lt;/p&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;Explainability is linked to post-hoc explainability since it covers the techniques used to convert a non-interpretable model into a explainable one. In the remaining of this manuscript, explainability will be considered as the main design objective, since it represents a broader concept. A model can be explained, but the interpretability of the model is something that comes from the design of the model itself. Bearing these observations in mind, explainable AI can be defined as follows:
&lt;br /&gt;
‘Given an audience, an explainable Artificial Intelligence is one that produces details or reasons to make its functioning clear or easy to understand.’
&lt;br /&gt;
This definition is posed here as a first contribution of the present overview, implicitly assumes that the ease of understanding and clarity targeted by XAI techniques for the model at hand reverts on different application purposes, such as a better trustworthiness of the model’s output by the audience.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; 설명가능성(explainability)는 해석이 불가능한 모델을 가능케한다는 점에서 사후(post-hoc) 설명성과 연관이 있다. 이 후의 논문에서는 더 넓은 의미인 설명가능성을 주요 목표로 생각할 것이다. 그러나 모델의 해석가능성(interpretability)은 모델 자체 설계에서 비롯된다. 이러한 생각을 염두해두고, explainable AI는 다음과 같이 정의할 수 있다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;strong&gt;설명 가능한 인공지능(explainable Artificial Intelligence)은 청중에게 자신의 기능을 명백하게 혹은 이해하기 쉬운 세부사항/이유를 생산하는 인공지능을 말한다.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;23-why&quot;&gt;2.3 Why?&lt;/h2&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;As stated in the introduction, explainability is one of the main barriers AI is facing nowadays in regards to its practical implementation. The inability to explain or to fully understand the reasons by which state-of-the-art ML algorithms perform as well as they do, is a problem that find its roots in two different causes, which are conceptually illustrated in Fig. 2.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; 도입부에 기술한 바와 같이, 설명가능성은 AI의 실질적 활용에 직면하고 있는 주요 장벽 중 하나이다. 최첨단 ML 알고리즘이 잘 작동하는 이유를 설명하지 못하거나 완전히 이해할 수 없는 것은 두 가지 다른 원인에 그 뿌리를 찾는 문제이며, 이는 개념적으로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Fig 2&lt;/code&gt;에 나타나 있다. &lt;span style=&quot;color:#aaa&quot;&gt;([주] 그 원인은 청중이 누구인가에 따라서 ML 알고리즘의 필요한 설명이 다르기 때문이다)&lt;/span&gt;&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1KcJ-gbJw7a8xSghhYs5uM3eefZ9h2vo7&quot; alt=&quot;Fig 2. 각기 다른 청중에 따라 달라지는 설명가능성의 목적&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Fig 2. 각기 다른 청중에 따라 달라지는 설명가능성의 목적&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;Without a doubt, the first cause is the gap between the research community and business sectors, impeding the full penetration of the newest ML models in sectors that have traditionally lagged behind in the digital transformation of their processes, such as banking, finances, security and health, among many others. In general this issue occurs in strictly regulated sectors with some reluctance to implement techniques that may put at risk their assets.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; 의심할 여지 없이, 첫 번째 원인은 연구 커뮤니티와 사업 부문 사이의 격차로 인해 은행, 금융, 보안, 건강 등 전통적으로 프로세스의 디지털 전환에서 뒤처진 분야에서 최신 ML 모델의 완전한 보급에 장애가 되고 있다. 일반적으로 이 문제는 엄격하게 규제되는 부문에서 발생하며 자산의 위험을 초래할 수 있는 기법의 시행을 일부 꺼린다.&lt;/p&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;The second axis is that of knowledge. AI has helped research across the world with the task of inferring relations that were far beyond the human cognitive reach. Every field dealing with huge amounts of reliable data has largely benefited from the adoption of AI and ML techniques. However, we are entering an era in which results and performance metrics are the only interest shown up in research studies. Although for certain disciplines this might be the fair case, science and society are far from being concerned just by performance. The search for understanding is what opens the door for further model improvement and its practical utility.
&lt;br /&gt;
The following section develops these ideas further by analyzing the goals motivating the search for explainable AI models.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; 두번째는 지식을 추구하는 측면이다. AI는 인간의 인지 범위를 벗어난 관계를 추론하는 연구를 도왔다. 막대한 양의 데이터를 다루는 모든 분야는 AI와 ML 기술을 도입함으로서 큰 혜택을 입었다. 그러나 연구 성과 지표에만 관심을 가지는 시대가 접어들 면서 이는 문제가 된다. 성과 지표로만 과학과 사회를 이야기 하기에는 올바르지 않기 때문이다. 이해를 연구한다는 것은 모델을 개선시키고 그 유용성을 증진시키는 일이다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;24-what-for&quot;&gt;2.4 What for?&lt;/h2&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;The research activity around XAI has so far exposed different goals to draw from the achievement of an explainable model. Almost none of the papers reviewed completely agrees in the goals required to describe what an explainable model should compel. However, all these different goals might help discriminate the purpose for which a given exercise of ML explainability is performed. Unfortunately, scarce contributions have attempted to define such goals from a conceptual perspective [5], [13], [24], [30]. We now synthesize and enumerate definitions for these XAI goals, so as to settle a first classification criteria for the full suit of papers covered in this review:&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; “설명 가능한 모델이 무엇을 강조해야하는가?”라는 목적(혹은 이에대한 합의제시)을 가진 논문은 거의 없었다. 이제부터 분류기준을 정하고, XAI의 목표에 대한 정의를 종합적으로 열거하려고 한다.&lt;/p&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;Trustworthiness: Several authors agree upon the search for trustworthiness as the primary aim of an explainable AI model [31], [32]. However, declaring a model as explainable as per its capabilities of inducing trust might not be fully compliant with the requirement of model explainability. Trustworthiness might be considered as the confidence of whether a model will act as intended when facing a given problem. Although it should most certainly be a property of any explainable model, it does not imply that every trustworthy model can be considered explainable on its own, nor is trustworthiness a property easy to quantify. Trust might be far from being the only purpose of an explainable model since the relation among the two, if agreed upon, is not reciprocal. Part of the reviewed papers mention the concept of trust when stating their purpose for achieving explainability. However, as seen in Table 1, they do not amount to a large share of the recent contributions related to XAI.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; &lt;strong&gt;신뢰도(Trustworthiness):&lt;/strong&gt; 몇몇 연구자들은 신뢰도를 설명 가능한 모델의 우선적 목표를 둬야한다고 주장한다(&lt;a href=&quot;https://scholar.google.com/scholar_lookup?title=iBCM%3A%20Interactive%20Bayesian%20case%20model%20empowering%20humans%20via%20intuitive%20interaction&amp;amp;publication_year=2015&amp;amp;author=B.%20Kim&amp;amp;author=E.%20Glassman&amp;amp;author=B.%20Johnson&amp;amp;author=J.%20Shah&quot;&gt;[31]&lt;/a&gt;, &lt;a href=&quot;https://scholar.google.com/scholar?q=Why%20should%20I%20trust%20you:%20Explaining%20the%20predictions%20of%20any%20classifier&quot;&gt;[32]&lt;/a&gt;). 그러나 이러한 주장은 모델 설명성의 요구조건을 완전히 충족하지 못한다. 신뢰도는 모델이 직면한 어떤 문제에서 설계 의도된 바로 행동하는 것으로 간주 할 수 있다. 신뢰도는 설명 가능한 모델의 속성이 되어야 하지만, 모든 신뢰성있는 모델이 설명 가능하지는 않으며, 이 특성을 계량하기 쉽지도 않다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;표1&lt;/code&gt;에서도 확인 할 수 있지만 최근의 연구기여들 중에서 큰 비중을 차지 하지 않는다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;Causality: Another common goal for explainability is that of finding causality among data variables. Several authors argue that explainable models might ease the task of finding relationships that, should they occur, could be tested further for a stronger causal link between the involved variables [159], [160]. The inference of causal relationships from observational data is a field that has been broadly studied over time [161]. As widely acknowledged by the community working on this topic, causality requires a wide frame of prior knowledge to prove that observed effects are causal. A ML model only discovers correlations among the data it learns from, and therefore might not suffice for unveiling a cause-effect relationship. However, causation involves correlation, so an explainable ML model could validate the results provided by causality inference techniques, or provide a first intuition of possible causal relationships within the available data. Again, Table 1 reveals that causality is not among the most important goals if we attend to the amount of papers that state it explicitly as their goal.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; &lt;strong&gt;인과성(Causality):&lt;/strong&gt; 설명가능성의 다른 목표로는 변수들 간의 인과성을 찾는 것이다. 몇몇 저자들은 이 과정을 용이하게 할 수 있다고 주장한다(&lt;a href=&quot;https://scholar.google.com/scholar?q=Smoking%20and%20the%20occurence%20of%20alzheimers%20disease:%20Cross-sectional%20and%20longitudinal%20data%20in%20a%20population-based%20study&quot;&gt;[159]&lt;/a&gt;, &lt;a href=&quot;https://scholar.google.com/scholar?q=An%20empirical%20study%20of%20machine%20learning%20techniques%20for%20affect%20recognition%20in%20humanrobot%20interaction&quot;&gt;[160]&lt;/a&gt;). 인과 관계의 추론은 상당히 오랜시간 연구되었다(&lt;a href=&quot;https://scholar.google.com/scholar_lookup?title=Causality&amp;amp;publication_year=2009&amp;amp;author=J.%20Pearl&quot;&gt;[161]&lt;/a&gt;). 우리가 관찰한 영향(effects)이 인과성이 있다는 것을 증명하기 위해서, 인과 관계 분야는 광범위한 사전 지식의 프레임을 필요로 한다. 머신러닝 모델은 데이터의 상관 관계를 찾기만 하지, 인과 관계를 충분하게 밝히지는 않는다. 그러나, 인과성은 상관성을 포함하기 때문에, 다양한 기법을 이용해 설명 가능한 머신러닝 모델이 결과에 대해서 검증하거나, 인과관계를 찾아볼 수는 있다. 하지만 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;표1&lt;/code&gt;에서 볼 수 있듯이, 논문의 양을 기준으로 한다면, 메인 목표는 아직 아니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;Transferability: Models are always bounded by constraints that should allow for their seamless transferability. This is the main reason why a training-testing approach is used when dealing with ML problems [162], [163]. Explainability is also an advocate for transferability, since it may ease the task of elucidating the boundaries that might affect a model, allowing for a better understanding and implementation. Similarly, the mere understanding of the inner relations taking place within a model facilitates the ability of a user to reuse this knowledge in another problem. There are cases in which the lack of a proper understanding of the model might drive the user toward incorrect assumptions and fatal consequences [44], [164]. Transferability should also fall between the resulting properties of an explainable model, but again, not every transferable model should be considered as explainable. As observed in Table 1, the amount of papers stating that the ability of rendering a model explainable is to better understand the concepts needed to reuse it or to improve its performance is the second most used reason for pursuing model explainability.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; &lt;strong&gt;전이가능성(Transferability):&lt;/strong&gt; 모델은 원활한 전이가능성을 가지기 위해서 일반화가 잘 되어야 한다. 그래서 training-testing 방법을 사용해서 훈련하는 것이다(&lt;a href=&quot;https://scholar.google.com/scholar_lookup?title=Applied%20predictive%20modeling&amp;amp;publication_year=2013&amp;amp;author=M.%20Kuhn&amp;amp;author=K.%20Johnson&quot;&gt;[162]&lt;/a&gt;, &lt;a href=&quot;https://scholar.google.com/scholar_lookup?title=An%20introduction%20to%20statistical%20learning&amp;amp;publication_year=2013&amp;amp;author=G.%20James&amp;amp;author=D.%20Witten&amp;amp;author=T.%20Hastie&amp;amp;author=R.%20Tibshirani&quot;&gt;[163]&lt;/a&gt;). 설명가능성도 전이가능성이 필요한데, 모델에 영향을 미칠 수 있는 경계를 확장 하면서 더 나은 이해와 구현을 가능하게 하기 때문이고, 내부관계의 이해를 바탕으로 사용자가 다른 문제에서 이 지식을 재사용 할 수 있기 때문이다. 다만, 모델에 대한 이해가 부족하여 잘못된 가정과 치명적인 결과를 초래할 경우도 있다(&lt;a href=&quot;https://scholar.google.com/scholar_lookup?title=Intelligible%20models%20for%20healthcare%3A%20Predicting%20pneumonia%20risk%20and%20hospital%2030-day%20readmission&amp;amp;publication_year=2015&amp;amp;author=R.%20Caruana&amp;amp;author=Y.%20Lou&amp;amp;author=J.%20Gehrke&amp;amp;author=P.%20Koch&amp;amp;author=M.%20Sturm&amp;amp;author=N.%20Elhadad&quot;&gt;[44]&lt;/a&gt;, &lt;a href=&quot;https://scholar.google.com/scholar?q=C.%20Szegedy,%20W.%20Zaremba,%20I.%20Sutskever,%20J.%20Bruna,%20D.%20Erhan,%20I.%20Goodfellow,%20R.%20Fergus,%20Intriguing%20properties%20of%20neural%20networks,%202013.&quot;&gt;[164]&lt;/a&gt;). 또한, 전이가능성은 설명 가능한 모델의 특성이지만, 모든 전이가능한 모델이 설명가능하지는 않다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;표1&lt;/code&gt;에서 볼수 있듯이, 모델의 전이가능성은 (연구기여의 양적으로 따졌을 때) 모델의 설명성을 추구하는 2번째 이유가 되며, 설명가능성은 모델을 재사용 하기 위해 필요한 개념을 더 잘 이해하고, 모델 성능을 향상시키기 위해 사용될 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;Informativeness: ML models are used with the ultimate intention of supporting decision making [92]. However, it should not be forgotten that the problem being solved by the model is not equal to that being faced by its human counterpart. Hence, a great deal of information is needed in order to be able to relate the user’s decision to the solution given by the model, and to avoid falling in misconception pitfalls. For this purpose, explainable ML models should give information about the problem being tackled. Most of the reasons found among the papers reviewed is that of extracting information about the inner relations of a model. Almost all rule extraction techniques substantiate their approach on the search for a simpler understanding of what the model internally does, stating that the knowledge (information) can be expressed in these simpler proxies that they consider explaining the antecedent. This is the most used argument found among the reviewed papers to back up what they expect from reaching explainable models.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; &lt;strong&gt;정보성(Informativeness):&lt;/strong&gt; 머신러닝 모델의 궁극적인 목적은 의사 결정의 지원이다(&lt;a href=&quot;https://scholar.google.com/scholar_lookup?title=An%20empirical%20evaluation%20of%20the%20comprehensibility%20of%20decision%20table%2C%20tree%20and%20rule%20based%20predictive%20models&amp;amp;publication_year=2011&amp;amp;author=J.%20Huysmans&amp;amp;author=K.%20Dejaeger&amp;amp;author=C.%20Mues&amp;amp;author=J.%20Vanthienen&amp;amp;author=B.%20Baesens&quot;&gt;[92]&lt;/a&gt;). 그러나 모델이 풀고 있는 문제는 인간이 직면하고 있는 문제와 항상 같은 것은 아니다. &lt;span style=&quot;color:#aaa&quot;&gt;([주] 아직까지 모델은 더 단순한 문제를 해결하고 있기 때문, 아직 복합적인 정보를 결합하여 문제를 해결하지는 못한다.)&lt;/span&gt; 따라서 사용자의 의사결정에 모델이 내놓은 솔루션을 오해하지 않게 잘 연관 시키려면 더 많은 양의 정보가 필요하다. 이를 위해, 설명 가능한 모델은 문제에 태클이 될 만한 정보를 더 많이 제공해야한다. 대부분 논문을 살펴본 결과, 그 이유는 모델의 내부 관계에서 정보를 추출하기 위함이었다. 대부분의 규칙기반 기술을 사용하려는 사람들은 모델 행동의 이해를 더 간단하게 만들기 위해 방법론을 연구하고 있었다. 그들은 모델의 지식이나 정보를 더 간단하게 대체할 수 있을 것이라 주장했다. 이는 설명 가능한 모델에서 가장 많은 기대를 하는 특성이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;Confidence: As a generalization of robustness and stability, confidence should always be assessed on a model in which reliability is expected. The methods to maintain confidence under control are different depending on the model. As stated in [165], [166], [167], stability is a must-have when drawing interpretations from a certain model. Trustworthy interpretations should not be produced by models that are not stable. Hence, an explainable model should contain information about the confidence of its working regime.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; &lt;strong&gt;확신(Confidence):&lt;/strong&gt; 건전성(robustness)와 안전성(stability)의 일반화로서, 신뢰성이 기대되는 모델은 그 확신의 정도를 가늠할 수 있어야 한다. 확신을 유지하는 방법은 모델에 따라서 다르다. &lt;a href=&quot;https://scholar.google.com/scholar_lookup?title=Robust%20statistics%3A%20The%20approach%20based%20on%20influence%20functions&amp;amp;publication_year=1987&amp;amp;author=D.%20Ruppert&quot;&gt;[165]&lt;/a&gt;, &lt;a href=&quot;https://scholar.google.com/scholar_lookup?title=Iterative%20random%20forests%20to%20discover%20predictive%20and%20stable%20high-order%20interactions&amp;amp;publication_year=2018&amp;amp;author=S.%20Basu&amp;amp;author=K.%20Kumbier&amp;amp;author=J.B.%20Brown&amp;amp;author=B.%20Yu&quot;&gt;[166]&lt;/a&gt;, &lt;a href=&quot;https://scholar.google.com/scholar_lookup?title=Stability&amp;amp;publication_year=2013&amp;amp;author=B.%20Yu&quot;&gt;[167]&lt;/a&gt;에서 기술한 바와 같이, 안정성은 어떤 모델에서 해석을 도출하기 위해서 꼭 필요한 특성이다. &lt;span style=&quot;color:#aaa&quot;&gt;([주] 일단 모델이 일반화가 잘 되어 있어야 그 해석 또한 안정적으로 도출 할 수 있다.)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;Fairness: From a social standpoint, explainability can be considered as the capacity to reach and guarantee fairness in ML models. In a certain literature strand, an explainable ML model suggests a clear visualization of the relations affecting a result, allowing for a fairness or ethical analysis of the model at hand [3], [100]. Likewise, a related objective of XAI is highlighting bias in the data a model was exposed to [168], [169]. The support of algorithms and models is growing fast in fields that involve human lives, hence explainability should be considered as a bridge to avoid the unfair or unethical use of algorithm’s outputs.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; &lt;strong&gt;공정성(Fairness):&lt;/strong&gt; 사회적 관점에서 설명가능성은 머신러닝의 공정성을 보장하는 능력으로 볼 수 있다. 특정 문헌에서 설명 가능한 모델은 명백한 결과의 관계 시각화를 통해 공정성 혹은 윤리적 분석을 가능하게 한다(&lt;a href=&quot;https://scholar.google.com/scholar?q=European%20union%20regulations%20on%20algorithmic%20decision-making%20and%20a%20right%20to%20explanation&quot;&gt;[3]&lt;/a&gt;, &lt;a href=&quot;https://scholar.google.com/scholar_lookup?title=Fair%20prediction%20with%20disparate%20impact%3A%20A%20study%20of%20bias%20in%20recidivism%20prediction%20instruments&amp;amp;publication_year=2017&amp;amp;author=A.%20Chouldechova&quot;&gt;[100]&lt;/a&gt;). 이와 관련된 목표로는 &lt;a href=&quot;https://scholar.google.com/scholar?q=K.%20Burns,%20L.A.%20Hendricks,%20K.%20Saenko,%20T.%20Darrell,%20A.%20Rohrbach,%20Women%20also%20Snowboard:%20Overcoming%20Bias%20in%20Captioning%20Models,%202018.&quot;&gt;[168]&lt;/a&gt;, &lt;a href=&quot;https://scholar.google.com/scholar_lookup?title=Towards%20explainable%20neural-symbolic%20visual%20reasoning&amp;amp;publication_year=2019&amp;amp;author=A.%20Bennetot&amp;amp;author=J.-L.%20Laurent&amp;amp;author=R.%20Chatila&amp;amp;author=N.%20D%C3%ADaz-Rodr%C3%ADguez&quot;&gt;[169]&lt;/a&gt;에서 보여준 바와 같이, 모델이 학습한 데이터의 편향을 강조하는 것이다. 사람들의 삶에서 머신러닝 모델(알고리즘)은 앞으로 계속 빠르게 노출될 수 밖에 없기에, 설명가능성은 이러한 불공평과 비윤리적인 알고리즘의 산출물을 피할 수 있게 하는 가교역할이 되어야 한다. &lt;span style=&quot;color:#aaa&quot;&gt;([주] 최근 &lt;a href=&quot;https://blog.pingpong.us/luda-issue-faq/?fbclid=IwAR15-eiWeIPSnv8lT0WXlO07HBpP0aJaoN36vThaGDmIaBeZpU6jiIy_oJw&quot;&gt;이루다&lt;/a&gt; 일은 신뢰도에도 속하지만, 이 범주에도 속한다고 할 수 있겠다.)&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;Accessibility: A minor subset of the reviewed contributions argues for explainability as the property that allows end users to get more involved in the process of improving and developing a certain ML model [37], [86]. It seems clear that explainable models will ease the burden felt by non-technical or non-expert users when having to deal with algorithms that seem incomprehensible at first sight. This concept is expressed as the third most considered goal among the surveyed literature.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; &lt;strong&gt;접근성(Accessibility):&lt;/strong&gt; 일부 연구자들은 설명가능성은 최종 사용자가 특정 모델을 개발하고 개선하는 프로세스에 더 많이 관여할 수 있는 속성이라고 주장한다(&lt;a href=&quot;https://scholar.google.com/scholar_lookup?title=Working%20with%20beliefs%3A%20AI%20transparency%20in%20the%20enterprise.&amp;amp;publication_year=2018&amp;amp;author=A.%20Chander&amp;amp;author=R.%20Srinivasan&amp;amp;author=S.%20Chelian&amp;amp;author=J.%20Wang&amp;amp;author=K.%20Uchino&quot;&gt;[38]&lt;/a&gt;, &lt;a href=&quot;https://scholar.google.com/scholar_lookup?title=Explainable%20AI%3A%20Beware%20of%20inmates%20running%20the%20asylum&amp;amp;publication_year=2017&amp;amp;author=T.%20Miller&amp;amp;author=P.%20Howe&amp;amp;author=L.%20Sonenberg&quot;&gt;[86]&lt;/a&gt;). 설명 가능한 모델은 비전문가 사용자에게 처음 보는 알 수 없는 알고리즘에 대한 부담을 덜어 줄 수 있어보인다. 이는 이번 조사에서 3번째로 많이 고려된 목표다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;Interactivity: Some contributions [50], [59] include the ability of a model to be interactive with the user as one of the goals targeted by an explainable ML model. Once again, this goal is related to fields in which the end users are of great importance, and their ability to tweak and interact with the models is what ensures success.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; &lt;strong&gt;상호작용(Interactivity):&lt;/strong&gt; 특정 논문([50], [59])에서는 사용자와 모델이 상호작용하는 능력을 설명 가능한 모델의 목표로 잡았다. 이는 최종 사용자와 더 관련이 있으며, 이들의 모델을 수정하고 상호작용하는 능력이 목표달성의 성공을 보장한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;Privacy awareness: Almost forgotten in the reviewed literature, one of the byproducts enabled by explainability in ML models is its ability to assess privacy. ML models may have complex representations of their learned patterns. Not being able to understand what has been captured by the model [4] and stored in its internal representation may entail a privacy breach. Contrarily, the ability to explain the inner relations of a trained model by non-authorized third parties may also compromise the differential privacy of the data origin. Due to its criticality in sectors where XAI is foreseen to play a crucial role, confidentiality and privacy issues will be covered further in Sections 5.4 and 6.3, respectively.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt;&lt;strong&gt;프라이버시 인식(Privacy awareness):&lt;/strong&gt; 대부분의 논문에서 언급되지 않았지만 설명 가능한 모델의 부산물 중에 하나는 프라이버시를 평가하는 능력이다. 머신러닝에서 학습한 패턴은 복잡한 표현(representations)&lt;span style=&quot;color:#aaa&quot;&gt;([주] 여기서 “표현”이란 데이터 혹은 패턴을 압축하여 나타내는 어떤 상태다.)&lt;/span&gt;으로 나타낼 수 있다. 모델 내부에 어떤 것이 포착되어 있는지 알 수 없다면, 개인정보의 침해가 일어날 수 있다. 반대로, 비인가 제3자에 의해 훈련된 모델의 내부를 설명할 수 있다면, 그것 또한 다른 의미로써 데이터 출처에 대한 프라이버시 침해라고 할 수 있다. 사안의 중요성 때문에, 이 기밀성(confidentiality)와 개인정보 문제는 section 5.4와 6.3에서 더 다룰 예정이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;XAI Goal&lt;/th&gt;
      &lt;th&gt;Main target audience (Fig. 2)&lt;/th&gt;
      &lt;th&gt;References&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Trustworthiness&lt;/td&gt;
      &lt;td&gt;Domain experts, users of the model affected by decisions&lt;/td&gt;
      &lt;td&gt;[5], [10], [24], [32], [33], [34], [35], [36], [37]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Causality&lt;/td&gt;
      &lt;td&gt;Domain experts, managers and executive board members, regulatory entities/agencies&lt;/td&gt;
      &lt;td&gt;[35], [38], [39], [40], [41], [42], [43]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Transferability&lt;/td&gt;
      &lt;td&gt;Domain experts, data scientists&lt;/td&gt;
      &lt;td&gt;[5], [21], [26], [30], [32], [37], [38], [39], [44], [45], [46], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [60], [61], [62], [63], [64], [65], [66], [67], [68], [69], [70], [71], [72], [73], [74], [75], [76], [77], [78], [79], [80], [81], [82], [83], [84], [85]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Informativeness&lt;/td&gt;
      &lt;td&gt;All&lt;/td&gt;
      &lt;td&gt;[5], [21], [25], [26], [30], [32], [34], [35], [37], [38], [41], [44], [45], [46], [49], [50], [51], [52], [53], [54], [55], [56], [57], [58], [59], [59], [60], [63], [64], [65], [66], [68], [69], [70], [71], [72], [73], [74], [75], [76], [77], [78], [79], [86], [87], [88], [89], [90], [91], [92], [93], [94], [95], [96], [97], [98], [99], [100], [101], [102], [103], [104], [105], [106], [107], [108], [109], [110], [111], [112], [113], [114], [115], [116], [117], [118], [119], [120], [121], [122], [123], [124], [125], [126], [127], [128], [129], [130], [131], [132], [133], [134], [135], [136], [137], [138], [139], [140], [141], [142], [143], [144], [145], [146], [147], [148], [149], [150], [151], [152], [153], [154]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Confidence&lt;/td&gt;
      &lt;td&gt;Domain experts, developers, managers, regulatory entities/agencies&lt;/td&gt;
      &lt;td&gt;[5], [35], [45], [46], [48], [54], [61], [72], [88], [89], [96], [108], [117], [119], [155]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Fairness&lt;/td&gt;
      &lt;td&gt;Users affected by model decisions, regulatory entities/agencies&lt;/td&gt;
      &lt;td&gt;[5], [24], [35], [45], [47], [99], [100], [101], [120], [121], [128], [156], [157], [158]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Accessibility&lt;/td&gt;
      &lt;td&gt;Product owners, managers, users affected by model decisions&lt;/td&gt;
      &lt;td&gt;[21], [26], [30], [32], [37], [50], [53], [55], [62], [67], [68], [69], [70], [71], [74], [75], [76], [86], [93], [94], [103], [105], [107], [108], [111], [112], [113], [114], [115], [124], [129]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Interactivity&lt;/td&gt;
      &lt;td&gt;Domain experts, users affected by model decisions&lt;/td&gt;
      &lt;td&gt;[37], [50], [59], [65], [67], [74], [86], [124]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Privacy awareness&lt;/td&gt;
      &lt;td&gt;Users affected by model decisions, regulatory entities/agencies&lt;/td&gt;
      &lt;td&gt;[89]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;표 1&lt;/code&gt; 설명가능성에 도달하기 위해 검토된 문헌에서 추구된 목표들과 그들의 주요 목표 청중들.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;25-how&quot;&gt;2.5 How?&lt;/h2&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;The literature makes a clear distinction among models that are interpretable by design, and those that can be explained by means of external XAI techniques. This duality could also be regarded as the difference between interpretable models and model interpretability techniques; a more widely accepted classification is that of transparent models and post-hoc explainability. This same duality also appears in the paper presented in [17] in which the distinction its authors make refers to the methods to solve the transparent box design problem against the problem of explaining the black-box problem. This work, further extends the distinction made among transparent models including the different levels of transparency considered.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; 본 논문은 해석 가능한 모델을 &lt;strong&gt;해석 가능한 모델&lt;/strong&gt;(구조적으로 설명 가능한 부분)과 &lt;strong&gt;해석 가능한 기법&lt;/strong&gt;(외부 XAI 기법에 의해 설명될 수 있는 부분)으로 나눈다. 현재 보다 널리 받아들여지고 있는 분류법 용어는 투명한 모델(transparent models)과 사후 설명가능성(post-hoc explainability)이다. [17]에서도 언급하는데, 블랙박스 문제를 설명하려면 투명한 모델의 디자인 문제를 참고해야한다. 본 논문에서는 투명한 모델을 다양한 단계로 세분화해서 그 차이를 알아 볼 것이다.&lt;/p&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;Within transparency, three levels are contemplated: algorithmic transparency, decomposability and simulatability Among post-hoc techniques we may distinguish among text explanations, visualizations, local explanations, explanations by example, explanations by simplification and feature relevance. In this context, there is a broader distinction proposed by [24] discerning between 1) opaque systems, where the mappings from input to output are invisible to the user; 2) interpretable systems, in which users can mathematically analyze the mappings; and 3) comprehensible systems, in which the models should output symbols or rules along with their specific output to aid in the understanding process of the rationale behind the mappings being made. This last classification criterion could be considered included within the one proposed earlier, hence this paper will attempt at following the more specific one.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; 투명성(transparency)은 알고리즘 투명성(algorithmic transparency), 분해가능성(decomposability) 그리고 시뮬레이션성(simulatability) &lt;span style=&quot;color:#aaa&quot;&gt;([주] 시스템 혹은 프로세스의 시뮬레이션 능력, the capacity of a system or process to be simulated, 아직 어떤 느낌이 안온다.)&lt;/span&gt;순으로 3 가지 단계를 고려해야한다. 사후 분석(post-hoc) 기법은 텍스트 설명, 시각화, 국지적 설명, 예시 설명, 단순화 및 피처중요도등 방법과 구별되어야 한다. 이러한 맥락에서 더 광범위한 구별법이 &lt;a href=&quot;https://scholar.google.com/scholar?q=D.%20Doran,%20S.%20Schulz,%20T.R.%20Besold,%20What%20does%20explainable%20AI%20really%20mean%20a%20new%20conceptualization%20of%20perspectives,%202017.&quot;&gt;[24]&lt;/a&gt;에서 제시 되었다. 1) 입력에서 출력까지의 매핑이 사용자에게 보이지 않는 불투명한(opaque) 시스템 2) 사용자가 수학적으로 매핑을 분석할 수 있는 해석 가능한(interpretable) 시스템 3) 모델이 결정한 매핑의 이유를 사람이 이해 가능하게 출력하는 포괄적 이해 가능한(comprehensible) 시스템&lt;/p&gt;

&lt;h3 id=&quot;251-levels-of-transparency-in-machine-learning-models&quot;&gt;2.5.1. Levels of transparency in machine learning models&lt;/h3&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;Transparent models convey some degree of interpretability by themselves. Models belonging to this category can be also approached in terms of the domain in which they are interpretable, namely, algorithmic transparency, decomposability and simulatability. As we elaborate next in connection to Fig. 3, each of these classes contains its predecessors, e.g. a simulatable model is at the same time a model that is decomposable and algorithmically transparent:&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; 투명한 모델은 모델 그 자체로 어느 정도의 해석가능성을 가지고 있다. 위에 언급한 대로 알고리즘 투명성, 분해가능성 그리고 시뮬레이션성 순으로 접근 할 수 있다. Fig 3에서 설명하겠지만, 각 분류는 이전 단계의 구성을 포함한다.. 예를 들어, 시뮬레이션 가능한 모델은 분해 가능하며, 투명한 알고리즘을 포함한다.&lt;/p&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;Simulatability denotes the ability of a model of being simulated or thought about strictly by a human, hence complexity takes a dominant place in this class. This being said, simple but extensive (i.e., with too large amount of rules) rule based systems fall out of this characteristic, whereas a single perceptron neural network falls within. This aspect aligns with the claim that sparse linear models are more interpretable than dense ones [170], and that an interpretable model is one that can be easily presented to a human by means of text and visualizations [32]. Again, endowing a decomposable model with simulatability requires that the model has to be self-contained enough for a human to think and reason about it as a whole.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; &lt;strong&gt;시뮬레이션성(Simulatability):&lt;/strong&gt; 사람에 의해 엄격하게 시뮬레이션된 모델의 능력이다. 따라서 복잡성이 가장 중요하다. 단순하지만 광범위한 규칙기반 시스템 보다는 퍼셉트론 신경망이 기준에 더 부합한다. 이러한 관점에서 sparse한 선형모델이 dense 한 것보다 더 해석가능성이 높으며 &lt;a href=&quot;https://scholar.google.com/scholar_lookup?title=Regression%20shrinkage%20and%20selection%20via%20the%20lasso&amp;amp;publication_year=1996&amp;amp;author=R.%20Tibshirani&quot;&gt;[170]&lt;/a&gt;, 설명 가능한 모델의 텍스트와 시각화를 통해 인간이 더 쉽게 설명 할 수 있다라는 주장&lt;a href=&quot;https://scholar.google.com/scholar?q=Why%20should%20I%20trust%20you:%20Explaining%20the%20predictions%20of%20any%20classifier&quot;&gt;[32]&lt;/a&gt;과 일치한다. 다시 말하지만 시뮬레이션성을 가지는 분해 가능한 모델은 인간에게 생각과 이유를 혼자 설명할 수 있어야 한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;Decomposability stands for the ability to explain each of the parts of a model (input, parameter and calculation). It can be considered as intelligibility as stated in [171]. This characteristic might empower the ability to understand, interpret or explain the behavior of a model. However, as occurs with algorithmic transparency, not every model can fulfill this property. Decomposability requires every input to be readily interpretable (e.g. cumbersome features will not fit the premise). The added constraint for an algorithmically transparent model to become decomposable is that every part of the model must be understandable by a human without the need for additional tools.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; &lt;strong&gt;분해가능성(Decomposability):&lt;/strong&gt; 모델의 각 부분을 설명하는 능력인데, &lt;a href=&quot;https://scholar.google.com/scholar_lookup?title=Intelligible%20models%20for%20classification%20and%20regression&amp;amp;publication_year=2012&amp;amp;author=Y.%20Lou&amp;amp;author=R.%20Caruana&amp;amp;author=J.%20Gehrke&quot;&gt;[171]&lt;/a&gt;에서 언급된 명료성(intelligibility)으로 볼 수 있다. 이 특성은 모델의 행동을 이해하고, 해석하거나 설명하는 능력을 강조한다. 그러나 모든 모델이 이 특성이 있는 것은 아니다. 분해가능성은 모든 입력의 쉽게 해석할 수 있어야 하는데, 알고리즘적 투명성까지 만족하기 위해서는 인간이 모델의 모든 부분에서 추가해석 없이 이해할 수 있어야 한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;Algorithmic transparency can be seen in different ways. It deals with the ability of the user to understand the process followed by the model to produce any given output from its input data. Put it differently, a linear model is deemed transparent because its error surface can be understood and reasoned about, allowing the user to understand how the model will act in every situation it may face [163]. Contrarily, it is not possible to understand it in deep architectures as the loss landscape might be opaque [172], [173] since it cannot be fully observed and the solution has to be approximated through heuristic optimization (e.g. through stochastic gradient descent). The main constraint for algorithmically transparent models is that the model has to be fully explorable by means of mathematical analysis and methods.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; &lt;strong&gt;알고리즘적 투명성(Algorithmic transparency):&lt;/strong&gt; 사용자가 모델에 대한 프로세스(모델이 도출한 입력 데이터에 대한 출력) 이해 능력을 나타낸다. 선형모델은 사용자가 모델이 어떻게 행동할 지 예측할 수 있고, error surface를 이해하고 설명할 수 있기 때문에 투명하다고 볼 수 있다&lt;a href=&quot;https://scholar.google.com/scholar_lookup?title=An%20introduction%20to%20statistical%20learning&amp;amp;publication_year=2013&amp;amp;author=G.%20James&amp;amp;author=D.%20Witten&amp;amp;author=T.%20Hastie&amp;amp;author=R.%20Tibshirani&quot;&gt;[163]&lt;/a&gt;. 반대로, 깊은 모델 구조를 가지는 모델은 손실값이 불투명하여(&lt;a href=&quot;https://scholar.google.com/scholar_lookup?title=Deep%20learning%20without%20poor%20local%20minima&amp;amp;publication_year=2016&amp;amp;author=K.%20Kawaguchi&quot;&gt;[172]&lt;/a&gt;, &lt;a href=&quot;https://scholar.google.com/scholar_lookup?title=Algorithmic%20transparency%20via%20quantitative%20input%20influence%3A%20Theory%20and%20experiments%20with%20learning%20systems&amp;amp;publication_year=2016&amp;amp;author=A.%20Datta&amp;amp;author=S.%20Sen&amp;amp;author=Y.%20Zick&quot;&gt;[173]&lt;/a&gt;), 특정 휴리스틱한 최적화(예, stochastic gradient descent)를 통해서 근사치를 구해야한다. &lt;span style=&quot;color:#aaa&quot;&gt;([주] 수학적으로 명쾌한 solution이 안보이면 불투명하다고 보는 것 같다. 특히 비선형함수의 손실값)&lt;/span&gt; 알고리즘적 투명성의 주된 제약 조건은 모델이 수학적 분석과 방법을 통해 완전이 탐구 가능해야 한다는 것이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1iZXqf9hnwcu-N9If2_R4WWF5RinPIhPX&quot; alt=&quot;Fig 3. 다양한 단계의 투명성&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Fig 3. 다양한 단계의 투명성&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; 다양한 단계의 투명성을 설명해두었다. 머신러닝 모델은 $M_{\varphi}$, 그에 해당하는 파라미터는 $\varphi$ 로 표기했다. (a) 시뮬레이션성 (b) 분해가능성 (c) 알고리즘적 투명성. 각 예제는 일반적인 손실값 가정을 고려하지 않은 선에서, 모델이 설명 대상에 따라서 얼마나 달라지는지를 보여준다.&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color:#aaa&quot;&gt; [주] 이 파트가 제일 이해하기 어려웠는데, (a) 같은 경우 입력 데이터는 잘 몰라도, 내부의 구조를 그대로 재현 가능하면 만족하는 것 같고, (b) 의 경우 사람이 각 입력 피처까지 이해할 수 있어야 한다. (c)의 경우 사람이 전체 데이터의 특성까지 파악하고 이에 대한 규칙을 이해해야 한다라고 이해했다. &lt;/span&gt;&lt;/p&gt;

&lt;h3 id=&quot;252-post-hoc-explainability-techniques-for-machine-learning-models&quot;&gt;2.5.2. Post-hoc explainability techniques for machine learning models&lt;/h3&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;Post-hoc explainability targets models that are not readily interpretable by design by resorting to diverse means to enhance their interpretability, such as text explanations, visual explanations, local explanations, explanations by example, explanations by simplification and feature relevance explanations techniques. Each of these techniques covers one of the most common ways humans explain systems and processes by themselves.
&lt;br /&gt;
Further along this river, actual techniques, or better put, actual group of techniques are specified to ease the future work of any researcher that intends to look up for an specific technique that suits its knowledge. Not ending there, the classification also includes the type of data in which the techniques has been applied. Note that many techniques might be suitable for many different types of data, although the categorization only considers the type used by the authors that proposed such technique. Overall, post-hoc explainability techniques are divided first by the intention of the author (explanation technique e.g. Explanation by simplification), then, by the method utilized (actual technique e.g. sensitivity analysis) and finally by the type of data in which it was applied (e.g. images).&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; &lt;strong&gt;사후 설명가능성(post-hoc explainability)&lt;/strong&gt;은 쉽게 해석할 수 없는 모델을 위해 고안된 방법이다. 텍스트, 시각화, 부분, 예시, 단순화 그리고 피처 연관 설명 등 방법들이 있다.&lt;/p&gt;

&lt;p&gt;각 방법들에 대해 특정 기술 뿐만 아니라 적용되는 데이터 유형까지 소개한다. 여기서는 인용한 저자들이 적용한 데이터에 의거해 분류를 했지만, 이 중에 어떤 방법들은 다른 분야(데이터)에도 충분히 적용할 수 있다.&lt;/p&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;Text explanations deal with the problem of bringing explainability for a model by means of learning to generate text explanations that help explaining the results from the model [169]. Text explanations also include every method generating symbols that represent the functioning of the model. These symbols may portrait the rationale of the algorithm by means of a semantic mapping from model to symbols.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; &lt;strong&gt;텍스트 설명(Text explanation)&lt;/strong&gt;은 모델이 자신의 결과를 설명하는 “텍스트 생성 학습” 문제다. 이 방법은 모델의 기능을 나타내는 심볼을 생성&lt;span style=&quot;color:#aaa&quot;&gt;([주] 인간의 언어가 될 수도 있고, 수식일 수도)&lt;/span&gt;하는 방식인데, 이 심볼들은 의미론적(semantic)으로 알고리즘의 작동 방식을 매핑한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;Visual explanation techniques for post-hoc explainability aim at visualizing the model’s behavior. Many of the visualization methods existing in the literature come along with dimensionality reduction techniques that allow for a human interpretable simple visualization. Visualizations may be coupled with other techniques to improve their understanding, and are considered as the most suitable way to introduce complex interactions within the variables involved in the model to users not acquainted to ML modeling.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; &lt;strong&gt;시각적 설명(Visual explanation)&lt;/strong&gt;의 목표는 모델의 행동을 시각적으로 설명한는 것이다. 많은 방법들 중에서 대부분 인간이 해석하기 쉽게 차원감소(dimension reduction) 기법과 함께 사용된다. 이 방법은 다른 방법들과 함께 사용되서 이해를 향상시킬 수 있다. 머신러닝 모델링에 익숙하지 않은 사용자에게 모델과 관련된 변수의 복잡한 상호작용을 알리는데 있어 가장 적합한 도구다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;Local explanations tackle explainability by segmenting the solution space and giving explanations to less complex solution subspaces that are relevant for the whole model. These explanations can be formed by means of techniques with the differentiating property that these only explain part of the whole system’s functioning.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; &lt;strong&gt;부분 설명(Local explanation)&lt;/strong&gt;은 전체모델의 일부분을 쉽게 설명하는데 집중한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;Explanations by example consider the extraction of data examples that relate to the result generated by a certain model, enabling to get a better understanding of the model itself. Similarly to how humans behave when attempting to explain a given process, explanations by example are mainly centered in extracting representative examples that grasp the inner relationships and correlations found by the model being analyzed.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; &lt;strong&gt;예시 설명(Example explanation)&lt;/strong&gt;은 데이터 샘플에서 결과와 관련된 예제를 추출하는 방법이다. 주로 모델 결과의 내적 관계 혹은 상관관계에 관련된 예제를 추출하게 된다. 이 방법은 사람이 어떤 프로세스를 설명하려고 할 때랑 비슷하게 행동한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;Explanations by simplification collectively denote those techniques in which a whole new system is rebuilt based on the trained model to be explained. This new, simplified model usually attempts at optimizing its resemblance to its antecedent functioning, while reducing its complexity, and keeping a similar performance score. An interesting byproduct of this family of post-hoc techniques is that the simplified model is, in general, easier to be implemented due to its reduced complexity with respect to the model it represents.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; &lt;strong&gt;단순화 설명(Simplification explanation)&lt;/strong&gt;은 훈련된 모델에 기초하여 설명을 위한 새로운 시스템을 만들어내는 방법이다. 이 새로운 시스템은 복잡성을 최대한 줄이고, 유사한 기능 및 성능을 유지하는 것이 중요하다. 이 방법은 기존에 복잡한 모델에 반해, 더 쉽게 구현할 수 있다는 것이 장점이 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;Finally, feature relevance explanation methods for post-hoc explainability clarify the inner functioning of a model by computing a relevance score for its managed variables. These scores quantify the affection (sensitivity) a feature has upon the output of the model. A comparison of the scores among different variables unveils the importance granted by the model to each of such variables when producing its output. Feature relevance methods can be thought to be an indirect method to explain a model.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; &lt;strong&gt;피처 연관 설명(Feature relevance explanation)&lt;/strong&gt;은 모델의 변수와 관련된 점수를 계산하는 방식으로 구현된다. 이 점수는 피처의 영향력(affection 혹은 sensitivity)를 계량화한다. 출력에 대한 점수가 각기 다르기 때문에 각 피처의 중요도를 확인할 수 있다. 이는 모델을 설명하는 간접적인 방법이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;The above classification (portrayed graphically in Fig. 4) will be used when reviewing specific/agnostic XAI techniques for ML models in the following sections (Table 2). For each ML model, a distinction of the propositions to each of these categories is presented in order to pose an overall image of the field’s trends.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; 위 분류를 Fig 4로 표현했으며, 표 2에서도 정리했다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1CDEwm6jcM8SKvE3YT21n9HlTTPq2Orol&quot; alt=&quot;Fig 4. 사후 설명가능성 방법에 대한 컨셉 다이어그램&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Fig 4. 사후 설명가능성 방법에 대한 컨셉 다이어그램&lt;/figcaption&gt;&lt;/figure&gt;

&lt;hr /&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt;Transparent ML Models&lt;/th&gt;
      &lt;th&gt;Transparent ML Models&lt;/th&gt;
      &lt;th&gt;Transparent ML Models&lt;/th&gt;
      &lt;th&gt;Post-hoc analysis&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Model&lt;/th&gt;
      &lt;th&gt;Simulatability&lt;/th&gt;
      &lt;th&gt;Decomposability&lt;/th&gt;
      &lt;th&gt;Algorithmic Transparency&lt;/th&gt;
      &lt;th&gt;Post-hoc analysis&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Linear/Logistic Regression&lt;/td&gt;
      &lt;td&gt;예측 변수는 사람이 판독할 수 있으며 예측 변수 간의 상호 작용은 최소한으로 유지됨&lt;/td&gt;
      &lt;td&gt;변수는 여전히 읽을 수 있지만, 변수와 관련된 상호작용과 예측 변수의 수는 분해를 강요하는 수준으로 증가했다.&lt;/td&gt;
      &lt;td&gt;변수와 교호작용이 너무 복잡하여 수학적 도구가 없으면 분석할 수 없음&lt;/td&gt;
      &lt;td&gt;필요 없음&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Decision Trees&lt;/td&gt;
      &lt;td&gt;사람은 어떤 수학적 배경도 요구하지 않고 스스로 의사결정 나무의 예측을 시뮬레이션하고 얻을 수 있다.&lt;/td&gt;
      &lt;td&gt;데이터가 어떻든 모델은 규칙을 전혀 변경하지 않고 가독성을 유지함&lt;/td&gt;
      &lt;td&gt;데이터로부터 학습한 지식을 사람이 이해 할 만한 규칙으로 설명하고, 예측 프로세스를 직관적으로 알 수 있음&lt;/td&gt;
      &lt;td&gt;필요 없음&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;K-Nearest Neighbors&lt;/td&gt;
      &lt;td&gt;인간의 나이브한 능력에 따라서 모델 복잡도가 결정된다(변수의 개수, 변수간 유사성의 이해도)&lt;/td&gt;
      &lt;td&gt;변수의 양이 너무 많거나 유사성 측도가 너무 복잡하여 모형을 완전히 시뮬레이션할 수 없지만 유사성 측도와 변수 집합을 별도로 분해하여 분석할 수 있다.&lt;/td&gt;
      &lt;td&gt;유사성 측정은 분해될 수 없으며/또는 변수 수가 너무 많아서 사용자는 모델을 분석하기 위해 수학적 및 통계적 도구에 의존해야함&lt;/td&gt;
      &lt;td&gt;필요 없음&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Rule Based Learners&lt;/td&gt;
      &lt;td&gt;규칙에 포함된 변수는 읽을 수 있으며 규칙 집합의 크기는 외부 도움 없이 사용자가 관리할 수 있음&lt;/td&gt;
      &lt;td&gt;규칙 집합의 크기가 너무 커서 작은 규칙 청크로 분해하지 않고 분석할 수 없음&lt;/td&gt;
      &lt;td&gt;규칙이 너무 복잡해져서(그리고 규칙 집합 크기가 너무 커져서) 모델 동작을 검사하는 데 수학적 도구가 필요함&lt;/td&gt;
      &lt;td&gt;필요 없음&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;General Additive Models&lt;/td&gt;
      &lt;td&gt;모델에 포함된 원활한 기능에 따라 변수 및 변수 간의 상호 작용은 인간이 이해할 수 있는 범위에 제한되어야 함&lt;/td&gt;
      &lt;td&gt;교호작용이 너무 복잡해져서 시뮬레이션할 수 없으므로 모델을 분석하려면 분해 기법이 필요함&lt;/td&gt;
      &lt;td&gt;복잡성 때문에, 변수와 상호작용은 수학적, 통계적 도구를 적용하지 않고는 분석할 수 없음&lt;/td&gt;
      &lt;td&gt;필요 없음&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Bayesian Models&lt;/td&gt;
      &lt;td&gt;변수 및 변수 자체의 통계적 관계는 청중들이 직접 이해할 수 있어야 함&lt;/td&gt;
      &lt;td&gt;통계적 관계가 너무 많이 포함되어 있어서, 분해를 해야 분석이 용이함&lt;/td&gt;
      &lt;td&gt;통계적 관계는 이미 분해되어도 해석할 수 없는 수준이고 복잡한 수학적 도구를 사용해야 모델을 분석할 수 있음&lt;/td&gt;
      &lt;td&gt;필요 없음&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Tree Ensembles&lt;/td&gt;
      &lt;td&gt;✗&lt;/td&gt;
      &lt;td&gt;✗&lt;/td&gt;
      &lt;td&gt;✗&lt;/td&gt;
      &lt;td&gt;필요: 모델 단순화 혹은 피처 연관 설명&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Support Vector Machines&lt;/td&gt;
      &lt;td&gt;✗&lt;/td&gt;
      &lt;td&gt;✗&lt;/td&gt;
      &lt;td&gt;✗&lt;/td&gt;
      &lt;td&gt;필요: 모델 단순화 혹은 부분 설명&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Multi–layer Neural Network&lt;/td&gt;
      &lt;td&gt;✗&lt;/td&gt;
      &lt;td&gt;✗&lt;/td&gt;
      &lt;td&gt;✗&lt;/td&gt;
      &lt;td&gt;필요: 모델 단순화, 피처 연관 설명 혹은 시각화 설명&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Convolutional Neural Network&lt;/td&gt;
      &lt;td&gt;✗&lt;/td&gt;
      &lt;td&gt;✗&lt;/td&gt;
      &lt;td&gt;✗&lt;/td&gt;
      &lt;td&gt;필요: 모델 단순화, 피처 연관 설명 혹은 시각화 설명&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Recurrent Neural Network&lt;/td&gt;
      &lt;td&gt;✗&lt;/td&gt;
      &lt;td&gt;✗&lt;/td&gt;
      &lt;td&gt;✗&lt;/td&gt;
      &lt;td&gt;필요: 피처 연관 설명&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;표 2&lt;/code&gt; 설명가능성 수준에 따른 ML 모델의 분류에 대한 전체적인 그림.&lt;/p&gt;
</description>
        <pubDate>Thu, 14 Jan 2021 11:38:38 +0900</pubDate>
        <link>https://simonjisu.github.io/paper/2021/01/14/xaitutorial2.html</link>
        <guid isPermaLink="true">https://simonjisu.github.io/paper/2021/01/14/xaitutorial2.html</guid>
        
        
        <category>paper</category>
        
      </item>
    
      <item>
        <title>[XAI] Explainable Artificial Intelligence (XAI) - 1 </title>
        <description>&lt;h1 id=&quot;explainable-artificial-intelligence-xai-concepts-taxonomies-opportunities-and-challenges-toward-responsible-ai&quot;&gt;Explainable Artificial Intelligence (XAI): Concepts, taxonomies, opportunities and challenges toward responsible AI&lt;/h1&gt;

&lt;p&gt;Paper Link: &lt;a href=&quot;https://arxiv.org/abs/1910.10045&quot;&gt;https://arxiv.org/abs/1910.10045&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;XAI에 대한 전반적인 소개를 정리한 논문이 나와서 차근 차근 요약 정리해보려고 한다(무려 115페이지, reference만 6페이지). 약간의 번역 어투와 생략된 것도 있으니 영어 원문을 참고하길 바란다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://simonjisu.github.io/paper/2020/12/31/xaitutorial1.html&quot;&gt;&lt;span style=&quot;color:#e25252&quot;&gt;Introduction(이번편)&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://simonjisu.github.io/paper/2021/01/14/xaitutorial2.html&quot;&gt;Explainability: What, why, what for and how?&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://simonjisu.github.io/paper/2021/01/23/xaitutorial3.html&quot;&gt;Transparent machine learning models&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Post-hoc explainability techniques for machile learning models: Taxonomy, shallow models and deep learning&lt;/li&gt;
  &lt;li&gt;XAI: Opportunities, challenges and future research needs&lt;/li&gt;
  &lt;li&gt;Toward responsible AI: Principles of artificial intelligence, fairness, privacy and data fusion&lt;/li&gt;
  &lt;li&gt;Conclusions and outlook&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;1-introduction&quot;&gt;1. Introduction&lt;/h1&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;Artificial Intelligence (AI) lies at the core of many activity sectors that have embraced new information technologies [1]. While the roots of AI trace back to several decades ago, there is a clear consensus on the paramount importance featured nowadays by intelligent machines endowed with learning, reasoning and adaptation capabilities. It is by virtue of these capabilities that AI methods are achieving unprecedented levels of performance when learning to solve increasingly complex computational tasks, making them pivotal for the future development of the human society [2]. The sophistication of AI-powered systems has lately increased to such an extent that almost no human intervention is required for their design and deployment. When decisions derived from such systems ultimately affect humans’ lives (as in e.g. medicine, law or defense), there is an emerging need for understanding how such decisions are furnished by AI methods [3].&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; 인공지능이 정교해지면서 계산이 점점 복잡해지는 반면, 궁극적으로 인간의 삶에 영향을 미치는(의학, 법률, 국방) 시스템(기계)의 결정이 어떻게 내려졌는지, 우리는 이해할 필요가 있다.&lt;/p&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;While the very first AI systems were easily interpretable, the last years have witnessed the rise of opaque decision systems such as Deep Neural Networks (DNNs). The empirical success of Deep Learning (DL) models such as DNNs stems from a combination of efficient learning algorithms and their huge parametric space. The latter space comprises hundreds of layers and millions of parameters, which makes DNNs be considered as complex black-box models [4]. The opposite of black-box-ness is transparency, i.e., the search for a direct understanding of the mechanism by which a model works [5].&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; 딥러닝 모델은 효율적인 학습 알고리즘과 거대한 파라미터 공간의 결합에서 비롯된다. 그리고 black-box 모델로 간주 된다. 이의 반대는 &lt;strong&gt;투명성(transparency)&lt;/strong&gt;이다.&lt;/p&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;As black-box Machine Learning (ML) models are increasingly being employed to make important predictions in critical contexts, the demand for transparency is increasing from the various stakeholders in AI [6]. The danger is on creating and using decisions that are not justifiable, legitimate, or that simply do not allow obtaining detailed explanations of their behaviour [7]. Explanations supporting the output of a model are crucial, e.g., in precision medicine, where experts require far more information from the model than a simple binary prediction for supporting their diagnosis [8]. Other examples include autonomous vehicles in transportation, security, and finance, among others.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; Machine Learning 모델이 점점 많이 활용되면서, 이해관계자들로부터 투명성의 요구가 높아지고 있다. 예를 들어, 의료(진단), 교통(자율주행), 보안, 금융등 이 있다.&lt;/p&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;In general, humans are reticent to adopt techniques that are not directly interpretable, tractable and trustworthy [9], given the increasing demand for ethical AI [3]. It is customary to think that by focusing solely on performance, the systems will be increasingly opaque. This is true in the sense that there is a trade-off between the performance of a model and its transparency [10]. However, an improvement in the understanding of a system can lead to the correction of its deficiencies. When developing a ML model, the consideration of interpretability as an additional design driver can improve its implementability for 3 reasons:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Interpretability helps ensure impartiality in decision-making, i.e. to detect, and consequently, correct from bias in the training dataset.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Interpretability facilitates the provision of robustness by highlighting potential adversarial perturbations that could change the prediction.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Interpretability can act as an insurance that only meaningful variables infer the output, i.e., guaranteeing that an underlying truthful causality exists in the model reasoning.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;All these means that the interpretation of the system should, in order to be considered practical, provide either an understanding of the model mechanisms and predictions, a visualization of the model’s discrimination rules, or hints on what could perturb the model [11].&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; 통상적으로 성과에만 치중할 수록 시스템은 점점 불투명해질 것이라 생각한다. 모델의 성능과 투명성 사이에 trade-off가 있다는 점은 사실이나, 모델에 대한 이해는 모델의 성능 향상을 이끌어 낼 수도 있다. 추가로 ML모델을 개발할 때, 해석 가능성을 모듈로 넣으면 세 가지 이유로 구현 가능성을 향상 시킬 수 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;해석가능성은 의사결정에서 공정성을 보장하는데 도움이 된다. 즉, 교육 데이터 집합의 편향성을 탐지하고 결과적으로 수정한다.&lt;/li&gt;
  &lt;li&gt;해석가능성은 예측을 바꿀 수 있는 잠재적 적대적 섭동을 강조함으로써 건전성의 제공을 촉진한다.&lt;/li&gt;
  &lt;li&gt;해석가능성은 유의미한 변수만으로 산출물을 유추하는 보험으로서, 즉 모형 추론에서 근본적인 진실적 인과관계가 존재함을 보증하는 보험으로 작용할 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;즉, 해석가능한 시스템은 모델 매커니즘과 예측에 대한 이해, 모델의 판결 규칙 시각화, 또는 모델을 방해하는 것에 대한 힌트 등을 제공해야한다.&lt;/p&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;In order to avoid limiting the effectiveness of the current generation of AI systems, eXplainable AI (XAI) [7] proposes creating a suite of ML techniques that 1) produce more explainable models while maintaining a high level of learning performance (e.g., prediction accuracy), and 2) enable humans to understand, appropriately trust, and effectively manage the emerging generation of artificially intelligent partners. XAI draws as well insights from the Social Sciences [12] and considers the psychology of explanation.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; 현재의 효과적인 AI 시스템을 제한시키지 않는 선에서, eXplainable AI(XAI)은 1) 학습 퍼포먼스는 최대한으로 유지하면서 설명가능한 모델을 만들것을 제안 2) 사람이 이해하고, 적절하고 효과적으로 신뢰할 수 있도록 한다.&lt;/p&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;Fig. 1 displays the rising trend of contributions on XAI and related concepts. This literature outbreak shares its rationale with the research agendas of national governments and agencies. Although some recent surveys [8], [10], [13], [14], [15], [16], [17] summarize the upsurge of activity in XAI across sectors and disciplines, this overview aims to cover the creation of a complete unified framework of categories and concepts that allow for scrutiny and understanding of the field of XAI methods. Furthermore, we pose intriguing thoughts around the explainability of AI models in data fusion contexts with regards to data privacy and model confidentiality. This, along with other research opportunities and challenges identified throughout our study, serve as the pull factor toward Responsible Artificial Intelligence, term by which we refer to a series of AI principles to be necessarily met when deploying AI in real applications. As we will later show in detail, model explainability is among the most crucial aspects to be ensured within this methodological framework. All in all, the novel contributions of this overview can be summarized as follows:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Grounded on a first elaboration of concepts and terms used in XAI-related research, we propose a novel definition of explainability that places audience (Fig. 2) as a key aspect to be considered when explaining a ML model. We also elaborate on the diverse purposes sought when using XAI techniques, from trustworthiness to privacy awareness, which round up the claimed importance of purpose and targeted audience in model explainability.&lt;/li&gt;
  &lt;li&gt;We define and examine the different levels of transparency that a ML model can feature by itself, as well as the diverse approaches to post-hoc explainability, namely, the explanation of ML models that are not transparent by design.&lt;/li&gt;
  &lt;li&gt;We thoroughly analyze the literature on XAI and related concepts published to date, covering approximately 400 contributions arranged into two different taxonomies. The first taxonomy addresses the explainability of ML models using the previously made distinction between transparency and post-hoc explainability, including models that are transparent by themselves, Deep and non-Deep (i.e., shallow) learning models. The second taxonomy deals with XAI methods suited for the explanation of Deep Learning models, using classification criteria closely linked to this family of ML methods (e.g. layerwise explanations, representation vectors, attention).&lt;/li&gt;
  &lt;li&gt;We enumerate a series of challenges of XAI that still remain insufficiently addressed to date. Specifically, we identify research needs around the concepts and metrics to evaluate the explainability of ML models, and outline research directions toward making Deep Learning models more understandable. We further augment the scope of our prospects toward the implications of XAI techniques in regards to confidentiality, robustness in adversarial settings, data diversity, and other areas intersecting with explainability.&lt;/li&gt;
  &lt;li&gt;After the previous prospective discussion, we arrive at the concept of Responsible Artificial Intelligence, a manifold concept that imposes the systematic adoption of several AI principles for AI models to be of practical use. In addition to explainability, the guidelines behind Responsible AI establish that fairness, accountability and privacy should also be considered when implementing AI models in real environments.&lt;/li&gt;
  &lt;li&gt;Since Responsible AI blends together model explainability and privacy/security by design, we call for a profound reflection around the benefits and risks of XAI techniques in scenarios dealing with sensitive information and/or confidential ML models. As we will later show, the regulatory push toward data privacy, quality, integrity and governance demands more efforts to assess the role of XAI in this arena. In this regard, we provide an insight on the implications of XAI in terms of privacy and security under different data fusion paradigms.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=119QnRBvYV4gHiuKz7kpaOVo_2b2tlhz5&quot; alt=&quot;Fig 1. 학계에서 XAI 및 연관된 개념의 기여도 추세&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Fig 1. 학계에서 XAI 및 연관된 개념의 기여도 추세&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Fig 1&lt;/code&gt;에서 볼 수 있듯이 국가 정부 및 기관의 연구의제의 키워드 추세를 살펴보면 XAI관련 활동이 최근 급증했지만, 통일된 프레임워크가 없다. 이번 논문에서는 통일된 프레임워크의 작성하고, 개인정보 보호 및 모델 기밀성에 대해서 의견을 제시할 것이다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;지금까지 XAI 관련 연구에서 사용된 개념과 용어의 기초하여, ML 모델을 설명할 때 청중(audience)을 핵심으로 고려할 것이다(그림 2). 또한 XAI 기법을 사용할 때 추구하는 다양한 목적에 따라 세분화할 것이다. 그리고 설명가능성에서 목적과 타겟 청중의 중요함을 이야기 한다.&lt;/li&gt;
  &lt;li&gt;다양한 레벨의 투명성을 정의하고 검토한다. 대상에는 사후(post-hoc) 설명이 가능한, 자체 설명가능한 혹은 설계에 의해 설명이 불가능한 모델들 등이 있다.&lt;/li&gt;
  &lt;li&gt;XAI에 관한 문헌과 지금까지 출판된 관련 개념들을 철저하게 분석하여, 대략 400개의 기여를 두 개의 다른 분류법으로 배열하였다. 첫 번째 분류법은 이전에 만든 투명성(transparency)과 사후 설명성(post-hoc explainability) 사이의 구별을 사용하여 ML 모델의 설명가능성을 다루고 있으며, 여기에는 스스로 투명하고 깊지 않은(즉, shallow 얉은) 학습 모델이 포함된다. 두 번째 분류법은 딥러닝 모델의 설명에 적합한 XAI 방법을 다루며, 이 ML 방법 계열과 밀접하게 연계된 분류 기준(예: 계층적 설명 layer-wise explanations, 표현 벡터 representation vectors, 어텐션 attention)을 사용한다.&lt;/li&gt;
  &lt;li&gt;지금까지도 불충분하게 다루어지지 않고 있는 XAI의 일련의 과제를 열거한다. 구체적으로는 ML 모델의 설명 가능성을 평가하기 위해 개념 및 메트릭스를 중심으로 연구 요구를 파악하고, 딥러닝 모델을 보다 이해할 수 있도록 연구 방향을 정리한다. 기밀성, 적대적 설정의 견고성, 데이터 다양성 및 설명 가능성과 교차하는 기타 영역에 관한 XAI 기법의 함축성을 향한 전망의 범위를 더욱 확대합니다.&lt;/li&gt;
  &lt;li&gt;앞서의 장래의 논의를 거쳐, AI 모델이 실용화하기 위해 여러 가지 AI 원리를 체계적으로 채택하는 매니폴드 개념인 책임감 있는 인공지능의 개념에 도달한다. 책임 AI를 뒷받침하는 가이드라인은 설명가능성 외에도 실제 환경에서 AI 모델을 구현할 때 공정성, 책임성, 프라이버시 등도 고려해야 한다고 규정하고 있다.&lt;/li&gt;
  &lt;li&gt;책임 있는 AI는 모델 설명 가능성과 개인 정보 보호/보안성을 설계별로 혼합하므로, 민감한 정보 및/또는 기밀 ML 모델을 다루는 시나리오에서 XAI 기법의 유익성과 위해성에 대해 심오한 반성을 요구한다. 나중에 보여드리겠지만, 데이터 개인 정보 보호, 품질, 무결성 및 거버넌스를 향한 규제는 이 분야에서 XAI의 역할을 평가하기 위한 더 많은 노력을 요구합니다. 이와 관련하여, 우리는 서로 다른 데이터 융합 패러다임 하에서의 프라이버시 및 보안 측면에서 XAI의 의미에 대한 통찰력을 제공한다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;[expand]summary:영어원문 👈&lt;/p&gt;

&lt;p&gt;The remainder of this overview is structured as follows: first, Section 2 and subsections therein open a discussion on the terminology and concepts revolving around explainability and interpretability in AI, ending up with the aforementioned novel definition of interpretability (Section 2.1 and 2.2), and a general criterion to categorize and analyze ML models from the XAI perspective. Sections 3 and 4 proceed by reviewing recent findings on XAI for ML models (on transparent models and post-hoc techniques respectively) that comprise the main division in the aforementioned taxonomy. We also include a review on hybrid approaches among the two, to attain XAI. Benefits and caveats of the synergies among the families of methods are discussed in Section 5, where we present a prospect of general challenges and some consequences to be cautious about. Finally, Section 6 elaborates on the concept of Responsible Artificial Intelligence. Section 7 concludes the survey with an outlook aimed at engaging the community around this vibrant research area, which has the potential to impact society, in particular those sectors that have progressively embraced ML as a core technology of their activity.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;&lt;span style=&quot;color:#e25252&quot;&gt;요약:&lt;/span&gt; 나머지 부분은 다음과 같이 구성되어 있다:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Section 2: 설명가능성(explainability)와 해석가능성(interpretability)의 새로운 정의, XAI 관점에서 ML 모델 분류 및 분석을 위한 용어 및 개념에 대한 이야기&lt;/li&gt;
  &lt;li&gt;Section 3, 4: 최근 연구 결과와 하이브리드 방법&lt;/li&gt;
  &lt;li&gt;Section 5: 해당 방법들에 대한 장단점 및 주의해야할 몇 가지 결과들 제시&lt;/li&gt;
  &lt;li&gt;Section 6: “책임감 있는 인공지능” 개념에 대한 설명&lt;/li&gt;
  &lt;li&gt;Section 7: 사회에 영향을 미칠 가능성이 있는 연구 영역인 만큼, ML 기술을 채택한 사람들을 커뮤니티를 참여시키는 목표로 결론을 내리고자 한다.&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Thu, 31 Dec 2020 11:38:38 +0900</pubDate>
        <link>https://simonjisu.github.io/paper/2020/12/31/xaitutorial1.html</link>
        <guid isPermaLink="true">https://simonjisu.github.io/paper/2020/12/31/xaitutorial1.html</guid>
        
        
        <category>paper</category>
        
      </item>
    
  </channel>
</rss>
