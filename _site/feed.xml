<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Soo</title>
    <description>My Blog
</description>
    <link>http://simonjisu.github.io/</link>
    <atom:link href="http://simonjisu.github.io/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Mon, 19 Mar 2018 20:34:10 +0900</pubDate>
    <lastBuildDate>Mon, 19 Mar 2018 20:34:10 +0900</lastBuildDate>
    <generator>Jekyll v3.2.1</generator>
    
      <item>
        <title>RNN &amp; LSTM - 2: Numpy with RNN</title>
        <description>&lt;h1 id=&quot;rnn--lstm----2&quot;&gt;자세하게 설명한 RNN 과 LSTM 시리즈 - 2&lt;/h1&gt;

&lt;h2 id=&quot;numpy--rnn-&quot;&gt;Numpy 로 RNN 만들어보기&lt;/h2&gt;
&lt;p&gt;모든 코드는 Github: &lt;a href=&quot;https://github.com/simonjisu/NUMPYwithNN&quot;&gt;&lt;span style=&quot;color: #7d7ee8&quot;&gt;NUMPYwithNN&lt;/span&gt;&lt;/a&gt; 에 올려져 있습니다.&lt;/p&gt;

&lt;p&gt;Jupyter Notebook 으로 전체과정 보기: &lt;a href=&quot;https://nbviewer.jupyter.org/github/simonjisu/NUMPYwithNN/blob/master/Notebook/Character_Predicting_RNN.ipynb&quot;&gt;&lt;span style=&quot;color: #7d7ee8&quot;&gt;링크 &lt;/span&gt;&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;rnn-forward--backward--&quot;&gt;RNN Forward 와 Backward의 계산 그래프&lt;/h2&gt;

&lt;ul id=&quot;light-slider1&quot;&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/graph_forward0.png&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/graph_forward1.png&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/graph_forward2.png&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;ul id=&quot;light-slider1&quot;&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/graph_backward0.png&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/graph_backward1.png&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/graph_backward2.png&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/graph_backward3.png&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/graph_backward4.png&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/graph_backward5.png&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;backward에서 잊지 말아야 할 부분은 $t=T$일 때(마지막 Step일 때) $d h_T$는 0으로 초기화 되며, 구해진 $d h_{t-1}^{raw}$ 가 이 다음 역전파로 들어가기 전에 이전 단계로 부터 얻은 $dh_{t-1}$ 와 더해져 계산한다는 점이다. 그 이유는 forward 시 다음 step으로 hidden 값($h_t$)을 전파하기 때문이라는 것을 잊지 말자.&lt;/p&gt;

&lt;p&gt;위 그림은 &lt;a href=&quot;https://ratsgo.github.io/natural%20language%20processing/2017/03/09/rnnlstm/&quot;&gt;&lt;span style=&quot;color: #7d7ee8&quot;&gt;ratsgo’s blog&lt;/span&gt;&lt;/a&gt; 님의 포스트에서 많은 참조를 하고 새로 만들었음을 밝힙니다.&lt;/p&gt;

&lt;h3 id=&quot;bptt--&quot;&gt;참고) BPTT 수식적 이해&lt;/h3&gt;
&lt;p&gt;$tanh$의 미분을 $f(x) = 1 - tanh^2(x)$ 라고 하면,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
dh_{0} = \dfrac{\partial L}{\partial h_{0}}
&amp;= \dfrac{\partial L}{\partial y_t} \dfrac{\partial y_t}{\partial h_0} + \dfrac{\partial L}{\partial y_{t-1}} \dfrac{\partial y_{t-1}}{\partial h_0} \cdots + \dfrac{\partial L}{\partial y_1} \dfrac{\partial y_1}{\partial h_0}\\
&amp;= \dfrac{\partial L}{\partial y_t} \dfrac{\partial y_t}{\partial h_t} \dfrac{\partial h_t}{\partial a_t} \dfrac{\partial a_t}{\partial h_{t-1}} \cdots \dfrac{\partial a_1}{\partial h_{0}} + \cdots +
\dfrac{\partial L}{\partial y_1} \dfrac{\partial y_1}{\partial h_1} \dfrac{\partial h_1}{\partial a_1} \dfrac{\partial a_1}{\partial h_0} \\
&amp;= W_{hy} dy_t W_{hh} f(a_t) W_{hh} f(a_{t-1}) \cdots W_{hh} f(a_1) + \cdots + W_{hy} dy_2 W_{hh} f(a_2) W_{hh} f(a_1) + W_{hy} dy_1 W_{hh} f(a_1) \\
&amp;= \sum_{i=1}^{t} \Big( dy_i W_{hy} {(W_{hh})}^{i} \prod_{j=1}^{i} f(a_j) \Big)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;위 식을 위에 있는 그림대로 그려보자, 뒤에 $W_{hh} f(a_1)$ 부처 차근차근 묶어서 아래의 식을 얻을 수 있다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\dfrac{\partial L}{\partial h_{0}}
&amp;= W_{hh} f(a_1) \bigg( W_{hy} dy_t  W_{hh} f(a_t) W_{hh} f(a_{t-1}) \cdots W_{hh} f(a_2) + \cdots + W_{hy} dy_2 W_{hh} f(a_2) + W_{hy} dy_1 \bigg) \\
&amp;= W_{hh} f(a_1) \bigg( W_{hh} f(a_2) \Big( W_{hy} dy_t W_{hh} f(a_t) W_{hh} f(a_{t-1}) \cdots W_{hh} f(a_3) + \cdots + W_{hy} dy_2 \Big) + W_{hy} dy_1 \bigg) \\
&amp;= W_{hh} f(a_1) \bigg( W_{hh} f(a_2) \Big( \cdots W_{hh} f(a_{t-1}) \big( \underbrace{W_{hh} f(a_t) (\underbrace{ W_{hy} dy_t }_{dh_t^{raw}} + 0)}_{dh_{t-1}} + \underbrace{ W_{hy} dy_{t-1} }_{dh_{t-1}^{raw}} \big) \cdots + W_{hy} dy_2 \Big) + W_{hy} dy_1 \bigg) \\
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;위에 그림과 비교해보면 이런 식으로 계속 더해진다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;backpropagation-through-time-bptt-&quot;&gt;BackPropagation Through Time (BPTT) 구현&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Single_Layer_RNN&lt;/strong&gt; 의 코드는 &lt;a href=&quot;https://github.com/simonjisu/NUMPYwithNN/blob/master/common/SimpleRNN.py&quot;&gt;&lt;span style=&quot;color: #7d7ee8&quot;&gt;여기&lt;/span&gt;&lt;/a&gt;에 있습니다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Layer&lt;/strong&gt; 의 구현을 참고하려면 Github의 &lt;a href=&quot;https://github.com/simonjisu/NUMPYwithNN/blob/master/common/layers.py&quot;&gt;&lt;span style=&quot;color: #7d7ee8&quot;&gt;common/layers&lt;/span&gt;&lt;/a&gt; 참고하세요!&lt;/li&gt;
  &lt;li&gt;처음 Layer를 짜보시는 분은 &lt;a href=&quot;https://simonjisu.github.io/deeplearning/2017/12/07/numpywithnn_1.html&quot;&gt;&lt;span style=&quot;color: #7d7ee8&quot;&gt;Numpy로 짜보는 Neural Network Basic&lt;/span&gt;&lt;/a&gt; 시리즈를 참고하세요!&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;우선 미분한 값의 합을 구하기 위해 각각 Layer의 파라미터와같은 형태(shape)로 만들어 준다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def _params_summation_init(self):
    self.params_summ = {}
    self.params_summ['W_xh'] = np.zeros_like(self.params['W_xh'])
    self.params_summ['W_hh'] = np.zeros_like(self.params['W_hh'])
    self.params_summ['W_hy'] = np.zeros_like(self.params['W_hy'])
    self.params_summ['b_h'] = np.zeros_like(self.params['b_h'])
    self.params_summ['b_y'] = np.zeros_like(self.params['b_y'])
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;또한, $dh_T$ 를 0으로 초기화 한다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;dht = np.zeros_like(self.h0)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;그후에 총 길이 $T$의 역순으로 각 Layer 의 Back Propagation 을 진행한다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;for t in np.arange(self.T)[::-1]:
    dout = self.last_layers[t].backward()
    dht_raw = self.layers['Affine_hy'][t].backward(dout)
    dat = self.layers['Activation'][t].backward(dht_raw + dht)
    dht = self.layers['Affine_hh'][t].backward(dat)
    dx = self.layers['Affine_xh'][t].backward(dat)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;또한, 파라미터 $W$ 와 $b$ 의 합도 같이 구해준다. 그 이유는 전편에서 설명되어 있지만, 다시 한번 이야기 하자면, 최종 Loss Function은 각 Output Loss의 평균이기 때문에, 각 Output 마다 파라미터들을 summation 하는 과정이 있다. (평균을 구할때 우선 summation을 한다는 것을 잊지 말자.)&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;self.params_summ['W_xh'] += self.layers['Affine_xh'][t].dW
self.params_summ['W_hh'] += self.layers['Affine_hh'][t].dW
self.params_summ['W_hy'] += self.layers['Affine_hy'][t].dW
self.params_summ['b_h'] += self.layers['Affine_hh'][t].db
self.params_summ['b_y'] += self.layers['Affine_hy'][t].db
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;전체 Backward 과정&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def backward(self):
    # BPTT
    self._params_summation_init()
    dht = np.zeros_like(self.h0)

    for t in np.arange(self.T)[::-1]:
        dout = self.last_layers[t].backward()
        dht_raw = self.layers['Affine_hy'][t].backward(dout)
        dat = self.layers['Activation'][t].backward(dht_raw + dht)
        dht = self.layers['Affine_hh'][t].backward(dat)
        dx = self.layers['Affine_xh'][t].backward(dat)

        self.params_summ['W_xh'] += self.layers['Affine_xh'][t].dW
        self.params_summ['W_hh'] += self.layers['Affine_hh'][t].dW
        self.params_summ['W_hy'] += self.layers['Affine_hy'][t].dW
        self.params_summ['b_h'] += self.layers['Affine_hh'][t].db
        self.params_summ['b_y'] += self.layers['Affine_hy'][t].db
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;truncate-backpropagation-through-time-t-bptt&quot;&gt;Truncate BackPropagation Through Time (T-BPTT)&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Truncate BackPropagation Through Time (T-BPTT)&lt;/strong&gt; 은 기존 BPTT 에서 과거 모든 미분값을 참조하는 대신 고정된 길이로 참조 할 수 있도록 만든 알고리즘이다.&lt;/p&gt;

&lt;p&gt;왜 이런것을 만들었을 까? BPTT 알고리즘의 미분식을 다시 생각해보자.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
dh_{0} = \dfrac{\partial L}{\partial h_{0}}
&amp;= \sum_{i=1}^{t} \Big( dy_i W_{hy} {(W_{hh})}^{i} \prod_{j=1}^{i} f(a_j) \Big)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;위에서 설명했지만, BPTT 과정에서 Time-step이 길어질 수록, 많은 양의 곱셈이 이루어 진다. 계산량을 줄이기 위해서 이런 알고리즘이 나왔을 수 있다.&lt;/p&gt;

&lt;p&gt;다른 접근 방법으로, 학습하고 싶은 Sequence의 일정 길이만큼만 과거를 참조하고 싶기 때문일 수도 있다.&lt;/p&gt;

&lt;p&gt;예를 들어 “I live in Seoul. (중략) I am Korean.” 이라는 문장을 생각해보자. 학습 데이터는 아래와 같을 것이다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[&quot;I&quot;, &quot;live&quot;, &quot;in&quot;, &quot;Seoul&quot;, &quot;.&quot;, (중략), &quot;I&quot;, &quot;am&quot;, &quot;Korean&quot;, &quot;.&quot;]
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Forward 할때는 순차적으로 들어갈텐데, Backward 할때는 데이터의 역순으로(“.”, “Korean”) 진행될 것이다. 그러나 내가 한국인이라는 것은 내가 서울에 살고 있기 때문인데, 굳이 앞단의 “I”, “live”, “in” 까지 참조할 필요는 없는 것이다. 그렇다면 위에 식은 아래와 같이 변할 것이다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
dh_{0} = \dfrac{\partial L}{\partial h_{0}}
&amp;= \sum_{i=1}^{t} \Big( dy_i W_{hy} {(W_{hh})}^{k} \prod_{j=k}^{t} f(a_j) \Big) \\
where \quad k &amp;= \max(1, t - truncate)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;h3 id=&quot;t-bptt-&quot;&gt;T-BPTT 구현&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/assets/ML/rnn/normal_truncate.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그림 출처: &lt;a href=&quot;https://r2rt.com/styles-of-truncated-backpropagation.html&quot;&gt;&lt;span style=&quot;color: #7d7ee8&quot;&gt;r2rt.com&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def backward_truncate(self):
    # TBPTT
    self._params_summation_init()
    dht = np.zeros_like(self.h0)

    for t in np.arange(self.T)[::-1]:
        dout = self.last_layers[t].backward()
        dht_raw = self.layers['Affine_hy'][t].backward(dout)
        self.params_summ['W_hy'] += self.layers['Affine_hy'][t].dW
        self.params_summ['b_y'] += self.layers['Affine_hy'][t].db

        for bptt_step in np.arange(max(0, t + 1 - self.bptt_truncate), t + 1)[::-1]:
            dat = self.layers['Activation'][bptt_step].backward(dht_raw + dht)
            dht = self.layers['Affine_hh'][bptt_step].backward(dat)  # dh_t-1
            dx = self.layers['Affine_xh'][bptt_step].backward(dat)  # dx
            self.params_summ['W_xh'] += self.layers['Affine_xh'][bptt_step].dW
            self.params_summ['W_hh'] += self.layers['Affine_hh'][bptt_step].dW
            self.params_summ['b_h'] += self.layers['Affine_hh'][bptt_step].db
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;그러나 Tensorflow 에서는 아래와 같이 구현한다고 한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/rnn/tensorflow_truncate.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그림 출처: &lt;a href=&quot;https://r2rt.com/styles-of-truncated-backpropagation.html&quot;&gt;&lt;span style=&quot;color: #7d7ee8&quot;&gt;r2rt.com&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;실습&lt;/h2&gt;

&lt;h3 id=&quot;section-1&quot;&gt;목적&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;“hello world! nice to meet you! i love iron-man”&lt;/strong&gt; 을 RNN 으로 학습시키기.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Input&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt; &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Output&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;h&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;→&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;e&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;e&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;→&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;l&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;l&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;→&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;l&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;l&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;→&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;o&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;⋮&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;⋮&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;⋮&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;m&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;→&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;a&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;a&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;→&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;n&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;section-2&quot;&gt;데이터 및 우리가 만든 패키지 준비&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import numpy as np
from common.SimpleRNN import Single_layer_RNN
from common.optimizer import Adam
from common.train_graph import loss_graph
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;x = 'hello world! nice to meet you! i love iron-man'
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;인코딩 클래스 하나를 만들어서 문자열을 one-hot 인코딩 해준다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;class chr_coding(object):
    def __init__(self):
        self._dict = None
        self._one_hot_matrix = None
        self._dict_reversed = None

    def fit(self, x):
        if isinstance(x, str):
            x = list(x)

        self._one_hot_matrix = np.eye(len(set(x)))
        self._dict = {d: i for i, d in enumerate(list(set(x)))}
        self._dict_reversed = {v: k for k, v in self._dict.items()}

    def encode(self, x):
        encoded_data = np.array([self._one_hot_matrix[self._dict[d]] for d in x])
        return encoded_data

    def decode(self, x, probs=None):
        if probs is None:
            decoded_data = self._dict_reversed[x]
        else:
            decoded_data = self._dict_reversed[np.argmax(probs)]
        return decoded_data
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;encoder = chr_coding()
encoder.fit(x)
one_hot_data = encoder.encode(x)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;학습 데이터 x, y를 지정해준다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;train_x = one_hot_data[:-1]
train_y = one_hot_data[1:]
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;hyperparameters&quot;&gt;hyperparameters&lt;/h3&gt;

&lt;p&gt;INPUT_SIZE 와 OUTPUT_SIZE 는 중복되지 않는 문자열 사전의 길이라는 것을 잊지 말자.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;NUM_EPOCHS = 600
PRINT_EPOCH = 30
INPUT_SIZE = one_hot_data.shape[1]
OUTPUT_SIZE = one_hot_data.shape[1]
HIDDEN_SIZE = 20
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;accuracy--train-&quot;&gt;필요한 함수 설정: accuracy 와 train 함수&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def get_accuracy(x, test_string):
    bool_ = np.array(list(x))[1:] == np.array(list(test_string))[1:]
    return bool_.sum() / len(bool_)

def train(rnn, optim, print_epoch=20):
    total_loss_list = []
    total_acc_list = []
    for epoch in range(NUM_EPOCHS):
        test_string = 'h'
        # forward
        total_loss = rnn.loss(train_x, train_y)

        # backward
        rnn.backward()

        optim.update(rnn.params, rnn.params_summ)

        # test string
        predicted_idx = rnn.predict(train_x)
        for idx in predicted_idx:
            test_string += encoder.decode(idx)

        # get accuracy
        acc = get_accuracy(x, test_string)

        if epoch % print_epoch == 0:
            print('#{0}, Loss: {1:.6f}, Acc: {2:.6f}, Test_string: &quot;{3}&quot;'\
                  .format(epoch, total_loss, acc, test_string))
        elif epoch == (NUM_EPOCHS-1):
            print('#{0}, Loss: {1:.6f}, Acc: {2:.6f}, Test_string: &quot;{3}&quot;'\
                  .format(epoch, total_loss, acc, test_string))

        total_loss_list.append(total_loss)
        total_acc_list.append(acc)
    return total_loss_list, total_acc_list
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-3&quot;&gt;학습하기&lt;/h3&gt;

&lt;p&gt;rnn 모델을 만들고, 어떤 방식으로 업데이트 할 것인지 정하자. 여기서는 Adam을 썼다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Optimizer&lt;/strong&gt; 의 설명은 &lt;a href=&quot;https://github.com/simonjisu/NUMPYwithNN/blob/master/common/SimpleRNN.py&quot;&gt;&lt;span style=&quot;color: #7d7ee8&quot;&gt;Numpy로 짜보는 Neural Network Basic - 5&lt;/span&gt;&lt;/a&gt;에 있습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;rnn = Single_layer_RNN(input_size=INPUT_SIZE,
                       hidden_size=HIDDEN_SIZE,
                       output_size=OUTPUT_SIZE)
optim = Adam()
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;학습시키기!&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;total_loss_list, total_acc_list = train(rnn, optim, print_epoch=PRINT_EPOCH)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/assets/ML/rnn/rnn_bptt.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Loss Graph 도 찍어보자&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;loss_graph(train_loss_list=total_loss_list, train_acc_list=total_acc_list)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/rnn/rnn_bptt_loss.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-4&quot;&gt;공부에 도움 되었던 싸이트:&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://gist.github.com/karpathy/d4dee566867f8291f086&quot;&gt;&lt;span style=&quot;color: #7d7ee8&quot;&gt;karpathy github RNN part&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://ratsgo.github.io/natural%20language%20processing/2017/03/09/rnnlstm/&quot;&gt;&lt;span style=&quot;color: #7d7ee8&quot;&gt;ratsgo’s blog&lt;/span&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Wed, 14 Mar 2018 22:05:37 +0900</pubDate>
        <link>http://simonjisu.github.io/deeplearning/2018/03/14/rnnlstm2.html</link>
        <guid isPermaLink="true">http://simonjisu.github.io/deeplearning/2018/03/14/rnnlstm2.html</guid>
        
        
        <category>deeplearning</category>
        
      </item>
    
      <item>
        <title>RNN &amp; LSTM - 1: RNN</title>
        <description>&lt;h1 id=&quot;rnn--lstm----1&quot;&gt;자세하게 설명한 RNN 과 LSTM 시리즈 - 1&lt;/h1&gt;

&lt;h2 id=&quot;rnnrecurrent-neural-network&quot;&gt;RNN(Recurrent Neural Network)&lt;/h2&gt;
&lt;p&gt;우리가 사는 세상에 연속된 일들, 혹은 시간과 연관된 일은 매우매우 많을 것이다. 예를 들자면, 지금 이 글을 읽은 당신도 앞에 있는 내용을 기억하면서 글을 읽고 있을 것이다. 일반적인 신경망 구조에서는 이 ‘기억’ 이라는 시스템이 존재 하지 않는다. 하지만 RNN은 다르다. 이놈은 ‘기억’을 할 수가 있다. 그렇다면 RNN과 기존 신경망과 어떻게 다른지를 한번 살펴보자.&lt;/p&gt;

&lt;h2 id=&quot;rnn-&quot;&gt;RNN 구조&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;/assets/ML/rnn/rnn.png&quot; alt=&quot;Drawing&quot; style=&quot;width=500px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;RNN은 중간의 Hidden 층이 순환한다고해서 순환 신경망이라고 한다. 왼쪽의 구조를 펼쳐서 보면, 중간의 Hidden 노드가 어떤 방향으로 계속 이어진 다는 것을 알 수 있다. 이러한 쇠사슬 같은 성격은 RNN으로 하여금 연속된 이벤트와 리스트에 적합한 구조로 만들어 준다.&lt;/p&gt;

&lt;p&gt;이렇게 보면 엄청 어렵게 느껴질 수 있다. 그렇다면 예시를 들어서 RNN이 어떻게 돌아가는지 수학적으로 살펴보자.&lt;/p&gt;

&lt;h3 id=&quot;section&quot;&gt;기본 신경망 구조&lt;/h3&gt;

&lt;p&gt;기존의 신경 구조를 한번 다시 되새겨보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/rnn/stick.png&quot; alt=&quot;Drawing&quot; height=&quot;200&quot; width=&quot;200&quot; /&gt;&lt;/p&gt;

&lt;p&gt;여러개의 노드로 구성된 작은 블럭을 하나의 층이라고 가정하자. 기존의 신경망 구조는 아래와 같다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/rnn/basic_nn_mnist.png&quot; alt=&quot;Drawing&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Input $x$ 가 선형 결합 후, Hidden 에 Activation function을 거쳐 다시 선형결합을 통해 Output $y$를 구해 예측하는 알고리즘이다. 여기서 첫번째 데이터($x_1$)와 그 다음 데이터($x_2$ 등)간의 구조는 독립적이라고 할 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;forward&quot;&gt;Forward&lt;/h3&gt;
&lt;p&gt;예시로 time step($T$)이 3인 RNN을 살펴보자. (좌우 클릭으로 프로세스 과정 볼 수 있다)&lt;/p&gt;

&lt;ul id=&quot;light-slider1&quot;&gt;
    &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/rnn_0.png&quot; /&gt;&lt;/li&gt;
    &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/rnn_1.png&quot; /&gt;&lt;/li&gt;
    &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/rnn_2.png&quot; /&gt;&lt;/li&gt;
    &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/rnn_3.png&quot; /&gt;&lt;/li&gt;
    &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/rnn_4.png&quot; /&gt;&lt;/li&gt;
    &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/rnn_5.png&quot; /&gt;&lt;/li&gt;
    &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/rnn_6.png&quot; /&gt;&lt;/li&gt;
    &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/rnn_7.png&quot; /&gt;&lt;/li&gt;
    &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/rnn_8.png&quot; /&gt;&lt;/li&gt;
  &lt;/ul&gt;

&lt;p&gt;Time step = 0 일때, 각각 Layer들의 Weight를 초기화하게 된다. $h_0$ 층은 0으로, 나머지는 Xavier 가중치 초기값으로 초기화한다. 또한 각 가중치는 각각 layer에서 공유하게 된다.
(가중치 초기화를 잊어 버렸다면 &lt;a href=&quot;https://simonjisu.github.io/datascience/2018/01/24/numpywithnn_6.html&quot;&gt;&lt;span style=&quot;color: #7d7ee8&quot;&gt;여기&lt;/span&gt;&lt;/a&gt;로)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
h_t &amp;= \tanh(W_{hh} h_{t-1}+W_{xh}x_t+b_h) \\
y_t &amp;= W_{hy} h_t + b_y
\end{aligned}
\quad for\ t\ in\ T %]]&gt;&lt;/script&gt;

&lt;p&gt;그리고, 시간이 지날때마 위의 식 처럼 Forward가 진행된다.&lt;/p&gt;

&lt;p&gt;최종 Cost는 모든 Cost Function의 평균으로 구해진다.&lt;/p&gt;

&lt;h3 id=&quot;backward&quot;&gt;Backward&lt;/h3&gt;
&lt;p&gt;RNN에서는 일반적인 신경망과 다른 Backward 알고리즘을 쓴다. 시간 경과에 따른 BackPropagation을 BPTT(BackPropagation Through Time)이라고 부른다.&lt;/p&gt;

&lt;ul id=&quot;light-slider1&quot;&gt;
    &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/rnn_back0.png&quot; /&gt;&lt;/li&gt;
    &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/rnn_back1.png&quot; /&gt;&lt;/li&gt;
    &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/rnn_back2.png&quot; /&gt;&lt;/li&gt;
    &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/rnn_back3.png&quot; /&gt;&lt;/li&gt;
    &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/rnn_back4.png&quot; /&gt;&lt;/li&gt;
    &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/rnn_back5.png&quot; /&gt;&lt;/li&gt;
  &lt;/ul&gt;

&lt;p&gt;최종적으로 학습 될 값은 Loss Function에서 각 미분한 ${\frac{\partial L}{\partial W}}^{(1)}$, ${\frac{\partial L}{\partial W}}^{(2)}$, ${\frac{\partial L}{\partial W}}^{(3)}$ 의 합으로 구해진다.&lt;/p&gt;

&lt;h3 id=&quot;long-term-dependency-&quot;&gt;장기 의존성(Long-Term Dependency) 문제&lt;/h3&gt;
&lt;p&gt;RNN이 이론상으로는 sequence의 첫번째 항부터 끝까지(즉, $x_1 \cdots x_T$ 까지) 학습 할 수 있을 것으로 보이나, 실제로는 장기기억, 즉 Time Step이 길어 질 수록 예전에 있던 정보를 기억 못한다. 이를 &lt;strong&gt;장기 의존성(Long-Term Dependency)&lt;/strong&gt; 문제라고 한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/rnn/rnn_bad.png&quot; alt=&quot;Drawing&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그 이유는 우리가 업데이트 하려는 미분 식을 살펴보면 알 수 있다. 예를 들어 $W_{hh}$ 를 업데이트 한다고 하자.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\dfrac{\partial L}{\partial W_{hh}}  
&amp;= \dfrac{\partial L}{\partial Cost_T} \dfrac{\partial Cost_T}{\partial W_{hh}} + \cdots +
\dfrac{\partial L}{\partial Cost_1} \dfrac{\partial Cost_1}{\partial W_{hh}} \\
&amp;= \dfrac{\partial L}{\partial Cost_T} \dfrac{\partial Cost_T}{\partial y_T} \dfrac{\partial y_T}{\partial h_T} \dfrac{\partial h_T}{\partial h_{T-1}}  \cdots \dfrac{\partial h_2}{\partial h_1} \dfrac{\partial h_1}{\partial W_{hh}} +
\cdots + \dfrac{\partial L}{\partial Cost_1} \dfrac{\partial Cost_1}{\partial y_1} \dfrac{\partial y_1}{\partial h_1} \dfrac{\partial h_1}{\partial W_{hh}} \\
&amp;= \dfrac{\partial L}{\partial Cost_T} \dfrac{\partial Cost_T}{\partial y_T} \dfrac{\partial y_T}{\partial h_T} \prod_{i=1}^{T-1} \dfrac{\partial h_{T-i+1}}{\partial h_{T-i}} \dfrac{\partial h_1}{\partial W_{hh}} + \cdots + \dfrac{\partial L}{\partial Cost_1} \dfrac{\partial Cost_1}{\partial y_1} \dfrac{\partial y_1}{\partial h_1} \dfrac{\partial h_1}{\partial W_{hh}}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;위의 식중에 $\prod_{i=1}^{T-1} \dfrac{\partial h_{T-i+1}}{\partial h_{T-i}}$ 부분을 자세히 펼쳐보면 아래와 같다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\prod_{i=1}^{T-1} \dfrac{\partial h_{T-i+1}}{\partial h_{T-i}}
&amp;= \prod_{i=1}^{T-1} \dfrac{\partial h_{T-i+1}}{\partial a_{T-i+1}} \dfrac{\partial a_{T-i+1}}{\partial h_{T-i}} \\
&amp;= \prod_{i=1}^{T-1} \dfrac{\partial h_{T-i+1}}{\partial a_{T-i+1}} W_{hh}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;여기서 $a_t=W_{hh}h_{t-1} + W_{xh}x_t + b_h$ 이다.&lt;/p&gt;

&lt;p&gt;앞부분 $\frac{\partial h_{T-i+1}}{\partial a_{T-i+1}}$은 &lt;strong&gt;tanh&lt;/strong&gt; 의 미분 값이다. 아래 그림과 같이 tanh의 미분 값은 0과 1사이의 값이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/rnn/tanh.png&quot; style=&quot;width=500px&quot; /&gt;
(그림출처: http://nn.readthedocs.io/en/latest/transfer/)&lt;/p&gt;

&lt;p&gt;뒷부분인 $W_{hh}$의 값들은 세가지 경우가 있다. 1과 같게 되면 Gradient가 수렴될 가능성이 높다. 그러나 1보다 클 경우 gradient가 무한대로 발산하는 &lt;strong&gt;Exploding Gradient&lt;/strong&gt; 문제가 발생한다. 그러나 보통의 경우 $W_{hh}$ 의 값들은 1보다 작다. (아래 논문 참고)&lt;/p&gt;

&lt;p&gt;0과 1사이의 작은 값을 계속 곱하게 되면 0으로 수렴한다. 따라서, 두 가지를 종합 해보았을 때, 출력값과 멀리 떨어진 Time Step일 수록 역전파가 전달 되지 않는 &lt;strong&gt;Vanishing Gradient&lt;/strong&gt; 문제가 생기게 된다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://proceedings.mlr.press/v28/pascanu13.pdf&quot;&gt;&lt;span style=&quot;color: #7d7ee8&quot;&gt;On the difficulty of training recurrent neural networks&lt;/span&gt;&lt;/a&gt; 논문에서는 Vanishing &amp;amp; Exploding Gradient 문제를 자세히 다루고 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;장기기억을 하지 못한다는 문제가 생기면서, 이를 해결하기 위해서 몇 가지 방법이 나왔다. 첫째로, Activation Function을 &lt;strong&gt;tanh&lt;/strong&gt; 을 쓰면 기울기가 0과 1사이의 값으로 고정되니 &lt;strong&gt;ReLU&lt;/strong&gt; 를 쓰자는 방법이 있었다. 둘째로, &lt;strong&gt;LSTM&lt;/strong&gt;, &lt;strong&gt;GRU&lt;/strong&gt; 등 새로운 방법들이 등장했다. 이 방법은 다음 시간에 설명하겠다. 더불어 Backward 의 계산 그래프도 같이 첨부하겠다.&lt;/p&gt;
</description>
        <pubDate>Wed, 07 Mar 2018 10:46:04 +0900</pubDate>
        <link>http://simonjisu.github.io/deeplearning/2018/03/07/rnnlstm.html</link>
        <guid isPermaLink="true">http://simonjisu.github.io/deeplearning/2018/03/07/rnnlstm.html</guid>
        
        
        <category>DeepLearning</category>
        
      </item>
    
      <item>
        <title>NUMPY with NN - 8: Summary</title>
        <description>&lt;h1 id=&quot;numpy--neural-network-basic---8&quot;&gt;Numpy로 짜보는 Neural Network Basic - 8&lt;/h1&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;section&quot;&gt;총 정리&lt;/h2&gt;
&lt;p&gt;지금까지 우리는 Neural Network의 기원부터 Feedforward 과정, BackPropogation 과정, 그리고 다양한 학습 관련 기술을 배웠다. 이들을 총 정리해서 Mnist 데이터를 다시 학습 시켜보자.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/simonjisu/ML/tree/master/NeuralNetwork/common&quot;&gt;&lt;span style=&quot;color: #7d7ee8&quot;&gt; 모든 코드 링크&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;package-load&quot;&gt;Package Load&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from common.Multilayer import MLP
from dataset.mnist import load_mnist
from common.optimizer import *
import time
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;data-load&quot;&gt;Data Load&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;(x_train, y_train), (x_test, y_test) = load_mnist(normalize=True, one_hot_label=True)
print(x_train.shape)
print(y_train.shape)
print(x_test.shape)
print(y_test.shape)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;(60000, 784)&lt;br /&gt;(60000, 10)&lt;br /&gt;(10000, 784)&lt;br /&gt;(10000, 10)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;network--optimizer-settings&quot;&gt;Network &amp;amp; Optimizer settings&lt;/h3&gt;

&lt;p&gt;우리의 네트워크는 총 3층이며 Input Size가 784, Hidden node는 각각 100, 50개, Output 은 10(숫자 0~9까지의 손글씨 분류이기 때문)이다.&lt;/p&gt;

&lt;p&gt;활성화 함수는 &lt;strong&gt;ReLu&lt;/strong&gt;, 초기값도 이에 따라 &lt;strong&gt;He&lt;/strong&gt; 를 써준다. 그리고 중간에 Batch Normalization을 써준다.&lt;/p&gt;

&lt;p&gt;가중치 업데이트를 위한 옵티마이저는 &lt;strong&gt;Adam&lt;/strong&gt; 을 쓰고, Loss Function은 &lt;strong&gt;Cross Entropy&lt;/strong&gt; 를 쓰게 된다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;nn = MLP(input_size=784, hidden_size=[100, 50], output_size=10,
         activation='relu', weight_init_std='he', use_batchnorm=True)
optimizer = Adam()
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;training--test&quot;&gt;Training &amp;amp; test&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;train_loss_list = []
train_acc_list = []
test_acc_list = []
epoch_list = []

epoch_num=3000
train_size = x_train.shape[0]
batch_size = 100
epsilon = 1e-6

iter_per_epoch = max(train_size / batch_size, 1)

start = start = time.time()

for epoch in range(epoch_num):
    # get mini batch:
    batch_mask = np.random.choice(train_size, batch_size) # shuffle 효과
    x_batch = x_train[batch_mask]
    y_batch = y_train[batch_mask]

    grads = nn.gradient(x_batch, y_batch)

    optimizer.update(nn.params, grads)

    # 1에폭당 정확도 계산
    if epoch % iter_per_epoch == 0:
        loss = nn.loss(x_batch, y_batch)
        train_loss_list.append(loss)
        train_acc = nn.accuracy(x_train, y_train)
        train_acc_list.append(train_acc)
        test_acc = nn.accuracy(x_test, y_test)
        test_acc_list.append(test_acc)
        epoch_list.append(epoch)
        print('# {0} | loss: {1:.5f} | trian acc: {2:.5f} | test acc: {3:.5f}'.format(epoch, loss, train_acc, test_acc))
    elif epoch == (epoch_num - 1):
        loss = nn.loss(x_batch, y_batch)
        train_loss_list.append(loss)
        train_acc = nn.accuracy(x_train, y_train)
        train_acc_list.append(train_acc)
        test_acc = nn.accuracy(x_test, y_test)
        test_acc_list.append(test_acc)
        epoch_list.append(epoch)
        print('# {0} | loss: {1:.5f} | trian acc: {2:.5f} | test acc: {3:.5f}'.format(epoch, loss, train_acc, test_acc))

end = time.time()
print('total time:', (end - start))        
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;# 0 | loss: 11.06622 | trian acc: 0.11408 | test acc: 0.11910&lt;br /&gt;# 600 | loss: 0.23165 | trian acc: 0.92055 | test acc: 0.92020&lt;br /&gt;# 1200 | loss: 0.19112 | trian acc: 0.93975 | test acc: 0.94180&lt;br /&gt;# 1800 | loss: 0.08235 | trian acc: 0.95188 | test acc: 0.95040&lt;br /&gt;# 2400 | loss: 0.09155 | trian acc: 0.95898 | test acc: 0.95600&lt;br /&gt;# 2999 | loss: 0.09883 | trian acc: 0.96513 | test acc: 0.96150&lt;br /&gt;total time: 27.169809818267822&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/nn/train_test-graph.png&quot; alt=&quot;Drawing&quot; style=&quot;width=500px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;시간은 3000 Epoch를 도는데 약 30초가 안걸렸으며, 테스트 결과도 우수하게 나오는 것으로 확인된다. CNN으로 하면 더 높아질 것으로 예상된다.&lt;/p&gt;

&lt;h3 id=&quot;model-check&quot;&gt;Model Check&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def check(x, y, model):
    pred_y = model.predict(x)
    if x.ndim != 2:
        x = x.reshape(28, 28)

    print('Predict Answer: {}'.format(np.argmax(pred_y)))
    print('Real Answer: {}'.format(np.argmax(y)))
    plt.imshow(x, cmap='binary')
    plt.grid(False)
    plt.axis('off')
    plt.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;테스트 데이터중 하나 골라서 실험해보자&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;check(x_test[45], y_test[45], nn)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;Predict Answer: 5&lt;br /&gt;Real Answer: 5&lt;/p&gt;

  &lt;p&gt;&lt;img src=&quot;/assets/ML/nn/num5.png&quot; alt=&quot;Drawing&quot; height=&quot;100&quot; width=&quot;100&quot; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        <pubDate>Thu, 08 Feb 2018 15:13:40 +0900</pubDate>
        <link>http://simonjisu.github.io/deeplearning/2018/02/08/numpywithnn_8.html</link>
        <guid isPermaLink="true">http://simonjisu.github.io/deeplearning/2018/02/08/numpywithnn_8.html</guid>
        
        
        <category>DeepLearning</category>
        
      </item>
    
      <item>
        <title>NUMPY with NN - 7: Batch Normalization</title>
        <description>&lt;h1 id=&quot;numpy--neural-network-basic---7&quot;&gt;Numpy로 짜보는 Neural Network Basic - 7&lt;/h1&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;part-3&quot;&gt;학습관련 기술 Part 3&lt;/h2&gt;

&lt;h3 id=&quot;batch-normalization&quot;&gt;배치 정규화 (Batch Normalization)&lt;/h3&gt;
&lt;p&gt;배치 정규화란 미니배치 단위로 선형합인 &lt;strong&gt;$a$&lt;/strong&gt; 값을 정규화하는 것이다. 즉, 미니배치에 한해서 데이터 분포가 평균이 0 분산이 1이 되도록 한다. 이는 데이터 분포가 덜 치우치게 하는 효과가 있어서 가중치 초기화 값의 영향을 덜 받게한다. 또한, 학습속도를 증가시키고 regularizer 역할을 하여 Overfitting을 방지함으로 Dropout의 필요성을 줄인다. &lt;del&gt;자세한 내용은 논문을 참고하자!&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;Paper: &lt;a href=&quot;https://arxiv.org/abs/1502.03167&quot;&gt;&lt;span style=&quot;color: #7d7ee8&quot;&gt;Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;기본적인 아이디어는 아래와 같다. $D$ 차원의 미니배치 데이터 $x = (x^{(1)}, \cdots, x^{(k)}, \cdots, x^{(D)})$에 대해서 각각의 평균과 분산을 구한 후, 정규화를 통해 새로운 $x^{(k)}$ ($\hat{x}^{(k)}$) 를 구한 후에 Scaling($\gamma$) 과 Shifting($\beta$)을 거쳐 새로운 $y$ 를 기존의 선형합성 곱인 $a$ 를 대신해 활성화 함수에 넣는 것이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/nn/6/batch_norm_idea.png&quot; alt=&quot;Drawing&quot; style=&quot;width=500px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;따라서, 하나의 Hidden Layer 는 $Affine \rightarrow BatchNorm \rightarrow Activation$ 으로 구성된다.&lt;/p&gt;

&lt;h3 id=&quot;backpropogation-&quot;&gt;배치 정규화의 BackPropogation 이해하기&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/nn/NN_batchnorm.png&quot; alt=&quot;Drawing&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;forward&quot;&gt;Forward:&lt;/h4&gt;

&lt;p&gt;x 부터 out 까지 차근차근 진행해보자. 헷갈리지 말아야할 점은 위에 공식에서 $i$ 는 batch를 iteration 한 것이라는 점이다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;## Forward Process
# step-1: mu (D,)
mu = x.mean(axis=0)
# step-2: xmu (N, D)
xmu = x - mu
# step-3: sq (N, D)
sq = xmu**2
# step-4: var (D,)
var = np.mean(sq, axis=0)
# step-5: std (D,)
std = np.sqrt(var + 1e-6)
# step-6: invstd (D,)
invstd = 1.0 / std
# step-7: xhat (N, D)
xhat = xmu * invstd
# step-8: scale (N, D)
scale = gamma * xhat
# step-9: out (N, D)
out = scale + beta
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;backward&quot;&gt;Backward:&lt;/h4&gt;

&lt;p&gt;우리의 목표는 $\dfrac{\partial L}{\partial x}, \dfrac{\partial L}{\partial \gamma}, \dfrac{\partial L}{\partial \beta}$ 를 구해서, $\dfrac{\partial L}{\partial x}$ 는 Affine Layer로 역전파 시키고 $\gamma, \beta$ 는 학습 시키는 것이다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step-9:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Forward : $out(scale, \beta) = scale + \beta$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;더하기 노드의 역전파는 그대로 흘러간다.&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{cases} dscale = \dfrac{\partial L}{\partial scale} = \dfrac{\partial L}{\partial out} \dfrac{\partial out}{\partial scale} = 1 * dout \\
\\
d\beta = \dfrac{\partial L}{\partial \beta} = \dfrac{\partial L}{\partial out} \dfrac{\partial out}{\partial \beta} = 1 * \sum_i^N dout \end{cases}&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Step-8:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Forward : $scale(\gamma, \hat{x}_i) = \gamma \ * \ \hat{x}_i$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;곱의 노드의 역전파는 들어왔던 신호를 역으로 곱해서 흘려 보낸다.&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{cases}
d\hat{x}_i = \dfrac{\partial L}{\partial \hat{x}_i} = \dfrac{\partial L}{\partial scale} \dfrac{\partial scale}{\partial \hat{x}_i} = 1 * \sum_i^N dout \\
\\
d\gamma = \dfrac{\partial L}{\partial \gamma} = \dfrac{\partial L}{\partial scale} \dfrac{\partial scale}{\partial \gamma} = \sum_i^N dout \ * \ \hat{x}_i
\end{cases}&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Step-7:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Forward : $\hat{x}_i(xmu, invstd) = xmu \ * \ invstd$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$xmu$는 윗쪽(step-7 $\rightarrow$ step-2)과 아래쪽(step-3 $\rightarrow$ step-2) 으로 두 번 돌아가기 때문에 첨자를 단다.&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{cases}
dxmu_1= \dfrac{\partial L}{\partial xmu_1} = \dfrac{\partial L}{\partial \hat{x}_i} \dfrac{\partial \hat{x}_i}{\partial xmu_1} = d\hat{x}_i \ * \ invstd \\
\\
dinvstd = \dfrac{\partial L}{\partial \hat{x}_i} = \dfrac{\partial L}{\partial \hat{x}_i} \dfrac{\partial \hat{x}_i}{\partial invstd} = d\hat{x}_i \ * \ xmu
\end{cases}&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Step-6:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Forward : $invstd(\sigma) = \dfrac{1}{\sigma}$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$f(x) = \dfrac{1}{x}$ 의 미분은 $f’(x) = -\dfrac{1}{x^2} = -f(x)^2$ 이기 때문에 아래와 같다.&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;d\sigma = \dfrac{\partial L}{\partial \sigma} = \dfrac{\partial L}{\partial invstd} \dfrac{\partial invstd}{\partial \sigma} = dinvstd \ * \ (-invstd^2)&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Step-5:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Forward : $\sigma(var) = \sqrt{var + \epsilon}$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$f(x) = \sqrt{x + \epsilon}$ 의 미분은 $f’(x) = -\dfrac{1}{2}(x+\epsilon)^{-\frac{1}{2}}$ 이기 때문에 아래와 같다.&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;dvar = \dfrac{\partial L}{\partial var} = \dfrac{\partial L}{\partial \sigma} \dfrac{\partial \sigma}{\partial var} = d\sigma \ * \ (-\dfrac{1}{2}(var+\epsilon)^{-\frac{1}{2}})&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Step-4:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Forward : $var(sq) = \dfrac{1}{N} \sum_i^N sq$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$f(x) = \dfrac{1}{N} \sum_i^N x_i$ 의 미분은 $f’(x) = \dfrac{1}{N} \sum_i^N 1$ 이기 때문에 아래와 같다. 단, x의 형상(shape)이 같아야한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
dsq = \dfrac{\partial L}{\partial sq} = \dfrac{\partial L}{\partial var} \dfrac{\partial var}{\partial sq} = \dfrac{1}{N} dvar \ * \ \begin{bmatrix} 1 &amp; \cdots &amp; 1 \\ \vdots &amp; \ddots &amp; \vdots \\ 1 &amp; \cdots &amp; 1 \end{bmatrix}_{(N, D)} = \dfrac{1}{N} dvar \ * \ ones(N, D) %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Step-3:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Forward : $sq = xmu^2$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$f(x) = x^2$ 의 미분은 $f’(x) = 2x$ 이기 때문에 아래와 같다.&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;dxmu_2 = \dfrac{\partial L}{\partial xmu_2} = \dfrac{\partial L}{\partial sq} \dfrac{\partial sq}{\partial xmu_2} = dsq \ * \ 2 \ xmu&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Step-2:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Forward : $xmu = x_i - \mu$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$dxmu = dxmu_1 + dxmu_2$ 로 정의 된다. 곱의 미분 법칙 생각해보면 된다. $h(x) = f(x) g(x)$ 를 $x$ 에 대해서 미분하면 $f’(x)g(x) + f(x)g’(x)$ 기 때문이다. &lt;br /&gt;
또한 이것도 덧셈과 마찬가지로 그대로 흘러 보내는다 밑에 쪽은 -1 을 곱해서 흘려 보낸다.&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{cases}
dx_1= \dfrac{\partial L}{\partial x_1} = \dfrac{\partial L}{\partial xmu} \dfrac{\partial xmu}{\partial x_1} = dmu \ * \ 1 \\
\\
d\mu = \dfrac{\partial L}{\partial \mu} = \dfrac{\partial L}{\partial xmu} \dfrac{\partial xmu}{\partial \mu} = \sum_i^N dxmu \ * \ (-1)
\end{cases}&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Step-1:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Forward : $\mu = \dfrac{1}{N} \sum_i^N x_i$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;step-4에서 설명했다.&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
dx_2 = \dfrac{\partial L}{\partial x_2} = \dfrac{\partial L}{\partial \mu} \dfrac{\partial \mu}{\partial x_2} = \dfrac{1}{N} d\mu \ * \ \begin{bmatrix} 1 &amp; \cdots &amp; 1 \\ \vdots &amp; \ddots &amp; \vdots \\ 1 &amp; \cdots &amp; 1 \end{bmatrix}_{(N, D)} = \dfrac{1}{N} d\mu \ * \ ones(N, D) %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Step-0:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;최종적으로 구하는 $dx = \dfrac{\partial L}{\partial x} = dx_1 + dx_2$ 로 정의 된다.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;## Backward Process
# step-9: out = scale + beta
dbeta = dout.sum(axis=0)
dscale = dout
# step-8: scale = gamma * xhat
dgamma = np.sum(xhat * dout, axis=0)
dxhat = gamma * dscale
# step-7: xhat = xmu * invstd
dxmu1 = dxhat * invstd
dinvstd = np.sum(dxhat * xmu, axis=0)
# step-6: invstd = 1 / std
dstd = dinvstd * (-invstd**2)
# step-5: std = np.sqrt(var + 1e-6)
dvar = -0.5 * dstd * (1 / np.sqrt(var + 1e-6))
# step-4: var = sum(sq)
dsq = (1.0 / batch_size) * np.ones(input_shape) * dvar
# step-3: sq = xmu**2
dxmu2 = dsq * 2 * xmu
# step-2: xmu = x - mu
dxmu = dxmu1 + dxmu2
dmu = -1 * np.sum(dxmu, axis=0)
dx1 = dxmu * 1
# step-1: mu = mean(x)
dx2 = (1.0 / batch_size) * np.ones(input_shape) * dmu
# step-0:
dx = dx1 + dx2
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;section&quot;&gt;실제 구현&lt;/h4&gt;
&lt;p&gt;그러나 실제 구현 시에는 training 과 testing을 나눠서 아래와 같이 진행된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/nn/6/batch_norm_al.png&quot; alt=&quot;Drawing&quot; style=&quot;width=500px&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;
&lt;h3 id=&quot;backpropogation---&quot;&gt;첨부: Backpropogation 전체 미분 수학식&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;수식의 이해는 이분의 블로그에서 많은 참조를 했다. Blog: [&lt;a href=&quot;http://cthorey.github.io/backpropagation/&quot;&gt;&lt;span style=&quot;color: #7d7ee8&quot;&gt;Clement Thorey&lt;/span&gt;&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
Y &amp;= \gamma \hat{X} + \beta \\
\hat{X} &amp;= (X - \mu)(\sigma^2+\epsilon)^{-1/2}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;size:&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
Y, \hat{X}, X &amp;= (N, D) \\
\mu, \sigma, \gamma, \beta &amp;= (D,)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;$N$은 미니 배치 싸이즈고, $D$는 데이터의 차원 수다.&lt;/p&gt;

&lt;p&gt;Matrix 로 정의한 수식을 다시 원소별로 표기를 정의 해보자. 매트릭스 $Y, X, \hat{X}$ 와 벡터 $\gamma, \beta$ 그리고 위에 수식은 아래와 같이 다시 정의 해볼 수 있다. (왜 매트릭스와 벡터인지는 Forward 과정에 나와있다. 각 차원별로 평균과 분산을 구하는걸 잊지말자)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
y_{kl} &amp;= \gamma_l \hat{x}_{kl} + \beta_l \\
\hat{x}_{kl} &amp;= (x_{kl} - \mu_l)(\sigma_l^2+\epsilon)^{-1/2}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;where\quad \mu_l = \dfrac{1}{N} \sum_{p=1}^{N} x_{pl} , \quad \sigma_l^2 = \dfrac{1}{N} \sum_{p=1}^{N} (x_{pl}-\mu_l)^2&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;with\quad k = [1, \cdots, N] \ ,\  l = [1, \cdots, D]&lt;/script&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;이제 우리고 구하려고 하는 미분 값들$(\dfrac{\partial L}{\partial x}, \dfrac{\partial L}{\partial \gamma}, \dfrac{\partial L}{\partial \beta})$을 하나씩 구해보자.&lt;/p&gt;

&lt;h4 id=&quot;xij---&quot;&gt;$x_{ij}$ 에 대한 미분&lt;/h4&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}\dfrac{\partial L}{\partial x_{ij}}
&amp;= \sum_{k,l} \dfrac{\partial L}{\partial y_{kl}} \dfrac{\partial y_{kl}}{\partial x_{ij}} \\
&amp;= \sum_{k,l} \dfrac{\partial L}{\partial y_{kl}} \dfrac{\partial y_{kl}}{\partial \hat{x}_{kl}} \dfrac{\partial \hat{x}_{kl}}{\partial {x}_{ij}} \\
&amp;= \sum_{k,l} \dfrac{\partial L}{\partial y_{kl}} \cdot \gamma_l \cdot \dfrac{\partial \hat{x}_{kl}}{\partial {x}_{ij}} \end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\dfrac{\partial \hat{x}_{kl}}{\partial {x}_{ij}} = \dfrac{\partial f}{\partial {x}_{ij}} g + f \dfrac{\partial g}{\partial {x}_{ij}} \quad where \quad \begin{cases} f = (x_{kl} - \mu_l) \\ g = (\sigma_l^2+\epsilon)^{-1/2} \end{cases}&lt;/script&gt; 에 대한 미분을 구해보자.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;우선 분자 $f = (x_{kl} - \mu_l)$ 에 대한 미분을 하면 아래와 같다.&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\dfrac{\partial f}{\partial {x}_{ij}} = \delta_{ik} \delta_{jl} - \frac{1}{N} \delta_{jl}&lt;/script&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\delta_{m,n} = \begin{cases} 1 \quad where \quad m = n \\ 0 \quad otherwise \end{cases}&lt;/script&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;$\delta_{m,n}$ 은 앞첨자 $m$ 이 뒷첨자 $n$과 같다면 1이 된다는 뜻이다.&lt;/p&gt;

&lt;p&gt;즉, 여기서 $i$ 가 $[1 \cdots k \cdots D]$ 까지, $j$ 가 $[1 \cdots l \cdots D]$ 까지 iteration 할 것인데, 오직 $i=k, j=l$ 일때만 앞 항인 $\delta_{il} \delta_{jl} = 1$ 이 될 것이고, $j=l$ 일때만 뒷항인 $\frac{1}{N} \delta_{jl} = \frac{1}{N}$ 이 될 것이다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;분모 $g = (\sigma_l^2+\epsilon)^{-1/2}$ 에 대한 미분은 아래와 같다.&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\dfrac{\partial g}{\partial {x}_{ij}} = -\dfrac{1}{2}(\sigma_l^2 + \epsilon)^{-3/2} \dfrac{\partial \sigma_l^2}{\partial x_{ij}}&lt;/script&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned} where \quad \sigma_l^2
&amp;= \dfrac{1}{N} \sum_{p=1}^{N} (x_{pl}-\mu_l)^2 \\
\dfrac{\partial \sigma_l^2}{\partial x_{ij}}
&amp;= \dfrac{1}{N} \sum_{p=1}^{N} 2(x_{pl}-\mu_l)(\delta_{ip} \delta_{jl} - \frac{1}{N} \delta_{jl}) \\
&amp;= \dfrac{2}{N} (x_{il}-\mu_l) \delta_{jl} - \dfrac{2}{N^2} \sum_{p=1}^N (x_{pl}-\mu_l) \delta_{jl} \\
&amp; = \dfrac{2}{N} (x_{il}-\mu_l) \delta_{jl} - \dfrac{2}{N} \delta_{jl} (\dfrac{1}{N}  \sum_{p=1}^N  (x_{pl}-\mu_l)) \cdots (1) \\
&amp; = \dfrac{2}{N} (x_{il}-\mu_l) \delta_{jl}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;(1) 번 식을 잠깐 이야기 하면 $\dfrac{1}{N} \sum_{p=1}^N  (x_{pl}-\mu_l) = 0$ 인것은 어떤 값들을 평균을 빼고 다시 평균 시키면 0이 된다.&lt;/p&gt;

&lt;p&gt;$e.g)\quad \frac{(1-2)+(2-2)+(3-2)}{3}=0$&lt;/p&gt;

&lt;p&gt;이제 드디어 &lt;script type=&quot;math/tex&quot;&gt;\dfrac{\hat{x}_{kl}}{\partial {x}_{ij}}&lt;/script&gt; 에 대해 구할수 있다. 곱의 미분 법칙을 사용하면 아래와 같이 전개 된다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned} \dfrac{\hat{x}_{kl}}{\partial {x}_{ij}}
&amp;= (\delta_{ik} \delta_{jl} - \frac{1}{N} \delta_{jl})(\sigma_l^2+\epsilon)^{-1/2}  -\dfrac{1}{N} (x_{kl} - \mu_l)(\sigma_l^2 + \epsilon)^{-3/2} (x_{il}-\mu_l) \delta_{jl} \\
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;최종적으로 우리의 목적 &lt;script type=&quot;math/tex&quot;&gt;\dfrac{\partial L}{\partial x_{ij}}&lt;/script&gt; 를 구해보자.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}\dfrac{\partial L}{\partial x_{ij}}
&amp;= \sum_{k,l} \dfrac{\partial L}{\partial y_{kl}} \cdot \gamma_l \cdot [(\delta_{ik} \delta_{jl} - \frac{1}{N} \delta_{jl})(\sigma_l^2+\epsilon)^{-1/2} - \dfrac{1}{N} (x_{kl} - \mu_l)(\sigma_l^2 + \epsilon)^{-3/2} (x_{il}-\mu_l) \delta_{jl}] \\
&amp;= \sum_{k,l} \dfrac{\partial L}{\partial y_{kl}} \gamma_l [(\delta_{ik} \delta_{jl} - \frac{1}{N} \delta_{jl})(\sigma_l^2+\epsilon)^{-1/2}] - \sum_{k,l} \dfrac{\partial L}{\partial y_{kl}} \gamma_l [\dfrac{1}{N} (x_{kl} - \mu_l)(\sigma_l^2 + \epsilon)^{-3/2} (x_{il}-\mu_l) \delta_{jl}] \\
&amp;= \sum_{k,l} \dfrac{\partial L}{\partial y_{kl}} \gamma_l (\delta_{ik} \delta_{jl})(\sigma_l^2+\epsilon)^{-1/2} - \frac{1}{N} \sum_{k,l} \dfrac{\partial L}{\partial y_{kl}} \gamma_l \delta_{jl}(\sigma_l^2+\epsilon)^{-1/2} - \sum_{k,l} \dfrac{\partial L}{\partial y_{kl}} \gamma_l [\dfrac{1}{N} (x_{kl} - \mu_l)(\sigma_l^2 + \epsilon)^{-3/2} (x_{il}-\mu_l) \delta_{jl}] \\
&amp;= \dfrac{\partial L}{\partial y_{ij}} \gamma_l \delta_{ii} \delta_{jj} (\sigma_l^2+\epsilon)^{-1/2} - \frac{1}{N} \sum_k \dfrac{\partial L}{\partial y_{kj}} \gamma_l \delta_{jj}(\sigma_j^2+\epsilon)^{-1/2} - \dfrac{1}{N} \sum_{k} \dfrac{\partial L}{\partial y_{kj}} \gamma_l [ (x_{kj} - \mu_j)(\sigma_j^2 + \epsilon)^{-3/2} (x_{ij}-\mu_j) \delta_{jj}] \cdots (2) \\
&amp;= \dfrac{\partial L}{\partial y_{ij}} \gamma_l (\sigma_l^2+\epsilon)^{-1/2} - \frac{1}{N} \sum_k \dfrac{\partial L}{\partial y_{kj}} \gamma_l (\sigma_j^2+\epsilon)^{-1/2} - \dfrac{1}{N} \sum_{k} \dfrac{\partial L}{\partial y_{kj}} \gamma_l (x_{kj} - \mu_j)(\sigma_j^2 + \epsilon)^{-3/2} (x_{ij}-\mu_j) \\
&amp;= \dfrac{1}{N} \gamma_l (\sigma_l^2+\epsilon)^{-1/2} [N \dfrac{\partial L}{\partial y_{ij}} - \sum_k \dfrac{\partial L}{\partial y_{kj}} - (x_{ij}-\mu_j)(\sigma_j^2 + \epsilon)^{-1} \sum_{k} \dfrac{\partial L}{\partial y_{kj}}(x_{kj} - \mu_j)]
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;(2) 번 식으로 도출 되는 과정을 잘 살펴보면, 각 항마다 곱으로 구성되어 있다. 첫번째 항은 $\sum_{k, l}$ 에서 오직 $k=i, l=j$ 일때 남아 있고 나머지는 전부다 0 이고, 두번째 항은 오직 $l=j$ 일때 남아있고 나머지는 전부다 0 이다. 그리고 마지막도 마친가지로 $l=j$ 일때만 남아있는다.&lt;/p&gt;

&lt;h4 id=&quot;gammaj---&quot;&gt;$\gamma_j$ 에 대한 미분&lt;/h4&gt;

&lt;p&gt;위에 까지 이해했으면 $\gamma_l$ 에 대한 미분은 간단하다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}\dfrac{\partial L}{\partial \gamma_j}
&amp;= \sum_{k,l} \dfrac{\partial L}{\partial y_{kl}} \dfrac{\partial y_{kl}}{\partial \gamma_j} \\
&amp;= \sum_{k,l} \dfrac{\partial L}{\partial y_{kl}} \hat{x}_{kl} \delta_{jl} \\
&amp;= \sum_k \dfrac{\partial L}{\partial y_{kj}} \hat{x}_{kj} \\
&amp;= \sum_k \dfrac{\partial L}{\partial y_{kj}} (x_{kj} - \mu_j)(\sigma_j^2+\epsilon)^{-1/2}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;h4 id=&quot;betaj---&quot;&gt;$\beta_j$ 에 대한 미분&lt;/h4&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}\dfrac{\partial L}{\partial \beta_j}
&amp;= \sum_{k,l} \dfrac{\partial L}{\partial y_{kl}} \dfrac{\partial y_{kl}}{\partial \gamma_j} \\
&amp;= \sum_{k,l} \dfrac{\partial L}{\partial y_{kl}} \delta_{jl} \\
&amp;= \sum_k \dfrac{\partial L}{\partial y_{kj}}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;여기서 우리는 왜 위에 step-9, 8 코드 구현에서 dgamma와 dbeta를 summation 하는지 알 수 있다.&lt;/p&gt;

&lt;p&gt;다음 마지막 시간에는 모든걸 종합해서 학습하는 과정을 코드로 살펴보자.&lt;/p&gt;
</description>
        <pubDate>Thu, 25 Jan 2018 12:54:15 +0900</pubDate>
        <link>http://simonjisu.github.io/deeplearning/2018/01/25/numpywithnn_7.html</link>
        <guid isPermaLink="true">http://simonjisu.github.io/deeplearning/2018/01/25/numpywithnn_7.html</guid>
        
        
        <category>DeepLearning</category>
        
      </item>
    
      <item>
        <title>NUMPY with NN - 6: Weight Initialization</title>
        <description>&lt;h1 id=&quot;numpy--neural-network-basic---6&quot;&gt;Numpy로 짜보는 Neural Network Basic - 6&lt;/h1&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;part-2&quot;&gt;학습관련 기술 Part 2&lt;/h2&gt;

&lt;h3 id=&quot;weight-initialization&quot;&gt;가중치 초기값 설정(Weight Initialization)&lt;/h3&gt;
&lt;p&gt;이전에 활성화 함수가 왜 중요한지 이야기 했었다. 다시 한 번 이야기 하면, 비 선형 활성화 함수를 사용해서 선형으로만 표현할 수 없는 값을 표현할 수 있게 되며, 그로 인해 은닉층을 쌓는 의미가 생긴다. 이런 비 선형 함수의 가중치 미분을 구해서 학습하고자 하는 파라미터를 업데이트 하게 된다.&lt;/p&gt;

&lt;p&gt;[&lt;a href=&quot;https://simonjisu.github.io/datascience/2017/12/08/numpywithnn_2.html&quot;&gt;&lt;span style=&quot;color: #7d7ee8&quot;&gt;Numpy로 짜보는 Neural Network Basic - 2&lt;/span&gt;&lt;/a&gt;] 참고&lt;/p&gt;

&lt;p&gt;그렇다면 Sigmoid를 예를 들어서 이야기 해보자, 아래 그림은 Sigmoid 함수와 미분의 그래프다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned} \sigma(a) &amp; = \dfrac{1}{1+e^{-a}} \\ \sigma'(a) &amp;= \sigma(a)(1 - \sigma(a))\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/nn/6/sigmoid_prime.png&quot; alt=&quot;Drawing&quot; /&gt;&lt;/p&gt;

&lt;p&gt;선형결합을 통해 구해진 값 a은 뉴런을 거쳐서 Sigmoid로 활성화 된 함수는 대부분 $[0, 1]$ 사이의 값을 가지게 될 것이다. 선형결합을 통해 구해진 값이 조금만 커져도 (약 $[-5, 5]$ 이외 값) Gradient 값이 0으로 되는 경우가 많아진다. 이를 &lt;strong&gt;Gradient Vanishing Problem&lt;/strong&gt;, 즉 가중치 0에 가까워져 업데이트 안되는 현상을 말한다. 따라서 가중치 초기 값이 엄청 작게 설정 했다고 해도 dot product해진 값이 커지면 이런 현상이 일어날 수가 있다.&lt;/p&gt;

&lt;h4 id=&quot;mnist--&quot;&gt;Mnist 데이터로 살펴보기&lt;/h4&gt;

&lt;p&gt;실제로 활성화 함수 값이 어떤 분포인지 mnist 데이터로 살펴보자. 내가 만든 뉴럴 네트워크의 구조는 아래와 같다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned} Input_{(784)}
&amp;\rightarrow [Affine1 \rightarrow Activation1]_{hidden1: (100)} \\
&amp;\rightarrow [Affine2 \rightarrow Activation2]_{hidden2: (50)} \\
&amp;\rightarrow [Affine3 \rightarrow SoftmaxwithLoss]_{output:(10)_{}}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;Hidden Node 는 각 100개와 50개로 설정하고 Activation Fucntion은 simgoid로 했다.
아래는 200 epoch까지 중간에 Activation 값들의 분포를 찍어본 것이다. 가중치 초기 값은 1을 곱한 것으로써 랜덤 Initialization 되었다고 생각하면 된다.(= $W$에다 1을 곱했다.)&lt;/p&gt;

&lt;video controls=&quot;controls&quot; autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot;&gt; &lt;source type=&quot;video/mp4&quot; src=&quot;/assets/ML/nn/6/sig_act1.mp4&quot; /&gt; &amp;lt;/source&amp;gt; &lt;/video&gt;

&lt;p&gt;대부분의 값이 0과 1로 이루어져 있다는 것을 알 수 있다. 이는 즉 대부분의 값이 미분을 했을 때 0이될 가능성이 높다는 뜻이다.&lt;/p&gt;

&lt;video controls=&quot;controls&quot; autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot;&gt; &lt;source type=&quot;video/mp4&quot; src=&quot;/assets/ML/nn/6/sig_back1.mp4&quot; /&gt; &amp;lt;/source&amp;gt; &lt;/video&gt;

&lt;p&gt;앞쪽의 Layer로 backward 할 수록 가중치 미분 값이 0에 가까워지는 것을 볼 수 있다.&lt;/p&gt;

&lt;p&gt;우리는 &lt;a href=&quot;https://simonjisu.github.io/datascience/2017/12/15/numpywithnn_4.html&quot;&gt;&lt;span style=&quot;color: #7d7ee8&quot;&gt;4편&lt;/span&gt;&lt;/a&gt;에서 가중치 값을 0.01 초기화 시켰더니 학습이 전혀 안된 모습을 볼 수 있었다. 그렇다면 0.01로 가중치 값을 초기화 하면 어떻게 될까?&lt;/p&gt;

&lt;video controls=&quot;controls&quot; autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot;&gt; &lt;source type=&quot;video/mp4&quot; src=&quot;/assets/ML/nn/6/sig_act2.mp4&quot; /&gt; &amp;lt;/source&amp;gt; &lt;/video&gt;

&lt;p&gt;가중치 활성화 값이 0.5로 치우쳐져 두 레이어의 분포가 거의 비슷해졌다. 다수의 뉴런이 같은 값을 출력하고 있다는 뜻으로 우리가 비선형함수를 써서 예측 불가능하게 만드려고 한 노력을 물거품으로 만들어 버렸다. 즉, 위에서 이야기 했던 층을 여러게 쌓은 의미가 없어진다. 이를 &lt;strong&gt;“표현력이 제한된다”&lt;/strong&gt; 라고 말한다.&lt;/p&gt;

&lt;video controls=&quot;controls&quot; autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot;&gt; &lt;source type=&quot;video/mp4&quot; src=&quot;/assets/ML/nn/6/sig_back2.mp4&quot; /&gt; &amp;lt;/source&amp;gt; &lt;/video&gt;

&lt;p&gt;가중치의 미분 값들이 대부분 0 근처에 있는 것을 확인 할 수가 있다.&lt;/p&gt;

&lt;p&gt;따라서 초기 값을 잘 설정해주어야 하는데, Sigmoid 함수에 대해서 자주 사용하는 Xavier 초기 값이 있다.&lt;/p&gt;

&lt;p&gt;Paper: &lt;a href=&quot;http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf&quot;&gt;&lt;span style=&quot;color: #7d7ee8&quot;&gt;Understanding the difficulty of training deep feedforward neural networks&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;W \sim Uniform(n_{in}, n_{out})&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Var(W)=\dfrac{1}{n_{in}}&lt;/script&gt;

&lt;p&gt;즉 가중치 초기화를 할때 각 파라미터 $W$ 에 대하여 $\dfrac{1}{\sqrt{n_{in}}}$ 를 곱해주는 것이다.&lt;/p&gt;

&lt;p&gt;아래는 Xavier 가중치 초기값을 설정했을 때의 Activation 분포다. 두 층이 전혀 다른 분포가 되어있는 것을 볼 수가 있다.&lt;/p&gt;

&lt;video controls=&quot;controls&quot; autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot;&gt; &lt;source type=&quot;video/mp4&quot; src=&quot;/assets/ML/nn/6/sig_act3.mp4&quot; /&gt; &amp;lt;/source&amp;gt; &lt;/video&gt;

&lt;video controls=&quot;controls&quot; autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot;&gt; &lt;source type=&quot;video/mp4&quot; src=&quot;/assets/ML/nn/6/sig_back3.mp4&quot; /&gt; &amp;lt;/source&amp;gt; &lt;/video&gt;

&lt;p&gt;각각의 가중치 초기화 값에 대한 학습 결과를 살펴보자. 총 10000번의 epochs를 돌린 결과다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;학습결과&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;img src=&quot;/assets/ML/nn/6/sig1.png&quot; alt=&quot;Drawing&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$w_{std} = 1$: 처음에 빠른것 같지만 나중에 굉장히 천천히 학습 되는 것을 확인 할 수 있다. &lt;br /&gt; 또한 매번 실행시 학습 속도가 다르다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;img src=&quot;/assets/ML/nn/6/sig2.png&quot; alt=&quot;Drawing&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$w_{std} = 0.01$: 학습이 전혀 안되는 것을 확인 할 수 있다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;img src=&quot;/assets/ML/nn/6/sig3.png&quot; alt=&quot;Drawing&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$w_{std} = \dfrac{1}{\sqrt{n}}$: test 성적이 조금 더 좋아 졌다.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&quot;relu&quot;&gt;활성화 함수를 바꿔보자: ReLu&lt;/h4&gt;
&lt;p&gt;ReLu의 미분 값은 $x &amp;gt; 0$ 에서 $1$ 이고 나머지는 $0$ 이다. ReLu는 &lt;strong&gt;He&lt;/strong&gt; 라는 초기값을 설정하게 된다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;W \sim Uniform(n_{in}, n_{out})&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Var(W)=\dfrac{2}{n_{in}}&lt;/script&gt;

&lt;p&gt;즉, 가중치 $W$ 에 $\sqrt{\dfrac{2}{n_{in}}}$ 을 곱하게 된다. 아래 동영상을 보면 0보다 큰 부분에서 꾸준히 활성화 되는 모습을 볼 수 있다.&lt;/p&gt;

&lt;video controls=&quot;controls&quot; autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot;&gt; &lt;source type=&quot;video/mp4&quot; src=&quot;/assets/ML/nn/6/relu_act3.mp4&quot; /&gt; &amp;lt;/source&amp;gt; &lt;/video&gt;

&lt;video controls=&quot;controls&quot; autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot;&gt; &lt;source type=&quot;video/mp4&quot; src=&quot;/assets/ML/nn/6/relu_back3.mp4&quot; /&gt; &amp;lt;/source&amp;gt; &lt;/video&gt;

&lt;p&gt;다음 시간에는 배치 정규화에 대해서 알아보자.&lt;/p&gt;
</description>
        <pubDate>Wed, 24 Jan 2018 12:31:37 +0900</pubDate>
        <link>http://simonjisu.github.io/deeplearning/2018/01/24/numpywithnn_6.html</link>
        <guid isPermaLink="true">http://simonjisu.github.io/deeplearning/2018/01/24/numpywithnn_6.html</guid>
        
        
        <category>DeepLearning</category>
        
      </item>
    
      <item>
        <title>NUMPY with NN - 5: Optimizer</title>
        <description>&lt;h1 id=&quot;numpy--neural-network-basic---5&quot;&gt;Numpy로 짜보는 Neural Network Basic - 5&lt;/h1&gt;
&lt;hr /&gt;
&lt;h2 id=&quot;part-1&quot;&gt;학습관련 기술 Part 1&lt;/h2&gt;

&lt;h3 id=&quot;optimizer&quot;&gt;Optimizer&lt;/h3&gt;

&lt;p&gt;손실 함수 값을 가능한 낮게 만들어 매개변수 최적값을 찾는 과정을 &lt;strong&gt;최적화&lt;/strong&gt; 라고 한다. 여기서 몇가지 방법을 한번 살펴본다.&lt;/p&gt;

&lt;h4 id=&quot;sgd--&quot;&gt;SGD(확률적 경사 하강법)&lt;/h4&gt;
&lt;p&gt;$W \leftarrow W - \eta \dfrac{\partial L}{\partial W}$&lt;/p&gt;

&lt;p&gt;$\eta$ 는 학습률로 얼만큼 가중치를 업데이트 할지 정하는 하이퍼파라미터다. 즉 우리가 미리 정해줘야하는 변수다. 그러나 SGD 알고리즘에서는 이 변수에 따라서 학습되는 모양이 다르다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;class SGD(object):
    def __init__(self, lr=0.01):
        self.lr = lr

    def update(self, params, grads):
        for key in params.keys():
            params[key] -= self.lr * grads[key]
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;장점&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;일부 데이터로 업데이트를 해서 진동이 심할 수도 있지만, 전체 데이터의 Gradient를 구하는 것보다 빠르다&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;단점&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;learning rate에 따라서 global min을 찾지 못하고 local min에 갇힐 가능서 존재&lt;/li&gt;
  &lt;li&gt;Oscilation(발진 현상): 해에 접근 할 수록 수렴 속도($\dfrac{\partial L}{\partial W}$)가 느려짐, 따라서 협곡 같은 모양에서 헤매는 경우 존재한다. 그렇다고 lr을 너무 높히면 발산 할 수도 있음(loss값이 커지는 현상)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;아래와 같은 함수의 최적값을 찾아보자.&lt;/p&gt;

&lt;p&gt;$f(x, y) = \dfrac{1}{20} x^2 + y^2$&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def f(x, y):
    return np.array((1/20)*(x**2) + (y**2))
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;$f$ 를 미분하면 아래와 같다.&lt;/p&gt;

&lt;p&gt;$\dfrac{\partial f}{\partial x}, \dfrac{\partial f}{\partial y} = \dfrac{x}{10}, 2y$&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def f_prime(x, y, grads=None):
    if grads is None:
        grads = {}

    grads['x'] = (1/10)*x
    grads['y'] = 2*y
    return grads
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;시작은 &lt;strong&gt;(-7, 2)&lt;/strong&gt; 점부터 시작한다고 하면 아래처럼 그림으로 표현할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/nn/fgraph.png&quot; alt=&quot;Drawing&quot; style=&quot;width: 400px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이 함수의 최저점은 (0, 0) 점으로 볼 수 있다.&lt;/p&gt;

&lt;p&gt;이제 learning rate 를 0.1 과 0.9로 각각 정해서 SGD를 적요해보자. 총 30 epoch동안 Gradient를 구하고 이를 조금씩 업데이트 하는 방식을 취했다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Video&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Graph&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;video controls=&quot;controls&quot; style=&quot;width: 400px;&quot; autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot;&gt; &lt;source type=&quot;video/mp4&quot; src=&quot;/assets/ML/nn/SGD_0.1.mp4&quot; /&gt; &amp;lt;/source&amp;gt;&lt;/video&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;img src=&quot;/assets/ML/nn/SGD_0.1.png&quot; alt=&quot;Drawing&quot; style=&quot;width: 400px;&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;learning rate 가 0.1 일때 학습이 조금씩 진행 되는 것을 볼 수 있다. 그러나 epoch 횟수가 너무 적어 최적의 값까지 도달을 못했다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Video&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Graph&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;video controls=&quot;controls&quot; style=&quot;width: 400px;&quot; autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot;&gt; &lt;source type=&quot;video/mp4&quot; src=&quot;/assets/ML/nn/SGD_0.9.mp4&quot; /&gt; &amp;lt;/source&amp;gt;&lt;/video&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;img src=&quot;/assets/ML/nn/SGD_0.9.png&quot; alt=&quot;Drawing&quot; style=&quot;width: 400px;&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;learning rate 가 0.9 일때 학습이 크게 진행 되는 것을 볼 수 있다. 그러나 변동이 심해서 크게 흔들리면서 최저점으로 가는 모습을 볼 수 있다.&lt;/p&gt;

&lt;p&gt;학습률이 다르다는 것은 한 번 나아갈때 폭의 길이를 보면 그 차이를 알 수 가 있다.&lt;/p&gt;

&lt;h4 id=&quot;momentum&quot;&gt;Momentum&lt;/h4&gt;
&lt;p&gt;$v \leftarrow \gamma v - \eta \dfrac{\partial L}{\partial W}$&lt;/p&gt;

&lt;p&gt;$W \leftarrow W + v$&lt;/p&gt;

&lt;p&gt;모멘텀 방식은 gradient 방향에 일종의 관성을 더해줘서 기존의 이동 방향에 힘들 실어줘 더 이동할 수 있게 만들어준다. $v$ 의 초기값은 0으로 설정하고 진행한다. 따라서 첫 step이 후 기존에 이동했던 방향을 저장해둔 $v$ 가 추가로 저장 되어 다음 step에 더해져 조금 더 움직이게 된다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Video&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Graph&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;video controls=&quot;controls&quot; style=&quot;width: 400px;&quot; autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot;&gt; &lt;source type=&quot;video/mp4&quot; src=&quot;/assets/ML/nn/Momentum.mp4&quot; /&gt; &amp;lt;/source&amp;gt;&lt;/video&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;img src=&quot;/assets/ML/nn/Momentum.png&quot; alt=&quot;Drawing&quot; style=&quot;width: 400px;&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;learning rate가 0.1 일때 SGD보다 더 많이 가는 것을 알 수 있다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Video&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Graph&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;video controls=&quot;controls&quot; style=&quot;width: 400px;&quot; autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot;&gt; &lt;source type=&quot;video/mp4&quot; src=&quot;/assets/ML/nn/Momentum_0.9.mp4&quot; /&gt; &amp;lt;/source&amp;gt;&lt;/video&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;img src=&quot;/assets/ML/nn/Momentum_0.9.png&quot; alt=&quot;Drawing&quot; style=&quot;width: 400px;&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;learning rate가 0.9 일때 주변을 헤매면서 가는 모습을 볼 수 있다. 하이퍼파라미터를 잘 조정해야 학습이 빠르게 진행 된 다는 것을 알 수 있다.&lt;/p&gt;

&lt;h4 id=&quot;adagrad&quot;&gt;Adagrad&lt;/h4&gt;
&lt;p&gt;$h \leftarrow h + \dfrac{\partial L}{\partial W} \odot \dfrac{\partial L}{\partial W}$&lt;/p&gt;

&lt;p&gt;$W \leftarrow W - \eta \dfrac{1}{\sqrt{h +\epsilon}} \dfrac{\partial L}{\partial W}$&lt;/p&gt;

&lt;p&gt;학습률($\eta$)에 대한 고민이 많이지자 이를 해결해보기 위해 나온 알고리즘이 AdaGrad 다.&lt;/p&gt;

&lt;p&gt;학습률을 처음에 크게 했다 나중에 차차 줄여가는 &lt;strong&gt;학습률 감소(learning rate decay)&lt;/strong&gt; 기술이 이 알고리즘의 특징이다. 각각의 매개변수에 맞춤형 학습률 값을 맞춰 줄 수가 있다.&lt;/p&gt;

&lt;p&gt;$\odot$ 는 여기서 dot product가 아닌 element-wise multiplication를 말한다. 수식을 보면 gradient를 제곱하여 h에 저장한다. 업데이트시 여태까지 저장해온 gradient 제곱 값을 분모로 두게 된다. 따라서 시간이 지날 수록 gradient 누적 값이 큰 것은 learning rate 가 반대로 작아지게 된서 학습률이 조정 된다. 이를 적응적으로(adaptive) 학습률을 조정한다고 한다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;class Adagrad(object):
    def __init__(self, lr=0.01):
        self.lr = lr
        self.h = None
        self.epsilon = 1e-6  # 0으로 나누눈 것을 방지

    def update(self, params, grads):
        if self.h is None:
            self.h = {}
            for key, val in params.items():
                self.h[key] = np.zeros_like(val)

        for key in params.keys():
            self.h[key] += grads[key] * grads[key]
            params[key] -= self.lr * grads[key] / np.sqrt(self.h[key] + self.epsilon)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Video&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Graph&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;video controls=&quot;controls&quot; style=&quot;width: 400px;&quot; autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot;&gt; &lt;source type=&quot;video/mp4&quot; src=&quot;/assets/ML/nn/Adagrad.mp4&quot; /&gt; &amp;lt;/source&amp;gt;&lt;/video&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;img src=&quot;/assets/ML/nn/Adagrad.png&quot; alt=&quot;Drawing&quot; style=&quot;width: 400px;&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;학습률을 1.5로 크게 주었는데도 차차 감소하면서 학습되는 과정을 볼 수 가 있다.&lt;/p&gt;

&lt;p&gt;그러나 이렇게 좋아보이는 방법도 &lt;strong&gt;단점&lt;/strong&gt; 이 있다.&lt;/p&gt;

&lt;p&gt;과거의 기울기 값들을 전부 누적해서 더하기 때문에 h 값이 많이 커지게 되면 학습률 부분($\dfrac{1}{\sqrt{h +\epsilon}}$)이 1에 가까워져 업데이트 할 때 발산하는 형태로 가기 때문에 더 이상 학습이 진행이 안되는 상황이 발생할 수 있다.&lt;/p&gt;

&lt;p&gt;이를 개선하기 위해서 RMSProp과 Adadelta라는 방법이 있다. (코드는 기본 알고리즘 원리만 구현해놨다. 구체적으로 효율적인 학습을 위해서 조금씩 변형이 가해진다. 논문 참조 할 것, &lt;del&gt;아직 이해중&lt;/del&gt;)&lt;/p&gt;

&lt;p&gt;RMSProp:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;class RMSProp(object):
    def __init__(self, lr=0.01, gamma=0.9):
    &quot;&quot;&quot;G는 이동평균의 개념으로 과거 1보다 작은 gamma값을 곱해서 서서히 잊게 하고 새로운 값을 조금씩 더 해준다.&quot;&quot;&quot;
        self.lr = lr
        self.gamma = gamma  # decay term
        self.G = None
        self.epsilon = 1e-6  # 0으로 나누눈 것을 방지

    def update(self, params, grads):
        if self.G is None:
            self.G = {}
            for key, val in params.items():
                self.G[key] = np.zeros_like(val)

        for key in params.keys():
            self.G[key] += self.gamma * self.G[key] + (1 - self.gamma) * (grads[key] * grads[key])
            params[key] -= self.lr * grads[key] / np.sqrt(self.G[key] + self.epsilon)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;AdaDelta:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;class AdaDelta(object):
    def __init__(self, gamma=0.9):
        &quot;&quot;&quot;
        https://arxiv.org/pdf/1212.5701
        &quot;&quot;&quot;
        self.gamma = gamma  # decay term
        self.G = None  # accumulated gradients
        self.s = None  # accumulated updates
        self.del_W = None
        self.epsilon = 1e-6  # 0으로 나누눈 것을 방지
        self.iter = 0

    def update(self, params, grads):
        if (self.G is None) | (self.s is None) | (self.del_W is None):
            # Initialize accumulation variables
            self.G = {}
            self.s = {}  
            self.del_W = {}
            for key, val in params.items():
                self.G[key] = np.zeros_like(val)
                self.s[key] = np.zeros_like(val)
                self.del_W[key] = np.zeros_like(val)

        for key in params.keys():
            self.G[key] += self.gamma * self.G[key] + (1 - self.gamma) * (grads[key] * grads[key])
            self.del_W[key] = -(np.sqrt(self.s[key] + self.epsilon) / np.sqrt(self.G[key] + self.epsilon)) * grads[key]
            self.s[key] += self.gamma * self.s[key] + (1 - self.gamma) * self.del_W[key]**2
            params[key] += self.del_W[key]
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;h4 id=&quot;adamadaptive-moment-estimation&quot;&gt;Adam(Adaptive Moment Estimation)&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Adam&lt;/strong&gt; (Adaptive Moment Estimation)은 RMSProp과 Momentum 방식을 합친 것 같은 알고리즘이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/nn/Algorithm_Adam.png&quot; alt=&quot;Drawing&quot; style=&quot;width: 800px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;출처: &lt;a href=&quot;https://arxiv.org/abs/1412.6980v8&quot;&gt;&lt;span style=&quot;color: #7d7ee8&quot;&gt;https://arxiv.org/abs/1412.6980v8&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$m_t$: the exponential moving averages of the gradient (Momentum쪽)&lt;/li&gt;
  &lt;li&gt;$v_t$: the squared gradient (RMSProp쪽)&lt;/li&gt;
  &lt;li&gt;$\beta_1$: the exponential decay rates for $m_t$, 보통 0.9 취함&lt;/li&gt;
  &lt;li&gt;$\beta_2$: the exponential decay rates for $v_t$, 보통 0.999 취함&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;알고리즘 그대로 짜는게 아니라 조금더 효율적인 계산을 하기 위해서 아래와 같은 내용을 이해하고 보정해줘야 한다…(자세한 건 논문에 더 있음)&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;initialization-bias-correction&quot;&gt;추가 설명:(18.01.16) Initialization Bias Correction&lt;/h4&gt;
&lt;p&gt;우리가 구한 $m_t$, $v_t$ 값이 초기 값이 0으로 설정하고, $\beta$ 도 1에 가깝기 때문에 처음에 적용하는 gradient($g_t$) 값이 적용이 잘 안되서(즉, 업데이트가 안된다), 초기 epoch에서는 학습 진행이 안되는 경우가 있다.&lt;/p&gt;

&lt;p&gt;이는 $m_t$, $v_t$ 값이 실제로 $g_t$, $g_t^2$ 가 맞는지 확인하는 작업이 필요하다. 따라서 각각 기대값(Expectation)을 씌워서&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{cases}
E[m_t] = E[g_t] \\
E[v_t] = E[g_t^2]
\end{cases}&lt;/script&gt;

&lt;p&gt;가 성립하는지 확인해야 된다. $v_t$를 보면,&lt;/p&gt;

&lt;p&gt;$v_0 = 0$ (0 vector) 으로 초기 값을 주었기 때문에, $t = 1 \cdots t$ 까지 아래와 같이 정리해서 쓸 수가 있다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
v_0 &amp;= 0 \\
v_1 &amp;= \beta_2 v_0 + (1-\beta_2) g_1^2 = (1-\beta_2) g_1^2 \\
v_2 &amp;= \beta_2 v_1 + (1-\beta_2) g_2^2 = \beta_2 (1-\beta_2) g_1^2 + (1-\beta_2) g_2^2 = (1-\beta_2)(\beta_2^1 g_1^2 + \beta_2^0 g_2^2)\\
\vdots \\
v_t &amp;= \beta_2 v_{t-1} + (1-\beta_2) g_t^2 = (1-\beta_2)(\beta_2^{t-1} g_1^2 + \cdots + \beta_2^0 g_t^2) = (1-\beta_2) \sum_{i=1}^{t} \beta_2^{t-i}g_i^2 \cdots (1)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;(1) 식에서 $g_i^2$ 를 $g_i^2 - g_t^2 + g_t^2$ 로 바꿔 줄 수가 있다. 그후 양변에 Expectation을 취하게 된다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
E[v_t] &amp;= E[(1-\beta_2) \sum_{i=1}^{t} \beta_2^{t-i}(g_i^2 - g_t^2 + g_t^2))] \\
&amp;= E[(1-\beta_2) \sum_{i=1}^{t} \beta_2^{t-i}g_t^2] + E[(1-\beta_2) \sum_{i=1}^{t} \beta_2^{t-i}(g_i^2 - g_t^2))] \\
&amp;= E[g_t^2](1-\beta_2) \sum_{i=1}^{t} \beta_2^{t-i} + \zeta \\
&amp;= E[g_t^2](1-\beta_2)(\beta_2^{t-1} + \cdots + \beta_2^{0}) + \zeta \\
&amp;= E[g_t^2]\{(\beta_2^{t-1} + \cdots + \beta_2^{0}) - (\beta_2^{t} + \cdots + \beta_2^{1})\} + \zeta \\
&amp;= E[g_t^2](1-\beta_2^t) + \zeta \cdots (2)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;$E[g_t^2]$가 stationary 할때 $\zeta = 0$ 이 되고, 아니더라도 $\zeta$ 값은 이동평균의 특성상 따라 멀리 있는 $\beta_2^{t-i}$ 값이 아주 작아 0에 가까워 진다. 따라서 (2) 식만 남게 되는데, 우리가 원하는 $E[g_t^2]$ 를 구하기 위해서는 $E[g_t^2] = \dfrac{E[v_t]}{1-\beta_2^t}$ 를 해주면 초기값 0으로 설정하게 되어 생긴 bias를 조정 할 수 있게 된다.&lt;/p&gt;

&lt;p&gt;수식의 이해는 아래 블로그에서 도움을 조금 받았습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://dalpo0814.tistory.com/29#comment5316278&quot;&gt;&lt;span style=&quot;color: #7d7ee8&quot;&gt;http://dalpo0814.tistory.com&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;기존 알고리즘 코드:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;class Adam(object):
    &quot;&quot;&quot;Adam (http://arxiv.org/abs/1412.6980v8)&quot;&quot;&quot;

    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):
        self.lr = lr
        self.beta1 = beta1
        self.beta2 = beta2
        self.iter = 0
        self.m = None
        self.unbias_m = None
        self.v = None
        self.unbias_v = None

    def update(self, params, grads):
        if self.m is None:
            self.m, self.v = {}, {}
            for key, val in params.items():
                self.m[key] = np.zeros_like(val)
                self.v[key] = np.zeros_like(val)

        self.iter += 1

        for key in params.keys():
            self.m[key] = self.beta1*self.m[key] + (1-self.beta1)*grads[key]
            self.v[key] = self.beta2*self.v[key] + (1-self.beta2)*(grads[key]**2)

            self.unbias_m = self.m[key] / (1 - self.beta1**self.iter) # correct bias
            self.unbias_v = self.v[key] / (1 - self.beta2**self.iter) # correct bias
            params[key] -= self.lr * self.unbias_m / (np.sqrt(self.unbias_v) + 1e-7)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;아래는 다른 사람의 코드를 따와서 개조했다. 출처: &lt;a href=&quot;https://github.com/WegraLee/deep-learning-from-scratch/blob/master/common/optimizer.py&quot;&gt;&lt;span style=&quot;color: #7d7ee8&quot;&gt;https://github.com/WegraLee/deep-learning-from-scratch/&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;class Adam(object):
    &quot;&quot;&quot;Adam (http://arxiv.org/abs/1412.6980v8)&quot;&quot;&quot;

    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):
        self.lr = lr
        self.beta1 = beta1
        self.beta2 = beta2
        self.iter = 0
        self.m = None
        self.v = None

    def update(self, params, grads):
        if self.m is None:
            self.m, self.v = {}, {}
            for key, val in params.items():
                self.m[key] = np.zeros_like(val)
                self.v[key] = np.zeros_like(val)

        self.iter += 1
        lr_t = self.lr * np.sqrt(1.0 - self.beta2 ** self.iter) / (1.0 - self.beta1 ** self.iter)

        for key in params.keys():
            self.m[key] += (1 - self.beta1) * (grads[key] - self.m[key])
            self.v[key] += (1 - self.beta2) * (grads[key] ** 2 - self.v[key])

            params[key] -= lr_t * self.m[key] / (np.sqrt(self.v[key]) + 1e-7)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;조금 더 효율 적으로 개선된 것을 볼 수 있다. &lt;strong&gt;lr_t&lt;/strong&gt; 는 위에 unbias 항들을 넣어서 정리해주면 아래와 같이 정의 할 수 있다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
m_t &amp;= \beta_1 m_{t-1} + (1-\beta_1) g_t \\
&amp;= \beta_1 m_{t-1} + m_{t-1} - m_{t-1} + (1-\beta_1) g_t\\
&amp;= m_{t-1} - (1-\beta_1) m_{t-1} + (1-\beta_1) g_t\\
&amp;= m_{t-1} + (1-\beta_1)(g_t-m_{t-1})\\
v_t &amp;= v_{t-1} + (1-\beta_1)(g_t^2-v_{t-1}) \\
\alpha_t &amp;= \alpha \dfrac{\sqrt{1-\beta_2^t}}{1-\beta_1} \\
\theta_t &amp; \leftarrow \theta_{t-1} - \alpha_t \dfrac{m_t}{\sqrt{v_t} + \epsilon}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;h4 id=&quot;signal-to-noisesnr&quot;&gt;Signal-to-Noise(SNR)&lt;/h4&gt;
&lt;p&gt;보통의 경우 $\hat{v}_t$ (gradient 제곱의 지수 평균) 이 $\hat{m}_t$ (gradient의 지수 평균) 보다 크기 때문에 $\dfrac{\hat{m}_t}{\sqrt{\hat{v}_t}} \leq 1$ ($\epsilon = 0$ 이라 가정) 가 되서 learning rate 보다 작은 값으로 업데이트 될 것이라는 점이다.&lt;/p&gt;

&lt;p&gt;이를 논문에서는 $\dfrac{\hat{m}_t}{\sqrt{\hat{v}_t}}$ 를 &lt;strong&gt;signal-to-noise ratio(SNR)&lt;/strong&gt; 라고 하며, SNR 값이 작아질 수록 step size도 0에 근접하게 된다. 즉, learning rate 가 점점 작아져 자동적으로 수렴하게 된다는 이야기다. 지금까지 고민하던 고정 학습률의 고민을 해결해 준다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;step size : $\Delta_t = \theta_t - \theta_{t-1}$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그러나 조금 주의할 점은 데이터가 굉장히 sparse한 데이터 경우, 대부분의 $m_{t-1}$, $v_{t-1}$ 의 값은 0이 될 것이고, epoch($t$) 가 커질수록 $\hat{m}_t$, $\hat{v}_t$ 는 그 시점에서의 gradient 로 구성되어 있게 된다. 따라서 업데이트 식은 아래와 같게 된다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\theta_t \leftarrow \theta_{t-1} - \alpha \dfrac{1-\beta_1}{\sqrt{1-\beta_2}}&lt;/script&gt;

&lt;p&gt;이런 상황에서는 $\dfrac{1-\beta_1}{\sqrt{1-\beta_2}}$ 값이 1 보다 크기 때문에($beta_1 = 0.9, \beta_2 = 0.999$, 계산하면 약 3.16) 발산할 가능성이 높아진다. 이런 상황은 거의 드물다고 한다.&lt;/p&gt;

&lt;hr /&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Video&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Graph&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;video controls=&quot;controls&quot; style=&quot;width: 400px;&quot; autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot;&gt; &lt;source type=&quot;video/mp4&quot; src=&quot;/assets/ML/nn/Adam.mp4&quot; /&gt; &amp;lt;/source&amp;gt; &lt;/video&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;img src=&quot;/assets/ML/nn/Adam.png&quot; alt=&quot;Drawing&quot; style=&quot;width: 400px;&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;논문 결론 부에는 Adam 알고리즘이 큰 데이터 셋이나 고차원 파라미터 공간을 학습하는데 효율적이다라고 이야기 하고 있다.&lt;/p&gt;

&lt;p&gt;다음 시간에는 가중치 초기화와 배치 노말라이제이션에 대에서 이야기 해보도록 하겠다.&lt;/p&gt;
</description>
        <pubDate>Sat, 13 Jan 2018 14:17:06 +0900</pubDate>
        <link>http://simonjisu.github.io/deeplearning/2018/01/13/numpywithnn_5.html</link>
        <guid isPermaLink="true">http://simonjisu.github.io/deeplearning/2018/01/13/numpywithnn_5.html</guid>
        
        
        <category>DeepLearning</category>
        
      </item>
    
      <item>
        <title>DeepMindNLP 강의 정리 1</title>
        <description>&lt;h1 id=&quot;word-vectors-and-lexical-semantics&quot;&gt;Word Vectors and Lexical Semantics&lt;/h1&gt;

&lt;h2 id=&quot;how-to-represent-words&quot;&gt;How to represent Words&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;Natural language text = sequences of discrete symbols 이산 기호들의 배열(시퀀스)&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Navie representaion: one hot vectors $\in$ $R^{vocabulary}$, one hot 인코딩된 벡터들로 표현 아주큼&lt;/p&gt;

    &lt;p&gt;words = [‘딥마인드’, ‘워드’, ‘벡터’]
  df = pd.DataFrame(np.eye(len(words)), index=words, dtype=np.int)
  df&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;word&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;0&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;1&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;2&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;딥마인드&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;워드&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;벡터&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Classical IR: document and query vectors are superpositions of word vectors
&lt;script type=&quot;math/tex&quot;&gt;\hat{d_q}=\underset{d}{\arg \max} \sim(d,q)&lt;/script&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Similarly for word classification problems(e.g. Navie Bayes topic models)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Issues: sparse, orthogonal representations, semantically weak&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;semantic-similarity--&quot;&gt;Semantic similarity 의미론적 유사성&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;더 풍부하게 단어를 표현하고 싶다!!&lt;/li&gt;
  &lt;li&gt;Distributional semantics: 분산 의미론
    &lt;ul&gt;
      &lt;li&gt;Idea: produce dense vector representations based on the contex/use of words&lt;/li&gt;
      &lt;li&gt;Approaches:
        &lt;ul&gt;
          &lt;li&gt;count-based&lt;/li&gt;
          &lt;li&gt;predictive&lt;/li&gt;
          &lt;li&gt;task-based&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;count-based-methods&quot;&gt;Count-based methods&lt;/h3&gt;
&lt;p&gt;Define a basis vocabulary C of context words&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;고를 때는 linguistic intutition(언어적 직관, 주관적인) / statistics of the corpus 에 의해 고름&lt;/li&gt;
  &lt;li&gt;이것을 하는 이유는 a, the 같은 의미와 무관한 function word를 포함시키지 않기 위함&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Define a word window size $w$.&lt;/p&gt;

&lt;p&gt;Count the basis vocabulary words occurring $w$ words to the left or right of each instance of a target word in the corpus&lt;/p&gt;

&lt;p&gt;From a vector representation of the target word based on these counts&lt;/p&gt;

&lt;p&gt;Example:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from collections import Counter, defaultdict
from operator import itemgetter

def get_vocabulary_dict(contexts, stopwords):
vocabulary = Counter()
for sentence in contexts:
    words = [word for word in sentence.split() if word not in stopwords]
    vocabulary.update(words)
return vocabulary

def represent_vector(contexts_words, vocabulary):
vocab_len = len(vocabulary)
word2idx = {w: i for i, w in enumerate(vocabulary)}
count_based_vector = defaultdict()

for key_word, context_w in contexts_words.items():
    temp = np.zeros(vocab_len, dtype=np.int)
    for w in context_w:
        temp[word2idx[w]] += 1
    count_based_vector[key_word] = temp
return count_based_vector, word2idx

contexts = ['and the cute kitten purred and then',
        'the cute furry cat purred and miaowed',
        'that the small kitten miaowed and she',
        'the loud furry dog ran and bit']
stopwords=['and', 'then', 'she', 'that', 'the', 'cat', 'dog', 'kitten']
contexts_words = {'kitten': {'cute', 'purred', 'small', 'miaowed'},
              'cat': {'cute', 'furry', 'miaowed'},
              'dog': {'loud', 'furry', 'ran', 'bit'}}

vocabulary = get_vocabulary_dict(contexts, stopwords)
count_based_vector, word2idx = represent_vector(contexts_words, vocabulary)

word_idx_list = [w for i, w in sorted([(i, w) for w, i in word2idx.items()], key=itemgetter(0))]
df = pd.DataFrame(count_based_vector, index=word_idx_list)
df.T
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt; &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;cute&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;purred&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;furry&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;miaowed&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;small&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;loud&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;ran&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;bit&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;cat&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;dog&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;kitten&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Compare as similarity kernel:
$cosine(u, v) = \dfrac{u\cdot v}{|u|\times|v|}$&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def cosine(u, v):
    return np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))

print('kitten-cat:', cosine(df['kitten'], df['cat']))
print('kitten-dog:',cosine(df['kitten'], df['dog']))
print('cat-dog:',cosine(df['cat'], df['dog']))
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;kitten-cat: 0.57735026919&lt;/p&gt;

  &lt;p&gt;kitten-dog: 0.0&lt;/p&gt;

  &lt;p&gt;cat-dog: 0.288675134595&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Count-based method는 Navie Approach으로 접근&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Not all features are equal: we must distinguish counts that are high, because they are informative from those that are just independently frequent contexts.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Many Normalisation methods: TF-IDF, PMI, etc&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Some remove the need for norm-invariant similarity metrics&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;But… perhaps there are easier ways to address this problem of count-based mothods(and others, e.g. choice of basis context)&lt;/p&gt;

&lt;h3 id=&quot;neural-embedding-models&quot;&gt;Neural Embedding Models&lt;/h3&gt;
&lt;p&gt;Learning count based vecotrs produces an embedding matrix in $R^{|vocab|\times|context|}$&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt; &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;cute&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;purred&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;furry&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;miaowed&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;small&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;loud&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;ran&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;bit&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;cat&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;dog&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;kitten&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Rows are word vectors, so we can retrieve them with one hot vectors in ${0,1}^{&lt;/td&gt;
      &lt;td&gt;vocab&lt;/td&gt;
      &lt;td&gt;}$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;onehot_{cat} = \begin{bmatrix} 0 \newline 1 \newline 0 \end{bmatrix}, cat=onehot_{cat}^TE&lt;/script&gt;

&lt;p&gt;Symbols = unique vectors. Representation = embedding symbols with $E$&lt;/p&gt;

&lt;h4 id=&quot;generic-idea-behind-embedding-learning&quot;&gt;Generic(포괄적인) idea behind embedding learning:&lt;/h4&gt;
&lt;ol&gt;
  &lt;li&gt;Collect instances $t_i \in inst(t)$ of a word $t$ of vocab $V$&lt;/li&gt;
  &lt;li&gt;For each instance, collect its context words $c(t_i)$ (e.g. k-word window)&lt;/li&gt;
  &lt;li&gt;Define some score function $score(t_i, c(t_i); \theta, E)$ with upper bound on output&lt;/li&gt;
  &lt;li&gt;Define a loss:
&lt;script type=&quot;math/tex&quot;&gt;L=-\sum_{t\in V}\sum_{t_i \in inst(t)}score(t_i, c(t_i);\theta,E)&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;Estimate:
&lt;script type=&quot;math/tex&quot;&gt;\hat{\theta}, \hat{E}=\underset{\theta, E}{\arg \min}\ L&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;Use the estimated $E$ as your embedding matrix&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;problems-scoring-function&quot;&gt;Problems: Scoring function&lt;/h4&gt;

&lt;p&gt;Easy to design a useless scorer(e.g. ignore input, output upper bound)&lt;/p&gt;

&lt;p&gt;Implicitly define is useful&lt;/p&gt;

&lt;p&gt;Ideally, scorer:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Embeds $t_i$ with $E$&lt;/li&gt;
  &lt;li&gt;Produces a score which is a function of how well $t_i$ is accounted for by $c(t_i)$, and/or vice versa&lt;/li&gt;
  &lt;li&gt;Requires the word to account for the context(or the reverse) more than another word in the same place.&lt;/li&gt;
  &lt;li&gt;Produces a loss which is differentiable w.r.t. $\theta$ and $E$&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;cwcollobert-et-al-2011&quot;&gt;C&amp;amp;W(Collobert et al. 2011)&lt;/h4&gt;
&lt;p&gt;&lt;a href=&quot;http://www.jmlr.org/papers/volume12/collobert11a/collobert11a.pdf&quot;&gt;&lt;span style=&quot;color: #7d7ee8&quot;&gt;paper&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Interpretation: representations carry information about what neighbouring representations should look like&lt;/p&gt;

&lt;p&gt;where it belongs? 같은 정보를 포함&lt;/p&gt;

&lt;h4 id=&quot;cbow-mikolov-et-al-2013&quot;&gt;CBoW (Mikolov et al. 2013)&lt;/h4&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1301.3781&quot;&gt;&lt;span style=&quot;color: #7d7ee8&quot;&gt;paper&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Embed context words. Add them.&lt;/p&gt;

&lt;p&gt;Project back to vocabulary size. Softmax.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;softmax(l)_i=\dfrac{e^{l_i}}{\sum_{j}e^{l_i}}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{eqnarray} P(t_i|context(t_i) &amp; = &amp; softmax(\sum_{t_j\in context(t_i)} onehot_{t_j}^{t}\cdot E\cdot W_v) \newline
&amp; = &amp; softmax((\sum_{t_j\in context(t_i)} onehot_{t_j}^{t}\cdot E)\cdot W_v) \end{eqnarray} %]]&gt;&lt;/script&gt;

&lt;p&gt;Minimize Negative Log Likelihood:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L_{data} = -\sum_{t_i \in data}\log P(t_i|context(t_i))&lt;/script&gt;

&lt;p&gt;장점:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;All linear, so very fast. Basically a cheap way of applying one matrix to all inputs.&lt;/li&gt;
  &lt;li&gt;Historically, negative sampling used instead of expensive softmax.&lt;/li&gt;
  &lt;li&gt;NLL(negative log-likelihood) minimisation is more stable and is fast enough today&lt;/li&gt;
  &lt;li&gt;Variants: postion specific matrix per input(Ling et al. 2015)&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;skip-gram-mikolov-et-al-2013&quot;&gt;Skip-gram (Mikolov et al. 2013)&lt;/h4&gt;
&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1301.3781&quot;&gt;&lt;span style=&quot;color: #7d7ee8&quot;&gt;paper&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Target word predicts context words.&lt;/p&gt;

&lt;p&gt;Embed target word.&lt;/p&gt;

&lt;p&gt;Project into vocabulary. Softmax.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(t_j|t_i) = softmax(onehot_{t_i}^T\cdot E \cdot W_v)&lt;/script&gt;

&lt;p&gt;Learn to estimate Likelihood of context words.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;-\log P(context(t_i)|t_i) = -\log \prod_{t_j\in context(t_i)}P(t_j|t_i) - \sum_{t_j\in context(t_i)}\log P(t_j|t_i)&lt;/script&gt;

&lt;p&gt;장점:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Fast: One embedding versus $C$ (size of contexts) embeddings&lt;/li&gt;
  &lt;li&gt;Just read off probabilities from softmax&lt;/li&gt;
  &lt;li&gt;Similiar variants to CBoW possible: position specific projections&lt;/li&gt;
  &lt;li&gt;Trade off between efficiency and more structured notion of context&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;section&quot;&gt;기타&lt;/h4&gt;
&lt;p&gt;Word Embedding 하는 목적이 뭐냐? dense 한 vector 를 얻는 거다&lt;/p&gt;

&lt;p&gt;Word2Vec은 딥러닝이 아니라 shallow model(얕은 모델: 층이 하나밖에 없는)이다.&lt;/p&gt;

&lt;p&gt;Word2Vec == PMI Matrix factorization of count based models(Levy and Goldberg, 2014)&lt;/p&gt;

&lt;h3 id=&quot;specific-benefits-of-neural-approaches&quot;&gt;Specific Benefits of Neural Approaches&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Easy to learn, especially with good linear algebra libraries.&lt;/li&gt;
  &lt;li&gt;Highly parallel problem: minibatching, GPUs, distributed models.&lt;/li&gt;
  &lt;li&gt;Can predict other discrete aspects of context(dependencies, POS tags, etc). Can estimate these probabilities with counts, but sparsity quickly becomes a problems.&lt;/li&gt;
  &lt;li&gt;Can predict/condition on continuous contexts: e.g. images.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;evaluating-word-representations&quot;&gt;Evaluating Word Representations&lt;/h3&gt;
&lt;p&gt;Intrinsic Evaluation:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;WordSim-353 (Finkelstein et al. 2003)&lt;/li&gt;
  &lt;li&gt;SimLex-999 (Hill et al 2016, but has been around since 2014)&lt;/li&gt;
  &lt;li&gt;Word analogy task (Mikolov et al. 2013)&lt;/li&gt;
  &lt;li&gt;Embedding visualisation (nearest neighbours, T-SNE projection)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;t-SNE visualize, word 2 dimension cluster: &lt;span style=&quot;color: #e87d7d&quot;&gt; http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/ &lt;/span&gt;&lt;/p&gt;

&lt;p&gt;Extrinsic Evaluation:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Simply: do your embeddings improve performance on other task(s).&lt;/li&gt;
  &lt;li&gt;More …&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;task-based-embedding-learning&quot;&gt;Task-based Embedding Learning&lt;/h3&gt;
&lt;p&gt;Just saw methods for learning $E$ through minimising a loss.&lt;/p&gt;

&lt;p&gt;One use for $E$ is to get input features to a neural network from words.&lt;/p&gt;

&lt;p&gt;Neural network parameters are updated using gradients on loss $L(x, y, \theta)$:
&lt;script type=&quot;math/tex&quot;&gt;\theta_{t+1} = update(\theta_t, \triangledown_{\theta}L(x, y, \theta_t))&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;If $E \subseteq \theta$ then this update can modify $E$ (if we let it):
&lt;script type=&quot;math/tex&quot;&gt;E_{t+1} = update(E_t, \triangledown_E L(x, y, \theta_t))&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&quot;task-based-features-bow-classifiers&quot;&gt;Task-based Features: Bow Classifiers&lt;/h4&gt;
&lt;p&gt;Classify sentences/documents based on a variable number of word representations&lt;/p&gt;

&lt;p&gt;Simplest options: bag of vectors
&lt;script type=&quot;math/tex&quot;&gt;P(C|D)=softmax(W_C \sum_{t_i \in D} embed_E(t_i))&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Projection into logits (input to softmax) canbe arbitrarily complex. E.g.:
&lt;script type=&quot;math/tex&quot;&gt;P(C|D)=softmax(W_C \cdot \sigma (\sum_{t_i \in D} embed_E(t_i)))&lt;/script&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$C$: class&lt;/li&gt;
  &lt;li&gt;$D$: document&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Example tasks:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Sentiment analysis: tweets, movie reviews&lt;/li&gt;
  &lt;li&gt;Document classification: 20 Newsgroups&lt;/li&gt;
  &lt;li&gt;Author identification&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;task-based-features-bilingual-features&quot;&gt;Task-based Features: Bilingual Features&lt;/h4&gt;
&lt;p&gt;linguistic general approach: translations&lt;/p&gt;

&lt;p&gt;데이터가 많으면 그냥 pre-trained할 필요 없이 Embedding을 만든(random initialize) 담에 같이 train하면 됨, 만약에 데이터가 충분치 않다면, 미리 training하는 것이 좋아 보임&lt;/p&gt;

&lt;h2 id=&quot;torch-word2vec-&quot;&gt;Torch로 word2vec 짜보기&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.autograd import Variable
import torch.utils.data as data_utils
from torch.utils.data import DataLoader
from scipy.spatial.distance import cosine
import matplotlib.pylab as plt
from collections import Counter, defaultdict, deque
from nltk.tokenize import word_tokenize
from operator import itemgetter

class WORD2VEC(nn.Module):
    def __init__(self, N, half_window_size, lr, mode='cbow'):
        &quot;&quot;&quot;
        V: vocab_size
        N: hidden layer size(word vector size)
        window_size: how many words that you want to see near target word
        mode: cbow / skipgram
        &quot;&quot;&quot;
        super(WORD2VEC, self).__init__()

        self.V = None
        self.N = N
        # vocab and data setting
        self.half_window_size = half_window_size
        self.vocab_count = Counter()
        self.vocab2idx = defaultdict()
        self.vocab2idx['NULL'] = 0
        self.lr = lr

    def build_network(self):
        # network setting
        self.i2h = nn.Embedding(self.V, self.N, padding_idx=0)  # Embedding
        self.h2o = nn.Linear(self.N, self.V)
        self.softmax = nn.Softmax(dim=1)

    def get_vocabulary(self, corpus_list):
        for sentence in corpus_list:
            self.vocab_count.update(sentence)
        for i, w in enumerate(self.vocab_count.keys()):
            self.vocab2idx[w] = i + 1
        self.idx2vocab = {i: w for w, i in self.vocab2idx.items()}

    def generate_batch(self, sentence):
        # sentence size와 window size 결정 조건 확인(추가할것)
        target_words = []
        batch_windows = []

        # add padding data
        batch_sentence = ['NULL'] * self.half_window_size + sentence + ['NULL'] * self.half_window_size
        for i, target_word in enumerate(sentence):
            target_words.append(target_word)
            center_idx = i + self.half_window_size
            window = deque(maxlen=self.half_window_size * 2)
            window.extendleft(reversed(batch_sentence[i:center_idx]))
            window.extend(batch_sentence[center_idx + 1:center_idx + 1 + self.half_window_size])
            batch_windows.append(window)

        return batch_windows, target_words

    def data_transfer(self, corpus_list):
        &quot;&quot;&quot;batch_data = [windows(list), target(list)]&quot;&quot;&quot;
        batch_data = []
        for sentence in corpus_list:
            batch_windows, target_words = self.generate_batch(sentence)
            for window, target in zip(batch_windows, target_words):
                idxed_window = [self.vocab2idx[word] for word in window]
                idxed_target = [self.vocab2idx[target]]
                batch_data.append([idxed_window, idxed_target])
        return batch_data

    def tokenize_corpus(self, corpus):
        &quot;&quot;&quot;문장에 부호를 제거하고 단어 단위로 tokenize 한다&quot;&quot;&quot;
        check = ['.', '!', ':', ',', '(', ')', '?', '@', '#', '[', ']', '-', '+', '=', '_']
        corpus_list = []
        for sentence in corpus:
            temp = word_tokenize(sentence)
            temp = [word.lower() for word in temp if word not in check]
            corpus_list.append(temp)
        return corpus_list

    def fit(self, corpus):
        &quot;&quot;&quot;
        corpus를 학습시킬 데이터로 전환시켜준다. 모든 데이터는 단어의 vocab2idx를 근거해서 바뀐다.
        Vocab이 설정되면 네트워크도 같이 설정된다.
        batch_data = [window, target]
        &quot;&quot;&quot;
        corpus_list = self.tokenize_corpus(corpus)
        self.get_vocabulary(corpus_list)
        self.V = len(self.vocab2idx)
        batch_data = self.data_transfer(corpus_list)
        self.build_network()
        print('fit done!')
        return batch_data

    def forward(self, X):
        embed = self.i2h(X)  # batch x V x N
        h = Variable(embed.data.mean(dim=1))  # batch x N
        output = self.h2o(h)  # batch x V
        probs = self.softmax(output)  # batch x V
        return output, probs

#################################################
# Sample Data
#################################################

def create_sample_data():
    corpus = ['the king loves the queen',
              'the queen loves the king',
              'the dwarf hates the king',
              'the queen hates the dwarf',
              'the dwarf poisons the king',
              'the dwarf poisons the queen',]

    return corpus


def get_data_loader(batch_data, batch_size, num_workers, shuffle=False):
    features = torch.LongTensor([batch_data[i][0] for i in range(len(batch_data))])
    targets = torch.LongTensor([batch_data[i][1] for i in range(len(batch_data))])
    data = data_utils.TensorDataset(features, targets)

    loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)

    return loader

#################################################
# Train
#################################################

def word2vec_train(corpus, N, half_window_size=2, lr=0.01, n_epoch=1000, batch_size=10, print_epoch=100, num_workers=2, shuffle=False):
    &quot;&quot;&quot;본격적으로 데이터를 학습한다&quot;&quot;&quot;
    word2vec = WORD2VEC(N=N, half_window_size=half_window_size, lr=lr)
    batch_data = word2vec.fit(corpus)
    loader = get_data_loader(batch_data, batch_size, num_workers, shuffle)

    F = nn.CrossEntropyLoss()
    optimizer = optim.SGD(word2vec.parameters(), lr=word2vec.lr)

    loss_list = []
    for epoch in range(n_epoch):

        for batch_X, batch_y in loader:
            optimizer.zero_grad()
            batch_X = Variable(batch_X)
            batch_y = Variable(batch_y)

            output, probs = word2vec.forward(batch_X)
            loss = F(output, batch_y.squeeze(-1))  # must be 1-d tensor in labels

            loss.backward()
            optimizer.step()
        loss_list.append(loss.data[0])

        if epoch % print_epoch == 0:
            print('#{}| loss:{}'.format(epoch, loss.data[0]))

    return word2vec, loss_list
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Training은 아래와 같다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;corpus = create_sample_data()
N = 2
half_window_size = 2
lr = 0.01
n_epoch = 3000
print_epoch = 200
batch_size = 4
num_workers=2
shuffle=False
word2vec, loss_list = word2vec_train(corpus, N=N, half_window_size=half_window_size,
  lr=lr, n_epoch=n_epoch, batch_size=batch_size, print_epoch=print_epoch,
  num_workers=num_workers, shuffle=shuffle)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/Deepnlp/lec1/Loss.png&quot; alt=&quot;Drawing&quot; style=&quot;width: 300px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;2차원으로 embedding 했으니 평면에 그려보았다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/Deepnlp/lec1/vector.png&quot; alt=&quot;Drawing&quot; style=&quot;width: 300px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;조금더 큰 데이터를 그냥 CBOW 혹은 Skip-gram으로 학습 시킬 경우 속도가 아주 느린 것을 발견 할 수 가 있다. 이는 말뭉치가 많아질 수록 단어의 수도 많아 지기 때문에, 말단에 Hierarchical Softmax와 Negative Sampling 방법을 쓴다고 한다. 김범수님의 블로그 &lt;a href=&quot;https://shuuki4.wordpress.com/2016/01/27/word2vec-%EA%B4%80%EB%A0%A8-%EC%9D%B4%EB%A1%A0-%EC%A0%95%EB%A6%AC/&quot;&gt;[&lt;span style=&quot;color: #7d7ee8&quot;&gt;링크&lt;/span&gt;]&lt;/a&gt; 참조&lt;/p&gt;
</description>
        <pubDate>Tue, 02 Jan 2018 21:39:31 +0900</pubDate>
        <link>http://simonjisu.github.io/deepnlp/2018/01/02/deepmindnlp1.html</link>
        <guid isPermaLink="true">http://simonjisu.github.io/deepnlp/2018/01/02/deepmindnlp1.html</guid>
        
        
        <category>Deepnlp</category>
        
      </item>
    
      <item>
        <title>NUMPY with NN - 4: Backpropagation</title>
        <description>&lt;h1 id=&quot;numpy--neural-network-basic---4&quot;&gt;Numpy로 짜보는 Neural Network Basic - 4&lt;/h1&gt;
&lt;hr /&gt;

&lt;h2 id=&quot;backpropagation&quot;&gt;오차역전파(Backpropagation)&lt;/h2&gt;

&lt;h3 id=&quot;section&quot;&gt;연쇄법칙의 원리&lt;/h3&gt;
&lt;p&gt;합성 함수의 미분은 합성 함수를 구성하는 각 함수의 미분의 곱으로 나타낼 수 있다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{cases} z = t^2 \\ t = x + y \end{cases}&lt;/script&gt;

&lt;p&gt;위 식의 미분을 나타내면
&lt;script type=&quot;math/tex&quot;&gt;\frac{\partial{z}}{\partial{x}} = \frac{\partial{z}}{\partial{t}} \cdot \frac{\partial{t}}{\partial{x}}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;따라서 $z$, $t$ 식을 미분하게 되면&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\frac{\partial{z}}{\partial{t}} = 2t&lt;/script&gt;
&lt;script type=&quot;math/tex&quot;&gt;\frac{\partial{t}}{\partial{x}}=1&lt;/script&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\therefore\  \frac{\partial{z}}{\partial{x}} = \frac{\partial{z}}{\partial{t}} \cdot \frac{\partial{t}}{\partial{x}} = 2t \cdot 1 = 2(x+y)&lt;/script&gt;

&lt;p&gt;우리의 목적은 $L$ 에 대해서 $W$ 를 미분하여 조금씩 업데이트 하는 것임으로 아래와 같다고 할 수 있다.
&lt;script type=&quot;math/tex&quot;&gt;\frac{\partial{L}}{\partial{W}} = \frac{\partial{L}}{\partial{Y}} \cdot \frac{\partial{Y}}{\partial{W}}&lt;/script&gt;&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;덧셈노드와 곱셈노드의 역전파&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/nn/NN_add.png&quot; alt=&quot;Drawing&quot; style=&quot;width: 400px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;(그림출처: ratsgo님의 블로그[&lt;a href=&quot;https://ratsgo.github.io/deep%20learning/2017/05/14/backprop/&quot;&gt;&lt;span style=&quot;color: #7d7ee8&quot;&gt;링크&lt;/span&gt;&lt;/a&gt;])&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{cases} L(z) \\ z = x + y \end{cases}&lt;/script&gt;

&lt;p&gt;각각 미분하게 되면&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{cases}
    \dfrac{\partial{L}}{\partial{z}} \\
    \dfrac{\partial{z}}{\partial{x}} =
    \dfrac{\partial{z}}{\partial{y}} = 1
  \end{cases}&lt;/script&gt;

&lt;p&gt;따라서 $L$ 을 각각 $x$ 와 $y$ 로 미분하려면&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{cases}
    \dfrac{\partial{L}}{\partial{x}} = \dfrac{\partial{L}}{\partial{z}} \cdot \dfrac{\partial{z}}{\partial{x}} = \dfrac{\partial{L}}{\partial{z}} \cdot 1 \\
    \dfrac{\partial{L}}{\partial{y}} = \dfrac{\partial{L}}{\partial{z}} \cdot \dfrac{\partial{z}}{\partial{y}} = \dfrac{\partial{L}}{\partial{z}} \cdot 1
  \end{cases}&lt;/script&gt;

&lt;p&gt;따라서 &lt;strong&gt;덧셈&lt;/strong&gt; 노드는 들어온 신호($\frac{\partial{L}}{\partial{z}}$)를 &lt;strong&gt;그대로&lt;/strong&gt; 보낸다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/nn/NN_multiply.png&quot; alt=&quot;Drawing&quot; style=&quot;width: 400px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;(그림출처: ratsgo님의 블로그[&lt;a href=&quot;https://ratsgo.github.io/deep%20learning/2017/05/14/backprop/&quot;&gt;&lt;span style=&quot;color: #7d7ee8&quot;&gt;링크&lt;/span&gt;&lt;/a&gt;])&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{cases} L(z) \\ z = x \times y \end{cases}&lt;/script&gt;

&lt;p&gt;각각 미분하게 되면&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{cases}
    \dfrac{\partial{L}}{\partial{z}} \\
    \dfrac{\partial{z}}{\partial{x}} = y \\
    \dfrac{\partial{z}}{\partial{y}} = x
  \end{cases}&lt;/script&gt;

&lt;p&gt;따라서 $L$ 을 각각 $x$ 와 $y$ 로 미분하려면&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{cases}
    \dfrac{\partial{L}}{\partial{x}} = \dfrac{\partial{L}}{\partial{z}} \cdot \dfrac{\partial{z}}{\partial{x}} = \dfrac{\partial{L}}{\partial{z}} \cdot y \\
    \dfrac{\partial{L}}{\partial{y}} = \dfrac{\partial{L}}{\partial{z}} \cdot \dfrac{\partial{z}}{\partial{y}} = \dfrac{\partial{L}}{\partial{z}} \cdot x
  \end{cases}&lt;/script&gt;

&lt;p&gt;따라서 &lt;strong&gt;곱셈&lt;/strong&gt; 노드는 들어온 신호에 서로 바뀐 입력신호 값을 &lt;strong&gt;곱해서&lt;/strong&gt; 하류로 보낸다.&lt;/p&gt;

&lt;h2 id=&quot;sigmoid---&quot;&gt;Sigmoid 계층의 순전파와 역전파&lt;/h2&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;y = \frac{1}{1+\exp(-x)}&lt;/script&gt;

&lt;h3 id=&quot;forward&quot;&gt;Forward&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/nn/NN_sigmoid_forward.png&quot; alt=&quot;Drawing&quot; style=&quot;width: 600px;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;backward&quot;&gt;Backward&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/nn/NN_sigmoid_back.png&quot; alt=&quot;Drawing&quot; style=&quot;width: 600px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/nn/NN_sigmoid_back2.png&quot; alt=&quot;Drawing&quot; style=&quot;width: 600px;&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;h4 id=&quot;section-2&quot;&gt;역전파 1단계 ( / )&lt;/h4&gt;

  &lt;p&gt;”/” 연산은 입력변수 x를 $\dfrac{1}{x}$ 로 바꿔준다. 즉 $f_1(x) = \dfrac{1}{x}$ 가 된다.&lt;/p&gt;

  &lt;p&gt;미분을 하게 되면 $\dfrac{\partial{f_1}}{\partial{x}} = -\dfrac{1}{x^2} = -y^2$가 되서 입력신호를 하류로 보낸다.&lt;/p&gt;

  &lt;h4 id=&quot;section-3&quot;&gt;역전파 2단계 ( + )&lt;/h4&gt;

  &lt;p&gt;”+” 연산은 신호를 그대로 하류로 흘러 보낸다&lt;/p&gt;

  &lt;h4 id=&quot;exp&quot;&gt;역전파 3단계 (exp)&lt;/h4&gt;

  &lt;p&gt;“exp”연산은 $f_2(x) = exp(x)$ 이며, 미분도 $\dfrac{\partial{f_2}}{\partial{x}} = exp(x)$ 로 그대로 곱해서 하류로 보낸다.&lt;/p&gt;

  &lt;h4 id=&quot;x-&quot;&gt;역전파 4단계 ( x )&lt;/h4&gt;

  &lt;p&gt;”$\times$”연산은 서로 바뀐 입력신호의 값을 곱해서 보낸다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;따라서, 최종적으로 시그모이드의 역전파 출력값은 아래와 같다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/nn/NN_sigmoid_last.png&quot; alt=&quot;Drawing&quot; style=&quot;width: 400px;&quot; /&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\dfrac{\partial{L}}{\partial{y}}y^{2}\exp(-x)
&amp;= \dfrac{\partial{L}}{\partial{y}} \dfrac{1}{[1+\exp(-x)]^2}\exp(-x) \\
&amp;= \dfrac{\partial{L}}{\partial{y}} \dfrac{1}{1+\exp(-x)} \dfrac{\exp(-x)}{1+\exp(-x)} \\
&amp;= \dfrac{\partial{L}}{\partial{y}}y(1-y) \\
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;이것을 코드로 구현하게 되면&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;class Sigmoid(object):
    def __init__(self):
        self.out = None  # 역전파시 곱해야 하기 때문에 저장해둔다

    def forward(self, x):
        out = 1 / (1 + np.exp(-x))
        self.out = out

        return out

    def backward(self, dout):
        dx = dout * self.out * (1 - self.out)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;affine--affine-transform&quot;&gt;Affine 계층과 Affine Transform&lt;/h2&gt;
&lt;p&gt;기하학에서 신경망 순전파 때 수행하는 행렬의 내적을 Affine Transform이라 하며, Affine 계층은 어파인 변환을 수행 처리하는 계층이다.&lt;/p&gt;

&lt;p&gt;위키백과[&lt;a href=&quot;https://ko.wikipedia.org/wiki/%EC%95%84%ED%95%80_%EB%B3%80%ED%99%98&quot;&gt;&lt;span style=&quot;color: #7d7ee8&quot;&gt;링크&lt;/span&gt;&lt;/a&gt;]&lt;/p&gt;

&lt;h3 id=&quot;forward-1&quot;&gt;Forward&lt;/h3&gt;

&lt;p&gt;$A = X \cdot W + B$&lt;/p&gt;

&lt;h3 id=&quot;backward-1&quot;&gt;Backward&lt;/h3&gt;

&lt;p&gt;$\begin{cases}
    \dfrac{\partial{L}}{\partial{X}} = \dfrac{\partial{L}}{\partial{A}} \cdot \dfrac{\partial{A}}{\partial{X}} = \dfrac{\partial{L}}{\partial{A}} \cdot W^T &lt;br /&gt;
    \dfrac{\partial{L}}{\partial{W}} = \dfrac{\partial{L}}{\partial{A}} \cdot \dfrac{\partial{A}}{\partial{W}} = X^T \cdot \dfrac{\partial{L}}{\partial{A}} &lt;br /&gt;
    \dfrac{\partial{L}}{\partial{B}} = 1
  \end{cases}$&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;class Affine(object):
    def __init__(self, W, b):
        self.W = W
        self.b = b
        self.x = None
        self.dW = None
        self.db = None

    def forward(self, x):
        self.x = x
        out = np.dot(self.x, self.W) + self.b

        return out

    def backward(self, dout):
        dx = np.dot(dout, self.W.T)
        self.dW = np.dot(self.x.T, dout)
        self.db = np.sum(self.b, axis=0)

        return dx
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;backpropogation--&quot;&gt;Backpropogation 사용한 학습구현&lt;/h2&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import collections
from layers import *

class TwoLayer(object):
    def __init__(self, input_size, hidden_size, output_size, weight_init_std=0.01):
        self.params = {}
        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)
        self.params['b1'] = np.zeros(hidden_size)
        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)
        self.params['b2'] = np.zeros(hidden_size)

        # 계층 생성
        self.layers = collections.OrderedDict()
        self.layers['Affine1'] = Affine(self.params['W1'], self.params['b1'])
        self.layers['ReLu1'] = ReLu()
        self.layers['Affine2'] = Affine(self.params['W2'], self.params['b2'])

        self.lastLayer = SoftmaxWithLoss()

    def predict(self, x):
        for layer in self.layers.values():
            x = layer.forward(x)

        return x

    # x: 입력 데이터, t: 정답 데이터
    def loss(self, x, t):
        y = self.predict(x)
        return self.lastLayer.forward(y, t)

    def accuracy(self, x, t):
        y = self.predict(x)
        y = np.argmax(y, axis=1)
        if t.ndim != 1: t = np.argmax(t, axis=1)

        acc = np.sum(y == t) / float(x.shape[0])
        return acc

    def gradient(self, x, t):
        # forward
        self.loss(x, t)

        # backward
        dout = 1
        dout = self.lastLayer.backward(dout)

        layers = list(self.layers.values())
        layers.reverse()

        for layer in layers:
            dout = layer.backward(dout)

        # save
        grads = {}
        grads['W1'] = self.layers['Affine1'].dW
        grads['b1'] = self.layers['Affine1'].db
        grads['W2'] = self.layers['Affine2'].dW
        grads['b2'] = self.layers['Affine2'].db

        return grads
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;TwoLayer Neural Network 를 생성하는 객체는 따로 파일에 저장하고 불러내는 것이 좋다. OrderedDict은 dictionary 형태로 입력 순서를 기억해주는 좋은 함수다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from dataset.mnist import load_mnist
from two_layer_nn import TwoLayer

# data_loading
(x_train, y_train), (x_test, y_test) = load_mnist(normalize=True, one_hot_label=True)

train_loss_list = []
train_acc_list = []
test_acc_list = []

#highper parameter
epoch_num = 10000
train_size = x_train.shape[0]
batch_size = 100
alpha = 0.01  # learning rate
epsilon = 1e-6

# 1에폭당 반복 수
iter_per_epoch = max(train_size / batch_size, 1)

start = time.time()
nn = TwoLayer(input_size=784, hidden_size=100, output_size=10, weight_init_std=0.01)
for epoch in range(epoch_num):
    # get mini batch:
    batch_mask = np.random.choice(train_size, batch_size) # shuffle 효과
    x_batch = x_train[batch_mask]
    y_batch = y_train[batch_mask]

    # gradient 계산
    grad = nn.gradient(x_batch, y_batch)

    # update
    for key in ['W1', 'b1', 'W2', 'b2']:
        nn.params[key] = nn.params[key] - alpha * grad[key]

    # record
    loss = nn.loss(x_batch, y_batch)
    train_loss_list.append(loss)

    # 1에폭당 정확도 계산
    if epoch % iter_per_epoch == 0:
        train_acc = nn.accuracy(x_train, y_train)
        test_acc = nn.accuracy(x_test, y_test)
        train_acc_list.append(train_acc)
        test_acc_list.append(test_acc)
        print('# {0} | trian acc: {1:.5f} | test acc: {2:.5f}'.format(epoch, train_acc, test_acc))

end = time.time()
print('total time:', (end - start))

# 결과
# 0 | trian acc: 0.10775 | test acc: 0.10700
# 600 | trian acc: 0.10775 | test acc: 0.10700
# 1200 | trian acc: 0.10775 | test acc: 0.10700
# 1800 | trian acc: 0.10775 | test acc: 0.10700
# 2400 | trian acc: 0.10775 | test acc: 0.10700
# 3000 | trian acc: 0.10775 | test acc: 0.10700
# 3600 | trian acc: 0.10775 | test acc: 0.10700
# 4200 | trian acc: 0.10775 | test acc: 0.10700
# 4800 | trian acc: 0.10775 | test acc: 0.10700
# 5400 | trian acc: 0.10775 | test acc: 0.10700
# 6000 | trian acc: 0.10775 | test acc: 0.10700
# 6600 | trian acc: 0.10775 | test acc: 0.10700
# 7200 | trian acc: 0.10775 | test acc: 0.10700
# 7800 | trian acc: 0.10775 | test acc: 0.10700
# 8400 | trian acc: 0.10775 | test acc: 0.10700
# 9000 | trian acc: 0.10775 | test acc: 0.10700
# 9600 | trian acc: 0.10775 | test acc: 0.10700
# total time: 61.07117795944214
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;학습은 전혀 안되지만 수치 미분보다 더 빠르게 진행된다는 것을 알 수 있다.&lt;/p&gt;

&lt;p&gt;왜 학습이 안됐을까에 대해서는 담은 시간에 이야기 하겠다.&lt;/p&gt;
</description>
        <pubDate>Fri, 15 Dec 2017 12:21:48 +0900</pubDate>
        <link>http://simonjisu.github.io/deeplearning/2017/12/15/numpywithnn_4.html</link>
        <guid isPermaLink="true">http://simonjisu.github.io/deeplearning/2017/12/15/numpywithnn_4.html</guid>
        
        
        <category>DeepLearning</category>
        
      </item>
    
      <item>
        <title>NUMPY with NN - 3: Loss Function</title>
        <description>&lt;h1 id=&quot;numpy--neural-network-basic---3&quot;&gt;Numpy로 짜보는 Neural Network Basic - 3&lt;/h1&gt;
&lt;hr /&gt;

&lt;p&gt;저번 시간에는 Feedforward 과정을 보았는데, 정확도가 8.578% 밖에 안됐다. 이제 Neural Network가 데이터로부터 어떻게 학습하여 정확도를 올리는지 보자.&lt;/p&gt;

&lt;h2 id=&quot;loss-function&quot;&gt;손실 함수(Loss Function)&lt;/h2&gt;
&lt;p&gt;왜 우리의 목표인 정확도를 안쓰고 손실 함수라는 매개변수를 설정하는 걸까?&lt;/p&gt;

&lt;p&gt;그 이유는 먼저 밝히면 신경망 학습에 미분이 사용되기 때문이다. 최적의 가중치(그리고 편향)을 탐색할 때 손실 함수의 값을 가능한 작게하는 가중치 값을 찾는데, 이때 가중치의 미분을 계산하고, 그 미분 값을 단서로 가중치를 서서히 갱신하는 과정을 거친다. 그러나 손실함수에 정확도를 쓰면 가중치의 미분이 대부분의 장소에서 0이 되기 때문에 가중치 값을 갱신할 수가 없다.&lt;/p&gt;

&lt;p&gt;mnist 데이터의 경우 최종 출력층에 나온 $y$ 값은 Softmax에 의해 $(10 \times 1)$ 행렬의 확률로 출력되고, 그에 응답하는 정답 $t$ 는 one-hot encoded된 행렬이다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;y = np.array([0.05, 0.01, 0.7, 0.14, 0.05, 0.0, 0.05, 0.0, 0.0, 0.0])
t = np.array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0])
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;mse&quot;&gt;평균 제곱 오차(MSE)&lt;/h3&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;E=\frac{1}{2}\sum_{k}{(y_k - t_k)^2}&lt;/script&gt;&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def mean_squared_error(y, t):
    return (1/2) * np.sum((y - t) ** 2)

mean_squared_error(y, t)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;0.05860000000000002&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;cross-entropy&quot;&gt;교차 엔트로피 오차(Cross Entropy)&lt;/h3&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;E=-\sum_{k}{t_k\log{y_k}}&lt;/script&gt;&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def cross_entropy_error(y, t):
    delta = 1e-7
    return -np.sum(t * np.log(y + delta))

cross_entropy_error(y, t)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;0.51082545709933802&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;여기서 delta라는 작은 값을 더해준 이유는 y값이 0이면 $\log 0= -\inf$가 되서 미분 계산이 불가능하기 때문이다.&lt;/p&gt;

&lt;h3 id=&quot;section&quot;&gt;미니 배치 학습&lt;/h3&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;E=-\frac{1}{N}\sum_{n}{\sum_{k}{t_k\log{y_k}}}&lt;/script&gt;

&lt;p&gt;엄청나게 많은 양의 데이터를 사용하는데 오차를 한번에 계산하려면 오랜 시간이 든다. 따라서 작은 양의 데이터를 사용해 조금씩 오차의 합을 구한다음에 그것의 평균을 내면 전체의 근사치로 사용할 수 있다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def cross_entropy_error(y, t):
    delta = 1e-7
    if y.ndim == 1:
        t = t.reshape(1, t.size)
        y = y.reshape(1, y.size)

    batch_size = y.shape[0]
    return -np.sum(t * np.log(y[np.arange(batch_size), t] + delta)) / batch_size
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;h2 id=&quot;section-1&quot;&gt;미분&lt;/h2&gt;

&lt;p&gt;목적을 정했으니 이제 학습에 들어가면된다. 손실함수를 가중치에 대한 미분을 구해야 한다.&lt;/p&gt;

&lt;h3 id=&quot;section-2&quot;&gt;수치 미분과 중심 차분법&lt;/h3&gt;

&lt;p&gt;수치 미분이란 변화율이라고 볼 수 있다. $x$에서 $h$만큼 변했을 때 $f(x)$의 변화량을 나타낸 것이다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{df(x)}{dx} = \lim_{h\rightarrow0}{\frac{f(x+h) - f(x)}{h}}&lt;/script&gt;

&lt;p&gt;그러나 $f(x+h) - f(x)$ 는 굉장히 작은 수라 컴퓨터로 구현시 Underflow문제에 봉착하게 된다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;np.float32(1e-50)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;0.0&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;따라서 수치 미분에서 $h$는 되도록 너무 작은 값은 못쓴다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;중심 차분법&lt;/strong&gt; 을 이용하면 미분은 아래와 같다.&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\frac{df(x)}{dx} = \lim_{h\rightarrow0}{\frac{f(x+h) - f(x-h)}{2h}}&lt;/script&gt;&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def numerical_diff(f, x):
    h = 1e-4
    return (f(x + h) - f(x - h)) / (2*h)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;예시 함수 $y = 0.01 x^2 + 0.1 x$ 의 수치 미분을 보자&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def f1(x):
    return 0.01 * x**2 + 0.1 * x

print(numerical_diff(f1, 5))
print(numerical_diff(f1, 10))
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;0.1999999999990898&lt;/p&gt;

  &lt;p&gt;0.2999999999986347&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;정확하게 0.2와 0.3이 나오지 않는 이유는 이진수 부동소수점 방식[&lt;a href=&quot;https://ko.wikipedia.org/wiki/%EB%B6%80%EB%8F%99%EC%86%8C%EC%88%98%EC%A0%90&quot;&gt;&lt;span style=&quot;color: #7d7ee8&quot;&gt;링크&lt;/span&gt;&lt;/a&gt;]의 정확도 문제니까 round 함수를 사용해 반올림하여 사용해야한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/nn/numerical_diff.png&quot; alt=&quot;Drawing&quot; style=&quot;width: 500px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;2차원 이상의 데이터는 어떻게 짜야할까? 아래의 코드를 참조하자&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def numerical_gradient(f, x):
    h = 1e-4  # 0.0001
    grad = np.zeros_like(x)

    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])
    while not it.finished:
        idx = it.multi_index
        tmp_val = x[idx]
        x[idx] = float(tmp_val) + h
        fxh1 = f(x)  # f(x+h)

        x[idx] = tmp_val - h
        fxh2 = f(x)  # f(x-h)
        grad[idx] = (fxh1 - fxh2) / (2 * h)

        x[idx] = tmp_val  # 값 복원
        it.iternext()

    return grad
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;ul&gt;
  &lt;li&gt;np.nditer: iterator 객체를 만들어 준다. 행마다 원소가 iterate 된다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;gradient-descent&quot;&gt;Gradient Descent&lt;/h3&gt;

&lt;p&gt;경사 하강법이란 현 위치에서 기울어진 방향으로 일정 거리를 이동하고, 또 그 위치에서 기울기를 구해서 그 방향으로 계속 나아가는 방법이다. 이렇게 해서 손실함수를 점점 작게 만들어 손실함수의 최저점으로 이끌고 간다(가능하다면).&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;w_{new} = w_{old} - \eta \cdot \frac{\partial f}{\partial w_{old}}&lt;/script&gt;

&lt;p&gt;$\eta$ 는 학습률(learning rate)라고 하며 갱신하는 양을 나타낸다.&lt;/p&gt;

&lt;p&gt;아래 그림은 주변이 높고 중앙이 낮은 모양(그릇을 생각하자)을 3차원에서 2차원으로 그렸을 때, $(4, 5)$ 점에서 시작해서 경사 하강법으로 최저점을 찾는 과정이다. 함수는 $f(x) = x^2\ , x\in \mathbb{R}^3$ 다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/nn/GDanimation.gif&quot; alt=&quot;Drawing&quot; style=&quot;width: 500px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-3&quot;&gt;학습 알고리즘&lt;/h2&gt;

&lt;h3 id=&quot;nn----&quot;&gt;간단한 NN 으로 가중치의 미분 구해보기&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;class simpleNet(object):
    def __init__(self):
        # Input size = 2
        # Output size = 3
        self.W = np.random.normal(size=(2,3))

    def predict(self, x):
        a = np.dot(x, self.W)
        y = softmax(a)

        return y

    def loss(self, x, t):
        y = self.predict(x)
        loss = cross_entropy_error(y, t)

        return loss

x = np.array([0.6, 0.9])
t = np.array([0, 0, 1])
nn = simpleNet()

f = lambda w: nn.loss(x, t)
dW = numerical_gradient(f, nn.W)
print(dW)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;[[ 0.05244267  0.24743359 -0.29987626]&lt;/p&gt;

  &lt;p&gt;[ 0.07866401  0.37115039 -0.44981439]]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;sgd&quot;&gt;확률적 경사 하강법(SGD)&lt;/h3&gt;
&lt;p&gt;아래 방법은 데이터를 무작위로 가져와서 학습하는 것이기 때문에 확률적 경사 하강법(Stochastic Gradient Descent)이라고도 한다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;1단계: 미니배치&lt;/p&gt;

    &lt;p&gt;훈련 데이터 중 일부를 무작위로 가져온 데이터를 미니 배치라고 하며, 미니 배치의 손실 함수 값을 줄이는 것이 목표다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;2단계: 기울기 산출&lt;/p&gt;

    &lt;p&gt;미니배치의 손실 함수 값을 줄이기 위해 각 가중치 매개변수의 기울기를 구한다. 기울기는 손실 함수의 값을 가장 작게 만든다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;3단계: 매개변수(가중치) 갱신&lt;/p&gt;

    &lt;p&gt;가중치 매개변수를 기울기 방향으로 아주 조금 갱신한다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;4단계: 반복&lt;/p&gt;

    &lt;p&gt;1~3 단계를 반복한다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;neural-network-&quot;&gt;2층 Neural Network 실습&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/nn/NN_3.png&quot; alt=&quot;Drawing&quot; style=&quot;width: 350px;&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Input Size: m = 3&lt;/li&gt;
  &lt;li&gt;Hidden Size: h = 4&lt;/li&gt;
  &lt;li&gt;Output Size: o = 3
&lt;script type=&quot;math/tex&quot;&gt;X_{(batch,\ m)} \cdot W1_{(m,\ h)} + B1_{(batch,\ h)} \rightarrow A1_{(batch,\ h)}&lt;/script&gt;
&lt;script type=&quot;math/tex&quot;&gt;sigmoid(A1_{(batch,\ h)}) \rightarrow Z1_{(batch,\ h)}&lt;/script&gt;
&lt;script type=&quot;math/tex&quot;&gt;Z1_{(batch,\ h)} \cdot W1_{(h,\ o)} + B1_{(batch,\ o)} \rightarrow A2_{(batch,\ o)}&lt;/script&gt;
&lt;script type=&quot;math/tex&quot;&gt;\sigma(A2_{(batch,\ o)}) \rightarrow Y_{(batch,\ o)}&lt;/script&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이것을 구현해보자. 수치로 구현한 2층 Neural Network 코드는 [&lt;a href=&quot;https://github.com/WegraLee/deep-learning-from-scratch/blob/master/ch04/two_layer_net.py&quot;&gt;&lt;span style=&quot;color: #7d7ee8&quot;&gt;여기&lt;/span&gt;&lt;/a&gt;]서 가져왔다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;(x_train, y_train), (x_test, y_test) = load_mnist(normalize=True, one_hot_label=True)

train_loss_list = []
train_acc_list = []
test_acc_list = []

#highper parameter
epoch_num = 1
train_size = x_train.shape[0]
batch_size = 100
alpha = 0.1  # learning rate
epsilon = 1e-6

# 1에폭당 반복 수
iter_per_epoch = max(train_size / batch_size, 1)
nn = TwoLayer(input_size=784, hidden_size=100, output_size=10)

start = time.time()
for epoch in range(epoch_num):
    # get mini batch:
    batch_mask = np.random.choice(train_size, batch_size) # shuffle 효과
    x_batch = x_train[batch_mask]
    y_batch = y_train[batch_mask]

    # gradient 계산
    grad = nn.num_gradient(x_batch, y_batch)

    # update
    for key in ['W1', 'b1', 'W2', 'b2']:
        nn.params[key] = nn.params[key] - alpha * grad[key]

    # record
    loss = nn.loss(x_batch, y_batch)
    train_loss_list.append(loss)

    # 1에폭당 정확도 계산
    if epoch % iter_per_epoch == 0:
        train_acc = nn.accuracy(x_train, y_train)
        test_acc = nn.accuracy(x_test, y_test)
        train_acc_list.append(train_acc)
        test_acc_list.append(test_acc)
        print('trian acc: {0:.5f} | test acc: {1:.5f}'.format(train_acc, test_acc))

    # stop point
    if epoch &amp;gt; 10:
        stop_point = np.sum(np.diff(np.array(train_loss_list[i-11:])) &amp;lt; epsilon)
        if stop_point == 10:
            print(epoch)
            break

end = time.time()
print('total time:', (end - start))
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;blockquote&gt;
  &lt;table&gt;
    &lt;tbody&gt;
      &lt;tr&gt;
        &lt;td&gt;trian acc: 0.10442&lt;/td&gt;
        &lt;td&gt;test acc: 0.10280&lt;/td&gt;
      &lt;/tr&gt;
    &lt;/tbody&gt;
  &lt;/table&gt;

  &lt;p&gt;total time: 175.5657160282135&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;2단계에서 수치미분을 구현하기는 쉬우나 업데이트 하는데 시간이 너무 오래 걸린다. 1 Epoch만 돌렸는데 175초 걸렸다.&lt;/p&gt;

&lt;p&gt;따라서 가중치 매개변수의 기울기를 효율적으로 계산하는 &lt;strong&gt;오차역전파&lt;/strong&gt; 방법으로 업데이트 해야한다. 이건 다음 글에서 계속 진행하겠다.&lt;/p&gt;
</description>
        <pubDate>Sun, 10 Dec 2017 14:06:55 +0900</pubDate>
        <link>http://simonjisu.github.io/deeplearning/2017/12/10/numpywithnn_3.html</link>
        <guid isPermaLink="true">http://simonjisu.github.io/deeplearning/2017/12/10/numpywithnn_3.html</guid>
        
        
        <category>DeepLearning</category>
        
      </item>
    
      <item>
        <title>NUMPY with NN - 2: Activation Function</title>
        <description>&lt;h1 id=&quot;numpy--neural-network-basic---2&quot;&gt;Numpy로 짜보는 Neural Network Basic - 2&lt;/h1&gt;
&lt;hr /&gt;

&lt;p&gt;저번 시간에는 Neural Network의 기본이 되었던 XOR 문제를 풀어보았다. 그 과정에서 Feedforward 퍼셉트론이라는 개념이 등장했고 오늘은 Feedforward 과정이 어떻게 진행되는지 알아보자.&lt;/p&gt;

&lt;h2 id=&quot;activation-function&quot;&gt;활성화 함수(Activation Function)&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/nn/NN.jpg&quot; alt=&quot;Drawing&quot; style=&quot;width: 350px;&quot; /&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned} a &amp;=b + w_1x_1 + w_2x_2 \\ y &amp;= h(a)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;단일 퍼셉트론의 과정을 담은 그림과 수식이다. 각 뉴런(동그라미들)에서 다음 층의 뉴런(오른쪽 큰 동그라미)로 진행하는데 우선 각 $x$ 를 가중합 $a$ 를 구하고, 그 합을 다시 어떤 함수 $h$ 를 거쳐 Output인 $y$ 가 나오게 된다.&lt;/p&gt;

&lt;p&gt;저번 시간에 이야기 했던 AND를 적용해보면 $h$ 는 0과 1을 반환하는 아래와 같은 함수일 것이다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;y = h(a) =
  \begin{cases}
  0\ \ (a = b + w_1x_1 + w_2x_2 \leq 0) \\
  1\ \ (a = b + w_1x_1 + w_2x_2 &gt; 0)
  \end{cases}&lt;/script&gt;

&lt;p&gt;이런 $h$ 함수를 &lt;strong&gt;활성화 함수&lt;/strong&gt; 라고 부르며, 보통 비선형 함수를 쓴다.&lt;/p&gt;

&lt;h3 id=&quot;section&quot;&gt;왜 비선형을 쓰는가?&lt;/h3&gt;
&lt;p&gt;우리는 활성화 함수를 예측 불가능한 함수로 만들어야 하기 때문인데 비선형함수가 적합하기 때문이다. 선형함수의 특징은 더 해도 선형이라는 것인데, 예를 들어&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;y=3x&lt;/script&gt;

&lt;p&gt;라는 선형 함수와 간단한 산수인 $1+5=6$ 이란 것을 생각해보자. 좌변에 $1$과 $5$를 선형함수에 넣어서 더한 값인 $3 + 15 = 18$ 이란 값을 우리는 우변의 $6$ 을 선형함수에 넣었을 때 값이랑 같다는 것을 충분히 알 수 있다. 이를 “&lt;strong&gt;예측&lt;/strong&gt; 할 수 있다.” 라고 이야기 한다. 이처럼 두 개의 선형함수를 더하면 선형이 된다는 것이다.&lt;/p&gt;

&lt;p&gt;하지만 어떤 비선형 함수&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;y=3x^2&lt;/script&gt;
로 아까의 과정을 똑같이 해보자, 좌변의 값을 넣어서 더하면 $3 + 75 = 78$ 인데, 우변의 값을 넣으면 $108$ 이 된다. 따라서 비선형 함수는 더해도 같은 비선형이 아니며 다른 값이 나오기 때문에 예측 불가능하다 라고 말 할 수 있다.&lt;/p&gt;

&lt;p&gt;비선형 함수를 통과함으로서 뉴런이 &lt;strong&gt;활성화&lt;/strong&gt; 된다라고 이야기 한다.&lt;/p&gt;

&lt;p&gt;또 한 가지 이유를 들자면, 선형일 경우에 여러 층을 쌓는 이유가 없어진다. 만약에 $h=c\cdot a$ 가 선형인 함수 였다면 여러 층을 거치게 되면 $h(h(h(a))) = c\cdot c\cdot c\cdot a$ 인데 이는 결국 $b\cdot a=c^3\cdot a$ 라는 선형함수로 바꿀 수 있어서 여전히 예측 가능하기 때문이다.&lt;/p&gt;

&lt;p&gt;더 자세한 비선형함수와 선형함수의 차이는 링크의 블로그를 참조해보자 [&lt;a href=&quot;http://sdolnote.tistory.com/entry/LinearityNonlinearityFunction&quot;&gt;&lt;span style=&quot;color: #7d7ee8&quot;&gt;링크&lt;/span&gt;&lt;/a&gt;]&lt;/p&gt;

&lt;h3 id=&quot;section-1&quot;&gt;자주 쓰는 활성화 함수들&lt;/h3&gt;

&lt;h4 id=&quot;step-function&quot;&gt;계단 함수(Step Function)&lt;/h4&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;h(x) =
  \begin{cases}
  1\ \ (x &gt; 0) \\
  0\ \ (x  \leq 0)
\end{cases}&lt;/script&gt;&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def step_function(x):
    y = x &amp;gt; 0
    return y.astype(np.int)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/assets/ML/nn/step.png&quot; alt=&quot;Drawing&quot; style=&quot;width: 350px;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;sigmoid-function&quot;&gt;시그모이드 함수(Sigmoid Function)&lt;/h4&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;h(x) = \frac{1}{1+exp(-x)}&lt;/script&gt;&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def sigmoid(x):
    return 1 / (1 + np.exp(-x))
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/assets/ML/nn/sigmoid.png&quot; alt=&quot;Drawing&quot; style=&quot;width: 350px;&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;relu-relu-function&quot;&gt;ReLu 함수(ReLu Function)&lt;/h4&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;h(x) =
  \begin{cases}
  x\ \ (x &gt; 0) \\
  0\ \ (x \leq 0)
  \end{cases}&lt;/script&gt;&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def ReLu(x):
    return np.maximum(0, x)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/assets/ML/nn/relu.png&quot; alt=&quot;Drawing&quot; style=&quot;width: 350px;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;feedforward-&quot;&gt;Feedforward 과정&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/nn/NN_2.jpg&quot; alt=&quot;Drawing&quot; style=&quot;width: 500px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;(사진출처: 밑바닥부터 시작하는 딥러닝)&lt;/p&gt;

&lt;p&gt;위와 같은 Neural Network의 과정을 한번 살펴 보자, 여러개의 Perceptron을 쌓으면 이런 모양이 나오는 것을 알 수 있다. 여기서 제일 왼쪽에 있는 $x_1, x_2$ 2개의 뉴런을 한 층으로 보며, 이를 입력층(Input Layer)라고 한다. (1 이란 뉴런은 매번 뉴런을 거칠 때마다 더 해주는 숫자기 때문에 앞으로도 한번만 쓰도록 한다.) 마찬가지로 중간에 두 개의 층을 은닉층(Hidden Layer)이라고 하며 마지막을 출력층(Output Layer)이라고 한다. 보통 입력층은 갯수로 안세며 위 그림은 총 3층인 Neural Network 라고 할 수 있다.&lt;/p&gt;

&lt;p&gt;단계별로 살펴보자.&lt;/p&gt;

&lt;h3 id=&quot;input-rightarrow-hidden-1&quot;&gt;Input $\rightarrow$ Hidden 1&lt;/h3&gt;

&lt;p&gt;Input에서 Hidden1 층으로 가는 과정을 행렬로 표시해볼 것이다.&lt;/p&gt;

&lt;p&gt;가중치 $w$ 의 표기법은 $w_{오른쪽\ 뉴런위치,\ 왼쪽\ 뉴런위치}^{몇번째\ 층}$ 로써,&lt;/p&gt;

&lt;p&gt;첫번째 층에서 입력층 $x_1$ 뉴런에서 히든층1 $a_2^{(1)}$ 방향인 가중치는 $w_{21}^{(1)}$ 이라고 표기한다.&lt;/p&gt;

&lt;p&gt;따라서 각각의 가중치 합을 구하면,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;A = \begin{bmatrix}
    a_1^{(1)} \\
    a_2^{(1)} \\
    a_3^{(1)}
    \end{bmatrix} =
    \begin{bmatrix}
    w_{11}^{(1)}x_1 + w_{12}^{(1)}x_2 + b_1^{(1)} \\
    w_{21}^{(1)}x_1 + w_{22}^{(1)}x_2 + b_2^{(1)} \\
    w_{31}^{(1)}x_1 + w_{32}^{(1)}x_2 + b_3^{(1)}
\end{bmatrix}&lt;/script&gt;

&lt;p&gt;가 되는데, 이를 다시 간단하게 쓰면&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;X =
  \begin{bmatrix}
  x_1 \\
  x_2
\end{bmatrix}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
W^{(1)} =
      \begin{bmatrix}
      w_{11}^{(1)} &amp; w_{12}^{(1)} \\
      w_{21}^{(1)} &amp; w_{22}^{(1)} \\
      w_{31}^{(1)} &amp; w_{32}^{(1)}
      \end{bmatrix} %]]&gt;&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;B^{(1)} =
  \begin{bmatrix}
  b_1^{(1)} \\
  b_2^{(1)} \\
  b_3^{(1)}
  \end{bmatrix}&lt;/script&gt;

&lt;p&gt;$A = W^{(1)} \cdot X + B^{(1)}$ 가 되며, 형태는 $(3, 1) = (3, 2) \times (2, 1) + (3, 1)$ 로 된다. 이는 간단한 내적 연산으로 구할 수 있게 된다.&lt;/p&gt;

&lt;p&gt;가중치의 합을 구하면 이제 비활성함수에 대입해서 뉴런을 활성화 시킨다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Z^{(1)} =
    \begin{bmatrix}
    z_1^{(1)} \\
    z_2^{(1)} \\
    z_3^{(1)}
    \end{bmatrix} =
    \begin{bmatrix}
    h(a_1^{(1)}) \\
    h(a_2^{(1)}) \\
    h(a_3^{(1)})
    \end{bmatrix}&lt;/script&gt;

&lt;p&gt;이렇게 나온 $Z^{(1)}$ 값들은 다음 층에서 입력으로 쓰이게 된다.&lt;/p&gt;

&lt;p&gt;아래 코드의 Shape도 같이 잘 살펴보자.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;X = np.array([1.0, 0.5])
W1 = np.array([[0.1, 0.2],
               [0.3, 0.4],
               [0.5, 0.6]])
B1 = np.array([0.1, 0.2, 0.3])

print('X:', X.shape)
print('W1:', W1.shape)
print('B1:', B1.shape)
# Input -&amp;gt; Hidden 1
print('=================')
print('Input -&amp;gt; Hidden1')
print('=================')
# linear sum
A1 = np.dot(W1, X) + B1
print('A1:', A1.shape)
print(A1)
# activation
Z1 = sigmoid(A1)
print('Z1:', Z1.shape)
print(Z1)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;W1: (3, 2)&lt;/p&gt;

  &lt;p&gt;B1: (3,)&lt;/p&gt;

  &lt;p&gt;=================&lt;/p&gt;

  &lt;p&gt;Input -&amp;gt; Hidden1&lt;/p&gt;

  &lt;p&gt;=================&lt;/p&gt;

  &lt;p&gt;A1: (3,)&lt;/p&gt;

  &lt;p&gt;[ 0.3  0.7  1.1]&lt;/p&gt;

  &lt;p&gt;Z1: (3,)&lt;/p&gt;

  &lt;p&gt;[ 0.57444252  0.66818777  0.75026011]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;hidden-1-rightarrow-hidden-2&quot;&gt;Hidden 1 $\rightarrow$ Hidden 2&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;W2 = np.array([[0.1, 0.2, 0.3],
               [0.4, 0.5, 0.6]])
B2 = np.array([0.1, 0.2])

print('Z1:', Z1.shape)
print('W2:', W2.shape)
print('B2:', B2.shape)
# Hidden 1 -&amp;gt; Hidden 2
print('=================')
print('Hidden 1 -&amp;gt; Hidden 2')
print('=================')
# linear sum
A2 = np.dot(W2, Z1) + B2
print('A2:', A2.shape)
print(A2)
# activation
Z2 = sigmoid(A2)
print('Z2:', Z2.shape)
print(Z2)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;Z1: (3,)&lt;/p&gt;

  &lt;p&gt;W2: (2, 3)&lt;/p&gt;

  &lt;p&gt;B2: (2,)&lt;/p&gt;

  &lt;p&gt;=================&lt;/p&gt;

  &lt;p&gt;Hidden 1 -&amp;gt; Hidden 2&lt;/p&gt;

  &lt;p&gt;=================
A2: (2,)&lt;/p&gt;

  &lt;p&gt;[ 0.51615984  1.21402696]&lt;/p&gt;

  &lt;p&gt;Z2: (2,)&lt;/p&gt;

  &lt;p&gt;[ 0.62624937  0.7710107 ]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;hidden-2-rightarrow-output&quot;&gt;Hidden 2 $\rightarrow$ Output&lt;/h3&gt;

&lt;p&gt;마지막 출력 층에서는 이전 층에 출력된 $Z$ 값들을 그대로 가져올 수 있다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def identity_function(x):
    return x

W3 = np.array([[0.1, 0.2],
               [0.3, 0.4]])
B3 = np.array([0.1, 0.2])

A3 = np.dot(W3, Z2) + B3
Y = identity_function(A3)
print(Y)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;[ 0.31682708  0.69627909]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;혹은 Softmax라는 함수를 써서 각 Output의 확률로서 나타낼 수 있다. 보통을 이걸 쓴다.&lt;/p&gt;

&lt;h4 id=&quot;softmax&quot;&gt;Softmax&lt;/h4&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;y_k = \frac{exp(a_k)}{\sum_{i=1}^{n}{exp(a_i)}}&lt;/script&gt;&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def softmax(x):
    return np.exp(x) / np.sum(np.exp(x))
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;얼핏 잘 만든 것 같지만 컴퓨터에서 아주 큰 수를 계산시 Overflow문제가 발생한다. 오버플로우란, 사용 가능한 하드웨어(즉, 32bit 단위 워드의 하드웨어, 레지스터 등)로 연산 결과를 표현할 수 없을 때 오버플로우가 발생한다고 한다. (오버플로우 개념 출처: [&lt;a href=&quot;https://m.blog.naver.com/PostView.nhn?blogId=osw5144&amp;amp;logNo=120206206420&amp;amp;proxyReferer=https%3A%2F%2Fwww.google.co.kr%2F&quot;&gt;&lt;span style=&quot;color: #7d7ee8&quot;&gt;링크&lt;/span&gt;&lt;/a&gt;])&lt;/p&gt;

&lt;p&gt;간단히 예를 들어보면 아래의 코드를 실행해보면 금방 알 수 있다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;a = np.array([1010, 1000, 990])
softmax(a)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;/Users/user/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:2: RuntimeWarning: overflow encountered in exp
from ipykernel import kernelapp as app&lt;/p&gt;

  &lt;p&gt;/Users/user/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:2: RuntimeWarning: invalid value encountered in true_divide
  from ipykernel import kernelapp as app&lt;/p&gt;

  &lt;p&gt;array([ nan,  nan,  nan])&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;경고가 뜨면서 NaN 값들만 나온다. 이를 방지하기 위해서 입력 신호 중 최대값을 이용하는게 일반적이다. 아래는 분모, 분자 변수에 어떤 상수 C’를 더해도 결국엔 Softmax가 되는 것을 증명 한 식이다.&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{aligned}
y_k &amp;= \frac{exp(a_k)}{\sum_{i=1}^{n}{exp(a_i)}} \\
&amp;= \frac{Cexp(a_k)}{C\sum_{i=1}^{n}{exp(a_i)}} \\
&amp;= \frac{exp(a_k+\log{C})}{\sum_{i=1}^{n}{exp(a_i+\log{C})}}\\
&amp;= \frac{exp(a_k+C^{'})}{\sum_{i=1}^{n}{exp(a_i+C^{'})}}
\end{aligned} %]]&gt;&lt;/script&gt;&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;c = np.max(a)
print(a - c)
print(softmax(a-c))
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;[  0 -10 -20]&lt;/p&gt;

  &lt;p&gt;[  9.99954600e-01   4.53978686e-05   2.06106005e-09]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이번에는 경고 없이 실행이 잘 된다. 이제 최종 Softmax는 아래와 같다. 이를 출력층에 적용하면 y값에 대한 확률을 볼 수 있다. 이를 0과 1사이의 값으로 만드는 이유가 있는데 향후 학습시에 필요하기 때문이다. (네트워크 학습에서 설명)&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def softmax(a):
    c = np.max(a)
    return np.exp(a - c) / np.sum(np.exp(a - c))
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;h2 id=&quot;feedforward--1&quot;&gt;Feedforward 실습&lt;/h2&gt;

&lt;p&gt;여태 보았던 3층 Neural Network를 만들어 보자, 어려운 것은 없고 아까 만들었던 것을 나열해보면 쉽다.&lt;/p&gt;

&lt;p&gt;실습할 데이터는 mnist 데이터 이며, 아래 링크로 받을 수 있다.&lt;/p&gt;

&lt;p&gt;&amp;lt;밑바닥 부터 시작하는 딥러닝&amp;gt; 책의 Github: [&lt;a href=&quot;https://github.com/WegraLee/deep-learning-from-scratch&quot;&gt;&lt;span style=&quot;color: #7d7ee8&quot;&gt;링크&lt;/span&gt;&lt;/a&gt;]&lt;/p&gt;

&lt;p&gt;입력층에는 784 개의 뉴런, 은닉층1에는 50개, 은닉층2에는 100개, 마지막 층에는 10개의 뉴런으로 구성되어 있는 네트워크다. 활성화 함수는 sigmoid를 쓰고, 마지막에 Softmax로 확률을 구했다. 실행단계에서 batch라는 것이 있는데, 한번에 많은 양의 데이터를 계산하면 느리니, 조금씩 데이터를 사용해서 계산하는 방법이라고 생각하면 된다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# 네트워크 만들기
from dataset.mnist import load_mnist
import numpy as np

class NN(object):
    def __init__(self):
        # W1(50, 784) X(784, batch_size)
        # W2(100, 50) Z1(50, batch_size)
        # W3(10, 100) Z2(100, batch_size)
        # B1(50, batch_size)
        # B2(100, batch_size)
        # B3(10, batch_size)
        self.W = {'W1': np.random.normal(size=(50, 784)),  
                  'W2': np.random.normal(size=(100, 50)),  
                  'W3': np.random.normal(size=(10, 100)),}  
        self.B = {'B1': np.random.normal(size=(50, batch_size)),  
                  'B2': np.random.normal(size=(100, batch_size)),  
                  'B3': np.random.normal(size=(10, batch_size)),}  

    def get_data(self):
        (x_train, t_train), (x_test, t_test) = load_mnist(flatten=True,
                                                          normalize=True,
                                                          one_hot_label=False)
        return x_train, t_train, x_test, t_test

    def predict(self, X):
        W1, W2, W3 = self.W['W1'], self.W['W2'], self.W['W3']
        B1, B2, B3 = self.B['B1'], self.B['B2'], self.B['B3']
        # Input -&amp;gt; Hidden 1
        A1 = np.dot(W1, X) + B1
        Z1 = sigmoid(A1)
        # Hidden 1 -&amp;gt; Hidden 2
        A2 = np.dot(W2, Z1) + B2
        Z2 = sigmoid(A2)
        # Hidden 2 -&amp;gt; Output
        A3 = np.dot(W3, Z2) + B3
        Y = softmax(A3)

        return Y

# 실행 단계
model_mnist = NN()
x_train, t_train, x_test, t_test = model_mnist.get_data()
acc_count = 0
batch_size = 100
for i in range(0, len(x_train), batch_size):
    x_batch = x_train[i:i+batch_size].T  # (784, 100)
    y_batch = model_mnist.predict(x_batch) # (10, 100)
    p = np.argmax(y_batch, axis=0)
    acc_count += np.sum(p == t_train[i:i+batch_size])
print(&quot;accuracy:&quot;, acc_count / len(x_train))
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;accuracy: 0.0857833333333&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;정확도란 데이터 중에서 얼만큼 라벨 맞췃는지 측정하는 것인데, 당연하지만 결과가 아주 형편이 없다. 이제 네트워크를 학습시키면서 이를 향상 시킬 것이니까 너무 걱정하지 말자.&lt;/p&gt;
</description>
        <pubDate>Fri, 08 Dec 2017 11:52:21 +0900</pubDate>
        <link>http://simonjisu.github.io/deeplearning/2017/12/08/numpywithnn_2.html</link>
        <guid isPermaLink="true">http://simonjisu.github.io/deeplearning/2017/12/08/numpywithnn_2.html</guid>
        
        
        <category>DeepLearning</category>
        
      </item>
    
  </channel>
</rss>
