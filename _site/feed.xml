<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Soopace</title>
    <description>Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.
</description>
    <link>https://simonjisu.github.io/</link>
    <atom:link href="https://simonjisu.github.io/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sun, 24 Oct 2021 21:25:16 +0900</pubDate>
    <lastBuildDate>Sun, 24 Oct 2021 21:25:16 +0900</lastBuildDate>
    <generator>Jekyll v4.2.0</generator>
    
      <item>
        <title>Background: Text2SQL</title>
        <description>&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1GcfpUQEg_all-HDuvJmrIlxEgo_yq9oX&quot; alt=&quot;Reference: Pixabay&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Reference: Pixabay&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h1 id=&quot;text-to-sql&quot;&gt;Text-to-SQL&lt;/h1&gt;

&lt;p&gt;관계형 데이터 베이스(Relational Database)는 현재 가장 많이 쓰이고 있는 데이터 베이스다. 관계형 데이터 베이스는 여러개의 테이블(table)로 이루어져 있으며, 우리가 평소에 많이 접하는 엑셀이 테이블의 가장 흔한 예시라고 할 수 있다.&lt;/p&gt;

&lt;p&gt;당신이 만약에 스타벅스 한국지사 관리자라고 상상을 해보자. 한국지사의 데이터 베이스에는 각 지역별 매장의 위치, 매출, 비용 등등 많은 양의 정보(테이블)가 들어 있다. 보통 회사의 데이터 분석가들이 DB에서 SQL을 통해 데이터를 추출하여, 분석을 하고 분석한 내용을 당신에게 보고서를 만들 것이다. 예를 들어 보고서에서 다음과 같은 테이블을 보았다.&lt;/p&gt;

&lt;h3 id=&quot;regiondata&quot;&gt;RegionData&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;region&lt;/th&gt;
      &lt;th&gt;n_store&lt;/th&gt;
      &lt;th&gt;sales&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;서울특별시&lt;/td&gt;
      &lt;td&gt;568&lt;/td&gt;
      &lt;td&gt;537,727,860,697&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;경기도&lt;/td&gt;
      &lt;td&gt;361&lt;/td&gt;
      &lt;td&gt;341,760,136,816&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;부산광역시&lt;/td&gt;
      &lt;td&gt;127&lt;/td&gt;
      &lt;td&gt;120,231,405,473&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;대구광역시&lt;/td&gt;
      &lt;td&gt;71&lt;/td&gt;
      &lt;td&gt;67,215,982,587&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;인천광역시&lt;/td&gt;
      &lt;td&gt;63&lt;/td&gt;
      &lt;td&gt;59,642,350,746&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;경상남도&lt;/td&gt;
      &lt;td&gt;59&lt;/td&gt;
      &lt;td&gt;55,855,534,826&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;광주광역시&lt;/td&gt;
      &lt;td&gt;59&lt;/td&gt;
      &lt;td&gt;55,855,534,826&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;대전광역시&lt;/td&gt;
      &lt;td&gt;56&lt;/td&gt;
      &lt;td&gt;53,015,422,886&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;경상북도&lt;/td&gt;
      &lt;td&gt;47&lt;/td&gt;
      &lt;td&gt;44,495,087,065&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;충청남도&lt;/td&gt;
      &lt;td&gt;33&lt;/td&gt;
      &lt;td&gt;31,241,231,343&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;울산광역시&lt;/td&gt;
      &lt;td&gt;30&lt;/td&gt;
      &lt;td&gt;28,401,119,403&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;전라북도&lt;/td&gt;
      &lt;td&gt;27&lt;/td&gt;
      &lt;td&gt;25,561,007,463&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;충청북도&lt;/td&gt;
      &lt;td&gt;25&lt;/td&gt;
      &lt;td&gt;23,667,599,502&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;강원도&lt;/td&gt;
      &lt;td&gt;25&lt;/td&gt;
      &lt;td&gt;23,667,599,502&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;제주특별자치도&lt;/td&gt;
      &lt;td&gt;23&lt;/td&gt;
      &lt;td&gt;21,774,191,542&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;전라남도&lt;/td&gt;
      &lt;td&gt;23&lt;/td&gt;
      &lt;td&gt;21,774,191,542&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;세종특별자치시&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;10,413,743,781&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;스타벅스 매장의 개수에 따라서 정렬된 테이블을 보고 당신은 이런 궁금증이 생겼다. “지역별로 매출이 매장의 개수에 따라 많아지는데, 비용은 어떻게 될까?”, “효율적으로 매출을 내는 지역은 어디일까?”&lt;/p&gt;

&lt;p&gt;이러한 궁금증들이 당장 답변을 받고 싶지만, 다시 직원에게 보고서를 만들어 오라고 하기에는 너무 시간이 오래 걸린다. 만약, 당신이 자연어로 질문을 했을 때 필요한 SQL문을 인공지능이 알아서 작성하게 된다면 얼마나 좋을까?&lt;/p&gt;

&lt;p&gt;이렇게 자연어 발화를 SQL로 바꾸는 분야를 &lt;strong&gt;Text-to-SQL(혹은 NL-to-SQL)&lt;/strong&gt;이라고 한다. SQL을 배우지 않아도 자연어로 쉽게 데이터를 추출가능하게 하고, 데이터의 접근성을 향상 시킬 수 있다.&lt;/p&gt;

&lt;p&gt;사실, 이러한 분야는 오래전부터 연구가 시작되었다. 이러한 문제를 보통 Natural Language Interfaces to Databases(NLIDBs, &lt;a href=&quot;https://arxiv.org/abs/cmp-lg/9503016&quot;&gt;Androutsopoulos et al, 1995&lt;/a&gt;)라는 이름으로 데이터 베이스 분야에서 존재 했었다. 이 당시에는 전통적인 자연어 처리 기법으로 문제를 해결하려고 노력했다. 그러나 최근 Transfomer 및 Pre-trained Language Model의 급 부상으로 딥러닝 기반의 방법론이 많이 적용이 되었다.&lt;/p&gt;

&lt;p&gt;추가로 말하자면, 이러한 분야를 Semantic Parsing 이라고도 하며, 보통 자연어 발화를 유의미한 표현으로 전환하는 문제를 말한다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;데이터-이야기&quot;&gt;데이터 이야기&lt;/h1&gt;

&lt;p&gt;사실 2017년 전까지는 이 분야에는 ImageNet처럼 방대하게 실험해 볼 수 있는 데이터 세트가 없었다. 2017년 이후 부터 WikiSQL, SPIDER 등 다양한 벤치마크 데이터 세트가 등장하면서 활발한 연구가 시작되었다.&lt;/p&gt;

&lt;h2 id=&quot;wikisql&quot;&gt;WikiSQL&lt;/h2&gt;

&lt;p&gt;2017년에 Salesforce에서 크라우드 소싱하여 상대적으로 큰 데이터 세트인 WikiSQL를 만들었다. 지금까지도 데이터 세트는 표준 데이터처럼 사용한다. WikiSQL은 총 25,683개의 테이블과 80,654 쌍의 자연어 질의와 SQL문이 있다. 문제의 단순화를 위해서, 오직 독립적인 하나의 테이블의 국한하여 질의를 하고, SELECT, WHERE 및 간단한 AGGREGATION 정도의 단순한 구문으로 구성되어 있다.&lt;/p&gt;

&lt;p&gt;위의 스타벅스 테이블을 예로 들면 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;질의: 서울특별시의 스타벅스 매장 개수가 어떻게 되?
SQL: SELECT n_store FROM RegionData WHERE region = &quot;서울특별시&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;spider&quot;&gt;SPIDER&lt;/h2&gt;

&lt;p&gt;WikiSQL의 문제점은 심플한 쿼리에다 자주 쓰이는 JOIN, GROUP BY, ORDER BY 등이 없다는 점이다. 이러한 단점을 보완하기 위해서 Yale 대학교를 주축으로 11개의 대학에서 대략 1,000시간을 소요해서 200개의 데이터베이스, 10,181개의 자연어 질문, 5,693개의 난이도가 상이한 쿼리문으로 구성된 &lt;a href=&quot;https://yale-lily.github.io/spider&quot;&gt;SPIDER&lt;/a&gt; 데이터 세트를 제작했다. 기존의 비해 양도 많고, 훈련/테스트 데이터 세트를 데이터 베이스 기준으로 잘라서 실험했다는 점에서 신선한 관점을 줬었다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1FugtDbQb5TINzAmaknIyS5s-HPbt9kfz&quot; alt=&quot;다른 데이터 세트와 Spider 1.0 데이터 세트의 비교&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;다른 데이터 세트와 Spider 1.0 데이터 세트의 비교&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;물론 여기도 여러가지 제약이 있는데, 자세한 내용은 해당 논문 리뷰(&lt;a href=&quot;https://github.com/simonjisu/Text2SQL/blob/main/MD/01.md&quot;&gt;링크&lt;/a&gt;) 를 참고하길 바란다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;접근법&quot;&gt;접근법&lt;/h1&gt;

&lt;p&gt;결국 Text2SQL의 목적은 자연어 발화가 주어지면 올바른 SQL을 생성하는 문제로, 어떻게 보면 Machine Translation과 비슷한 Task라고 볼 수 있다. 그런 점에서 초기에 Seq-to-Seq로 접근 하는 부분이 많았지만, 이러한 접근 법은 순서가 어느 정도 중요한 SQL 구문 특성상 잘 작동하지 않았다.&lt;/p&gt;

&lt;p&gt;다른 법근 법으로 SQL문을 각기 다른 파트인 Sub-Tasks로 나눠서, 이 문제를 풀려고 했고, 네이버의 SQLova, MS의 HydraNet등 다양한 모델들이 좋은 성능을 내기 시작했다.&lt;/p&gt;

&lt;p&gt;이 후에도 다양한 접근 법들이 나오고 있는데, Domain Ontology, Linking, 타입(Type) 임베딩, Graph적인 접근 등등 다양한 방법들이 시도되고 있다. 차후 글들에서 이러한 접근법을 하나씩 읽어보고 소개하려고 한다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;문제점&quot;&gt;문제점&lt;/h1&gt;

&lt;p&gt;이 분야를 연구하면서 교수님으로부터 제일 많이 들었던 소리는 실제 기업의 데이터 베이스가 주어진 데이터 세트처럼 아름답지가 않다고 한다. 무슨 말인가 했는데, Text2SQL의 핵심중 하나는 사실 테이블의 칼럼 이름과 레코드 값들이 자연어와 “언어”라는 도메인을 공유하고 있다는 점이다. 그러나 실제 기업의 데이터 베이스의 칼럼 이름은 간단하게 짓고, 나중에 mapping table로 해당 칼럼 이름을 확인한다는 말을 많이 들었다(물론 이런 곳이 없는 곳이 있을 것 같지만).&lt;/p&gt;

&lt;p&gt;다른 문제점은 인간에게 당연한 상식이나 추론을 적용하기 어렵다는 점이다. 즉, 명확한 질문에 해당하는 SQL문만 가능하다는 것인데, 예를 들어, “Display the employee id for the employees who report to John”의 질문을 쿼리로 바꾸면 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;language-sql highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;employee_id&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;employees&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;manager_id&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;SELECT&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;employee_id&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;FROM&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;employees&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;WHERE&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;first_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;&apos;John&apos;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;사람은 “X reports to Y”구문에서 “John”이 “employee manager”라는 상식을 유추할 수 있지만, 이는 데이터베이스로부터 알 수 없는 사실이다.&lt;/p&gt;

&lt;p&gt;이러한 문제점 들을 고려하여 정말 사람들에게 유용하게 적용 될 수 있는 Text2SQL 연구가 필요할 것이다.&lt;/p&gt;
</description>
        <pubDate>Sun, 24 Oct 2021 21:00:01 +0900</pubDate>
        <link>https://simonjisu.github.io/nlp/2021/10/24/background_text2sql.html</link>
        <guid isPermaLink="true">https://simonjisu.github.io/nlp/2021/10/24/background_text2sql.html</guid>
        
        
        <category>nlp</category>
        
      </item>
    
      <item>
        <title>카카오 블라인드 코딩테스트 후기</title>
        <description>&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1kJshUGkeuqBEeUh8CQ3diK3L7Bqc4yiS&quot; alt=&quot;Reference: Pixabay&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Reference: Pixabay&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;지난 18일과 25일 양일간 2022 카카오 블라인드 코딩테스트를 마쳤다. 오늘은 그 후기를 써보고자 한다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://programmers.co.kr/competitions/1571/2022-kakao-blind-recruitment&quot;&gt;2022 KAKAO BLIND RECRUITMENT 링크&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;1차-테스트&quot;&gt;1차 테스트&lt;/h1&gt;

&lt;p&gt;1차 테스트는 여차 다른 코딩테스트와 다른 것이 없었다. 시간은 대략 5시간 정도였고, 작년과 문제는 완전히 다르지만 대략 7문제 정도 출제됐다. 나는 4문제 정도 풀었다. 지금은 문제를 언급하면 문제가 됨으로 나중에 공개되면 하나씩 다시 돌아볼 예정이다.&lt;/p&gt;

&lt;p&gt;코딩 테스트 공부는 나동빈 님의 “&lt;a href=&quot;http://www.yes24.com/Product/Goods/91433923&quot;&gt;&lt;strong&gt;이것이 취업을 위한 코딩테스트다 with 파이썬&lt;/strong&gt;&lt;/a&gt;” 책을 보면서 전체적인 느낌을 훑고, Leetcode 문제를 조금씩 풀어봤다. 책이 정말 많은 도움이 됐는데, 코딩 테스트를 어디서 부터 공부 할 지 모르겠다면 한 번 구매해서 보는 것을 강력히 추천한다. 이 책은 코딩테스트를 어떻게 준비하는지 부터 시작해서 어떤 문제가 있는 지 유형별로 알려준다.&lt;/p&gt;

&lt;p&gt;다만 너무 늦게 시작해서 주요 알고리즘 이론만 공부한게 조금 아쉬웠다. 익숙하지 않으니 변형된 문제에 시간을 많이 소비했다. 내가 느낀 취업에서 코딩 테스트는 기초 체력과 같다. 복싱장에 가면 처음에 줄넘기부터 배워 체력을 키우듯이, 코딩 테스트도 매일 꾸준히 훈련하고 응용해야 수업시간에  배우는 알고리즘이 녹슬지 않는다.&lt;/p&gt;

&lt;p&gt;그래서 새로운 목표를 새웠다. 앞으로 졸업전 남은 기간 동안 적어도 하루에 1시간은 코딩 테스트에 시간을 쏟을 것이다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://gmlwjd9405.github.io/2018/05/14/how-to-study-algorithms.html&quot;&gt;읽어두면 좋은 알고리즘을 공부하는 방법 관련 글&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://tech.kakao.com/2021/01/25/2021-kakao-recruitment-round-1/&quot;&gt;2021년도 1차 코딩 테스트 해설&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;2차-테스트&quot;&gt;2차 테스트&lt;/h1&gt;

&lt;p&gt;2차 테스트는 CS 테스트와 코딩 테스트가 준비 되어 있었다.&lt;/p&gt;

&lt;h2 id=&quot;cs-테스트&quot;&gt;CS 테스트&lt;/h2&gt;

&lt;p&gt;CS 테스트는 총 10개의 문제로 20분 정도 주어졌는데, 생각보다 어려웠다. 아무래도 일반 개발자도 아니고, 컴공 기초지식이 부족하다보니 은근히 쉬운 문제도 틀렸다. 비록 지금은 인공지능을 공부하고 있지만, 인공지능은 전체 시스템의 5% 정도만 차지 하고 있다(그림의 논문 참고). 다른 어플리케이션과 융합을 시키려면 적어도 기본적인 지식은 알아둬야 된다고 생각이 드는 하루였다. 이번에 공부하면서 좋은 &lt;a href=&quot;https://github.com/JaeYeopHan/Interview_Question_for_Beginner&quot;&gt;repository&lt;/a&gt; 하나 발견했는데, 앞으로 하나씩 내걸로 만들어야겠다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=12F8TOfwcA6GRbXprshHzhJeeIBCrrgMs&quot; alt=&quot;https://proceedings.neurips.cc/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;https://proceedings.neurips.cc/paper/2015/file/86df7dcfd896fcaf2674f757a2463eba-Paper.pdf&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 id=&quot;코딩-테스트&quot;&gt;코딩 테스트&lt;/h2&gt;

&lt;p&gt;코딩 테스트는 4시간 45분 동안 REST API를 활용하여 문제를 해결하는 것이다. 지문을 이해하고 구조화 할 줄 알아야 한다. REST API 호출 처리 모듈를 작년의 문제를 참고하여, python으로 Parser 모듈을 만들었다(&lt;a href=&quot;https://gist.github.com/simonjisu/c63f28d9740f3577a2a51ee2337790b3&quot;&gt;링크&lt;/a&gt;).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://tech.kakao.com/2021/02/16/2021-kakao-recruitment-round-2/&quot;&gt;2021 2차 코딩 테스트 해설&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;json&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;requests&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Parser&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;object&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;token&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base_url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;verbose&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base_url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;/&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;base_url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base_url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base_url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base_url&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;content_type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;application/json&apos;&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;token&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;token&lt;/span&gt;
        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;verbose&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;verbose&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;post&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;headers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;/&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;/&apos;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base_url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;response&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;requests&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;post&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;headers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;headers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;verbose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;status_code&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;json&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;headers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;/&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;/&apos;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base_url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;response&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;requests&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;headers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;headers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;verbose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;status_code&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;json&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;headers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;/&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;/&apos;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base_url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;response&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;requests&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;put&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;headers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;headers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;verbose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;status_code&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;response&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;json&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그럼에도 불구하고 지문을 이해하는데 대략 30분정도 걸렸고, 이를 다시 지문에 맞게 구조화하는데 2시간 가량 걸렸다. 이 부분에서 너무 많은 시간을 쏟아서 뒤에 테스트 해보고 싶은 알고리즘을 구성하는데 시간이 부족했다.&lt;/p&gt;

&lt;p&gt;이번의 문제는 매칭 시스템과 관련이 있었는데, 전혀 감을 잡지 못했다. 예전에 자주하던 게임중에 Clash of Clan 이라는 게임이 있었는데, 여기서도 타워레벨과 유저 rating간의 매칭이 불균형하다고 불평이 많았었다. 이런 문제를 커뮤니티에서 보면서 이런 점을 개선 시길 방안은 없을까 생각했었는데, 게임 회사에서는 많이 고민하는 문제 일 것 같다. 다음의 영상을 보면서 영감을 얻어 본다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;[NDC21-게임기획] 실력점수? 랭킹? 다 비슷한 거 아닌가요: &lt;a href=&quot;https://youtu.be/DbRr7X8B-Co&quot;&gt;https://youtu.be/DbRr7X8B-Co&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sat, 25 Sep 2021 22:00:01 +0900</pubDate>
        <link>https://simonjisu.github.io/others/2021/09/25/kakaocoding.html</link>
        <guid isPermaLink="true">https://simonjisu.github.io/others/2021/09/25/kakaocoding.html</guid>
        
        
        <category>others</category>
        
      </item>
    
      <item>
        <title>Machine Learning: Evaluation</title>
        <description>&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1rxOWFSNawoCtGJQLLpQzE90tYWCAtEEI&quot; alt=&quot;Reference: Pixabay&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Reference: Pixabay&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h1 id=&quot;confusion-matrix&quot;&gt;Confusion Matrix&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Confusion Matrix&lt;/strong&gt; 는 보통 supervised learning 관련 머신러닝 알고리즘의 퍼포먼스를 측정하기 위한 도구로 사용된다. 자주 사용되는 것인데 계속 잊어버려서 한 번 정리해보고 어떤 상황에서 사용되는지 알아보자.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;개념&quot;&gt;개념&lt;/h1&gt;

&lt;p&gt;분류 문제에서 정확도를 평가지표로 사용할 때, 클래스의 불균형 문제가 있으면 잘못된 결과를 낳다. 예를 들어, 개/고양이를 분류하는 문제에서 95개의 고양이와 5개의 개 사진이 있고, 어떤 모델이 전부 고양이를 예측했다. 최종 정확도는 95%지만, 고양이의 검출율 은 100% (95개 중 95개 예측)이고 개의 검출율를 0% (5개 중 0개 예측)이다.&lt;/p&gt;

&lt;p&gt;정확도로 탐지할 수 없는 모델의 문제점을 정보(informedness)로 표현을 하게되자 어떤 문제가 있는지 알게 되었다. 이 예시에서는 모델이 항상 고양이만 예측한다는 것이다.&lt;/p&gt;

&lt;p&gt;두 개의 클래스가 있을 때 Confusion Matrix는 다음과 같이 정의 된다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt; &lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;Predicted&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;Positive&lt;/strong&gt;&lt;/th&gt;
      &lt;th&gt;&lt;strong&gt;Negative&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Actual&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;Positive&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;True Positive&lt;/td&gt;
      &lt;td&gt;False Negative&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;Negative&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;False Positive&lt;/td&gt;
      &lt;td&gt;True Negative&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;여기서 행은 실제(Actual) 데이터의 레이블이고, 칼럼은 모델이 예측(Predict)한 레이블을 뜻한다. 표의 내용은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(앞)진위여부 (뒤)예측&lt;/code&gt;과 같이 해석하는게 좋다. 즉, True Positive는 예측(Predicted)는 Positive인데 실제(Actual)로 Positive라서 진위 여부는 True다. 하나더 예를 보면 False Negative면 예측은 Negative인데 실제로 Negative라 진위 여부는 False다.&lt;/p&gt;

&lt;p&gt;Confusion Matrix에서 파생되는 여러가지 지표들이 있는데 지금부터 알아보겠다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;지표&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;공식&lt;/th&gt;
      &lt;th&gt;설명&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Accuracy&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$\dfrac{(TP + TN)}{(TP + TN + FN + FP)}$&lt;/td&gt;
      &lt;td&gt;전체 맞게 예측한 비율&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Precision&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$\dfrac{TP}{(TP + FP)}$&lt;/td&gt;
      &lt;td&gt;예측한 Positive 중에 맞게(True) 예측한 비율&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Recall / Sensitivity&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$\dfrac{TP}{(TP + FN)}$&lt;/td&gt;
      &lt;td&gt;실제 Positive 중에 맞게(True) 예측한 비율&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Fall-out&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$\dfrac{FP}{(FP + TN)}$&lt;/td&gt;
      &lt;td&gt;실제 Negative 중에 틀리게(False) 예측한 비율&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;F1 Score&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$\dfrac{2}{(1/Precision + 1/Recall)} = \dfrac{2\times Precision\times Recall}{Precision + Recall}$&lt;/td&gt;
      &lt;td&gt;Precision 과 Recall의 조화 평균, 데이터 분포가 불균형 일때 사용, 큰 비중이 끼치는 bias 가 줄어듦&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;예시&quot;&gt;예시&lt;/h1&gt;

&lt;p&gt;예를 들어, 쇼핑몰의 머신러닝 개발자가 조금더 편한 태깅을 위해, 의류 사진를 보고 어떤 종류인지 예측해서 분류하는 머신러닝 모델을 만들었다고 생각해보자. 의류는 총 3가지 class 이며 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;cls_dict&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;상의&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;하의&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;신발&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그리고 신규 물품 사진에 대한 모델의 에측 결과를 다음과 같이 저장했다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
    &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 상의 6개
&lt;/span&gt;    &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 하의 10개
&lt;/span&gt;    &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 신발 9개
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그러면 Confusion matrix를 다음과 같이 만들 수 있다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unique&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;confusion_matrix&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;confusion_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;confusion_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#         Predict
#        [[4 1 1]
# Target  [6 2 2]
#         [3 0 6]]
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;accuracy&quot;&gt;Accuracy&lt;/h2&gt;

&lt;p&gt;정확도는 전체에서 옳게 맞춘 비율임으로 다음과 같이 계산된다.&lt;/p&gt;

\[\text{Accuracy} =\dfrac{4+2+6}{25}\]

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;total&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;true_positive&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eye&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;confusion_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;true_positive&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;total&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 0.48
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;precision&quot;&gt;Precision&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;정밀도(Precision)&lt;/strong&gt; 는 Positive라고 예측한 것들 중에서 실제로 맞게 예측한 비율임으로 다음과 같이 계산된다.&lt;/p&gt;

\[\begin{aligned} \text{Class 0} &amp;amp;= \dfrac{4}{4+6+3} \\ \text{Class 1} &amp;amp;= \dfrac{2}{1+2+0} \\ \text{Class 2} &amp;amp;= \dfrac{6}{1+2+6} \end{aligned}\]

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;predicted&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;confusion_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;precisions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;true_positive&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predicted&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;precisions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Macro Precision &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;precisions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;precisions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# [0.3077 0.6667 0.6667]
# Macro Precision 0.5470
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;recall--sensitivity&quot;&gt;Recall / Sensitivity&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;재현율(Recall/Sensitivity)&lt;/strong&gt; 은 실제 Positive 인것들 중에서 맞게 예측한 비율임으로 다음과 같이 계산된다.&lt;/p&gt;

\[\begin{aligned} \text{Class 0} &amp;amp;= \dfrac{4}{4+1+1} \\ \text{Class 1} &amp;amp;= \dfrac{2}{6+2+2} \\ \text{Class 2} &amp;amp;= \dfrac{6}{3+0+6} \end{aligned}\]

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;actual_count&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;confusion_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;recalls&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;true_positive&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;actual_count&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recalls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Macro Recall &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recalls&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recalls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# [0.6667 0.2    0.6667]
# Macro Recall 0.5111
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;fallout&quot;&gt;Fallout&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Fallout&lt;/strong&gt; 은 Negative라고 예측했는데 실제로 Positive라고 맞춘 비율임으로 다음과 같이 계산된다.&lt;/p&gt;

\[\begin{aligned} \text{Class 0} &amp;amp;= \dfrac{6+3}{6+2+2+3+0+6} \\ \text{Class 1} &amp;amp;= \dfrac{1+0}{4+1+1+3+0+6} \\ \text{Class 2} &amp;amp;= \dfrac{1+2}{4+1+1+6+2+2} \end{aligned}\]

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;itertools&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;combinations&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;fallouts&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cls_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;neg_idx&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;reversed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;combinations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;false_positive&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;confusion_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;neg_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cls_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;negative&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;confusion_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;neg_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;fpr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;false_positive&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;negative&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;fallouts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fpr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
&lt;span class=&quot;n&quot;&gt;fallouts&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fallouts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fallouts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Macro Fallout &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fallouts&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fallouts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# [0.4737 0.0667 0.1875]
# Macro Fallout 0.2426
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;f1-score&quot;&gt;F1 Score&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;F1 Score&lt;/strong&gt; 는 다음과 같이 계산된다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;f1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;precisions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;recalls&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;precisions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;recalls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Total F1 &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# [0.4211 0.3077 0.6667]
# Total F1 0.4651
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;scikit-learn&quot;&gt;Scikit-Learn&lt;/h1&gt;

&lt;p&gt;Scikit-learn 패키지중 이를 한번에 구해주는 패키지가 있다. 이 표를 보고 모델의 성능을 한번 평가해보자.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.metrics&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;classification_report&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;classification_report&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target_names&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&apos;상의&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;하의&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&apos;신발&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#               precision    recall  f1-score   support
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#         상의       0.31      0.67      0.42         6
#         하의       0.67      0.20      0.31        10
#         신발       0.67      0.67      0.67         9
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#     accuracy                           0.48        25
#    macro avg       0.55      0.51      0.47        25
# weighted avg       0.58      0.48      0.46        25
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;precision-1&quot;&gt;Precision&lt;/h3&gt;

&lt;p&gt;정밀도는 Type-I Error와 연관있다. Type-I Error는 실제 Negative를 Positive라고 예측한 경우인데, 예를 들어 재판의 경우 죄를 짓지 않았는데 유죄 판결을 내리는 경우 피고인은 무고할 수가 있다.  Precision이 높을 수록 Type-I Error를 줄일 수 있다.&lt;/p&gt;

&lt;p&gt;의류분류기 모델의 경우 “상의”에 대해서는 상의가 아닌데 상의라고 판별할 가능성이 높다는 것이다.&lt;/p&gt;

&lt;h3 id=&quot;recall&quot;&gt;Recall&lt;/h3&gt;

&lt;p&gt;재현율은 Type-II Error와 연관있다. Type-II Error는 실제 Positive를 Negative라고 예측한 경우인데, 암 판정의 예시를 들면, 암이 있는데 암이 없다고 판정한 것이며, 이는 환자에게 치명적일 수가 있다. Recall이 높을 수록 Type-II Error를 줄 일 수 있다.&lt;/p&gt;

&lt;p&gt;의류분류기 모델의 경우 “하의”에 대해서는 실제로 “하의”인데 다른 클래스라고 판별할 가능성이 높다는 것이다.&lt;/p&gt;

&lt;h3 id=&quot;f1-score-1&quot;&gt;F1 Score&lt;/h3&gt;

&lt;p&gt;조화 평균인 F1 Score은 데이터 분포가 불균형 일때 사용되는데, 큰 비중이 끼치는 bias 가 줄어들게 된다. 예를 들어 recall이 $0.9$ 이고 precision이 $0.01$ 인 경우, 일반 평균을 구하면 $(0.9+0.01)/2 = 0.455$가 나오지만 조화 평균을 사용하게 되면, $2\times 0.9 \times 0.01 / (0.9 + 0.01) = 0.020$으로 굉장히 낮게 나온다.&lt;/p&gt;

&lt;p&gt;의류분류기 모델의 경우 “신발”의 성능이 상대적으로 “하의”, “상의”보다는 더 나은 퍼포먼스를 보인다.&lt;/p&gt;
</description>
        <pubDate>Sat, 28 Aug 2021 12:13:01 +0900</pubDate>
        <link>https://simonjisu.github.io/machinelearning/2021/08/28/mleval.html</link>
        <guid isPermaLink="true">https://simonjisu.github.io/machinelearning/2021/08/28/mleval.html</guid>
        
        
        <category>machinelearning</category>
        
      </item>
    
      <item>
        <title>[NLP] Hybrid Ranking Network for Text-to-SQL</title>
        <description>&lt;p&gt;Paper Link: &lt;a href=&quot;https://arxiv.org/abs/2008.04759&quot;&gt;https://arxiv.org/abs/2008.04759&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;abstract&quot;&gt;Abstract&lt;/h1&gt;

&lt;p&gt;문제를 column-wise ranking, decoding 그리고 column-wise 결과물을 SQL 룰에 따라서 모으는 것으로 나눴다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;1-introduction&quot;&gt;1. Introduction&lt;/h1&gt;

&lt;p&gt;Relational database는 실제 세상에서 널리 사용되고 있다. SQL은 많이 사용되고 있으나 보통 이를 마스터하기엔 어렵다. 자연어를 통해서 데이터베이스와 소통하는 방법을 오랫동안 연구되어 왔다. 이를 일반화 하면 &lt;strong&gt;“Natural Language Interface to Databases(NLIDBs)”&lt;/strong&gt; 라는 분야다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/cmp-lg/9503016&quot;&gt;Natural Language Interfaces to Databases – An Introduction&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;최근에 딥러닝 기반의 방법들이 이를 해결해보고자 했는데 이를 “NL-to-SQL” 혹은 “Text-to-SQL”이라고 하는데, 이 논문에선 Text-to-SQL 문제를 WikiSQL 데이터로 실험한 것에 대해서만 다룬다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;WikiSQL: &lt;a href=&quot;https://github.com/salesforce/WikiSQL&quot;&gt;https://github.com/salesforce/WikiSQL&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;제약 조건: 테이블의 내용을 알고 각 질의(Question)는 하나의 테이블만 해당함&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;WikiSQL데이터에서 이전에 제안된 연구들은 여러 난관이 있었다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;NL question과 table schema 정보를 어떻게 &lt;strong&gt;조합(fuse)&lt;/strong&gt; 할 것인가?&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;실행가능&lt;/strong&gt;하고 &lt;strong&gt;정확한&lt;/strong&gt; SQL문을 어떻게 생성할 것인가?&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;pre-trained language model&lt;/strong&gt;을 어떻게 활용할 것인가?&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이 논문의 동기는 3번 문제였으나 이전의 다른 접근 방법들(Hwang et al, 2019; He et al, 2019)이 language model의 힘을 이끌어 내지 못한다는 점을 주장한다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Encoding 단계에서 전체 테이블 스키마를 자연어 질의와 합쳐서 BERT에 전달한다.&lt;/li&gt;
  &lt;li&gt;Decoding 단게에서 각 칼럼의 hidden representation을 필요로 한다. 이때 칼럼 토큰들을 adhoc pooling을 하게 된다. 이 ad-hoc pooling이 정보손실을 야기하고 불필요하게 복잡도를 올린다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;따라서 이러한 문제를 해결하기 위해 하나의 칼럼만 인코딩하는 방법을 선택했다. 그리고 Decoding 단게에서 multiple sub-tasks를 수행하게 된다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Sub-Tasks: SELECT &amp;amp; WHERE column ranking, condition operator 그리고 condition value span 진행&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그리고 Decoder가 SQL문을 바로 생성하는 것은 아니기 때문에, 직관적인 룰을 사용하여 결과를 합친다. 이를 통해 다음과 같은 효과를 얻을 수 있다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;먼저, question과 column pair 형태가 BERT 혹은 RoBERTa와 sentence pair training task와 유사하기 때문에 효율적으로 이용할 수 있다.&lt;/li&gt;
  &lt;li&gt;둘째, 하나의 칼럼을 인코딩에 사용하기 때문에 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[CLS]&lt;/code&gt; 토큰 벡터에는 모든 정보(question과 column)를 포함하고 있다. 따라서 더 이상 추가 pooling 혹은 더 복잡한 layer를 추가할 필요가 없다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;2-related-work&quot;&gt;2. Related Work&lt;/h1&gt;

&lt;p&gt;생략&lt;/p&gt;

&lt;h1 id=&quot;3-approach&quot;&gt;3. Approach&lt;/h1&gt;

&lt;h2 id=&quot;31-input-representation&quot;&gt;3.1 Input Representation&lt;/h2&gt;

&lt;p&gt;질문 $q$ 와 column 후보 $c_1, c_2, \cdots, c_k$ 가 주어졌을 때, 입력 정보쌍를 다음과 같이 구성할 수 있다.&lt;/p&gt;

\[\big( \text{Concat}(\phi_{c_i}, t_{c_i}, c_i), q \big)\]

&lt;p&gt;여기서 $\phi_{c_i}$는 column $c_i$의 타입 정보(string, real, integer 등), $\text{Concat}$함수는 blank space로 토큰을 하나의 string으로 합친다. 따라서, 입력은 tokenizer에 의해서 다음과 같이 토큰화 된다.&lt;/p&gt;

\[\text{[CLS]}, x_1, x_2, \cdots, x_m, \text{[SEP]}, y_1, y_2, \cdots, y_n, \text{[SEP]}\]

&lt;p&gt;여기서 $x_1, x_2, \cdots, x_m$은 $\text{Concat}(\phi_{c_i}, t_{c_i}, c_i)$을 토큰화 한 것, $y_1, y_2, \cdots, y_n$는 질문 $q$에 대해 토큰화 한 것이다.&lt;/p&gt;

&lt;h2 id=&quot;32-sql-query-representation-and-tasks&quot;&gt;3.2 SQL Query Representation and Tasks&lt;/h2&gt;

&lt;p&gt;이 논문에서 SQL은 nested 구조가 아니기 때문에 다음과 같은 폼을 가진다(WikiSQL 데이터 세트의 제약조건).&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;s&quot;&gt;&quot;sql&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;select&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;agg1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scol1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;agg2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scol2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...],&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;from&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;table1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;table2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...],&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;where&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wcol1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;op1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;wcol2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;op2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;SQL를 2개의 Task(Object)으로 분류 할 수 있다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;구체적 칼럼이 필요한 Task: aggregation operator, value text span&lt;/li&gt;
  &lt;li&gt;구체적 칼럼이 필요하지 않은 Global Task: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;select_num&lt;/code&gt;(SELECT 구문의 갯수), &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;where_num&lt;/code&gt;(WHERE 조건문의 갯수)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;각 칼럼-질문 입력쌍 $(c_i, q)$에 대해서 1번 목적은 sentence pair classification과 question answering task로 도식화 할 수 있다. 그 전에 각 토큰에 해당하는 벡터를 다음과 같이 표현한다.&lt;/p&gt;

\[h_{\text{[CLS]}}, h_{x_1}, h_{x_2}, \cdots, h_{x_m}, h_{\text{[SEP]}}, h_{y_1}, h_{y_2}, \cdots, h_{y_n}, h_{\text{[SEP]}}\]

&lt;p&gt;&lt;strong&gt;구체적 칼럼이 필요한 Task&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;aggregation operator&lt;/strong&gt; $a_j$: $P(a_j \vert c_i, q) = \text{softmax}(W^{agg}[j, :] \cdot h_{\text{[CLS]}})$로 정의한다. Training 때, SELECT 구문에 속하지 않는 칼럼은 mask out 한다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;condition operator&lt;/strong&gt; $o_j$:  $P(o_j \vert c_i, q) = \text{softmax}(W^{op}[j, :] \cdot h_{\text{[CLS]}})$로 정의한다. Training 때, WHERE 구문에 속하지 않는 칼럼은 mask out한다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;value&lt;/strong&gt; &lt;strong&gt;start &amp;amp; end index&lt;/strong&gt;: $P(y_j=\text{start} \vert c_i, q) = \text{softmax}(W^{\text{start}} \cdot h_j^q)$와 $P(y_j=\text{end} \vert c_i, q) = \text{softmax}(W^{\text{end}} \cdot h_j^q)$로 정의한다. Training 때, WHERE 구문에 속하지 않는 칼럼에 대해서 시작과 끝 인덱스는 0으로 세팅한다(BERT QA 세팅과 비슷).&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;구체적 칼럼이 필요하지 않은 Global Task&lt;/strong&gt;&lt;/p&gt;

\[P(z \vert q) = \sum_{c_i} P(z \vert c_i, q)P(c_i \vert q)\]

&lt;ul&gt;
  &lt;li&gt;$P(z \vert c_i, q)$: Sentence pair classification&lt;/li&gt;
  &lt;li&gt;$P(c_i \vert q)$: 칼럼과 질문의 유사도, 계산 방법은 다음 세션에서 소개&lt;/li&gt;
  &lt;li&gt;SELECT 구문의 개수 $n_s$에 대해서는 $P(n_s \vert q) = \sum_{c_i} P(n_s \vert c_i, q) P(c_i \vert q)$로 정의&lt;/li&gt;
  &lt;li&gt;WHERE 구문의 개수 $n_w$에 대해서는 $P(n_w \vert q) = \sum_{c_i} P(n_w \vert c_i, q) P(c_i \vert q)$로 정의&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;33-column-ranking&quot;&gt;3.3 Column Ranking&lt;/h2&gt;

&lt;p&gt;각 질문 $q$에 대해서 $\mathcal{S}_q$를 SELECT 구문과 연관된 칼럼, $\mathcal{W}_q$를 WHERE 구문과 연관된 칼럼이라고 하면, 쿼리문에 나온 칼럼들을 $\mathcal{R}_q \doteq \mathcal{S}_q \cup \mathcal{R}_q$ 로 정의할 수 있다. 마지막으로 후보 칼럼 집합을 $\mathcal{C}_q = \lbrace c_1, c_2, \cdots, c_k \rbrace$이라고 정의 할 수 있으며, 당연하게도 $\mathcal{R}_q \subseteq \mathcal{C}_q$ 관계가 성립된다.&lt;/p&gt;

&lt;p&gt;이에 따라 3개의 &lt;strong&gt;Ranking Tasks&lt;/strong&gt;를 정의할 수 있다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT-Rank&lt;/code&gt;: $q$ 와 연관된 쿼리에서 SELECT 구문에 포함된 칼럼 $c_i \in C_q$을 랭킹, $c_i \in \mathcal{S}_q$&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WHERE-Rank&lt;/code&gt;: $q$ 와 연관된 쿼리에서 WHERE 구문에 포함된 칼럼 $c_i \in C_q$을 랭킹, $c_i \in \mathcal{W}_q$&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Relevance-Rank&lt;/code&gt;: $q$ 와 연관된 쿼리에서 SQL 쿼리 포함된 칼럼 $c_i \in C_q$을 랭킹, $c_i \in \mathcal{R}_q$&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;BERT는 ranking tasks에서 강력한 파워를 보여준다. &lt;a href=&quot;https://arxiv.org/abs/1904.07531&quot;&gt;Qiao et al, 2019&lt;/a&gt;에서 $w \cdot h_{\text{[CLS]}}$를 ranking score로 간주해서 fine-tuning을 하게 된다. 그러면 각 Ranking Tasks에서 Ranking Score는 다음과 같이 정의 할 수 있다.&lt;/p&gt;

\[\begin{aligned} 
P(c_i \in \mathcal{S}_q \vert q) &amp;amp;= \text{sigmoid}(w_{sc} \cdot h_{\text{[CLS]}}) \\ P(c_i \in \mathcal{W}_q \vert q) &amp;amp;= \text{sigmoid}(w_{wc} \cdot h_{\text{[CLS]}}) \\ P(c_i \in \mathcal{R}_q \vert q) &amp;amp;= \text{sigmoid}(w_{rc} \cdot h_{\text{[CLS]}})
\end{aligned}\]

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT-Rank&lt;/code&gt; Score $P(c_i \in \mathcal{S}_q \vert q)$에서 가장 가능성이 높은 후보를 선택한다. 다만 SELECT 구문의 칼럼 갯수 $n_s$를 유지하기 위해서 다음과 같이 결정할 수 있다.&lt;/p&gt;

    &lt;ol&gt;
      &lt;li&gt;특정 threshold 보다 높은 확률을 가진 칼럼 후보만 선택&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;3.2에서 제안한 $n_s$를 직접 예측하기&lt;/p&gt;

\[\hat{n}_s = \underset{n_s}{\arg \max} P(n_s \vert q) = \sum_{c_i \in \mathcal{C}_q} P(n_s \vert c_i, q) P(c_i \in \mathcal{R}_q \vert q)\]

        &lt;p&gt;이번 논문에서는 2번째 방법을 사용했다.&lt;/p&gt;
      &lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WHERE-Rank&lt;/code&gt; Score $P(c_i \in \mathcal{W}_q \vert q)$ 도 마찬가지로 직접 $n_w$를 예측 한다.&lt;/p&gt;

\[\hat{n}_w = \underset{n_w}{\arg \max} P(n_w \vert q) = \sum_{c_i \in \mathcal{C}_q} P(n_s \vert c_i, q) P(c_i \in \mathcal{R}_q \vert q)\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;34-training-and-inference&quot;&gt;3.4 Training and Inference&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Training&lt;/strong&gt; 단계에서 labeled samples를 먼저 $n_i$ column-question samples 로 바꾼다.&lt;/p&gt;

\[\begin{aligned}
\text{labeled samples} &amp;amp;: (q_i, \mathcal{R}_{q_i}), \mathcal{C}_{q_i} = \lbrace c_{q_i1}, c_{q_i2}, \cdots c_{q_in_i} \rbrace \\
\text{column-question samples} &amp;amp;: (c_{q_i1}, q_i), (c_{q_i2}, q_i), \cdots, (c_{q_in_i}, q_i)
\end{aligned}\]

&lt;p&gt;SQL 쿼리 레이블 $(q_i, \mathcal{C}_{q_i})$은 column-question samples와 함께 3.2와 3.3의 Task를 수행하게 되며, 이 문제의 Optimization Object는 모든 샘플에 대해서 $(c_{q_1}, q_1), (c_{q_2}, q_2), \cdots, (c_{q_n}, q_n)$, 모든 Task의 cross-entropy loss를 줄이는 것이다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Inference&lt;/strong&gt; 단계에서는 각 Task의 class labels를 예측한다. 그리고 다음 스텝으로 쿼리문이 만들어진다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;select_num&lt;/code&gt; $n_{s}$ 과 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;where_num&lt;/code&gt; $n_w$를 예측한다.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$c_i \in \mathcal{C}_q$ 의 랭킹을 통해 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;SELECT-Rank&lt;/code&gt; Score를 구하고 상위 $\hat{n}_s$  개의 칼럼($\hat{sc}_1, \hat{sc}_2, \cdots, \hat{sc}_{\hat{n}_s}$) 을 선택한다 따라서 SELECT 구문은 다음과 같으며, $\hat{agg}_i$ 는 예측된 $\hat{sc}_i$ ($i = 1, 2, \cdots, \hat{n}_s$)의 aggregation operator다&lt;/p&gt;

\[[(\hat{agg}_1, \hat{sc}_1), (\hat{agg}_2, \hat{sc}_2), \cdots, (\hat{agg}_{\hat{n}_s}, \hat{sc}_{\hat{n}_s})]\]
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$c_i \in \mathcal{W}_q$의 랭킹을 통해 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WHERE-Rank&lt;/code&gt; Score를 구하고 상위 $\hat{n}_w$ 개의 칼럼($\hat{wc}_1, \hat{wc}_2, \cdots, \hat{wc}_{\hat{n}_w}$) 을 선택한다 따라서 WHERE 구문은 다음과 같으며, $\hat{op}_i, \hat{val}_i$ 는 예측된 $\hat{wc}_i$ ($i = 1, 2, \cdots, \hat{n}_s$)의 condition operator와 value text다.&lt;/p&gt;

\[[(\hat{wc}_1, \hat{op}_1, \hat{val}_1), (\hat{wc}_2, \hat{op}_2, \hat{val}_2), \cdots, (\hat{wc}_{\hat{n}_s}, \hat{op}_{\hat{n}_s}, \hat{val}_{\hat{n}_s})]\]
  &lt;/li&gt;
  &lt;li&gt;$\hat{\mathcal{T}} = \lbrace \hat{t}_1, \hat{t}_2, \cdots, \hat{t}_{n_t} \rbrace$를 모든 예측된 칼럼 $\hat{sc}_i, \hat{wc}_i$의 테이블 집합이라고 정의하면, FROM 구문은 $[\hat{t}_1, \hat{t}_2, \cdots, \hat{t}_{n_t}]$에 해당된다.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;35-execution-guided-decoding&quot;&gt;3.5 Execution-guided decoding&lt;/h2&gt;

&lt;p&gt;Neural Network 모델은 입력 질문, column-value 관계에서 추출된 syntactic과 semantic 정보로 SQL 쿼리를 예측한다. 하지만, 런타임에서 좋은 예측을 못내고 있는데 그 이유는 다음과 같다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;데이터베이스의 값과 칼럼들은 이산적인 관계를 가지며 특별한 제약도 없다. 따라서 매핑된 칼럼들은 값이나 성격이 수시로 바뀔 수 있다. 훈련된 모델은 최신 데이터베이스 정보를 놓쳐서 예전 정보를 기반으로 예측할 가능성이 있다.&lt;/li&gt;
  &lt;li&gt;각 Task에 해당하는 모델의 출력들은 독립적으로 예측한 것이다. 따라서 말이 안되는 조합을 생성할 수 도 있다. string-type의 칼럼에 aggregation operator, greater-than이라는 condition operator를 예측하는 등을 예로 들 수 있다. 이런 케이스들은 가능성을 원천적으로 제거해야한다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이러한 이슈를 해결하기 위해 &lt;a href=&quot;https://arxiv.org/abs/1807.03100&quot;&gt;Wang et al. 2018&lt;/a&gt;에서는 Execution-guided decoding(EG)를 제안했다. 이 논문에서는 SQL 쿼리문 생성시, 만약 데이터베이스 엔진이 런타임 에러가 나거나 빈 출력을 반환 시, 수정을 해주는 아이디어를 제안했다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1NJelQlAmhTJdr62nH40QwTDul3kkUMY5&quot; alt=&quot;Execution Guided Decoding 알고리즘&quot; width=&quot;75%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Execution Guided Decoding 알고리즘&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h1 id=&quot;4-experiment&quot;&gt;4. Experiment&lt;/h1&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1KwHiNi20fOvrP3Cf7TzhlEmZjHf68jlN&quot; alt=&quot;Table 1&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Table 1&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;Logical form accuracy를 봤을 때, WikiSQL 데이터 세트에서 우수함을 보인다.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1WT043OhVRZ5ARrv81DZJZhLuLzsctFUp&quot; alt=&quot;Table 2&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Table 2&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;execution accuracy에서 볼 수 있듯이, HydraNet은 generalization에서도 더 우수함을 보였다.&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Fri, 13 Aug 2021 22:00:01 +0900</pubDate>
        <link>https://simonjisu.github.io/paper/2021/08/13/hybridranking.html</link>
        <guid isPermaLink="true">https://simonjisu.github.io/paper/2021/08/13/hybridranking.html</guid>
        
        
        <category>paper</category>
        
      </item>
    
      <item>
        <title>[글또 6기] 포스트 작성계획 및 다짐</title>
        <description>&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1qmObbD3KqGx2x-PDhXjQzDJQirST_MiC&quot; alt=&quot;그림출처: Pixabay, 그리스가 가고싶어서 넣은 그림&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;그림출처: Pixabay, 그리스가 가고싶어서 넣은 그림&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h1 id=&quot;글또-6기-참여를-시작하며&quot;&gt;글또 6기 참여를 시작하며&lt;/h1&gt;

&lt;p&gt;지난 글또 3, 4기 이후 잠깐 대학원 생활 한다고 1회 쉬었던 글또를 다시 참여하게 됐다. 이번에는 무려 131 명이라고 한다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;글또 페이스북: https://www.facebook.com/groups/geultto/&lt;/li&gt;
  &lt;li&gt;글또 노션 페이지: https://bit.ly/geultto&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;지난 번에 실행할 수 있는 계획을 쓰는게 중요하다고 생각해서 &lt;a href=&quot;https://simonjisu.github.io/others/2020/02/19/geultto4.html&quot;&gt;4기 때 썼던 다짐&lt;/a&gt;을 다시 보니, 그래도 나름 글을 꾸준히 쓴것 같다(12회/13회 글 작성, 패스 1회 사용, 피드백 1회 미달). 나름 시리즈로 기본적인 알고리즘에 대한 글도 써서 사람들에게 도움이 되서 나름 뿌듯했다.&lt;/p&gt;

&lt;p&gt;그러나 사람은 목표를 높게 잡아야하는 법, 이번에는 패스를 한 번도 사용하지 않고, 매 회자마다 글을 작성해보려고 한다. 사실 지원할 때부터 미리 생각해둔 주제들이 있어서 어떤 글을 쓸지는 이미 정해져있는데, 대학원 마지막 학기라 시간 관리를 잘 해야한다고 생각된다. 이번에도 잘 해보자!&lt;/p&gt;

&lt;h1 id=&quot;포스트-작성-계획&quot;&gt;포스트 작성 계획&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Semantic Parsing&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;대학원 학위 논문을 이 분야로 정해서 공부한 것을 잘 정리해보려고 한다. 나는 어떤 기술이던 사람에게 도움이 되어야 한다고 생각한다. 아무리 좋은 기술이라도, 현실에서 쓰이지 못하면 그것은 그림의 떡이라고 생각된다(물론 아직 어플리케이션 연구가 덜 되서 그런 것일 수도 있다).&lt;/p&gt;

&lt;p&gt;Text2SQL은 쿼리문을 잘 모르는 사람들에게 분명 유용한 기술이 될 것이라 생각한다. 주변 일반 회사를 다니는 사람들의 이야기를 들어보면 데이터 분석이 대세여서 해보려고 하는데, 데이터를 DB에서 불러오는 것 부터가 문제라고 한다. 매번 사내 개발자에게 도움을 청할 수도 없는 노릇이고 학원에 가서 SQL를 듣자니 흥미가 크게 나지 않는다고 한다.&lt;/p&gt;

&lt;p&gt;나는 Text2SQL이 이런 사람들을 위한 기술이라 생각한다. 뿐만 아니라 조금 긴 시각으로 보면 Board Meeting 같은 곳에서 필요한 예측을 자연어로 질의하고 이에대한 추론을 해낼 수만 있다면, 더 효율적인 미팅이 되지 않을까 생각한다. 그래서 이 기술을 제대로 연구해 보고 싶다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Background Semantic Parsing &amp;amp; Text2SQL&lt;/li&gt;
  &lt;li&gt;Datasets in Text2SQL&lt;/li&gt;
  &lt;li&gt;Data Agumentation in NLP&lt;/li&gt;
  &lt;li&gt;Models: Hybrid Ranking Network for Text-to-SQL&lt;/li&gt;
  &lt;li&gt;Models: RYANSQL: Recursively Applying Sketch-based Slot Fillings for Complex Text-to-SQL in Cross-Domain Databases&lt;/li&gt;
  &lt;li&gt;Beam Search decoding: Execution-Guided Neural Program Decoding&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Machine Learning &amp;amp; Computer Science&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;기본기를 항상 다지자고 했는데 막상 정리할 시간이 없었다. 다행이도 이번에 논문 자격시험을 통해 이를 한 번에 훑어볼 기회가 생겨서 이를 다시 정리해보려고 한다. 지식을 정리하는 이유는 인간은 기억력은 나약해서 항상 잊기 때문이고 나중에 정리 한 것을 보면 금방 떠오르기 때문이다.&lt;/p&gt;

&lt;p&gt;면접에 갔을 때, 어떤 질문을 물어보면 한 번에 잘 대답한 적이 있는가? 정리를 한 번 했던 경우와 그렇지 않은 경우는 그 대답의 수준이 천지차이다. 정리를 한 경우, 부분 부분 나눠서 기억하고 있던 지식이 상위 계층으로 축약이 되면서, 두괄식 답변을 할 수 있게 만든다(물론 말 하는 스킬에도 연관이 있지만 도움이 되는 것은 사실). 두괄식으로 대답하지 못하는 경우는 해당 지식에 대해서 부분적으로 알고 있다는 반증이기도 하다. 그래서 나는 이번에 머신러닝 지식을 정리하고 이를 한 마디로 요약하는 연습을 해보려고 한다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Bagging: Random Forest&lt;/li&gt;
  &lt;li&gt;Evaluation Metrics Summary&lt;/li&gt;
  &lt;li&gt;Loss Functions&lt;/li&gt;
  &lt;li&gt;Linear &amp;amp; Logistic Regression&lt;/li&gt;
  &lt;li&gt;Data structure summary&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Others&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;취업 할 준비가 되서 그런지, 요즘 회사에 지원 이력서를 쓰고 있는데, 이번 글또에서 사람들과 이런 경험을 같이 공유해봤으면 좋겠다. 나는 어떤 사람인지를 스스로 생각해보고, 내가 잘하는게 무엇인지를 잘 알아보면 좋을 것 같다. 이런 생각을 공유하면서 사람들은 어떤 생각을 가지고 있는지 내가 배울만한 점은 더 있는지 알아보고 싶다. 그리고 내가 생각했던 회사의 모습 혹은 회사가 내 이력서를 보고 생각한 나의 모습을 회사지원하면서 직접 경험하고, 취업을 준비한 사람들과 공유하면서 간접적으로 경험하고 싶다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;나를 뒤돌아 보는 연습: 메타인지&lt;/li&gt;
  &lt;li&gt;나는 어떤 일을 하고 싶은가?&lt;/li&gt;
  &lt;li&gt;채용 공고에서 회사가 원하는 사람, 세세한 차이를 구별해낼 수 있을까? 채용공고 분석하기&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;여기까지 쓰는데 한 시간 딱 걸렸다. OT발표에서 이수진님이 말씀한대로, 매일 한 시간 정도 할애해서 한번 시도 해보는 것도 좋을 것 같다.&lt;/p&gt;
</description>
        <pubDate>Mon, 19 Jul 2021 17:49:01 +0900</pubDate>
        <link>https://simonjisu.github.io/others/2021/07/19/geultto.html</link>
        <guid isPermaLink="true">https://simonjisu.github.io/others/2021/07/19/geultto.html</guid>
        
        
        <category>others</category>
        
      </item>
    
      <item>
        <title>[XAI] Feature Visualization</title>
        <description>&lt;p&gt;&lt;a href=&quot;https://distill.pub/2017/feature-visualization/&quot;&gt;Feature Visualization&lt;/a&gt; 논문을 보면서 정리한다는게 통째로 번역을 해버렸다(물론 부족한 번역이지만…). 하지만 배운 점이 많았는데 그중에 하나로 attribution 방법과 상당히 다른 방향을 지향한다는 점이다. 링크된 페이지를 방문하면 interactive하게 결과물을 보면서 감상할 수 있다.&lt;/p&gt;

&lt;p&gt;기회가 되면 다른 논문인 &lt;a href=&quot;https://distill.pub/2018/building-blocks/&quot;&gt;The Building Blocks of Interpretability&lt;/a&gt;도 한번 쭉 보면서 정리해보겠다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;인간이 신경망을 해석 할 수 있어야한다는 인식이 점차 커지고 있는 가운데 neural network interpretability 분야가 점점 발전하고 있다. 특히 비전분야에서 feature visualization 와 attribution 두 가지 방법이 많이 연구되고 있다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1Ra-1t_qmuJKc9zmqhx5uiFMJMyi9_QkG&quot; alt=&quot;Feature Visualization VS Attribution&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Feature Visualization VS Attribution&lt;/figcaption&gt;&lt;/figure&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;feature-visualization-by-optimization&quot;&gt;Feature Visualization by Optimization&lt;/h1&gt;

&lt;p&gt;Reference: &lt;a href=&quot;https://www.researchgate.net/publication/265022827_Visualizing_Higher-Layer_Features_of_a_Deep_Network&quot;&gt;Visualizing higher-layer features of a deep networ&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;신경망은 대체로 입력에 대해 미분가능하다. 따라서 모델의 특정 행동(내부 뉴런값 혹은 마지막 층의 출력값등)의 원인이 입력의 어떤 부분인지 보고 싶다면 도함수를 사용해 점진적으로 목표에 다다르도록 조정 할 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;optimization-objectives&quot;&gt;Optimization Objectives&lt;/h2&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1x6MT8wNRMAVAiWWTrZsA1wVF0JP1Jkrl&quot; alt=&quot;Different Optimization Objectives&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Different Optimization Objectives&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;목적에 따라서 전혀 다른 해석을 가질 수 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;특정 위치의 한 뉴런 혹은 전체 채널: Neuron, Channel&lt;/li&gt;
  &lt;li&gt;특정 층: Layer/DeepDream&lt;/li&gt;
  &lt;li&gt;특정 클래스: Class Logits, Class Probability&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;why-visualize-by-optimization&quot;&gt;Why visualize by optimization?&lt;/h2&gt;

&lt;p&gt;optimization 기법은 모델이 정말로 무엇을 보고 있는지 알 수 있는 강력한 방법이다. 왜냐면 모델의 특정 행동을 일이키는 원인과 단순히 연관된(correlate)것을 분리할 수 있기 때문이다.&lt;/p&gt;

&lt;p&gt;또한 optimization 기법은 유연하다는 장점이 있다. 예를 들어서 뉴런들어 어떻게 결합되어 표현(jointly represent)되는지 보고 싶다면, 추가 뉴런이 활성화되기 위해 특정한 예가 어떻게 달라져야 하는지 알아 볼 수 있다. 이런 유연함은 네트워크 피처가 어떻게 훈련과정에서 발전하는지를 보여주는 시각화에 도움이 된다.&lt;/p&gt;

&lt;p&gt;장점도 있는 반면 어려운 점들도 있다. 다음 섹션에서는 다양한 시각화 기법들을 이해해본다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;diversity&quot;&gt;Diversity&lt;/h1&gt;

&lt;p&gt;optimization을 통해 예시를 만들때 주의해야할 점은 전체 그림을 생성하는지의 여부다. 왜냐면 이런 특별한 예시들은 피처 표현의 한 단면만 보여주기 때문에, 인지의 오해를 불러 일으킬 수 있다.&lt;/p&gt;

&lt;p&gt;데이터 세트로부터 예시를 생성하면 각기 다른 방면으로 활성화된 뉴런의 전체 스펙트럼을 볼 수 있다.&lt;/p&gt;

&lt;p&gt;아래 그림을 예로 들어 본다. Positive optimized는 특정 뉴런 A을 최대화하게 optimization 과정을 거친 이미지라면, Maximum activation example은 데이터 세트 이미지를 모델에게 입력으로 넣어서, 우리가 optimization을 진행한 뉴런 A을 제일 크게 만드는 이미지만 골라내는 것이다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1sH6G1DatWGtZvoHpFSLPLIHfvIeVfZhG&quot; alt=&quot;Different optimization method in Inception Model&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Different optimization method in Inception Model&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 id=&quot;achieving-diversity-with-optimization&quot;&gt;Achieving Diversity with Optimization&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1507.02379&quot;&gt;Understanding Intra-Class Knowledge Inside CNN(Wei et al. 2015)&lt;/a&gt; 에서는 전체 훈련데이터세트의 활성화 값을 기록하면서, 이들을 클러스터링하고, 클러스터링된 중심값(cluster centroids)으로 부터 optimization하면서, 클래스 간(“intra-class”)의 다양성을 증명했다.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1602.03616&quot;&gt;Multifaceted feature visualization: Uncovering the different types of features learned by each neuron in deep neural networks(Nguyen et al. 2016)&lt;/a&gt; 에서는 하나의 뉴런이 아닌 다양한 방면을 표현하는 피처로부터 optimization을 시작함으로써 다양성을 증명한다.&lt;/li&gt;
  &lt;li&gt;최근 연구인 &lt;a href=&quot;https://arxiv.org/abs/1612.00005&quot;&gt;Plug &amp;amp; play generative networks: Conditional iterative generation of images in latent space(Nguyen et al. 2017)&lt;/a&gt; 에서는 generative model를 결합해서 다양한 예시를 샘플링한다. generative model 접근법이 꽤 잘 되는 편인데, learned priors에서 이를 더 다루기로 한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;diversity를 이루는 방법은 “diversity” 항을 목적함수에 추가함으로써 심플하게 달성할 수 있다. diversity 항은 다양하게 구성할 수 있으며, 그 예시로 다른 클래스 데이터와의 cosine similarity를 패널티로 부여하여 달성 할 수 있다. 다른 예로는 style transfer(&lt;a href=&quot;https://arxiv.org/abs/1508.06576&quot;&gt;A neural algorithm of artistic style, Gatys et al. 2015&lt;/a&gt;)에서 보여준 피처로하여금 다른 스타일을 강제하는 방법이 있다.&lt;/p&gt;

&lt;p&gt;[expand]summary: add “diversity” term 👈&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1eAqOW5e_zGMMRCfdrhbC-owHqpVl9hHs&quot; alt=&quot;원문&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;원문&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;artistic style transfer로부터 영감을 얻음. Gram matrix $G$의 채널들로부터 계산을 시작한다. $G_{i,j}$는 flatten된 필터 $i$와 필터 $j$의 dot product다.&lt;/p&gt;

&lt;p&gt;$G_{i,j} = \sum_{x,y} \text{layer}_n\text{[x, y, i]} \cdot \text{layer}_n\text{[x, y, j]}$&lt;/p&gt;

&lt;p&gt;여기서 diversity term을 계산할 수 있다. the negative pairwise cosine similarity of pairs of visualizations.&lt;/p&gt;

&lt;p&gt;$C_{\text{diversity}} = - \sum_{a} \sum_{b\neq a} \dfrac{\text{vec}(G_a) \cdot \text{vec}(G_b)}{\Vert\text{vec}(G_a)\Vert \Vert\text{vec}(G_b)\Vert}$&lt;/p&gt;

&lt;p&gt;이 후에 $C_{\text{diversity}}$를 optimization 목적함수에 패널티 항으로 추가하여 학습한다.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;낮은 차원의 뉴런들에서 diversity 항은 표현된 피처(feature representations)의 다양한 방면을 보여줄 수 있다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1VSLv-i9JG5uDZa2h4WSY4ECi3AsilOwE&quot; alt=&quot;diversity term reveals different curvy facets&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;diversity term reveals different curvy facets&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;다양한 피처 시각화는 무엇이 뉴런을 활성화하는지 자세히 들여다 볼 수 있게 해준다. 특히 데이터 세트로 본다면, 어떤 입력이 뉴런을 활성화 시키는지 더 다양하게 관찰하고 예측 할 수 있다. 예를 들어 다음 한 장의 optimization결과를 살펴본다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=19yqLldmhfok_rt3pYP6L5fbu2S2jz_yd&quot; alt=&quot;Simple optimization&quot; width=&quot;50%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Simple optimization&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;위 그림을 개의 머리 부분이 뉴런을 활성화 시킨 것으로 보인다. 그림의 일부를 보자면 개의 눈과 아래로 향하는 곡선으로 추측할 수 있다. 그러나 어떤 부분에서는 눈이 포함 안될 때도 있고, 아래로 향하는 곡선뿐만 아니라 위로 향하는 곡선도 있다. 따라서 이 뉴런이 활성화하는 것이 주로 모피 텍스처에 관한 것으로 가설을 세울 수 있다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1Hx7DEAK6jpHXmbTUeHPmGZ51D_ADUqJ6&quot; alt=&quot;Optimization with diversity&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Optimization with diversity&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;이 가설을 데이터 세트 예제를 통해 생성한 결과로 비교해 보면, 대체로 가설이 맞는 것으로 나타난다. 개의 털과 비슷한 질감의 색상과 텍스처를 활성화 했다는 점을 주목해야한다.&lt;/p&gt;

&lt;p&gt;다양함의 효과는 더 높은 층의 뉴런에서 두드러진다. 뉴런을 통해 다양한 물체 종류를 시뮬레이션 할 수 있다. 예를 들어, 다음 그림과 같이 다양한 종류의 볼들이 생성된 것을 볼 수 있다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1GjxqNJ7uwvONizNoTp7_CiZ4HIOXP5Ij&quot; alt=&quot;Optimization with diversity term reveals multiple types of balls&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Optimization with diversity term reveals multiple types of balls&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;이러한 접근법에도 단점이 있다. 예시를 다르게 만드려는 강압적인 방법 때문에 오히려 연관이 없는 물체가 생성 될 수도 있다. 추가로 optimization을 통해서 예시를 다르게 생성하는 것은 부자연스러운 방법이다. 예를 들어, 위 그림의 경우, 누군가는 다른 공들은 제외하고 깨끗한 축구공의 예시를 보고 싶었을 것이다. 데이터 세트에 기반한 기법들(&lt;a href=&quot;https://arxiv.org/abs/1507.02379&quot;&gt;Wei et al. 2015&lt;/a&gt;)은 이와 다르게 조금 더 자연스럽게 피처를 분리할 수 있지만, 각기 다른 데이터들이 어떻게 모델에서 동작하는 지를 이해하는 것에 크게 도움이 안될 수 있다.&lt;/p&gt;

&lt;p&gt;또 다른 근본적인 문제가 있다면, 다양함은 일관된 예시를 보여줄 수도 있지만 그렇지 않을 수 도 있다는 점이다. 아래 예시는 두 동물의 얼굴 그리고 차체의 결과다. 이러한 결과들로부터 우리는 뉴럴넷을 이해하는데 있어서, 하나의 뉴런이 꼭 정확한 의미론적(semantic) 단위는 아니라는 것을 알 수 있다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=153l1TwIixnPAIatf2TD3nqD1EhgMBIDb&quot; alt=&quot;Optimization with diversity term show cats, foxes, but also cars&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Optimization with diversity term show cats, foxes, but also cars&lt;/figcaption&gt;&lt;/figure&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;interaction-between-neurons&quot;&gt;Interaction between Neurons&lt;/h1&gt;

&lt;p&gt;만약에 뉴런이 뉴럴넷을 이해하는데 적절하지 않은 방법이라면, 도대체 무엇이 적절한 방법일까? 실제로 뉴럴넷에서는 여러 뉴런의 조합으로 이미지를 표현한다. 이에 도움이 되는 해석방법은 지리적(geometrically)으로 조합하는 것이다.&lt;/p&gt;

&lt;p&gt;예를 들어 &lt;strong&gt;활성화 공간(activation space)&lt;/strong&gt;이라는 것을 정의해 보자, 그렇다면 개별 활성화된 뉴런은 활성화 공간의 &lt;strong&gt;기저 벡터(basis vectors)&lt;/strong&gt;로 생각할 수 있다. 반대로, 활성화된 뉴런들의 조합들이 곧 활성화 공간이 된다.&lt;/p&gt;

&lt;p&gt;[expand]summary: 선형 대수에서 기저(basis)란? 👈&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://ko.wikipedia.org/wiki/%EA%B8%B0%EC%A0%80_(%EC%84%A0%ED%98%95%EB%8C%80%EC%88%98%ED%95%99)&quot;&gt;https://ko.wikipedia.org/wiki/기저_(선형대수학)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;선형대수학에서, 어떤 벡터 공간의 기저(基底, 영어: basis)는 그 벡터 공간을 선형생성하는 선형독립인 벡터들이다. 달리 말해, 벡터 공간의 임의의 벡터에게 선형결합으로서 유일한 표현을 부여하는 벡터들이다.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;이러한 프레임은 “활성화 공간의 벡터”로서 “뉴런”과 “뉴런의 조합”개념을 통합한다. 그러면 다음과 같은 질문을 할 수 있다. “특정 방향을 가지는 기저 벡터들이 다른 방향을 가지는 기저 벡터들보다 더 나은 해석가능함을 나타낼 수 있을까?”&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1312.6199&quot;&gt;Intriguing properties of neural networks(Szegedy et al. 2014)&lt;/a&gt;에서 저자들은 랜덤한 방향도 충분히 기저 벡터들의 방향만큼 의미가 있다는 것을 주장했다.&lt;/p&gt;

&lt;p&gt;[expand]summary: Intriguing properties of neural networks 👈&lt;/p&gt;

&lt;p&gt;Reference: &lt;a href=&quot;https://3ffr3s.github.io/2020-02-10-Intriguing_properties_of_neural_networks/&quot;&gt;https://3ffr3s.github.io/2020-02-10-Intriguing_properties_of_neural_networks/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;이전 연구에서는 이미지 데이터 집합 $I$에 속한 이미지 $x$가 주어졌을 때, 단일 피처의 activation을 최대화하는 입력 $x^{‘}$을 찾았다. $e_i$는 $i$번째 hidden unit에 관련된 natural basis vector를 뜻한다. 예: $e_i = 1 \text{ if i-th neuron else } 0$&lt;/p&gt;

\[x^{&apos;} = \underset{x \in I}{\arg \max} \text{&amp;lt;}\phi(x), e_i \text{&amp;gt;}\]

&lt;p&gt;하지만 저자들은 랜덤한 벡터 $v \in \Bbb{R}^{n}$ 로 해도 비슷한 해석이 가능하다는 것을 밝혀냈다.&lt;/p&gt;

\[x^{&apos;} = \underset{x \in I}{\arg \max} \text{&amp;lt;}\phi(x), v \text{&amp;gt;}\]

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1L0A9ZvvQe2UzsWcHTK3UJyUVxrXFG59J&quot; alt=&quot;Mnist에 대한 실험 결과&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Mnist에 대한 실험 결과&lt;/figcaption&gt;&lt;/figure&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1C55n-ng_wxzPLlH9qsSn6jDQE-xbXF29&quot; alt=&quot;ImageNet에 대한 실험결과&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;ImageNet에 대한 실험결과&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;여러 분석을 통해 뉴럴넷 $\phi(x)$의 특성을 살펴보는데 natural basis vector가 random vector와 큰 차이가 없다는 것을 뜻한다. 입력 분포의 특정 부분 집합에 대해서 불변성(invariance)을 띄는 $\phi$의 능력을 설명할 수 있지만, 나머지 도메인에 대해서 $\phi$의 행동을 설명 할 수가 없다.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1704.05796&quot;&gt;Network Dissection: Quantifying Interpretability of Deep Visual Representations(Zhou et al.)&lt;/a&gt;에서는 랜덤한 방향보다 basis vector의 방향이 더 해석가능하다고 밝혔다.&lt;/p&gt;

&lt;p&gt;우리의 실험에서는 두 가지 주장에 대체로 일치한다. 랜덤한 방향은 어느 때에는 더 해석가능하지만, basis 방향보다는 약간의 낮은 수치를 기록하고 있다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1gEssEqwLEh_Cdl9PWq56BdcOey2PmbbD&quot; alt=&quot;Dataset examples and optimized examples of random directions&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Dataset examples and optimized examples of random directions&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;우리는 활성화 공간에서 뉴런에 대해 약간의 산수를 통해 조금 더 흥미로운 방향을 정의할 수 있다. 예를 들어, “검정과 하양”을 “모자이크” 뉴런에 더하면, 검정고 하얀 모자이크를 얻을 수 있었다. 마치 Word2Vec의 의미론적 단어 임베딩과 비슷하다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1cNO3z_mtgocM0d0ggTIEE-llzqAxOt9Q&quot; alt=&quot;Jointly optimizing two neurons&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Jointly optimizing two neurons&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;위 그림의 예시는 뉴런들이 조건부 결합으로 표현된 이미지다. 이 둘 사이에 보간법을 적용해 뉴런들의 상호작용을 더 잘 이해하게 만들 수있다. 생성 모델(generative models)에서 latent space에 보간법을 적용하는 것과 비슷하다.&lt;/p&gt;

&lt;p&gt;[expand]summary: 생성모델에서 latent space애 보간법 적용하는 방법 👈&lt;/p&gt;

&lt;p&gt;간단히 0.1만큼 선형 보간법을 적용한다면 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt; 

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;interpolate_points&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_steps&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;
    p1, p2: shape of (hidden_dim) vector
    &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# interpolate ratios between the points
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;ratios&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_steps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# linear interpolate vectors
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;vectors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ratio&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ratios&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ratio&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ratio&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p2&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;vectors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vectors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;정확히 말하자면, 전체 optimization의 목적은 개별 채널의 목적함수의 선형 보간과 같다. 보간법을 더 잘 하기 위해서, 낮은 활성화 층과 비슷하도록 작은 alignment 목표를 추가한다. 더 쉽게 optimization을 달성하기 위해서, 분리되고 공유된 이미지의 매개변수 조합을 사용했다(랜덤하게 주어도 되지만).&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1ugBFfZq4HhAtBuAQEJBz1iJFQrj33C8W&quot; alt=&quot;Interploation&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Interploation&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;이 부분은 뉴런들이 어떻게 상호작용하는지 알아가는 시작 단계일 뿐이다. 우리도 어떻게 의미있는 방향을 선택하는지 아니면 실제로 의미가 있는 방향이 존재하는 지를 아직 모르겠다. 방향을 찾는 것과 별개로 방향들간에 서로 어떻게 작용하지에 대한 의문도 있다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;the-enemy-of-feature-visualization&quot;&gt;The Enemy of Feature Visualization&lt;/h1&gt;

&lt;p&gt;불행하게도, 단순히 최적화를 한다고해서 피처를 시각화 할 수 없다. 단순 최적화를 하면 어떤 착시 현상 - noise로 가득차고, 무의미한 &lt;strong&gt;고주파 패턴(high-frequency patterns)&lt;/strong&gt;만을 얻을 것이다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=14QbrkQC29NRJVA4XTzKVO7IFc0nx-wBr&quot; alt=&quot;Optimization results with noise&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Optimization results with noise&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;이는 실제 생활에서 일어나지 않을 법한 패턴이다. 만약에 충분이 오랬동안 최적화를 진행한다면, 일부 뉴런이 특출나게 어떤 것을 탐지해내지만, 이미지는 고주파 패턴으로 도배될 것이다. 이러한 패턴들은 &lt;a href=&quot;https://arxiv.org/abs/1312.6199&quot;&gt;Intriguing properties of neural networks(Szegedy et al. 2014)&lt;/a&gt;에서 언급한 &lt;strong&gt;적대적 예시의 현상(phenomenon of adversarial examples)&lt;/strong&gt;으로 보인다.&lt;/p&gt;

&lt;p&gt;왜 이런 고주파 패턴 현상이 발생하는지 100% 이해할 수는 없지만, strided convolutions 과 pooling 연산에서 이러한 현상을 야기시킨다는 것을 발견할 수 있었다(&lt;a href=&quot;https://distill.pub/2016/deconv-checkerboard/&quot;&gt;Deconvolution and checkerboard artifacts&lt;/a&gt; 글 참고 - up sampling시 resize-convolution 활용: interpolation 후에 Conv Layer 통과).&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1vndh70zXGkfumkWigTbm36Ty3boFo0hn&quot; alt=&quot;Reason why causes the hight frequency patterns&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Reason why causes the hight frequency patterns&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;고주파 패턴을 통해 우리는 최적화 기반의 시각화에서 제약으로부터 자유로울수록 매력적이지만, 이는 양날의 검이기도 하다는 것을 알 수 있다. 아무런 제약이 없다면 적대적 예시를 결과로 얻을 것이다.&lt;/p&gt;

&lt;h2 id=&quot;the-spectrum-of-regularization&quot;&gt;The Spectrum of Regularization&lt;/h2&gt;

&lt;p&gt;고주파 노이즈를 다루는 것이 곧 이 분야에서 주요 과제가 되었다. 유용한 시각화 결과를 얻기 위해서, 학습된 사전 분포(prior), 정규항(regularizer)이나 제약(constraint)등이 추가되어야 한다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;정규화(regularization)&lt;/strong&gt;는 최근 피처 시각화 연구에서 확인 할 수 있는 주요 포인트다. 이를 하나의 스펙트럼으로 나눌 수 있을 것이다. 극단적으로 아예 정규화를 하지 않으면, 적대적 예시를 얻고, 너무 강한 정규화를 하게 되면 오해를 부르는 연관성을 야기할 수 있다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1jOkkAiLo4I_Ui-OJbGRcYe4JpLN335s1&quot; alt=&quot;여러 방법론 정리&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;여러 방법론 정리&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 id=&quot;three-families-of-regularization&quot;&gt;Three Families of Regularization&lt;/h2&gt;

&lt;h3 id=&quot;frequency-penalization&quot;&gt;Frequency penalization&lt;/h3&gt;

&lt;p&gt;Frequency penalization는 고주파 노이즈를 직접 없에는 것을 목표로 한다. 명시적으로 근접 픽셀(total variation, &lt;a href=&quot;https://arxiv.org/abs/1412.0035v1&quot;&gt;Understanding deep image representations by inverting them(Mahendran, Vedaldi, 2014)&lt;/a&gt;)에 패널티를 부여하거나, 암묵적으로 이미지를 각 최적화 스텝마다 블러 처리를 하는 방법(&lt;a href=&quot;https://arxiv.org/abs/1412.1897&quot;&gt;Deep neural networks are easily fooled: High confidence predictions for unrecognizable images(Nguyen et al. 2014)&lt;/a&gt;)등이 있다. 안타깝게도 이러한 접근법들은 노이즈가 더해진 엣지같은 높은 주파수를 가지는 피처를 억제한다(즉, 엣지를 없엔다). 이는 bilateral filter를 활용하면 약간 해소할 수 있다(&lt;a href=&quot;https://mtyka.github.io/deepdream/2016/02/05/bilateral-class-vis.html&quot;&gt;Class visualization with bilateral filters, M. Tyka. 2016&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;[expand]summary: 블러 처리에 대한 주석 👈&lt;/p&gt;

&lt;p&gt;푸리에 공간에서 블러 처리를 한다면, 스케일링된 L2 정규항을 목적함수에 추가하는 것과 같다. 즉, 주파수에 기반해 각 푸리에 요소에 패널티를 부여하는 것과 같다.&lt;/p&gt;

&lt;p&gt;If we think about blurring in Fourier space, it is equivalent to adding a scaled L2 penalty to the objective, penalizing each Fourier-component based on its frequency.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;특정 연구(&lt;a href=&quot;https://www.auduno.com/2015/07/29/visualizing-googlenet-classes/&quot;&gt;Visualizing GoogLeNet Classes &lt;strong&gt;(&lt;/strong&gt;A. Øygard. 2015)&lt;/a&gt;, &lt;a href=&quot;https://www.tensorflow.org/tutorials/generative/deepdream?hl=ko&quot;&gt;DeepDreaming with TensorFlow (A. Mordvintsev. 2016)&lt;/a&gt;)에서는 시각화에서 특정 결과로 모으기 전에, 위에서 서술한 기술을 사용해 경사에서 높은 주파수를 제거하는 용도로 사용한다. 이는 약간 비슷하면서도 본질적으로 다른 면이 있는데 Preconditioning and Parameterization 파트에서 설명한다.&lt;/p&gt;

&lt;p&gt;아래 그림에서 높은 패널티를 줄 수록 고주파 패턴이 사라지고 선명해지는 경향이 있다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1_cTAnFiCtXB2D-zaYVBgAoH494JUaBhn&quot; alt=&quot;블러처리와 패널티&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;블러처리와 패널티&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h3 id=&quot;transformation-robustness&quot;&gt;Transformation robustness&lt;/h3&gt;

&lt;p&gt;Transformation robustness는 약간의 변형이 있어도 계속 최적화 타겟을 활성화 시키는 예시을 찾는 것을 목표로 한다. &lt;a href=&quot;https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html&quot;&gt;Inceptionism: Going deeper into neural networks(Google Research Blog. 2015)&lt;/a&gt; 에서 말하길 아주 작은 값이라도 이미지에서는 큰 효과를 가져온다. 특히, 높은 주파수가 결합된 일반적인 정규항에서 더 효과적이다(&lt;a href=&quot;https://www.auduno.com/2015/07/29/visualizing-googlenet-classes/&quot;&gt;Visualizing GoogLeNet Classes &lt;strong&gt;(&lt;/strong&gt;A. Øygard. 2015)&lt;/a&gt;, &lt;a href=&quot;https://www.tensorflow.org/tutorials/generative/deepdream?hl=ko&quot;&gt;DeepDreaming with TensorFlow (A. Mordvintsev. 2016)&lt;/a&gt;). 구체적으로 최적화 스텝을 진행하기 전에 확률적으로 이미지를 지터링(jitter), 회전(rotate) 또는 스케일링(scale) 한다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=10VzBQqtUVnPGIuGCUBSd2vgcQLr66L-O&quot; alt=&quot;Stochastically transforming the image&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Stochastically transforming the image&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h3 id=&quot;learned-priors&quot;&gt;Learned priors&lt;/h3&gt;

&lt;p&gt;이전에 이야기한 정규화항은 예제를 합리적으로 유지하기 위해 매우 간단하고 휴리스틱한 방법을 사용했다. 자연스럽데 다음 단계로 실제 데이터로부터 모델을 학습하고 이를 적용하는 것이다. 강력한 모델을 사용하면, 데이터 세트에서 검색하는 것과 비슷해진다. 이러한 접근법은 가장 사실적인 시각화를 제공하지만, 어떤 것이 모델로부터 시각화 되었고, 어떤 것이 사전 분포로부터 온것인지 모르는 단점이 있다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;잠재 공간(latent space)&lt;/strong&gt;으로 부터 예시를 매핑하는 &lt;strong&gt;생성기(generator)&lt;/strong&gt;를 학습하는 것이 하나의 방법이다. GAN, VAE와 같은 모델을 학습하고 잠재공간을 최적화 하는 방법이다(&lt;a href=&quot;https://arxiv.org/abs/1605.09304&quot;&gt;Synthesizing the preferred inputs for neurons in neural networks via deep generator networks(Nguyen et al. 2016)&lt;/a&gt;). 다른 접근 법으로는 확률의 경사를 얻을 수 있는 사전 분포를 학습하는 것이다. 이를 이용하면 목적에 따라 사전 분포를 조건부로 최적화 할 수 있다(&lt;a href=&quot;https://arxiv.org/abs/1612.00005&quot;&gt;Plug &amp;amp; play generative networks: Conditional iterative generation of images in latent space(Nguyen et al. 2016)&lt;/a&gt;, &lt;a href=&quot;https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html&quot;&gt;Inceptionism: Going deeper into neural networks(Google Research Blog. 2015)&lt;/a&gt;). 하나는 특정 클래스의 확률값과 사전 분포를 최적화하고, 다른 하나는 특정 클래스를 조건부로 생성 모델에서 데이터를 복구하는 것이다. 마지막으로 &lt;a href=&quot;https://arxiv.org/abs/1507.02379&quot;&gt;Understanding Intra-Class Knowledge Inside CNN(Wei et al. 2015)&lt;/a&gt; 에서는 생성 모델의 사전 분포를 대략 추정한다. 적어도 칼러 분포에서, 출력 이미지 패치들과 근처 패치들의 거리에 패널티를 부여하는 방법을 사용하는데, 여기서 근처 패치들은 훈련 데이터에서 수집한 이미지 패치 데이터베이스에서 검색하는 방식이다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;preconditioning-and-parameterization&quot;&gt;Preconditioning and Parameterization&lt;/h1&gt;

&lt;p&gt;이전 섹션에서 특정 방법들은 고주파 패턴을 시각화 자체에서 줄이는게 아니라 경사에 적용한다고 했었다(&lt;a href=&quot;https://www.auduno.com/2015/07/29/visualizing-googlenet-classes/&quot;&gt;Visualizing GoogLeNet Classes &lt;strong&gt;(&lt;/strong&gt;A. Øygard. 2015)&lt;/a&gt;, &lt;a href=&quot;https://www.tensorflow.org/tutorials/generative/deepdream?hl=ko&quot;&gt;DeepDreaming with TensorFlow (A. Mordvintsev. 2016)&lt;/a&gt;). 이러한 방법이 정규화항(regularizer)인지는 명확하지 않다. 높은 주파수를 억제하나, 경사에서 이를 계속 보낼 경우 높은 주파수의 형성을 허용하게 된다. 만약에 정규화항이 아니라면, 경사의 변화는 어떤 역할을 하는 것일까?&lt;/p&gt;

&lt;p&gt;경사를 변화시키는 것은 꽤나 강력한 도구이며, optimization에서 “&lt;strong&gt;preconditioning”&lt;/strong&gt;이라고 부르며, 같은 목적함수를 가장 가파른 경사로 최적화 하는데, 다른 파라미티 공간과 거리 조건 하에서 최적화를 한다고 생각할 수 있다. 경사를 얼마나 가파르게 변화하거나, 해당 방향으로 얼마나 빠르게 변화를 줘도, 최소가 되는 지점은 변함이 없다. local minima가 많아도, 경사를 수축/확장하면서 벗어날 수 있다. 따라서 적절한 &lt;strong&gt;preconditioning&lt;/strong&gt;은 최적화 문제를 조금 더 쉽게 만들어 준다.&lt;/p&gt;

&lt;p&gt;그러면 어떤 조건이 좋을까? 먼저 데이터와 연관을 줄이는 방향(decorrelated and whitened)으로 시도 해볼 수 있다. 이미지의 경우, 같은 에너지를 가지도록 주파를 스케일링하는 Fourier basis로 경사 하강법을 실행하는 것이다.&lt;/p&gt;

&lt;p&gt;다음 그림을 보면 거리 조절 방법에 따라서 경사의 방향이 달라진다. $L^2$ 정규화는 $L^{\infty}$ 와 decorrelated space와 확연한 차이를 보인다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1w5oDxg5cMQuTlFUgbKb08YPBGV5RQhNi&quot; alt=&quot;Three directions of steepest descent under different notions of distance&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Three directions of steepest descent under different notions of distance&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;위에서 서술한 모든 방향들은 다 유효한 경사 방향이지만,  결과물을 보면 근본적으로 다르다. decorrelated space로 최적화시, 높은 주파수를 줄일 수 있으며,  $L^{\infty}$ 방법은 오히려 반대로 이를 증가시킨다.&lt;/p&gt;

&lt;p&gt;decorrelated 경사 방향을 사용하면 꽤나 다른 시각화 결과를 얻을 수 있다. 이는 hyperparameter를 조절해야하기 때문에 공평한 비교가 힘들지만, 시각화 결과는 훨씬 더 좋으며, 더 빠르게 얻을 수 있다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1FCCHjI1N6DhzOXz5JebyIeVUjdlgC94b&quot; alt=&quot;Combining the preconditioning and transformation robustness&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Combining the preconditioning and transformation robustness&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;preconditioner가 단순 최적화를 가속 시키는 것인지? 즉, 같은 조건에 평범한 경사를 사용하여 오랜 시간 기다리면, preconditioner을 사용한 것과 같은 결과를 얻을지? 정규화를 함으로써 local minima를 피할 수 있는 것인지? 이는 아직 확실하게 말하기 어렵다. 한편으로 만약에 충분히 오랜 스텝동안 경사하강법을 진행한다면, 느리지만 결국에 수렴하게 된다. 또 다른 한편으로 정규화를 하지 않으면 preconditioner가 높은 주파스 패턴을 줄여준다.&lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;뉴런 시각화는 지난 몇년 동안 많은 발전을 이뤘다. 우리는 강력한 시각화를 만들 수 있는 원칙적인 방법을 개발했다. 그리고 여러 가지 중요한 과제를 계획하고 해결 방법을 찾았습니다.&lt;/p&gt;

&lt;p&gt;신경망을 해석가능하게 만들기 위해, 피처 시각화는 가장 유망하고 발전된 연구 방향 중 하나로 눈에 띈다. 피처 시각화 자체로는 완벽한 이해를 얻을 수 없다. 우리는 이를 다른 툴과 함께 사용하여, 인간이 시스템을 이해하기 위한 근본 요소중 하나로 보고있다.&lt;/p&gt;

&lt;p&gt;피처 시각화에는 아직 많은 해야할 일이 남아 있다. 뉴런의 상호작용을 이해하기, 활성화된 신경망을 이애하기 위해 가장 의미가 유닛을 찾기, 그리고 피처를 다방면으로 살펴보는 문제들이 바로 앞으로 해결해야할 문제들이다.&lt;/p&gt;

&lt;h1 id=&quot;appendix-inception-module&quot;&gt;Appendix: Inception Module&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://distill.pub/2017/feature-visualization/appendix/&quot;&gt;Feature Visualization - Appendix&lt;/a&gt;&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1_61451LmD03-WIxRI2z6Auy5nRs6TauO&quot; alt=&quot;Inception 모델에 대한 Layer 번호 설명&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Inception 모델에 대한 Layer 번호 설명&lt;/figcaption&gt;&lt;/figure&gt;
</description>
        <pubDate>Tue, 20 Apr 2021 22:00:01 +0900</pubDate>
        <link>https://simonjisu.github.io/paper/2021/04/20/featurevisualization.html</link>
        <guid isPermaLink="true">https://simonjisu.github.io/paper/2021/04/20/featurevisualization.html</guid>
        
        
        <category>paper</category>
        
      </item>
    
      <item>
        <title>FARM tutorial</title>
        <description>&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1hbtUClFoXg45IbViZoFRLnnDGVlr9Dlb&quot; alt=&quot;&quot; width=&quot;50%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h1 id=&quot;farm&quot;&gt;FARM&lt;/h1&gt;

&lt;blockquote&gt;
  &lt;p&gt;Framework for Adapting Representation Models&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이 패키지를 한 마디로 요약하면 Fine-tuning에 최적화된 도구다.&lt;/p&gt;

&lt;p&gt;최근의 자연어처리 분야는 Transformer와 그 변형의 등장으로 인해, 보통 2단계로 나눠서 학습이 진행된다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Pretrained Language Modeling&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;대량의 텍스트 데이터를 이용해 비지도학습(unsupervised learning)으로 언어 모델링은 진행한다. 언어 모델링이란 인간의 언어를 컴퓨터로 모델링하는 과정이다. 쉽게 말하면, 모델에게 단어들을 입력했을 때, 제일 말이 되는 단어(토큰)을 뱉어내게 하는 것이다. 과거에는 단어(토큰)의 순서가 중요했었다. 즉, 일정 단어들의 시퀀스 $x_{1:t-1}$가 주어지면, $t$번째 단어인 $x_t$를 잘 학습시키는 것이었다. 이를 &lt;strong&gt;Auto Regressive Modeling&lt;/strong&gt;이라고도 한다. 그러나, &lt;strong&gt;Masked Language Modeling&lt;/strong&gt; 방법이 등장했는데, 이는 랜덤으로 맞춰야할 단어를 가린 다음에 가려진 단어 $x_{mask}$가 포함된 시퀀스 $x_{1:t}$ 를 모델에게 입력하여 맞추는 학습 방법이다. 이러한 방법이 좋은 성과를 거두면서, 최근에는 모든 언어모델링 기법들이 MLM을 기반으로 하고 있다.&lt;/p&gt;

    &lt;p&gt;다만, 얼만큼의 확률로 적절하게 가릴지, transformer가 가지고 있는 태생적인 단점인 처리할 수 있는 토큰의 개수 제약 등 해결하려는 시도가 많이 있고, 앞으로도 해결해야할 문제들이다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Fine-tuning&lt;/strong&gt;&lt;/p&gt;

    &lt;p&gt;&lt;strong&gt;PLM(Pretrained Language Model)&lt;/strong&gt;을 만들고 나면, 각기 다른 downstream task에 따라서 fine-tuning을 하게 된다. Downstream task은 구체적으로 풀고 싶은 문제를 말하며, 주로 다음과 같은 문제들이다.&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;텍스트 분류 Text Classification&lt;/strong&gt; - 예시: 영화 댓글 긍정/부정 분류하기&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;개체명인식 NER(Named Entity Recognition)&lt;/strong&gt; - 예시: 특정 기관명, 인명 및 시간 날짜 등 토큰에 알맞는 태그로 분류하기&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;질의응답 Question and Answering&lt;/strong&gt; - 예시: 특정 지문과 질의(query)가 주어지면 대답하기&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;오늘 소개할 FARM 패키지는 2번째 단계인 Fine-tuning을 보다 손쉽게 만들어 놓은 패키지다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Tutorial github:&lt;/strong&gt; &lt;a href=&quot;https://github.com/simonjisu/FARM_tutorial&quot;&gt;https://github.com/simonjisu/FARM_tutorial&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Colab Tutorial:&lt;/strong&gt; &lt;a href=&quot;https://colab.research.google.com/github/simonjisu/FARM_tutorial/blob/main/notebooks/FARM_colab.ipynb&quot;&gt;링크&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;core-features&quot;&gt;Core Features&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Easy fine-tuning of language models&lt;/strong&gt; to your task and domain language&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Speed&lt;/strong&gt;: AMP(Automatic Mixed Precision) optimizers (~35% faster) and parallel preprocessing (16 CPU cores =&amp;gt; ~16x faster)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Modular design&lt;/strong&gt; of language models and prediction heads&lt;/li&gt;
  &lt;li&gt;Switch between heads or combine them for &lt;strong&gt;multitask learning&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Full Compatibility&lt;/strong&gt; with HuggingFace Transformers’ models and model hub&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Smooth upgrading&lt;/strong&gt; to newer language models&lt;/li&gt;
  &lt;li&gt;Integration of &lt;strong&gt;custom datasets&lt;/strong&gt; via Processor class&lt;/li&gt;
  &lt;li&gt;Powerful &lt;strong&gt;experiment tracking&lt;/strong&gt; &amp;amp; execution&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Checkpointing &amp;amp; Caching&lt;/strong&gt; to resume training and reduce costs with spot instances&lt;/li&gt;
  &lt;li&gt;Simple &lt;strong&gt;deployment&lt;/strong&gt; and &lt;strong&gt;visualization&lt;/strong&gt; to showcase your model&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[expand]summary:What is AMP? 👈&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Reference&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/NVIDIA/apex&quot;&gt;https://github.com/NVIDIA/apex&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://forums.fast.ai/t/mixed-precision-training/20720&quot;&gt;https://forums.fast.ai/t/mixed-precision-training/20720&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;mixed precision training이란&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;처리 속도를 높이기 위한 FP16(16bit floating point)연산과 정확도 유지를 위한 FP32 연산을 섞어 학습하는 방법&lt;/li&gt;
  &lt;li&gt;Tensor Core를 활용한 FP16연산을 이용하면 FP32연산 대비 절반의 메모리 사용량과 8배의 연산 처리량 &amp;amp; 2배의 메모리 처리량 효과가 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;nsmc-데이터로-farm-알아보기&quot;&gt;NSMC 데이터로 FARM 알아보기&lt;/h1&gt;

&lt;h2 id=&quot;nsmc-데이터&quot;&gt;NSMC 데이터&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;NSMC(Naver Sentiment Movie Corpus)&lt;/strong&gt;는 한국어로 된 영화 댓글 데이터 세트다. 해당 Task는 타겟 값이 긍정(1)/부정(0)이 되는 Binary Text Classification 문제로 볼 수 있다. &lt;a href=&quot;https://github.com/e9t/nsmc&quot;&gt;https://github.com/e9t/nsmc&lt;/a&gt;에서 받을 수 있다(아래 그림은 label을 bad와 good으로 처리해놓은 상태).&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1FIGIBtZxtuKD5Prps5vPOPldBb0xHwzH&quot; alt=&quot;[그림1] NSMC Dataset&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;[그림1] NSMC Dataset&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 id=&quot;fine-tuning-process&quot;&gt;Fine-tuning Process&lt;/h2&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1j9pn8Lpg7sy6S8Ubvq3E7JLWf28KvRt4&quot; alt=&quot;[그림2] Fine-tuning Process&quot; width=&quot;50%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;[그림2] Fine-tuning Process&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;Fine-tuning Process는 위 그림과 같이 진행된다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Load Data: 데이터를 알맞는 형식(json, csv 등)으로 불러온다.&lt;/li&gt;
  &lt;li&gt;Create Dataset: 데이터세트(Dataset) 만들기
    &lt;ul&gt;
      &lt;li&gt;Tokenization: 텍스트를 토큰으로 나누고, 단어장(vocab)을 생성한다.&lt;/li&gt;
      &lt;li&gt;ToTensor: vocab에 해당하는 단어를 수치화하는 과정 (transformers 패키지 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;input_ids&lt;/code&gt;에 해당)&lt;/li&gt;
      &lt;li&gt;Attention Mask: 패딩계산을 피하기 위해 Attention 해야할 토큰만 masking(transformers 패키지 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;attention_mask&lt;/code&gt; 에 해당)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Create Dataloader: 훈련, 평가시 배치크기 단위로 데이터를 불러오는 객체&lt;/li&gt;
  &lt;li&gt;Create Model:
    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;Pretrained Language Model: 대량의 텍스트 데이터로 사전에 훈련된 모델&lt;/p&gt;

\[\underset{\theta}{\arg \max} P(x_{mask} \vert x_{1:t})\]
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;Fine-tuninig Layer: Downstream Task에 맞춰서 학습한다.&lt;/p&gt;

\[\underset{\theta}{\arg \max}P(y\vert x_{1:t})\]

        &lt;p&gt;예를 들어, 영화 긍정/부정 분류 문제의 경우&lt;/p&gt;

\[\underset{\theta}{\arg \max} P(y=\text{긍정/부정} \vert x_{1:t})\]
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Train Model: 모델 훈련&lt;/li&gt;
  &lt;li&gt;Eval Model: 모델 평가&lt;/li&gt;
  &lt;li&gt;Inference: 모델 서비스&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;processor--data-silo&quot;&gt;Processor &amp;amp; Data Silo&lt;/h2&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1XCc0AJpPBMFcC81NW0A6w0mpswZ2KU7h&quot; alt=&quot;[그림3] Fine-tuning Process&quot; width=&quot;90%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;[그림3] Fine-tuning Process&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Processor&lt;/strong&gt;는 file 혹은 request를 PyTorch Datset로 만들어 주는 역할이다. 자세한 인자값은 다음 코드 블록에서 설명한다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Data Silo&lt;/strong&gt;는 train, dev, test sets를 관리하고, Processor의 function들 이용해 각 set를 DataLoader로 변환한다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Processor&lt;/strong&gt;는 각 데이터를 처리할 때, &lt;strong&gt;Samples&lt;/strong&gt;, &lt;strong&gt;SampleBasket&lt;/strong&gt;에 담게 되는데, 이들은 raw document를 관리하는 객체이며 tokenized, features등 데이터와 각 샘플을 관리하는 id를 저장하고 있다. 이렇게 하는 이유는 하나의 소스 텍스트(raw text)에서 여러개의 샘플을 생성할 수도 있기 때문이다
여담이지만 huggingface의 SquadProcessor는 512개 토큰이 넘어가면, 뒤에서 부터 512토큰을 세서 하나의 데이터를 두 개의 샘플로 만든다.
    &lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;dataset_from_dicts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...)&lt;/span&gt;
      &lt;span class=&quot;c1&quot;&gt;# ...
&lt;/span&gt;      &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_ids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;segment_ids&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokens&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;dicts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_ids_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;segment_ids_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding_masks_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tokens_batch&lt;/span&gt;
      &lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
          &lt;span class=&quot;c1&quot;&gt;# ...
&lt;/span&gt;          &lt;span class=&quot;c1&quot;&gt;# Add Basket to self.baskets
&lt;/span&gt;          &lt;span class=&quot;n&quot;&gt;curr_sample&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
              &lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;clear_text&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;tokenized&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenized&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;feat_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
          &lt;span class=&quot;n&quot;&gt;curr_basket&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SampleBasket&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;id_internal&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;raw&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dictionary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;id_external&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
              &lt;span class=&quot;n&quot;&gt;samples&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;curr_sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
          &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
          &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;baskets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;curr_basket&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

      &lt;span class=&quot;c1&quot;&gt;# ...
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;사용하는 방법은 다음과 같다.&lt;/p&gt;

&lt;p&gt;[expand]summary: 코드보기 👈&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Reference: https://github.com/Beomi/KcBERT
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;PRETRAINED_MODEL_NAME_OR_PATH&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;beomi/kcbert-base&quot;&lt;/span&gt;  
&lt;span class=&quot;n&quot;&gt;MAX_LENGTH&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;150&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;LABEL_LIST&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;bad&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;good&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;TRAIN_FILE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;train.tsv&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;TEST_FILE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;test.tsv&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;TASK_TYPE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;text_classification&quot;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Tokenizer
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pretrained_model_name_or_path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;PRETRAINED_MODEL_NAME_OR_PATH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;do_lower_case&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Processor
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;processor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TextClassificationProcessor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# tokenizer 
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;train_filename&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TRAIN_FILE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# training data 파일명
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;dev_filename&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# development data 파일명, 없으면, dev_split 비율만큼 training data에서 자른다 
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;test_filename&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TEST_FILE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# test data 파일명
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;dev_split&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# development data로 설정할 비율
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;header&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# csv, tsv, excel 등 tabular형태 데이터에서 첫행(보통은 컬럼명)의 위치
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;max_seq_len&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MAX_LENGTH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 문장의 최대 길이
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;data_dir&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DATA_PATH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 데이터의 디렉토리
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;label_list&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LABEL_LIST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 레이블 리스트(string 필요)
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;metric&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;acc&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 평가지표
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;label_column_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;label&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# tabular형태 데이터에서 레이블의 컬럼명
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;text_column_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;document&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# tabular형태 데이터에서 텍스트의 컬럼명
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;delimiter&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\t&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;data_silo&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DataSilo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;processor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;processor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;eval_batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;caching&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;코드 실행 후, 다음과 같이 tokenization 되며, sample 객체에 저장된다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1DVPT_Rjv_SI4ggJZzqfPh0MgsMa1Q9El&quot; alt=&quot;[그림4] 실행화면&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;[그림4] 실행화면&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;하나를 확대해서 살펴보면 Sample객체 안에 다양한 정보들이 들어 있다.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;03/28/2021 22:12:15 - INFO - farm.data_handler.processor -   

      .--.        _____                       _      
    .&apos;_\/_&apos;.     / ____|                     | |     
    &apos;. /\ .&apos;    | (___   __ _ _ __ ___  _ __ | | ___ 
      &quot;||&quot;       \___ \ / _` | &apos;_ ` _ \| &apos;_ \| |/ _ \ 
       || /\     ____) | (_| | | | | | | |_) | |  __/
    /\ ||//\)   |_____/ \__,_|_| |_| |_| .__/|_|\___|
   (/\||/                             |_|           
______\||/___________________________________________                     

ID: 437-0
Clear Text: 
 	text_classification_label: good
 	text: 이 영화를 보고 두통이 나았습니다. ㅠ ㅠ
Tokenized: 
 	tokens: [&apos;이&apos;, &apos;영화를&apos;, &apos;보고&apos;, &apos;두&apos;, &apos;##통이&apos;, &apos;나&apos;, &apos;##았습니다&apos;, &apos;.&apos;, &apos;[UNK]&apos;, &apos;[UNK]&apos;]
 	offsets: [0, 2, 6, 9, 10, 13, 14, 18, 20, 22]
 	start_of_word: [True, True, True, True, False, True, False, False, True, True]
Features: 
 	input_ids: [2, 2451, 25833, 8198, 917, 11765, 587, 21809, 17, 1, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
 	padding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
 	segment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
 	text_classification_label_ids: [1]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;modeling-layers-adaptivemodel--languagemodel--predictionhead&quot;&gt;Modeling Layers: AdaptiveModel = LanguageModel + PredictionHead&lt;/h2&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1OLWdr8rh7ucpF9t55gzVeMawMBJbRiEC&quot; alt=&quot;[그림5] Modeling Layers&quot; width=&quot;90%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;[그림5] Modeling Layers&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;LanguageModel&lt;/strong&gt;은 pretrained language models(BERT, XLNet …)의 표준 클래스&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;PredictionHead&lt;/strong&gt;는 모든 down-stream tasks(NER, Text classification, QA …)를 표준 클래스&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;AdaptiveModel&lt;/strong&gt;은 위 두 가지 모들의 결합, 하나의 LanguageModel과 여러 개의 PredictionHead를 결합할 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;[expand]summary: 코드보기 👈&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# LanguageModel: Build pretrained language model
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EMBEDS_DROPOUT_PROB&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;TASK_NAME&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;text_classification&quot;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;language_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LanguageModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;PRETRAINED_MODEL_NAME_OR_PATH&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;language&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;korean&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# PredictionHead: Build predictor layer
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prediction_head&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TextClassificationHead&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;num_labels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LABEL_LIST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;class_weights&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_silo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;calculate_class_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;task_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TASK_NAME&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AdaptiveModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;language_model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;language_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;prediction_heads&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;prediction_head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;embeds_dropout_prob&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;EMBEDS_DROPOUT_PROB&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;lm_output_types&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;per_sequence&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;실제 모델의 구성을 살펴보면 classification을 위한 bert와 유사하게 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;PredictionHead&lt;/code&gt;에서는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pooler&lt;/code&gt;에서 나온 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pooled_output&lt;/code&gt;을 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dropout&lt;/code&gt;층을 통과한 후에 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FeedForwardBlock&lt;/code&gt;으로 보내서 최종 logits을 생성한다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;AdaptiveModel&lt;/code&gt; class에서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;embeds_dropout_prob&lt;/code&gt;를 바꾸면, dropout 확률을 조절할 수 있다.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;h2 id=&quot;train--eval--inference&quot;&gt;Train &amp;amp; Eval &amp;amp; Inference&lt;/h2&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1bD54igqAn7T96gDCFZ2uxzFHpZIL5GOh&quot; alt=&quot;[그림6] Modeling Layers&quot; width=&quot;90%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;[그림6] Modeling Layers&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;여타 다른 패키지와 마찬가지로 Trainer는 모델과 분리되어 있다. FARM에는 EarlyStopping callback을 지원한다. 훈련 진행도중 정해진 스텝마다 평가를 하는데, 이때 callback이 작동한다.&lt;/p&gt;

&lt;h3 id=&quot;train--eval&quot;&gt;Train &amp;amp; Eval&lt;/h3&gt;

&lt;p&gt;[expand]summary: 코드보기 👈&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;LEARNING_RATE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;2e-5&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;N_EPOCHS&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;N_GPU&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;checkpoint_path&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;./ckpt/NSMC&quot;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Initialize Optimizer
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr_schedule&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialize_optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LEARNING_RATE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;n_batches&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_silo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loaders&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;train&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;n_epochs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N_EPOCHS&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# EarlyStopping
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;earlymetric&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;f1&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;task_name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;question_answering&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;acc&quot;&lt;/span&gt; 
&lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;max&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;task_name&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;text_classification&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;question_answering&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;min&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;earlystop&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;EarlyStopping&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;save_dir&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;checkpoint_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;metric&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;earlymetric&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;patience&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Trainer
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trainer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Trainer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;lr_schedule&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr_schedule&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;data_silo&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_silo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;early_stopping&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;earlystop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;evaluate_every&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;checkpoints_to_keep&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;checkpoint_root_dir&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;checkpoint_path&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;checkpoint_every&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;epochs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N_EPOCHS&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;n_gpu&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N_GPU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# now train!
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trainer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;훈련 과정에 계속 Log가 찍히고, Processor단계에서 입력해둔 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;test_filename&lt;/code&gt;로 평가도 해준다. 다음 그림은 430개의 배치 데이터(&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;batch_size=256&lt;/code&gt;)를 돌렸을 때 earlystopping한 결과다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1m1K9CjBNulC4dzSxC1vKjLb94p9BQu26&quot; alt=&quot;[그림7] logging 내용&quot; width=&quot;90%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;[그림7] logging 내용&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h3 id=&quot;inference&quot;&gt;Inference&lt;/h3&gt;

&lt;p&gt;실제 네이버 영화 두 곳에서 각기 다른 평점을 가져와서 테스트 해보았다.&lt;/p&gt;

&lt;p&gt;[expand]summary: 코드보기 👈&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;termcolor&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;farm.infer&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Inferencer&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pprint&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PrettyPrinter&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# https://movie.naver.com/movie/bi/mi/basic.nhn?code=161967
# https://movie.naver.com/movie/bi/mi/point.nhn?code=196051
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;basic_texts&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;text&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;비에 젖지 않는 고급 장난감 텐트와, 비에 젖다 못해 잠겨버리는 반지하 가구&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 161967 / 평점 10
&lt;/span&gt;    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;text&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&quot;&quot;남들이 난해하단거 보고 혼자 이해했다며 심오한척 하고플때나 보면 딱인 영화. 통찰도 시사점도 재미도 의미도 감동도 없는... 
진정한 킬링타임. 가난한 사람들 다 기생충에 비유한거야? 그렇다면 감독 개똥철학 완전꽝이고...&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 161967 / 평점 1
&lt;/span&gt;    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;text&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;와 이거 안보면 인생 절반 후회한겁니다 여러분&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 196051 / 평점 10
&lt;/span&gt;    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;text&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;절레절레 돈주고 보지마셈ㅋㅋㅋㅋ&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 196051 / 평점 1
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;infer_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Inferencer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model_name_or_path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;./ckpt/best_nsmc&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;task_type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;text_classification&quot;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;infer_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inference_from_dicts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dicts&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;basic_texts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;star&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;predictions&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;161967&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;161967&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;196051&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;196051&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;context&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;label&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;probability&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;probability&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;star&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;termcolor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;colored&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;star&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;blue&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attrs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;bold&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;bad&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;termcolor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;colored&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;red&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attrs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;bold&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;termcolor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;colored&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;green&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attrs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;bold&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;termcolor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;colored&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;[Movie: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mid&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;] Context:&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attrs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;bold&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Probability &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;probability&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;% | Predict: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; | Real Star: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;star&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1fI8ME4YexqN75CumIcCO32jUWl3BB86U&quot; alt=&quot;[그림8] 테스트 결과&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;[그림8] 테스트 결과&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;두 영화는 봉준호 감독님의 ‘기생충(id=161967)’, 최근 인기가도를 달리고 있는 ‘극장판 귀멸의 칼날: 무한열차편(id=196051)’를 선정했다. 하나를 제외하고 잘 맞춘 모습을 보여줬는데, 첫번째 샘플의 경우 사실 영화의 장면을 묘사한 것으로, 그만큼 인상깊었던 장면들을 달면서 평점은 10점으로 달았다. 사람으로써 이 영화을 본 관객이라면 이 평가가 10점에 알맞는 평점(혹은 긍정)이지만, 기계에게는 아직 어려운 점 중에 하나라고 생각한다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;mlflow&quot;&gt;MLflow&lt;/h1&gt;

&lt;p&gt;MLflow를 이용하 빠르고 쉽게 실험을 관리하고, 관련 평가지표도 함께 볼 수 있다. 다음 그림들은 TITAN RTX 4대에서 배치크기를 256으로 훈련 시킨 결과다(440 batches 에서 Early Stopping했다.).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;public mlflow(&lt;a href=&quot;https://public-mlflow.deepset.ai/#/experiments/313/runs/05e7e3d4945642f9ab3e296637d57c26&quot;&gt;링크&lt;/a&gt;)에서 확인하기&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=13Cg8eziHBgA3JLwZJ3Bo8YzeySWPRmiP&quot; alt=&quot;[그림9] Parameters&quot; width=&quot;50%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;[그림9] Parameters&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;Train과 Dev 세트의 loss는 다음과 같다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1cpFWVvjkSqshvN0hS_CuPk4RjyEyM0AV&quot; alt=&quot;[그림10] Loss Graph&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;[그림10] Loss Graph&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;Dev 세트의 정확도는 다음과 같다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1VPso9Gx60V8_dgE4as054n7kymCoQ9w5&quot; alt=&quot;[그림11] Dev Accuracy Graph&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;[그림11] Dev Accuracy Graph&lt;/figcaption&gt;&lt;/figure&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;task-supported&quot;&gt;TASK Supported&lt;/h1&gt;

&lt;p&gt;현재 지원되는 모델과 SubTask는 다음과 같다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Task&lt;/th&gt;
      &lt;th&gt;BERT&lt;/th&gt;
      &lt;th&gt;RoBERTa*&lt;/th&gt;
      &lt;th&gt;XLNet&lt;/th&gt;
      &lt;th&gt;ALBERT&lt;/th&gt;
      &lt;th&gt;DistilBERT&lt;/th&gt;
      &lt;th&gt;XLMRoBERTa&lt;/th&gt;
      &lt;th&gt;ELECTRA&lt;/th&gt;
      &lt;th&gt;MiniLM&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Text classification&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;NER&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Question Answering&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Language Model Fine-tuning&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Text Regression&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Multilabel Text classif.&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Extracting embeddings&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;LM from scratch&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Text Pair Classification&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Passage Ranking&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Document retrieval (DPR)&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
      &lt;td&gt;x&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;compare-to-others&quot;&gt;Compare to others&lt;/h1&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1TZoRpza8-o4wSTr0s16f8hHQRroLQg30&quot; alt=&quot;[그림12] 다른 패키지와의 비교&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;[그림12] 다른 패키지와의 비교&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;다른 모델과 비교해보면 FARM은 조금 더 huggingface와 pytorch-lightning의 합본 축약 버전이라고 생각할 수 있다. 마치 Tensorflow v1과 keras의 차이 느낌이다.&lt;/p&gt;

&lt;h2 id=&quot;farm-장단점&quot;&gt;FARM 장단점&lt;/h2&gt;

&lt;p&gt;장점:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;데이터 세트만 준비되어 있으면, 다른 패키지에 비해 상대적으로 설정 할 것이 적음&lt;/li&gt;
  &lt;li&gt;훈련 속도가 빠르고, 실험 기록 및 관리이 편리해서 빠르게 실험해 볼 수 있음(텐서보드 대신 mlflow 사용 가능)&lt;/li&gt;
  &lt;li&gt;멀티 GPU 설정을 해줄 필요가 없음&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;단점:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;customization이 상대적으로 힘듦&lt;/li&gt;
  &lt;li&gt;아직 발전 중이라 불안정하고 documentaton이 잘 안되어 있음&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Wed, 31 Mar 2021 01:30:01 +0900</pubDate>
        <link>https://simonjisu.github.io/nlp/2021/03/31/farm.html</link>
        <guid isPermaLink="true">https://simonjisu.github.io/nlp/2021/03/31/farm.html</guid>
        
        
        <category>nlp</category>
        
      </item>
    
      <item>
        <title>Jekyll Blog Collapsible Block 만들기</title>
        <description>&lt;h1 id=&quot;지킬블로그-텍스트-확장-블록-만들기&quot;&gt;지킬블로그 텍스트 확장 블록 만들기&lt;/h1&gt;

&lt;p&gt;지킬에서 블로그를 쓰다보면 가끔 아주 긴 부연설명에 대한 텍스트를 넣고 싶거나, 긴 코드블록을 숨겨서 이쁘게 꾸미고 싶을 때가 있다. 그런데 내가 인터넷에서 나오는 expand 모듈들은 markdown 내에 html 태그를 길게 써야되서 불편했다. 그래서 기존에 인터넷에 있던 코드를 기반으로 새로 만들었다. 그렇게 썩 깔끔한 코드는 아니지만, 해당기능이 필요한 사람들에게 잘 사용됐으면 좋겠다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;세팅법&quot;&gt;세팅법&lt;/h1&gt;

&lt;p&gt;제일먼저 세팅해야할 것은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_config.yml&lt;/code&gt; 에서 마크다운이 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;kramdown&lt;/code&gt; 인지 확인 하는 것이다. 그 이유는 collapsible block을 만들기 위해서는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;details&amp;gt;&lt;/code&gt; 태그를 사용해야하는데,  &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;kramdown&lt;/code&gt;이 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;details&amp;gt;&lt;/code&gt;를 지원하는 것으로 알고 있다.&lt;/p&gt;

&lt;div class=&quot;language-yaml highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# _config.yml&lt;/span&gt;
&lt;span class=&quot;na&quot;&gt;markdown&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;kramdown&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;[expand]summary:열어서 text-expander 코드 복사하기 👈&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://gist.github.com/simonjisu/43c789bf44e9f8171be440b46f0948a5&quot;&gt;여기&lt;/a&gt;에서 다운로드 하거나, 아래 코드를 복사한다.&lt;/p&gt;

&lt;div class=&quot;language-html highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c&quot;&gt;&amp;lt;!-- Author: https://github.com/simonjisu
Change `div.article-content` to your article container in jekyll blog
Put your file into `_include/text-expand.html`
--&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;script&amp;gt;&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;elements&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;document&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;querySelectorAll&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;div.article-content&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;childNodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// 수정1 &lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;addContent&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;contentsToAdd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[];&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;expandtags&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;detailText&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;detailsTag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;summaryTag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;detailsContent&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;null&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;elements&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
    &lt;span class=&quot;nx&quot;&gt;el&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;elements&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;el&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;innerHTML&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;[/expand]&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;addContent&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;detailsContent&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;document&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;createElement&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;div&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;detailsContent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;className&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;collaspe-content&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;detailsContent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;setAttribute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;markdown&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;el&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;parentNode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;removeChild&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;el&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;el&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;innerHTML&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;[expand]&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;el&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;nodeName&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;P&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;el&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;innerHTML&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;includes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;[expand]summary:&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;addContent&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;false&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;expandtags&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;el&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;innerHTML&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;summary:&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;expandtags&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
            &lt;span class=&quot;nx&quot;&gt;detailText&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;Details&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nx&quot;&gt;detailText&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;expandtags&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;detailsTag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;document&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;createElement&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;details&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;detailsTag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;className&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;collaspe-article&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;summaryTag&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;document&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;createElement&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;summary&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;summaryTag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;appendChild&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;document&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;createTextNode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;detailText&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;detailsTag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;appendChild&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;summaryTag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;contentsToAdd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;--&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nx&quot;&gt;detailsContent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;appendChild&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;contentsToAdd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;detailsTag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;appendChild&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;detailsContent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;el&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;parentNode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;replaceChild&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;detailsTag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;el&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;nx&quot;&gt;contentsToAdd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;addContent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;nx&quot;&gt;contentsToAdd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;push&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;el&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/script&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;그 다음 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_include&lt;/code&gt; 폴더내에 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;text-expand.html&lt;/code&gt; 파일을 만들고 다음 코드를 복사해서 붙여넣기 하자. 여기서 수정할 부분은 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;language-javascript highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nx&quot;&gt;elements&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;document&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;querySelectorAll&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;div.article-content&lt;/span&gt;&lt;span class=&quot;dl&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nx&quot;&gt;childNodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;div.article-content&lt;/code&gt; 부분을 수정해야하는데 자신의 jekyll 구조를 파악해서 글의 내용이 어느 컨테이너에 있는지 확인해야한다. 자신의 블로그에서 마우스 오른쪽 버튼을 누르고 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;검사&lt;/code&gt;를 통해 구조를 파악하거나, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_layout&lt;/code&gt;폴더의 파일들 중 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;body&amp;gt;&lt;/code&gt; 태그 사이를 잘 살펴보면 된다. 내 블로그의 경우 구조가 다음과 같은데, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;div class=&quot;article-content&quot;&amp;gt;&lt;/code&gt; 가 글에 해당하는 내용이다.&lt;/p&gt;

&lt;div class=&quot;language-html highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;&amp;lt;!DOCTYPE html&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;html&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;head&amp;gt;&lt;/span&gt; ... &lt;span class=&quot;nt&quot;&gt;&amp;lt;/head&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;body&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;div&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;class=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;page-content&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;div&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;class=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;container&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;div&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;class=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;three columns&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;header&amp;gt;&lt;/span&gt; ... &lt;span class=&quot;nt&quot;&gt;&amp;lt;/header&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;/div&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;div&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;class=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;nine columns&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;style=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;z-index:100;&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;div&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;class=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;wrapper&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;article&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;class=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;post&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;header&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;class=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;post-header&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
              &lt;span class=&quot;nt&quot;&gt;&amp;lt;h1&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;class=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;post-title&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt; ... &lt;span class=&quot;nt&quot;&gt;&amp;lt;/h1&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;/header&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;div&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;class=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;article-content&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
                content   &lt;span class=&quot;c&quot;&gt;&amp;lt;!-- 포스트의 내용이 담김 곳 --&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;/div&amp;gt;&lt;/span&gt;
            &lt;span class=&quot;nt&quot;&gt;&amp;lt;/article&amp;gt;&lt;/span&gt;
          &lt;span class=&quot;nt&quot;&gt;&amp;lt;/div&amp;gt;&lt;/span&gt;
        &lt;span class=&quot;nt&quot;&gt;&amp;lt;/div&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;/div&amp;gt;&lt;/span&gt;
      &lt;span class=&quot;nt&quot;&gt;&amp;lt;footer&amp;gt;&lt;/span&gt; ... &lt;span class=&quot;nt&quot;&gt;&amp;lt;/footer&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;/div&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;nt&quot;&gt;&amp;lt;/body&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/html&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그 다음 스텝으로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_layout&lt;/code&gt; 폴더에서 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;/body&amp;gt;&lt;/code&gt; 태그가 들어간 파일을 찾아, 이전에 다음과 같이 liquid 문법으로 아까 만든 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;text-expand.html&lt;/code&gt;을 포함시킨다.&lt;/p&gt;

&lt;div class=&quot;language-html highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{% include text-expand.html %}
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/body&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;마지막으로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_sass&lt;/code&gt; 폴더의 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;_layout.scss&lt;/code&gt; 파일에 관련 css만 추가해주면 끝난다.&lt;/p&gt;

&lt;div class=&quot;language-scss highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;// _sass/_layout.scss &lt;/span&gt;
&lt;span class=&quot;nc&quot;&gt;.collaspe-article&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nl&quot;&gt;padding-top&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;10px&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;nl&quot;&gt;padding-bottom&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;10px&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;nc&quot;&gt;.collaspe-content&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nl&quot;&gt;padding-top&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;5px&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;nc&quot;&gt;.collaspe-content&lt;/span&gt;&lt;span class=&quot;nd&quot;&gt;:before&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nl&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;nl&quot;&gt;display&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;nl&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;100%&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;nl&quot;&gt;border-bottom&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1px&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;solid&lt;/span&gt; &lt;span class=&quot;mh&quot;&gt;#bcbcbc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;nc&quot;&gt;.collaspe-content&lt;/span&gt;&lt;span class=&quot;nd&quot;&gt;:after&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;nl&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;nl&quot;&gt;display&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;nl&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;100%&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;nl&quot;&gt;border-bottom&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;1px&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;solid&lt;/span&gt; &lt;span class=&quot;mh&quot;&gt;#bcbcbc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;사용법&quot;&gt;사용법&lt;/h1&gt;

&lt;p&gt;마크다운에서 다음과 같이 쓰면 된다. 주의할 점은 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[expand]&lt;/code&gt;사이에 새 줄만 잘 띄어주면 된다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[expand]&lt;/code&gt;뒤에는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;summary:&lt;/code&gt;를 붙여서 설명하고 싶은 내용을 적을 수 있다. 만약에 없으면 기본으로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Details&lt;/code&gt;가 들어간다.&lt;/p&gt;

&lt;p&gt;예를 들면, 다음 코드는 아래처럼 바뀐다.&lt;/p&gt;

&lt;p&gt;[expand]summary:원하는 블록 요약 쓰기&lt;/p&gt;

&lt;p&gt;내용을 써주세요. [expand] 사이에 마크다운 문법이 가능합니다.&lt;/p&gt;

\[1 + 1 = 3\]

&lt;p&gt;설명을 위해 코드블록을 일부러 띄워 썼습니다. 실제로 쓸때는 밑에 띄어쓴 칸을 지우세요!&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;div class=&quot;language-markdown highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;
[expand]summary:원하는 블록 요약 쓰기

내용을 써주세요. [expand] 사이에 마크다운 문법이 가능합니다.

$$1 + 1 = 3$$

설명을 위해 코드블록을 일부러 띄워 썼습니다. 실제로 쓸때는 밑에 띄어쓴 칸을 지우세요!
    
    &lt;span class=&quot;p&quot;&gt;```&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;python
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;```&lt;/span&gt;

[/expand]

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;기본원리&quot;&gt;기본원리&lt;/h1&gt;

&lt;p&gt;짧게 설명하면, Markdown에서 Collapsible block의 문법은 다음과 같으며, 원하면 자신만의 코드로 커스텀해서 사용해볼 수 있다.&lt;/p&gt;

&lt;div class=&quot;language-html highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nt&quot;&gt;&amp;lt;details&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;summary&amp;gt;&lt;/span&gt; 표기할것 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/summary&amp;gt;&lt;/span&gt;
내용쓰기
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/details&amp;gt;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
</description>
        <pubDate>Sun, 07 Mar 2021 18:28:01 +0900</pubDate>
        <link>https://simonjisu.github.io/programming/2021/03/07/jekyllexpand.html</link>
        <guid isPermaLink="true">https://simonjisu.github.io/programming/2021/03/07/jekyllexpand.html</guid>
        
        
        <category>programming</category>
        
      </item>
    
      <item>
        <title>Tree-based Ensemble: Boosting</title>
        <description>&lt;h1 id=&quot;references&quot;&gt;References&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://ko.wikipedia.org/wiki/%EA%B2%B0%EC%A0%95_%ED%8A%B8%EB%A6%AC_%ED%95%99%EC%8A%B5%EB%B2%95&quot;&gt;위키백과: 결정 트리 학습법&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://brunch.co.kr/@snobberys/137&quot;&gt;Xgboost 사용하기&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://brunch.co.kr/@chris-song/98&quot;&gt;Ensemble: bagging, boosting&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://3months.tistory.com/368&quot;&gt;Gradient Boosting Algorithm의 직관적 이해&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/rpmcruz/machine-learning/blob/master/ensemble/boosting/gboost.py&quot;&gt;rpmcruz의 gboost코드&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;ensemble&quot;&gt;Ensemble&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;앙상블(Ensemble)&lt;/strong&gt;의 사전적 의미는 2인 이상의 노래나 연주를 뜻하는데, 머신러닝에서 앙상블 학습이란 하나의 학습 알고리즘 보다 더 좋은 성능을 내기 위해 다수의 약한 성능을 가진 학습 알고리즘을 합쳐서 사용하는 방법이다. 이때, 약한 성능을 가진 학습 알고리즘을 &lt;strong&gt;약한 학습자(Weak Learner)&lt;/strong&gt;라고 부른다. 앙상블 학습은 일반적으로 &lt;strong&gt;배깅(Bagging)&lt;/strong&gt; 과 &lt;strong&gt;부스팅(Boosting)&lt;/strong&gt; 두 가지의 유형으로 나눌 수 있다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Bagging(Bootstrap Aggregation): 샘플을 여러번 뽑아(Bootstrap)서 여러 개의 약한 학습자를 병렬적으로 학습시켜 결과물을 집계(Aggregration)하는 방법. 결과물을 집계하는 방법으로 회귀 문제의 경우 평균을 내거나, 분류 문제의 경우 가장 많이 나온 클래스로 투표(Hard Voting) 혹은 클래스의 확률을 평균화해서 가장 높은 확률로 도출(Soft Voting)한다. 모델의 variance를 줄이는 방향을 원한다면 배깅방법이 적합하다.&lt;/li&gt;
  &lt;li&gt;Boosting: 훈련 데이터를 샘플링하여 순차적으로 약한 학습자를 하나씩 추가시키면서 학습한다. 각 약한 학습자들은 가중치로 연결된다는 것이 특징이다. 다만 이전 약한 학습자가 틀린 데이터의 샘플링이 더 잘 되게 가중치를 부여하여 훈련 데이터를 생성하고 다시 학습한다. 모델의 bias를 줄이는 방향을 생각하고 있다면, 부스팅 방법이 적합하다.&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;boosting-ensemble&quot;&gt;Boosting Ensemble&lt;/h1&gt;

&lt;p&gt;앙상블 방법론중 부스팅 방법에는 &lt;strong&gt;적응형 부스팅(Adaptive Boosting)&lt;/strong&gt;, &lt;strong&gt;경사 부스팅(Gradient Boosting)&lt;/strong&gt;이 있다. 이번 글에서는 Gradient Boosting을 중점적으로 다뤄본다.&lt;/p&gt;

&lt;h2 id=&quot;gradient-boosting&quot;&gt;Gradient Boosting&lt;/h2&gt;

&lt;p&gt;Gradient Boosting을 한마디로 하면 Pseudo-Residual Fitting이라고 할 수 있다. 예를 들어, 약한 학습자 $A$로 데이터($Y, X$)를 학습시킨 결과를 다음 수식으로 표현해본다.&lt;/p&gt;

\[Y = A(X) + \epsilon_1\]

&lt;p&gt;여기서 $\epsilon_1$은 &lt;strong&gt;오차(error)&lt;/strong&gt; 혹은 &lt;strong&gt;잔차(residual)&lt;/strong&gt;이라고 부른다. 그러면 남은 $\epsilon_1$에 대해서 다른 약한 학습자 $B$를 예측을 잘하게 학습시켜서 $Y$를 예측한다.&lt;/p&gt;

\[\epsilon_1 = B(X) + \epsilon_2\]

&lt;p&gt;이렇게 계속 잔차를 줄여나가면서 여러 개의 약한 학습자를 연결시키는 것이 Gradient Boosting이다.&lt;/p&gt;

&lt;h3 id=&quot;negative-gradient&quot;&gt;Negative Gradient&lt;/h3&gt;

&lt;p&gt;그렇다면 왜 Gradient가 들어가는가? 그 해답은 손실함수(loss function)와 연결된다.&lt;/p&gt;

&lt;p&gt;예를 들어, Mean Squared Error를 손실함수로 설정하면, 다음과 같이 예측 값에 대해 경사(gradient)를 구할 수 있다.&lt;/p&gt;

\[\begin{aligned} 
\text{Loss} &amp;amp;= L \big(Y, f(X) \big) = \dfrac{1}{2} \big( Y - f(X) \big)^2 \\
\text{gradient} &amp;amp;= \dfrac{\partial L}{\partial f(X)} = \dfrac{1}{2} \times 2 \big( Y - f(X) \big) \times (-1) = -\big( Y - f(X) \big) \\
\text{residual} &amp;amp;= -\dfrac{\partial L}{\partial f(X)} = - \text{gradient}
\end{aligned}\]

&lt;p&gt;이때의 잔차는 음의 경사값이 되는 것을 알 수 있다. 이는 우리가 데이터를 남은 잔차에 대해서 학습하는 방법이 곧 전체 손실값을 줄이는 것과 같다는 이야기다.&lt;/p&gt;

&lt;p&gt;[expand]summary:부연 설명보기 👈&lt;/p&gt;

&lt;p&gt;부연 설명하자면, 두 개의 약한 학습자를 예로 들면 다음과 같다.&lt;/p&gt;

\[\begin{aligned}
\text{fitting: } Y &amp;amp;= f_1(X) + \epsilon_1 \\
L_1 &amp;amp;= L\big(Y, f_1(X) \big) = \dfrac{1}{2}\big( Y - f_1(X)\big)^2 \\
\dfrac{\partial L_1}{\partial f_1(X)} &amp;amp;= - \big( Y - f_1(X)\big) = - \epsilon_1 \\
\\
\text{fitting: } \epsilon_1 &amp;amp;= f_2(X) + \epsilon_2 \\
L_2 &amp;amp;= L\big(\epsilon_1, f_2(X) \big) = \dfrac{1}{2}\big( \epsilon_1 - f_2(X)\big)^2 \\
\dfrac{\partial L_2}{\partial f_2(X)} &amp;amp;= - \big( \epsilon_1 - f_2(X)\big) = - \epsilon_2 \\
\end{aligned}\]

&lt;p&gt;여기서 $\epsilon_1$을 $L_2$ 에 넣어보면&lt;/p&gt;

\[\begin{aligned}
L_2 &amp;amp;= \dfrac{1}{2}\big( Y - f_1(X) - f_2(X)\big)^2 \\
\dfrac{\partial L_2}{\partial f_2(X)} &amp;amp;= - \big( Y - f_1(X) - f_2(X)\big) = - \epsilon_2
\end{aligned}\]

&lt;p&gt;가 되고, $F(X) = f_1(X) + f_2(X)$ 라고 하면, 약한 학습자를 여러 개를 더한 모델($f_1(X) + f_2(X)$)을 최적화 하는 것과 하나의 잘 예측하는 모델($F(X)$)를 최적화하는 것과 같다는 것을 알 수 있다(말장난 같지만, 이유는 같은 잔차$\epsilon_2$ 가 남기 때문).&lt;/p&gt;

\[\begin{aligned}
L &amp;amp;= \dfrac{1}{2}\big( Y - F(X)\big)^2 \\
\dfrac{\partial L}{\partial F(X)} &amp;amp;= - \big( Y - F(X)\big) = - \epsilon_2
\end{aligned}\]

&lt;p&gt;또한, 원래 잔차를 구하려면 학습된 모델에 예측을 하고, 타겟값에 예측값을 빼줘야하는데, 미분으로 잔차를 구할 수 있으니 더 빠르게 학습이 가능하다.&lt;/p&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;결국에는 negative gradient가 잔차와 일치하기 때문에 Gradient 용어가 들어가는 것이다.&lt;/p&gt;

&lt;p&gt;알고리즘은 다음과 같이 진행한다(&lt;a href=&quot;https://github.com/rpmcruz/machine-learning/blob/master/ensemble/boosting/gboost.py&quot;&gt;rpmcruz의 gboost코드&lt;/a&gt;를 빌려 약간의 변형후 해석해본다).&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# self.first_estimator = 더미모델
# self.base_estimator = 약한 학습자
# self.loss = residual 함수, 여기서는 y - y_pred
# self.eta = Loss(y, y_pred)를 최소로 하는 eta값을 구하는데,
# 여기서는 생략하고 하나의 값으로 통일
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first_estimator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# step 0
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first_estimator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# step 1
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;M&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# step 2
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;R&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# step 3
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;clone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base_estimator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;R&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# step 4
&lt;/span&gt;        &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;f0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]],&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Step 0.&lt;/strong&gt; dummy 모델(예를 들어 모든 예측값이 0인 모델)로 초기화 한다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Step 1.&lt;/strong&gt; 모델의 개수 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;M&lt;/code&gt; 만큼 진행하며 항상 첫 스텝에 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;X&lt;/code&gt;에 대한 예측을 한다. 예측은 현재까지 저장해둔 약한 학습자의 예측값과 가중치(&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;self.eta&lt;/code&gt;)를 곱해서 합한 값으로 한다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Step 2.&lt;/strong&gt; 예측값(&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;y_pred&lt;/code&gt;)과 타겟값(&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;y&lt;/code&gt;)을 이용해 잔차(&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;R&lt;/code&gt;)을 구한다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Step 3.&lt;/strong&gt; 약한 학습자를 타겟값이 아닌 잔차값에 대해서 학습한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;tree-based-ensemble--cart&quot;&gt;Tree-Based Ensemble &amp;amp; CART&lt;/h1&gt;

&lt;p&gt;의사결정 나무 계열의 앙상블중 부스팅 방법을 사용하는 패키지들은 많이 있으나, 그중에서 XGBoost를 소개하려고 한다. 그 전에 의사결정 나무의 &lt;strong&gt;CART(Classification And Regression Tree)&lt;/strong&gt; 알고리즘을 소개하고 넘어간다.&lt;/p&gt;

&lt;p&gt;CART 알고리즘은 이름에서도 알 수 있듯이 분류와 회귀를 둘다 가능케하는 알고리즘이다. 분류의 경우 지니 계수(Gini Index)를 사용하고, 회귀의 경우 실제값과 예측값의 오차(MSE)를 사용해서 분기를 정한다. 일반적인 의사결정 나무와 다르게, 리프 노드(leaf node)에는 실제값 대신 결정값(decision values)을 보존하고 있다.&lt;/p&gt;

&lt;p&gt;예를 들어, 다음 그림과 같이 가족원 5명중 컴퓨터 게임을 좋아할 만한 사람을 분류하는 모델을 만들면 최종 리프 노드에는 해당 조건에 부합할 경우 양의 점수가 저장되고 그렇지 않으면 음의 점수가 저장된다. 이러한 결정값을 저장함으로써 더 유연한 비교와 추론을 할 수가 있다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=15_gKUfmzAV-oZaJ17uYDajhmGjIQc4Sc&quot; alt=&quot;출처: XGBoost Documentation&quot; width=&quot;80%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;출처: XGBoost Documentation&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;보통 하나의 의사결정 나무 모델을 쓰지 않고, 앙상블 학습법을 많이 쓰기 때문에, 예를 들어, 다음과 같이 두 개의 의사 결정나무를 예시로 어떻게 진행되는지 살펴보자.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1APEjS1gHrcfJXR_W7BC29mV6dNIteVe9&quot; alt=&quot;출처: XGBoost Documentation&quot; width=&quot;80%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;출처: XGBoost Documentation&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;각 샘플(가족원)의 최종 점수를 계산하려면 샘플이 속한 스코어를 전부 더하면 된다. 파란 옷을 입은 아들의 경우, 첫번째 모델에서 $+2$ 그리고 두번째 모델에서 $+0.9$의 결정값을 가짐으로 최종 결정값은 $+2.9$가 된다. 점수가 높을 수록 게임을 더 좋아한다는 뜻임으로, 아들은 게임을 좋아한다고 분류할 수 있다.&lt;/p&gt;

&lt;p&gt;여기에는 두 의사결정 나무 모델이 같은 가중치를 가지고 있다고 가정하고 있다. 물론 가중치를 다르게 줘서, 나이가 더 중요하다고 생각하면 첫번째 모델에 더 가중치를 줘서 높은 결정값을 가지게 할 수도 있다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;xgboost&quot;&gt;XGBoost&lt;/h1&gt;

&lt;p&gt;Gradient Boosting 알고리즘에서 가장 유명한 패키지는 &lt;a href=&quot;https://xgboost.readthedocs.io/en/latest/index.html&quot;&gt;&lt;strong&gt;XGBoost&lt;/strong&gt;&lt;/a&gt;이다. XGBoost는 Extreme Gradient Boosting 의 약자로써, 말그대로 엄청나게 빠른 Boosting 학습을 지원한다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;설치방법과 사용방법은 따로 다루지 않으며 아래 링크를 참고하길 바란다.
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://xgboost.readthedocs.io/en/latest/parameter.html&quot;&gt;XGBoost 공식문서&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://brunch.co.kr/@snobberys/137&quot;&gt;브런치: Xgboost 사용하기&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://eagle705.github.io/articles/2018-06/XGBoost-정리&quot;&gt;eagle705님의 블로그: XGBoost-정리&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;특징&quot;&gt;특징&lt;/h2&gt;

&lt;p&gt;정규화(regularization)를 도입해서 과적합을 피하고 있다. 목적함수에 의사결정 나무의 복잡도($\Omega$)를 구하여 이를 억제하는 방식으로 훈련한다.&lt;/p&gt;

\[\begin{aligned}
\text{Loss}^{(t)} = \sum_{i=1}^n L(y_i, y_i^{(t)}) + \sum_{j=1}^{t} \Omega(f_j)
\end{aligned}\]

&lt;p&gt;의사결정 나무를 (1)식과 같이 정의하면, 복잡도은 (2)식 처럼 정의할 수 있다. 여기서 $w$는 리프노드의 결정값 벡터이고, $q$는 각 데이터를 해당하는 $T$개의 모델의 리프노드에 배분하는 함수다. 모델 복잡도에서 $\gamma$는 정보획득(information gain)에 관한 변수이며, 정보획득량이 $\gamma$보다 낮은 경우 약한 학습자를 더하지 않는다. $\lambda$는 결정값에 관한 변수이며, 해당 값이 높을수록 결정값이 커지지 않게 더 큰 제약을 준다.&lt;/p&gt;

\[\begin{aligned}
f_t(x) &amp;amp;= w_{q(x)}, w \in R^T , q: R^d \rightarrow \{ 1, 2, \cdots, T\} &amp;amp; \cdots (1)\\
\Omega(f) &amp;amp;= \gamma T + \dfrac{1}{2} \lambda \sum_{j=1}^T w_j^2 &amp;amp; \cdots (2)
\end{aligned}\]

&lt;h2 id=&quot;xgboost의-병렬처리&quot;&gt;XGBoost의 병렬처리&lt;/h2&gt;

&lt;p&gt;원칙적으로 Boosting방법은 Additive 학습 방법이기 때문에, 학습 방법 자체는 병렬이 불가능한 구조다. 하지만, 의사결정 나무를 만드는 과정을 병렬화(하나의 모델 내에서 openMP로 개별 코어에게 분배해서 하위 브랜치를 만듦)함으로써 더 빠르게 학습을 완료시킬 수 있었다. 아래 레퍼런스를 참고하자.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://m.blog.naver.com/nicolechae0627/221811579005&quot;&gt;XGBoost vs GBM&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://machinelearningkorea.com/2019/07/25/xgboost-의-병렬처리가-어떻게-가능할까/&quot;&gt;XGBoost의 병렬처리&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://stackoverflow.com/questions/34151051/how-does-xgboost-do-parallel-computation&quot;&gt;How does XGBoost do parallel computation?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sun, 07 Mar 2021 17:13:01 +0900</pubDate>
        <link>https://simonjisu.github.io/machinelearning/2021/03/07/treeboosting.html</link>
        <guid isPermaLink="true">https://simonjisu.github.io/machinelearning/2021/03/07/treeboosting.html</guid>
        
        
        <category>machinelearning</category>
        
      </item>
    
      <item>
        <title>Decision Tree</title>
        <description>&lt;p&gt;가장 고전적인 머신러닝 모델이지만 정확하게 알고 넘어가야할 것 같아 정리한다.&lt;/p&gt;

&lt;h1 id=&quot;references&quot;&gt;References&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://ko.wikipedia.org/wiki/%EA%B2%B0%EC%A0%95_%ED%8A%B8%EB%A6%AC_%ED%95%99%EC%8A%B5%EB%B2%95&quot;&gt;위키백과: 결정 트리 학습법&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://ratsgo.github.io/machine%20learning/2017/03/26/tree/&quot;&gt;ratsgo blog: 의사결정나무(Decision Tree)&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://m.blog.naver.com/laonple/220861527086&quot;&gt;라온피플 blog: Decision Tree&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://scikit-learn.org/stable/modules/tree.html&quot;&gt;Scikit-Learn: Decision Tree&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://scikit-learn.org/stable/auto_examples/tree/plot_cost_complexity_pruning.html&quot;&gt;Scikit-Learn: Post Pruning&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://scikit-learn.org/stable/modules/permutation_importance.html&quot;&gt;Scikit-Learn: Permutation feature importance&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://hwi-doc.tistory.com/entry/Feature-selection-feature-importance-vs-permutation-importance&quot;&gt;Feature selection : feature importance vs permutation importance&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;의사결정-나무decision-tree&quot;&gt;의사결정 나무(Decision Tree)&lt;/h1&gt;

&lt;p&gt;의사결정 나무는 분류 및 회귀에 사용되는 전통적인 &lt;strong&gt;비모수(non-parametric)&lt;/strong&gt; 지도학습 방법이다. 이 알고리즘의 목적은 입력 데이터 피처(features)로부터 타겟 데이터를 유추할 수 있는 간단한 규칙을 학습하는 것이다. 위키백과에 나온 타이타닉 탑승객 생존 여부를 나태내는 트리로 예를 들면 다음과 같다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1U_uzhLK2KzUYOyxjCLoHcVjzVneLOQBn&quot; alt=&quot;출처: 위키백과&quot; width=&quot;50%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;출처: 위키백과&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;리프 노드(leaf node)가 아닌 노드들(마름모 모양)은 각 입력 데이터 피처에 대한 규칙을 나타내고 있으며, 이 그림에서는 위에서 부터&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;성별&lt;/li&gt;
  &lt;li&gt;나이&lt;/li&gt;
  &lt;li&gt;탑승한 배우자와 자녀의 수&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이다. 반면 리프 노드(생존/사망)는 각 규칙에 이어지는 경로를 따랐을 때, 타겟 데이터의 값이다. 이 그림에서는&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;생존 확률 = 해당 리프 노드에 속하는 생존 수 / 해당 클래스에 속하는 전체 승객 수&lt;/li&gt;
  &lt;li&gt;리프노드에 해당할 확률 = 사망 혹은 생존 수 / 전체 탑승객 수&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;을 나타내고 있다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;학습의-기준-불확실성&quot;&gt;학습의 기준: 불확실성&lt;/h2&gt;

&lt;p&gt;학습의 기준은 불확실성을 나타내는 &lt;strong&gt;엔트로피(entropy)&lt;/strong&gt; 혹은 &lt;strong&gt;불순도(impurity)&lt;/strong&gt;가 최대로 감소하는 방향으로 진행된다(엔트로피 함수 혹은 Gini계수를 쓰지만 여기서는 엔트로피를 사용한다). 이전 단계와 현재 단계의 불확실성의 차이를 &lt;strong&gt;정보획득(information gain, 이하 IG)&lt;/strong&gt;이라고 하며, 정보획득이 많은 방향으로 학습을 진행한다고 말 할 수 있다.&lt;/p&gt;

&lt;p&gt;예를 들어 아래 그림처럼, 특정 영역내에 두 색상의 공을 분류하는 문제가 있고, 사각형의 수평 혹은 수직 변에서 특정 지점을 기준으로 반으로 나누는 것을 규칙이라고 해보자. 우리의 목적은 10개의 공을 잘 나누는 규칙들을 학습하는 것이며, 빨간공을 1, 초록공을 2로 표기한다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=17jk7c6NbX0ckSKhZqebV5M7m-a3bHyeV&quot; alt=&quot;영역 A&quot; width=&quot;50%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;영역 A&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;이를 나누는 기준 엔트로피는 다음과 같으며 특정 영역 $A$의 불확실성을 나타낸다. 여기서 $p_k$는 특정 k 클래스에 속할 확률을 나타낸다($p_k$ = &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;k-class 공의 개수&lt;/code&gt; / &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;전체 공의 개수&lt;/code&gt;).&lt;/p&gt;

\[Entropy(A)= - \sum_{k=1}^{K} p_k \log_{2}(p_k)\]

&lt;p&gt;현재 상태의 엔트로피를 계산하면, 다음과 같다.&lt;/p&gt;

\[Entropy(A)= - \Big( \dfrac{6}{10}\log_{2}(\dfrac{6}{10}) + \dfrac{4}{10}\log_{2}(\dfrac{4}{10}) \Big) = 0.9710\]

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;calculate_entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;log&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;pks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# A: p_red, p_greem
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;entropy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;calculate_entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Entropy is &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Entropy is 0.9710
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=133G4Y4HmuHBGTeSisfZw76h3CoXhD-5B&quot; alt=&quot;좌우 영역 A1, A2 나눌 경우&quot; width=&quot;50%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;좌우 영역 A1, A2 나눌 경우&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;이제 가로변의 임의로 한 곳을 나눠서 두 개의 영역(좌: $A_1$, 우: $A_2$)으로 나눠본다. 이때의 엔트로피는 두 엔트로피의 가중합으로 계산할 수 있으며, 다음과 같다.&lt;/p&gt;

\[\begin{aligned} Entropy(A) &amp;amp;= \sum_{i=1}^{m} \dfrac{1}{m} Entropy(A_m) = \dfrac{1}{2} Entropy(A_1) + \dfrac{1}{2} Entropy(A_2) \\
&amp;amp;= - \sum_{i=1}^{2} \dfrac{1}{2} \sum_{k=1}^K p_k^{(i)} \log_2 (p_k^{(i)}) \\
&amp;amp;= - \dfrac{1}{2} \Big( \dfrac{5}{6}\log_{2}(\dfrac{5}{6}) + \dfrac{1}{6}\log_{2}(\dfrac{1}{6}) \Big) - \dfrac{1}{2} \Big( \dfrac{1}{4}\log_{2}(\dfrac{1}{4}) + \dfrac{3}{4}\log_{2}(\dfrac{3}{4}) \Big) \\
&amp;amp;= 0.7307
\end{aligned}\]

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;calculate_entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ndim&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;pks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expand_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;log&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1e-10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;entropy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;pks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# A_1: p_red, p_greem
&lt;/span&gt;    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# A_2: p_red, p_greem
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;entropy2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;calculate_entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Entropy is &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;entropy2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Entropy is 0.7307
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이제 우리는 정보획득(IG)을 계산할 수 있게 된다. 이전 단계과 현재 상태의 불확실성 차이인 $IG_1 = 0.9710 - 0.7307 = 0.2403$가 정보획득량이라고 할 수 있다.&lt;/p&gt;

&lt;p&gt;그렇다면 다른 경우에는 어떨까? 예를 들어 가로로 선을 그어 두 영역(상: $A_1$, 하: $A_2$)을 나눠보고 정보획득량을 계산해보자.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1VvzOYsLNMEoM2mOtCi9FbHxIo5e-bUVM&quot; alt=&quot;상하 영역 A1, A2 나눌 경우&quot; width=&quot;50%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;상하 영역 A1, A2 나눌 경우&lt;/figcaption&gt;&lt;/figure&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;pks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# A_1: p_red, p_greem
&lt;/span&gt;    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# A_2: p_red, p_greem
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;entropy3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;calculate_entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Entropy is &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;entropy3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Entropy is 0.8464
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;계산해보니 정보획득량은 $IG_2 = 0.9710 - 0.8464 = 0.1246$이 되기 때문에, 세로로 선을 긋는 방법 보다 선호하지 않는 규칙이 될 것이다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;학습-방법-재귀적-분기--가지치기&quot;&gt;학습 방법: 재귀적 분기 &amp;amp; 가지치기&lt;/h2&gt;

&lt;h3 id=&quot;재귀적-분기recursive-partitioning&quot;&gt;재귀적 분기(recursive partitioning)&lt;/h3&gt;

&lt;p&gt;예를 들어 대출 심사를 하는 데이터가 있다면, 어떻게 진행되는지 알아본다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;자동차 소유&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;소득&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;보유 대출 건수&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;대출여부&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;650&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yes&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;200&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;700&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;500&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;425&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;900&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yes&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;먼저 처음 시점의 엔트로피를 구하면 다음과 같다.&lt;/p&gt;

\[Entropy(A)= - \Big( \dfrac{4}{6}\log(\dfrac{4}{6}) + \dfrac{2}{6}\log(\dfrac{2}{6}) \Big) = 0.9183\]

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;pks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;entropy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;calculate_entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Entropy is &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Entropy is 0.9183
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;그 후 특정 피처를 선정해서 정렬 후에 각 분기점에서 한번씩 엔트로피를 계산하고 IG를 구한다. 예를 들어 다음 표처럼 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;소득 &amp;lt;= 200&lt;/code&gt;을 기준으로 나눠서 계산하고, 다음 기준을 선정해서 계속 계산한다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;자동차 소유&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;소득&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;보유 대출 건수&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;대출여부&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;span style=&quot;color: #7d7ee8&quot;&gt;0&lt;/span&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;span style=&quot;color: #7d7ee8&quot;&gt;200&lt;/span&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;span style=&quot;color: #7d7ee8&quot;&gt;0&lt;/span&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;span style=&quot;color: #7d7ee8&quot;&gt;no&lt;/span&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;425&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;500&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;0&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;650&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yes&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;700&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;no&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;900&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;yes&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;hr /&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Colname&lt;/th&gt;
      &lt;th&gt;Value&lt;/th&gt;
      &lt;th&gt;MaxIG&lt;/th&gt;
      &lt;th&gt;ClsCount&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;income&lt;/td&gt;
      &lt;td&gt;700&lt;/td&gt;
      &lt;td&gt;0.677653&lt;/td&gt;
      &lt;td&gt;{False: {0: 0, 1: 1}, True: {0: 4, 1: 1}}&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;existloan&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0.594646&lt;/td&gt;
      &lt;td&gt;{False: {0: 1, 1: 0}, True: {0: 3, 1: 2}}&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;car&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;-0.018797&lt;/td&gt;
      &lt;td&gt;{False: {0: 1, 1: 1}, True: {0: 3, 1: 1}}&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;[expand]summary:전체코드 보기 👈&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;calculate_entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;counts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;counts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ndim&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;counts&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;expand_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;counts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;counts&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;counts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepdims&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;log&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1e-10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_info_gain&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;E_base&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reset_index&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;drop&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;unique_x_values&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unique&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;[Start] Processing column: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_col&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unique_x_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;IG_candidates&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;IG_counts&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;unique_x_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;group&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;counts&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;groupby&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;group&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;loan&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;unstack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fill_value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;E_x_col&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;calculate_entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;counts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;E_x_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;counts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;counts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;E_x_col&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;E_x_col&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;E_x_col&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;E_x_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;info_gain&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;E_base&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;E_x_col&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;IG_candidates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;info_gain&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;IG_counts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;counts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;  Testing Value &amp;lt;= &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; | Entropy: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;E_x_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; | IG: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;info_gain&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;  Counts:&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;counts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;IG_candidates&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IG_candidates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;IG_max&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IG_candidates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;idx_IG_max&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IG_candidates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;IG_value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx_IG_max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;[Result] Max information gain is &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IG_max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; value: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IG_value&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;del&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;group&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IG_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IG_max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IG_counts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx_IG_max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;car&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;income&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;650&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;700&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;425&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;900&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;existloan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;E_base&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;calculate_entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;loan&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value_counts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;IGs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_col&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;car&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;income&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;existloan&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;IG_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IG_max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IG_counts&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;get_info_gain&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;E_base&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;IGs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IG_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IG_max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IG_counts&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df_res&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;col&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Colname&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Value&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;MaxIG&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;ClsCount&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IGs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))})&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;df_res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;MaxIG&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ascending&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# [Start] Processing column: car: [0, 1]
# 0.9370927078645052
#   Testing Value &amp;lt;= 0 | Entropy: 0.9371 | IG: -0.0188
#   Counts: {False: {0: 1, 1: 1}, True: {0: 3, 1: 1}}
# [Result] Max information gain is -0.0188 value: 0
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# [Start] Processing column: income: [200, 425, 500, 650, 700, 900]
# 0.6473003960626632
#   Testing Value &amp;lt;= 200 | Entropy: 0.6473 | IG: 0.2710
#   Counts: {False: {0: 3, 1: 2}, True: {0: 1, 1: 0}}
# 0.6666666664262174
#   Testing Value &amp;lt;= 425 | Entropy: 0.6667 | IG: 0.2516
#   Counts: {False: {0: 2, 1: 2}, True: {0: 2, 1: 0}}
# 0.6121972224625437
#   Testing Value &amp;lt;= 500 | Entropy: 0.6122 | IG: 0.3061
#   Counts: {False: {0: 1, 1: 2}, True: {0: 3, 1: 0}}
# 0.9370927078645052
#   Testing Value &amp;lt;= 650 | Entropy: 0.9371 | IG: -0.0188
#   Counts: {False: {0: 1, 1: 1}, True: {0: 3, 1: 1}}
# 0.2406426981034281
#   Testing Value &amp;lt;= 700 | Entropy: 0.2406 | IG: 0.6777
#   Counts: {False: {0: 0, 1: 1}, True: {0: 4, 1: 1}}
# [Result] Max information gain is 0.6777 value: 700
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# [Start] Processing column: existloan: [0, 1, 3]
# 0.6666666664262174
#   Testing Value &amp;lt;= 0 | Entropy: 0.6667 | IG: 0.2516
#   Counts: {False: {0: 2, 1: 2}, True: {0: 2, 1: 0}}
# 0.32365019795919686
#   Testing Value &amp;lt;= 1 | Entropy: 0.3237 | IG: 0.5946
#   Counts: {False: {0: 1, 1: 0}, True: {0: 3, 1: 2}}
# [Result] Max information gain is 0.5946 value: 0
&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;p&gt;위 코드와 표는 각 입력 피처로 하나씩 규칙을 찾은 결과다. 살펴보면 최대 정보획등량(MaxIG)은 $0.068056$ 으로 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;소득 &amp;lt;= 700&lt;/code&gt; 기준으로 나누는 첫번째 노드의 규칙이 된다. 만약 소득이 규칙인 700보다 작은 값이면, 대출여부가 0인 값은 4개, 1인 값은 1개가 되고, 700 보다 크다면 대출여부가 0인 값은 0개, 1인 값은 1개가 된다. 다시 풀어서 말하면, 만약에 당신의 소득이 700 보다 적다면, 학습된 데이터를 기반으로 보았을 때, 대출가능한 확률은 20%(1/5) 정도가 될것이다.&lt;/p&gt;

&lt;p&gt;이렇게 첫번째 규칙이 정해지면, 사람이 정한 하이퍼파라미터인 나무의 최대 깊이(max depth)에 따라서 계속 찾을 것인지 아니면 멈출지를 결정한다. 그리고 엔트로피가 0이 되면 학습을 최대 깊이가 아니더라도 알아서 멈추게 된다. 다만, 의사결정 나무 모델이 깊게 들어갈 수록 과적합(overfitting)될 가능성이 높다.&lt;/p&gt;

&lt;p&gt;scikit-learn 패키지를 활용하면 손쉽게 의사결정 나무를 학습시킬 수 있다. 다만 피처의 정렬하여 특정값을 기준값으로 정하지 않고 약간 다르게 적용한다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tree&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;car&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;income&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;650&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;700&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;425&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;900&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;existloan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;clf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tree&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DecisionTreeClassifier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;entropy&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_depth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;clf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;clf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;만약 graphviz를 설치했다면, 의사결정 나무 모델을 시각화 해볼 수도 있다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;graphviz&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dot_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tree&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;export_graphviz&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;clf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_file&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;feature_names&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;car&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;income&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;existloan&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;class_names&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;대출 불가능&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;대출 가능&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;filled&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rounded&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;special_characters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;graph&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;graphviz&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Source&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;graph&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1B8ZxPjkeFn_TCkG-ll5JSPu0JBGsLuHQ&quot; alt=&quot;Graphviz로 의사결정 나무 모델 시각화&quot; width=&quot;90%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Graphviz로 의사결정 나무 모델 시각화&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;이 모델 그래프에 따르면 대출이 가능한 사람은 수입(income)이 575 이상이어야 하고, 대출 보유 대출 건수(existloan)가 2개 이하여야 대출이 가능하다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;가지치기pruning&quot;&gt;가지치기(pruning)&lt;/h3&gt;

&lt;p&gt;과적합을 피하기 위해 다양한 방법이 있다. scikit-learn을 기준으로 설명하면 다음과 같다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;min_samples_leaf&lt;/code&gt;: 리프 노드가 되기 위한 최소 샘플의 개수를 말하며, 이 값이 커질 수록 모델이 간결해지나, 학습 데이터가 부족할 경우, 전체 정확도가 떨어질 수가 있다.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;max_depth&lt;/code&gt;: 최대 깊이, 깊이를 작게 만들어 모델을 간결하게 만들 수 있지만 정확도가 떨어질 가능성이 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;여기서 말하는 가지치기(purning)는 &lt;strong&gt;비용복잡도 가지치기(Cost Complexity Pruning)&lt;/strong&gt;을 말하며, 복잡도 파라미터라고 불리는 $\alpha$로 조절 할 수 있다. 의사결정 나무 모델 $T$가 주어 졌을 때, 비용복잡도 함수$R_{\alpha}(T)$는 다음과 같이 결정된다.&lt;/p&gt;

\[R_{\alpha}(T) = R(T) + \alpha \vert \hat{T} \vert\]

&lt;p&gt;여기서 $\vert \hat{T} \vert$는 리프 노드의 개수, $R(T)$는 전체 리프 노드에서 계산된 오분류율이다. Scikit-learn에서는 $R(T)$를 전체 샘플로 가중치화된 리프 노드의 불순도(impurity)로 대신 계산한다. $\alpha$값이 올라 갈 수록, 훈련 데이터에서 의사 결정 나무 모델의 깊이와 노드의 개수가 점점 떨어진다. 따라서, $\alpha$값을 잘 조절하면, 검증 데이터에서 좋은 성능을 낼 수 있는 최적의 모델을 만들 수 있다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1Q_0g6iCs1sS7dvG1c7OA451PPrDUIMEF&quot; alt=&quot;Alpha값에 따른 Train/Test 데이터에서 정확도 변화&quot; width=&quot;90%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;Alpha값에 따른 Train/Test 데이터에서 정확도 변화&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;feature-importance&quot;&gt;Feature Importance&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;피처 중요도(Feature Improtance)&lt;/strong&gt;란 의사결정 나무를 만드는데 기여한 피처의 정량적 평가라고 볼 수 있다. 재귀적 분리와 가지치기를 통해 의사결정 나무를 생성할 때, 불순도를 가장 많이 줄이는 피처가 곧 모델을 생성하는데 큰 공헌을 새운 피처라고 할 수 있으며, 중요도가 높다고 말 할 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;feature-importance-구하는-방법&quot;&gt;Feature Importance 구하는 방법&lt;/h3&gt;

&lt;p&gt;일반적인 Feature Importance를 구하는 방법은, 다름 의사결정 나무를 보고 계산하면서 알아보자.&lt;/p&gt;

&lt;p&gt;[expand]summary:전체코드 보기 👈&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;pandas&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tree&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;graphviz&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DataFrame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;car&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;income&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;650&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;700&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;425&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;900&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;550&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;existloan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loan&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iloc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;clf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tree&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DecisionTreeClassifier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;entropy&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_depth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;clf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;clf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;dot_data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tree&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;export_graphviz&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;clf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_file&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;feature_names&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;car&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;income&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;existloan&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;class_names&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;대출 불가능&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;대출 가능&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;filled&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rounded&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;special_characters&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;graph&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;graphviz&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Source&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;p&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1KZS2M8IQDzULdVkRTIbkK1SlkkGBUWQu&quot; alt=&quot;새로운 Tree&quot; width=&quot;90%&quot; height=&quot;auto&quot; /&gt;&lt;/p&gt;&lt;figcaption&gt;새로운 Tree&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;$i$번째 가지(feature)에서 노드가 $L$과 $R$로 분리 되었 다면 information gain 은 다음과 같이 구한다. 여기서 $N$은 전체 샘플의 개수, $N_i$는 분리 이전의 해당 노드에서 보유하고 있는 샘플의 개수, $N_{(i, L)}$는 좌측으로 분리된 샘플의 개수, $N_{(i, R)}$은 우측으로 분리된 샘플의 개수, $E_i$는 분리 이전의 엔트로피, $E_{(i, L)}$과, $E_{(i, R)}$은 각각 좌측과 우측의 엔트로피다.&lt;/p&gt;

\[IG_{i} = \dfrac{N_i}{N} E_{i} - \dfrac{N_{(i, L)}}{N_i} E_{(i, L)} - \dfrac{N_{(i, R)}}{N_i} E_{(i, R)}\]

&lt;p&gt;지금 그래프는 두 개의 피처(income, existloan)으로 인해 나눠졌고, 먼저 income의 정보획득량을 구해보면 다음과 같다.&lt;/p&gt;

\[\begin{aligned}
IG_{income} &amp;amp;= \dfrac{N_{income}}{N} E_{income} - \dfrac{N_{(income, L)}}{N_{income}} E_{(income, L)} - \dfrac{N_{(income, R)}}{N_{income}} E_{(income, R)} \\
&amp;amp;= \dfrac{7}{7} \times 0.9852 - \dfrac{3}{7} \times 0.0 - \dfrac{4}{7} \times 0.8113 \\
&amp;amp;= 0.5216
\end{aligned}\]

&lt;p&gt;나머지 existloan의 정보획득량은 다음과 같다.&lt;/p&gt;

\[\begin{aligned}
IG_{existloan} &amp;amp;= \dfrac{N_{existloan}}{N} E_{existloan} - \dfrac{N_{(existloan, L)}}{N_{existloan}} E_{(existloan, L)} - \dfrac{N_{(existloan, R)}}{N_{existloan}} E_{(existloan, R)} \\
&amp;amp;= \dfrac{4}{7} \times 0.8113 - \dfrac{1}{4} \times 0.0 - \dfrac{3}{4} \times 0.0 \\
&amp;amp;= 0.4636
\end{aligned}\]

&lt;p&gt;car 칼럼은 쓰이지 않았기 때문에 피처 중요도는 0이 된다. 따라서 각각의 피처 중요도를 일반화(normalize) 시키면 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;(car, income, existloan) = (0, 0.5295, 0.4705)&lt;/code&gt;가 된다.&lt;/p&gt;

&lt;p&gt;[expand]summary:계산코드 보기 👈&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;scipy.stats&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;entropy&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;calculate_ig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;e_base&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;e_left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;e_right&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;IG&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e_base&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e_left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;e_right&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;E Base: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e_base&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; | E Left &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e_left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; | E Right &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;e_right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Information Gain = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IG&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IG&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Income
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;[Feature] Income&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x_income&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x_income_left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x_income_right&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;IG_income&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;calculate_ig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_income&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_income_left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_income_right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Existloan
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;[Feature] Existloan&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x_existloan&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x_existloan_left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x_existloan_right&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;IG_existloan&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;calculate_ig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_existloan&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_existloan_left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_existloan_right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;[Feature Importance] Normalized (Car, Income, Existloan)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;IG_car&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;IG_car&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IG_income&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;IG_existloan&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;normed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;[Feature Importance] in scikit-learn&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;clf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;feature_importances_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# [Feature] Income
# E Base: 0.9852 | E Left 0.0000 | E Right 0.8113
# Information Gain = 0.5216
# [Feature] Existloan
# E Base: 0.8113 | E Left 0.0000 | E Right 0.0000
# Information Gain = 0.4636
# [Feature Importance] Normalized (Car, Income, Existloan)
# [0.     0.5295 0.4705]
# [Feature Importance] in scikit-learn
# [0.     0.5295 0.4705]
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;[/expand]&lt;/p&gt;

&lt;h3 id=&quot;사용시-주의할-점&quot;&gt;사용시 주의할 점&lt;/h3&gt;

&lt;p&gt;사용시에 주의할 점이 있는데, 피처 중요도를 절대적인 지표로 사용하면 안 된다. 그 이유는 훈련 데이터에 최적화된 모델에서 보여주는 중요도이기 때문에, 특정 피처가 중요하지 않다고 할 수 없다. 위에서 설명한 자동차 보유 여부인 피처 car의 경우 모델에 고려되지 않았다고 해서 대출의 중요한 척도가 아니다. 실제로 어떤 사람이 차를 소유했다면, 보통은 그 유지비용을 감당할 수 있어서(즉, 어느정도의 현금 흐름이 있다)차를 샀다고 생각하기 때문에 중요하지 않다고 보기는 힘들다. 하지만 상대적으로 중요하다고는 말 할 수 있기 때문에 모델을 만들고 분석시에 유용하게 쓰인다.&lt;/p&gt;

&lt;h2 id=&quot;permutation-feature-importance&quot;&gt;Permutation Feature Importance&lt;/h2&gt;

&lt;p&gt;Permutation Feature Importance는 feature의 값을 임의로 치환했을 때 성능의 변화를 본다. 만약 해당 feature가 모델에서 크게 중요한 역할을 하고 있다면 값을 치환했을 때 성능이 크겍 떨어진다는 아이디어에서 시작한다. 입력 데이터 $X$, 타겟 데이터 $y$, 모델 $f$과 손실함수 $L$로 주어 졌을 때, 주요 알고리즘은 다음과 같다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;현재 모델의 성능 측정: $e^{original} = L\big(y, f(X)\big)$&lt;/li&gt;
  &lt;li&gt;데이터의 각 피처 $j$에 대해서
    &lt;ol&gt;
      &lt;li&gt;$K$번 반복한다. ($k = 1, \cdots, K$)
        &lt;ol&gt;
          &lt;li&gt;랜덤하게 피처 $j$의 데이터를 셔플하여 새로운 변형된 데이터 세트 $\hat{X}^{(j)}_k$를 만든다&lt;/li&gt;
          &lt;li&gt;변형된 데이터 세트로 성능을 측정한다. $e^{(j)}_k = L\big(y, f(\hat{X}^{(j)}_k)\big)$&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;피처 $k$의 중요도 $I^{(j)}$를 계산한다. $I^{(j)} = e^{original} - \dfrac{1}{K} \sum_{k=1}^{K} e^{(j)}_k$&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Scikit-learn에서 다음과 같이 제공하고 있다. 다만 모델이 커질 경우 실행시간이 꽤 오래 걸린다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;sklearn.inspection&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;permutation_importance&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;permutation_importance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;clf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_repeats&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;30&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_state&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;importances_mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argsort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()[::&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;df&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;importances_mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; +/- &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;importances_std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# income  0.462 +/- 0.180
# existloan  0.195 +/- 0.078
# car  0.000 +/- 0.000
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;장단점&quot;&gt;장단점&lt;/h1&gt;

&lt;p&gt;어떤 문제를 해결할 때, 왜 이 모델을 사용하려고 하는지 이해하고 쓰는 것이 중요하기에, 의사결정 나무 모델의 장단점을 요약해서 정리해보았다.&lt;/p&gt;

&lt;h2 id=&quot;장점&quot;&gt;장점&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;사람이 해석하고, 이해하기 쉽게 시각화가 가능하다.&lt;/li&gt;
  &lt;li&gt;일반화(normalization), 더미변수(dummy variables), 결측치(missing values)에 대한 전처리가 거의 필요없다.&lt;/li&gt;
  &lt;li&gt;수치형과 범주형 데이터를 다룰 수가 있다.&lt;/li&gt;
  &lt;li&gt;조절해야할 하이퍼파라미터가 상대적으로 적긱 때문에, 빠르게 실험해 볼 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;단점&quot;&gt;단점&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;조절을 못하면 과적합된 모델을 생성할 가능성이 크다.&lt;/li&gt;
  &lt;li&gt;데이터의 작은 변동으로 인해 완전히 다른 트리가 생성될 수 있기 때문에 의사 결정 트리는 불안정할 수 있다. 이 문제는 앙상블 내에서 의사결정 트리를 사용함으로써 완화할 수 있다.&lt;/li&gt;
  &lt;li&gt;예측값이 매끄럽지도 않고 연속적이지도 않고 단편적으로 일정한 근사치이다. 보외법(extrapolation)을 수행하기가 어렵다. 즉, 일반화가 안될 수 있다.&lt;/li&gt;
  &lt;li&gt;특정 클래스의 값에 지배적으로 편향되는 경우, 편향된 트리를 만든다. 따라서 학습 전에 균형 있는 데이터 세트를 만드는 것이 중요하다.&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Thu, 04 Mar 2021 00:00:01 +0900</pubDate>
        <link>https://simonjisu.github.io/machinelearning/2021/03/04/decision_tree.html</link>
        <guid isPermaLink="true">https://simonjisu.github.io/machinelearning/2021/03/04/decision_tree.html</guid>
        
        
        <category>machinelearning</category>
        
      </item>
    
  </channel>
</rss>
