<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Soo</title>
    <description>My Blog
</description>
    <link>http://simonjisu.github.io/</link>
    <atom:link href="http://simonjisu.github.io/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Fri, 20 Apr 2018 19:08:23 +0900</pubDate>
    <lastBuildDate>Fri, 20 Apr 2018 19:08:23 +0900</lastBuildDate>
    <generator>Jekyll v3.2.1</generator>
    
      <item>
        <title>All about Word Vectors: Word2Vec</title>
        <description>&lt;h1 id=&quot;all-about-word-vectors-word2vec&quot;&gt;All about Word Vectors: Word2Vec&lt;/h1&gt;

&lt;hr /&gt;
&lt;p&gt;본 포스팅은 &lt;a href=&quot;http://web.stanford.edu/class/cs224n/&quot;&gt;CS224n&lt;/a&gt; Lecture 2 강의내용을 기반으로 강의 내용 이해를 돕고자 작성 됐습니다.&lt;/p&gt;

&lt;p&gt;자연어 처리 공부를 해보신 분이라면 한번쯤 접한 그림이 있을 것이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/nlp/L2_linear-relationships.png&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“king” - “man” + “woman” = ?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;느낌상 “왕”에서 “남자”라는 속성을 빼주고, “여자”의 속성을 더해주면?&lt;/p&gt;

&lt;p&gt;“queen” 이 나와야할 것 같다. Word Representation은 이런 것을 가능하게 했다.&lt;/p&gt;

&lt;p&gt;이번 시간에는 &lt;strong&gt;Word2vec&lt;/strong&gt; 에 대해서 알아보려고 한다.&lt;/p&gt;

&lt;h2 id=&quot;word2vec&quot;&gt;Word2Vec&lt;/h2&gt;

&lt;p&gt;Word2Vec은 두 가지 알고리즘이 있다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;ol&gt;
    &lt;li&gt;Skip-grams(SG)
      &lt;ul&gt;
        &lt;li&gt;target 단어를 기반으로 context 단어들을 예측한다. (position independent)&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;Continuous Bag of Words (CBOW)
      &lt;ul&gt;
        &lt;li&gt;context 단어들 집합(bag-of-words context)으로부터 target 단어를 예측한다.&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;ul id=&quot;light-slider1&quot;&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/nlp/L2_skipgram1.png&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/nlp/L2_skipgram2.png&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/nlp/L2_cbow1.png&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/nlp/L2_cbow2.png&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그리고 몇 가지 효율적인 훈련 방법들이 있다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Two (moderately efficient) training methods (vs Naive Softmax)&lt;/p&gt;
  &lt;ol&gt;
    &lt;li&gt;Hierarchical softmax&lt;/li&gt;
    &lt;li&gt;Negative sampling&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;출처: &lt;a href=&quot;http://web.stanford.edu/class/cs224n/syllabus.html&quot;&gt;CS224n Lecture 2&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;이번 포스팅에서는 Skip-gram 과 Negative Sampling을 메인으로 소개하겠다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;skip-gram-model-with-naive-softmax&quot;&gt;Skip-gram model with Naive Softmax&lt;/h2&gt;
&lt;p&gt;Paper: &lt;a href=&quot;https://arxiv.org/pdf/1310.4546.pdf&quot;&gt;Distributed Representations of Words and Phrases
and their Compositionality&lt;/a&gt; (Mikolov et al. 2013)&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;embedding-look-up&quot;&gt;Embedding Look up&lt;/h3&gt;

&lt;p&gt;모델 설명에 들어가기 앞서 &lt;strong&gt;Embedding Look up&lt;/strong&gt; 이란 것을 알아보자. 이 용어는 이제 여기저기서 많이 나올텐데 알아두면 좋다.&lt;/p&gt;

&lt;p&gt;우리가 하고 싶은 것은 엄청나게 차원이 큰 one-hot vector 를 고정된 작은 차원으로 넣고 싶은 것이다. 어떻게 하면 단어들을 &lt;strong&gt;2-dimension matrix&lt;/strong&gt; 로 표현 할 수 있을까?&lt;/p&gt;

&lt;p&gt;아래 그림의 예를 보자. 8차원 one-hot vector를 3차원으로 만들고 싶다. 그렇다면 $3\times 8$ 행렬을 만들어서 각 column vector 가 하나의 3차원 단으를 표현하면 2-D Matrix 가 되지 않는가? 이 Matrix를 &lt;strong&gt;Embedding Matrix&lt;/strong&gt; 라고 부르기로 하자&lt;/p&gt;

&lt;ul id=&quot;light-slider2&quot;&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/nlp/L2_embedlookup1.png&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/nlp/L2_embedlookup2.png&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그렇다면 어떻게 각 단어와 이 Embedding Matrix 를 매칭 시킬수 있을까? 여기서 &lt;strong&gt;내적&lt;/strong&gt; 을 활용하게 된다.&lt;/p&gt;

&lt;ul id=&quot;light-slider3&quot;&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/nlp/L2_embedlookup3.png&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/nlp/L2_embedlookup4.png&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/nlp/L2_embedlookup5.png&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그런데 자세히 보니, one-hot vector의 숫자 $1$ 이 위치한 index 가 Embedding Matrix 의 column vector 의 index 와 같다. 따라서 중복되지 않는 단어사전을 만들고, 각 단어에 대해 index를 메긴 다음, 찾고 싶은 단어를 Embedding Matrix 에서 column vector index 만 &lt;strong&gt;조회(Look up)&lt;/strong&gt; 하면 되는 것이다.&lt;/p&gt;

&lt;ul id=&quot;light-slider4&quot;&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/nlp/L2_embedlookup6.png&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/nlp/L2_embedlookup7.png&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;코드 예시:&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import numpy as np
sentence = &quot;I am going to watch Avengers Infinity War&quot;.split()
embedding_matrix = np.array([[1,2,5,1,9,10,3,4], [5,1,4,1,8,1,2,5], [7,8,1,4,1,6,2,1]])
vocab = {w: i for i, w in enumerate(sentence)}
word = &quot;I&quot;
print(embedding_matrix)
print(&quot;=&quot;*30)
print(&quot;Word:&quot;, word)
print(&quot;Index:&quot;, vocab[word])
print(&quot;Vector:&quot;, embedding_matrix[:, vocab.get(word)])
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;[[ 1  2  5  1  9 10  3  4]&lt;/p&gt;

  &lt;p&gt;[ 5  1  4  1  8  1  2  5]&lt;/p&gt;

  &lt;p&gt;[ 7  8  1  4  1  6  2  1]]&lt;/p&gt;

  &lt;p&gt;==============================&lt;/p&gt;

  &lt;p&gt;Word: I&lt;/p&gt;

  &lt;p&gt;Index: 0&lt;/p&gt;

  &lt;p&gt;Vector: [1 5 7]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이해가 됐으면 이제 모델로 들어가보자.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/nlp/L2_model_train.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;section&quot;&gt;목적&lt;/h3&gt;

&lt;p&gt;각 중심단어 $c$ 에 대해서 아래의 &lt;strong&gt;가능도/우도 (Likelihood)&lt;/strong&gt; 를 구해본다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L(\theta) = \prod_{t=1}^{T} \prod_{-m \leq j \leq m,\ j \neq 0} p(w_{t+j} | w_t; \theta) \quad \cdots\cdots \quad (1)&lt;/script&gt;

&lt;p&gt;수식을 말로 풀어보자. 각 포지션 $(\prod_{t=1}^{T})$ 의 중심단어 $c$ = $w_t$ 에 대해서, $w_t$ 가 주어졌을 때 다른 문맥단어 $o$ = $w_{t+j}$ 가 나오는 확률 $\big( p (w_{t+j} \vert w_t; \theta) \big)$ 을 가능하게 만드는 $\theta$ 를 구하는 것이다. 단 $j$ 는 윈도우 크기 $m$ 을 넘지 않으며, $0$ 이 될 수 없다.&lt;/p&gt;

&lt;p&gt;따라서 &lt;strong&gt;Likelihood&lt;/strong&gt; 를 &lt;strong&gt;최대화&lt;/strong&gt; 하는 것이 우리의 목적이 되겠다.&lt;/p&gt;

&lt;p&gt;그러나 여기서는 우리가 좋아하는 Gradient Descent 를 사용하기 위해서 이 식을 &lt;strong&gt;Negative Log Likelihood&lt;/strong&gt; 로 변형해서 쓰기로한다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\min J(\theta) = -\dfrac{1}{T} \sum_{t=1}^T \sum_{-m \leq j \leq m,\ j \neq 0} \log p(w_{t+j} | w_t) \quad \cdots\cdots \quad (2)&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;$(1)$ 식과 $(2)$ 식이 왜 동등한지는 밑에 &lt;strong&gt;&lt;span style=&quot;color: #e87d7d&quot;&gt;참고 1&lt;/span&gt;&lt;/strong&gt; 을 확인하길 바란다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;그렇다면 단어가 등장할 확률 $p(w_{t+j} \vert w_t)$ 는 어떻게 구할 것인가?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Softmax&lt;/strong&gt; 라는 input 값을 0과 1 사이로 만들어 주는 친근한 함수가 있다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;p(o|c) = \dfrac{\exp(u_o^T V_c)}{\sum_{w=1}^V \exp(u_w^T V_c)} \quad \cdots\cdots \quad (3)&lt;/script&gt;

&lt;p&gt;따라서 모델에 있는 모든 파라미터를 $\theta \in \Bbb{R}^{2dV}$ 로 두고, $(2)$ 식을 최적화 한다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;왜 $\theta \in \Bbb{R}^{2dV}$ 인가?
Center Word 의 Embedding Matrix $W$ Context Words 의 Embedding Matrix $W’$ 두개를 학습 시켜야하기 때문이다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;&lt;span style=&quot;color: #e87d7d&quot;&gt;주의 )&lt;/span&gt;&lt;/strong&gt; $W’$ 는 $W$ 의 전치 행렬이 아니라 완전히 새로운 Embedding Matrix 다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;update&quot;&gt;Update&lt;/h3&gt;

&lt;p&gt;Gradient를 통해서 각 파라미터들을 업데이트 하게 된다. $(3)$ 식의 $\log$ 를 취하게 되면 아래와 같다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f = \log \dfrac{\exp(u_o^T V_c)}{\sum_{w=1}^V \exp(u_w^T V_c)}&lt;/script&gt;

&lt;p&gt;이제 $f$ 의 Gradient 를 구해보자.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned} \dfrac{\partial f}{\partial V_c}
&amp;= \dfrac{\partial }{\partial V_c} \big(\log(\exp(u_o^T V_c)) - \log(\sum_{w=1}^V \exp(u_w^T V_c))\big) \\
&amp;= u_o - \dfrac{1}{\sum_{w=1}^V \exp(u_w^T V_c)}(\sum_{x=1}^V \exp(u_x^T V_c) u_x ) \\
&amp;= u_o - \sum_{x=1}^V \dfrac{\exp(u_x^T V_c)}{\sum_{w=1}^V \exp(u_w^T V_c)} u_x \\
&amp;= u_o - \sum_{x=1}^V P(x | c) u_x
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;$u_o$ : observed word, output context word&lt;/li&gt;
  &lt;li&gt;$P(x\vert c)$: probs context word $x$ given center word $c$&lt;/li&gt;
  &lt;li&gt;$P(x\vert c)u_x$: Expectation of all the context words: likelihood occurance probs $\times$ context vector&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;흥미로운 점: &lt;strong&gt;미분 값&lt;/strong&gt; 은 관측된 context word 벡터 $u_o$ 에서 center word $c$ 가 주어졌을 때 나올 수 있는 모든 단어의 기대치를 빼준 다는 것이다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;다음 시간에는 &lt;strong&gt;Naive Softmax&lt;/strong&gt; 로 훈련 시켰을 때의 단점과 이를 보완 해준 &lt;strong&gt;&lt;span style=&quot;color: #e87d7d&quot;&gt;Negative Sampling&lt;/span&gt;&lt;/strong&gt; 에 대해서 알아보자.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;why-mle-is-equivalent-to-minimize-nll&quot;&gt;참고 1: Why MLE is equivalent to minimize NLL?&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Likelihood&lt;/strong&gt; 의 정의:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;L(\theta|x_1,\cdots,x_n) = f(x_1, \cdots, x_n|\theta) = \prod_{i=1}^n f(x_i|\theta)&lt;/script&gt;

&lt;p&gt;log를 취하게 되면 아래와 같다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\log L(\theta|x_1,\cdots,x_n) =  \sum_{i=1}^n log f(x_i|\theta)&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;MLE(maximum likelihood estimator)&lt;/strong&gt; 의 정의:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{\theta}_{MLE} = \underset{\theta}{\arg \max} \sum_{i=1}^n \log f(x_i|\theta)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\underset{x}{\arg \max} (x) = \underset{x}{\arg \min}(-x)&lt;/script&gt;

&lt;p&gt;때문에 우리는 아래의 식을 얻을 수 있다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\hat{\theta}_{MLE} = \underset{\theta}{\arg \max} \sum_{i=1}^n \log f(x_i|\theta) = \underset{\theta}{\arg \min} -\sum_{i=1}^n \log f(x_i|\theta)&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;왜 log 로 바꾸는 것인가?
    &lt;ol&gt;
      &lt;li&gt;컴퓨터 연산시 곱하기 보다 더하기를 쓰면 &lt;strong&gt;복잡도&lt;/strong&gt; 가 훨씬 줄어들어 계산이 빠르다. ($O(n) \rightarrow O(1)$)&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;언더플로우&lt;/strong&gt; 를 방지할수 있다. 언더플로우란 1보다 작은 수를 계속곱하면 0에 가까워져 컴퓨터에서 0 으로 표시되는 현상을 말한다.&lt;/li&gt;
      &lt;li&gt;자연로그함수는 &lt;strong&gt;단조증가함수(monotonic increase function)&lt;/strong&gt; 라서 대소관계가 바뀌지 않는다. 예를 들자면, $5 &amp;lt; 10 \Longleftrightarrow log(5) &amp;lt; log(10)$ 의 관계가 바뀌지 않는 다는 것. 따라서 언제든지 지수를 취해서 다시 원래의 값으로 복귀 가능.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;참고
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://quantivity.wordpress.com/2011/05/23/why-minimize-negative-log-likelihood/&quot;&gt;why minimize negative log likelihood&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://ratsgo.github.io/deep%20learning/2017/09/24/loss/&quot;&gt;(ratsgo 님) 손실함수&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Fri, 20 Apr 2018 10:19:06 +0900</pubDate>
        <link>http://simonjisu.github.io/nlp/2018/04/20/allaboutwv2.html</link>
        <guid isPermaLink="true">http://simonjisu.github.io/nlp/2018/04/20/allaboutwv2.html</guid>
        
        
        <category>NLP</category>
        
      </item>
    
      <item>
        <title>All about Word Vectors: Intro</title>
        <description>&lt;h1 id=&quot;all-about-word-vectors-intro&quot;&gt;All about Word Vectors: Intro&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;본 포스팅은 &lt;a href=&quot;http://web.stanford.edu/class/cs224n/&quot;&gt;CS224n&lt;/a&gt; Lecture 2 강의내용을 기반으로 강의 내용 이해를 돕고자 작성 됐습니다.&lt;/p&gt;

&lt;h2 id=&quot;natural-language-processing&quot;&gt;자연어 처리 (Natural Language Processing)&lt;/h2&gt;
&lt;p&gt;이야기를 하기 앞서서, “언어”를 살펴보자. &lt;a href=&quot;https://ko.wikipedia.org/wiki/%EC%96%B8%EC%96%B4&quot;&gt;위키백과&lt;/a&gt; 에 따르면 아래와 같다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;언어(言語)에 대한 정의는 여러가지 시도가 있었다. 아래는 그러한 예의 일부이다.&lt;/p&gt;
  &lt;ul&gt;
    &lt;li&gt;사람들이 자신의 머리 속에 있는 생각을 다른 사람에게 나타내는 체계.&lt;/li&gt;
    &lt;li&gt;사물, 행동, 생각, 그리고 상태를 나타내는 체계.&lt;/li&gt;
    &lt;li&gt;사람들이 자신이 가지고 있는 생각을 다른 사람들에게 전달하는 데 사용하는 방법.&lt;/li&gt;
    &lt;li&gt;사람들 사이에 공유되는 의미들의 체계.&lt;/li&gt;
    &lt;li&gt;문법적으로 맞는 말의 집합(절대적이 아님).&lt;/li&gt;
    &lt;li&gt;언어 공동체 내에서 이해될 수 있는 말의 집합.&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;위의 예시를 추려내보면 어떤 추상적인 내용을 사람들간의 공통된 약속으로 규정했다는 것이다. 기계한테 어떻게 언어를 처리하도록 알려줘야하나? &lt;strong&gt;자연어 처리&lt;/strong&gt; 는 생각보다 오래된 역사를 가지고 있었다.&lt;/p&gt;

&lt;p&gt;1950년도 이전 부터 자연어를 처리하려는 시도가 꽤 많았던 모양이다. 1954년 조지 타운 실험은 60 개 이상의 러시아어 문장을 영어로 완전 자동 번역하는 작업을 진행했다. 그는 3-5년 안으로 해결 가능하다고 주장했지만 1966 년 ALPAC 보고서에 따르면 실제로 진전이 엄청느려서 연구 자금이 크게 줄었다고 한다. 그리고 최초의 통계 기계 번역 시스템이 개발 된 1980 년대 말까지 기계 번역에 대한 연구는 거의 이루어지지 않았다고 한다. (지금은 너두나두 번역기 만들 수 있지만…)&lt;/p&gt;

&lt;p&gt;또한, 1980년대까지 대부분의 자연어 처리 시스템은 손으로 쓴 복잡한 규칙 세트를 기반으로 했다. 그러나 점차 통계 기반의 자연어 처리 기법이 복잡한 자연어를 모델링 하는데 부상했다. (Reference: &lt;a href=&quot;https://en.wikipedia.org/wiki/Natural-language_processing&quot;&gt;NLP wikipedia&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;따라서, 자연어 처리의 기본 가정을 항상 염두하고 공부해야 할 것이다. 내가 생각하는 기본 가정은 &lt;strong&gt;“상호연관이 있는 단어의 분포와 모양은 비슷하다.”&lt;/strong&gt; 이지만, 아래 더 좋은 소개글을 링크로 걸어 두었으니 참고하길 바란다.&lt;/p&gt;

&lt;p&gt;참고: ratsgo 님의 블로그 - &lt;a href=&quot;https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/03/10/frequency/&quot;&gt;idea of statistical semantics&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;word-representation&quot;&gt;단어의 표현(Word Representation)&lt;/h2&gt;

&lt;p&gt;어떻게 하면 단어의 “의미”를 표현할 수 있을까?&lt;/p&gt;

&lt;p&gt;가장 간단한 방법은 단어를 종류별로 분류(taxonomy) 하는 것이다.&lt;/p&gt;

&lt;p&gt;영어에는 유명한 &lt;strong&gt;WordNet&lt;/strong&gt; 이라는 프로젝트가 있다. 이는 1985년부터 심리학 교수인 조지 A. 밀러가 지도하는 프린스턴 대학의 인지 과학 연구소에 의해 만들어졌고 유지되고 있다. 기본적으로 상위어(hypernyms) 밑에 동의어(synonym) 세트를 여러개 구성하는 것이다.&lt;/p&gt;

&lt;p&gt;좋긴한데 몇 가지 단점이 있다.&lt;/p&gt;

&lt;p&gt;첫째로, 단어간의 미묘한 차이, 뉘앙스(nuances)를 표현 할 수가 수 없다. 아래의 예를 보자.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from nltk.corpus import wordnet as wn
for synset in wn.synsets(&quot;adept&quot;):
    print(&quot;({})&quot;.format(synset.pos()) + &quot;, &quot;.join([l.name() for l in synset.lemmas()]))
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;(n) ace, adept, champion, sensation, maven, mavin, virtuoso, genius, hotshot, star, superstar, whiz, whizz, wizard, wiz
(s) adept, expert, good, practiced, proficient, skillful, skilful&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;“I’m good at deep learning” VS “I’m expert at deep learning” 이 두 문장은 확연히 다른 느낌의 문장이다. 잘하는 것과 전문가의 차이는 사람이 느끼기엔 다르다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;둘째로, 업데이트 비용이 많이 든다. 새로운 단어가 계속 나오면 업데이트 해줘야한다, 즉 구축비용이 쎄다는 것이다.&lt;/p&gt;

&lt;p&gt;셋째로, 사람마다 주관적이기 때문에 명쾌한 기준이 없다.&lt;/p&gt;

&lt;p&gt;마지막으로, 유사도 계산이 어렵다는 점이다. 즉, 같은 상위어에 속해 있는 하위어는 비슷한 것은 알겠는데, 정량적으로 이를 계산할 방법이 없다는 것이다.&lt;/p&gt;

&lt;h3 id=&quot;bag-of-words-representation&quot;&gt;Bag of words representation&lt;/h3&gt;

&lt;p&gt;또다른 방법으로 discrete 된 심볼로 단어를 표현했는데 이를 &lt;strong&gt;one-hot representation&lt;/strong&gt; 라고 하며, 아래와 같이 표현했다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;word = [0, 0, 0, 1, 0, 0, 0]&lt;/script&gt;

&lt;p&gt;이러한 방법론을 &lt;strong&gt;Bag of words representation&lt;/strong&gt; 이라 한다. 그러나 이는 두 가지 단점이 있다.&lt;/p&gt;

&lt;p&gt;첫째로, 차원(Dimensionality)의 문제. 단어가 많아 질 수록 벡터가 엄청 길어진다.&lt;/p&gt;

&lt;p&gt;둘째로, 제한적 표현(Localist representation)의 문제. 즉, 단어의 내적의미를 포함하지 않고, 각 단어들이 독립적이다. 예를 들면, “hotel” 과 “motel” 의 유사성을 계산하려고 하면, 0 이 나올 수 밖에 없다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
motel &amp;= \begin{bmatrix} 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \end{bmatrix} \\
hotel &amp;= \begin{bmatrix} 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 \end{bmatrix} \\
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;hotel \cdot motel^T = 0&lt;/script&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;distributional-similarity-based-representations&quot;&gt;분포 유사성 기반 표현 (Distributional similarity based representations)&lt;/h2&gt;

&lt;p&gt;연구자들은 one-hot vector 와 다른 어떤 유사도를 계산할 수 있는 벡터를 만들고 싶어했다. 따라서 유사도의 정보를 어디서 얻을 수 있을까를 찾기 시작했다. 그리고 어떤 핵심 아이디어를 생각해냈다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;어떤 단어의 “의미”는 그 단어 근처에 자주 출현하는 단어로부터 얻을 수 있다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/nlp/L2_context.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;출처: &lt;a href=&quot;http://web.stanford.edu/class/cs224n/syllabus.html&quot;&gt;CS224n Lecture 2&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;그들은 주변 단어의 정보로 어떤 단어의 의미를 규정하는 시도를 하였고, 이는 modern statistical NLP 에서 많은 각광을 받기 시작했다. 그리고 어떤 단어 $w$ 에 대해서 주변에 나타나는 단어의 집합을 &lt;strong&gt;맥락/문맥(context)&lt;/strong&gt; 이라고 했다.&lt;/p&gt;

&lt;h3 id=&quot;word-vectors&quot;&gt;Word Vectors&lt;/h3&gt;

&lt;p&gt;이전에 0과 1로 채워진 one-hot vector 와 달리 문맥에서 비슷한 단어들을 잘 예측 될 수 있게 단어 타입 별로 촘촘한 벡터(dense vector)를 만든다. 핵심 아이디어는 아래와 같다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Idea:&lt;/p&gt;
  &lt;ul&gt;
    &lt;li&gt;We have a large corpus of text&lt;/li&gt;
    &lt;li&gt;Every word in a fixed vocabulary is represented by a vector&lt;/li&gt;
    &lt;li&gt;Go through each &lt;strong&gt;position&lt;/strong&gt; $t$ in the text, which has a &lt;strong&gt;center word&lt;/strong&gt; $c$ and &lt;strong&gt;context (“outside”) words&lt;/strong&gt; $o$&lt;/li&gt;
    &lt;li&gt;Use the similarity of the word vectors for $c$ and $o$ to calculate the probability of $o$ given $c$ (or vice versa)&lt;/li&gt;
    &lt;li&gt;Keep adjusting the word vectors to maximize this probability&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;출처: &lt;a href=&quot;http://web.stanford.edu/class/cs224n/syllabus.html&quot;&gt;CS224n Lecture 2&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;요약하면 방대한 텍스트 데이터를 기반으로, 중심단어 $c$ 가 주어졌을 때, 그 주변단어 $o$ 가 나올 확률 분포를 최대화 하는 것을 구하는 것이다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Word vectors 는 때때로 Word Embeddings, Word Representation 이라고 불린다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;이렇게 해서 나온 알고리즘이 &lt;span style=&quot;color: #e87d7d&quot;&gt;“Word2Vec”&lt;/span&gt; 이며, 여기서 잠깐 끊고 다음 글에서 소개하도록 한다.&lt;/p&gt;
</description>
        <pubDate>Thu, 19 Apr 2018 16:41:36 +0900</pubDate>
        <link>http://simonjisu.github.io/nlp/2018/04/19/allaboutwv1.html</link>
        <guid isPermaLink="true">http://simonjisu.github.io/nlp/2018/04/19/allaboutwv1.html</guid>
        
        
        <category>NLP</category>
        
      </item>
    
      <item>
        <title>Bidirectional LSTM + self Attention Model</title>
        <description>&lt;h1 id=&quot;naver-sentiment-movie-corpus-classification&quot;&gt;Naver Sentiment Movie Corpus Classification&lt;/h1&gt;

&lt;hr /&gt;

&lt;p&gt;네이버 영화 감성분류 with Bidirectional LSTM + Self Attention&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;목표&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;영화 리뷰를 통해 긍정인지 부정인지 분류하는 문제 (Many-to-One)&lt;/li&gt;
  &lt;li&gt;사용한 모델: Bidirectional LSTM with Self Attention Model&lt;/li&gt;
  &lt;li&gt;이번 글은 논문과 제가 분석한 모델의 중요 요소를 곁들여 쓴 글입니다.&lt;/li&gt;
  &lt;li&gt;GitHub Code Link: &lt;a href=&quot;https://github.com/simonjisu/nsmc_study&quot;&gt;nsmc_study&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;그림이나 글은 퍼가셔도 좋지만, 출처 좀 남겨주세요~&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Reference Paper: &lt;a href=&quot;https://arxiv.org/pdf/1703.03130.pdf&quot;&gt;A STRUCTURED SELF-ATTENTIVE SENTENCE EMBEDDING&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;모델 핵심 부분 설명&lt;/h2&gt;

&lt;p&gt;그림과 수식을 함께 보면 이해하기 쉽다&lt;/p&gt;

&lt;p&gt;어떤 $n$ 개의 토근으로 이루어진 하나의 문장이 있다고 생각해보자.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;S = (w_1, w_2, \cdots, w_n)\qquad\qquad (1)&lt;/script&gt;

&lt;p&gt;여기서 $w_i$ 는 one-hot 인코딩된 단어가 아닌, $d$ 차원에 임베딩된 문장에서 $i$ 번째 단어다.&lt;/p&gt;

&lt;p&gt;따라서 $S$ 는 단어 벡터들을 concat 한 $n \times d$ 형태를 가지는 매트릭스다.&lt;/p&gt;

&lt;p&gt;문장 $S$ 는 각기 다른 문장과는 독립적이다. (하나의 문장이 하나의 평점과 세트로 생각하면 된다.) 하나의 문장에서 단어들 간의 관계를 알기 위해서 우리는 bidirectional LSTM 으로 하나의 문장을 처리하게 된다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\overrightarrow{h_t} &amp;= \overrightarrow{LSTM}(w_t, \overrightarrow{h_{t-1}})\qquad\qquad (2) \\
\overleftarrow{h_t} &amp;= \overleftarrow{LSTM}(w_t, \overleftarrow{h_{t-1}})\qquad\qquad (3)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;그후 우리는 각각의 $\overrightarrow{h_t}$ 과 $\overleftarrow{h_t}$ 를 concatenate 하여 하나의 히든 state $h_t$ 를 얻게 된다. 각 unidirectional LSTM(한 쪽 방향 LSTM)의 히든 유닛 크기를 $u$ 라고 하자. 조금 간단하게 표현하기 위해서 모든 $n$ 개의 $h_t$ 들을 $H$ 라고 하며, $n \times 2u$ 의 크기를 가진다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;H = (h_1, h_2, \cdots, h_n) \qquad\qquad (4)&lt;/script&gt;

&lt;ul id=&quot;light-slider1&quot;&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/nsmc/Self_Attention0.png&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/nsmc/Self_Attention1.png&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/nsmc/Self_Attention2.png&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/nsmc/Self_Attention3.png&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/nsmc/Self_Attention4.png&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;우리의 목적은 길이가 변화하는 문장을 어떤 &lt;strong&gt;고정된 크기&lt;/strong&gt; 의 임베딩으로 인코딩 하는 것이다. 이 목적을 달성하기 위해서 $H$ 와 attention 매커니즘이 요구되는 일종의 선형결합을 선택하게 된다. 즉, 아래와 같은 식과 $H$ 를 토대로, 어떤 벡터 $a$ 를 얻게 된다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;a = softmax(w_{s2} \tanh (W_{s1}H^T)) \qquad\qquad (5)&lt;/script&gt;

&lt;p&gt;여기서 $W_{s1}$ 는 $d_a \times 2u$ 형태를 가진 매트릭스, 그리고 $w_{s2}$ 는 $d_a$ 사이즈를 가진 벡터다. $d_a$ 는 하이퍼파라미터(hyperparameter)로 우리가 정할 수 잇는 변수다. $H$ 의 크기도 $n \times 2u$ 이기 때문에, 벡터 $a$ 는 $n$ 의 크기를 가진다. 또한 $softmax()$ 함수는 모든 weight들의 합을 1로 만들어 준다.&lt;/p&gt;

&lt;p&gt;그후 우리는 LSTM 의 히든상태들의 집합인 $H$ 를 주어진 $a$ 로 곱해서 한 문장을 임베딩한 벡터 $m$ 을 얻을 수 있다.&lt;/p&gt;

&lt;p&gt;이 벡터 $m$ 은 학습시 한 문장에서 어떤 단어를 중심적으로 보았는지 알 수 있다. 예를 들어 어떤 연관된 단어나 구문 등등.&lt;/p&gt;

&lt;p&gt;문장과 단어의 관계로 추가 설명하자면 아래와 같다.&lt;/p&gt;

&lt;p&gt;각 단어를 input으로 받은 hidden 상태의 노드들은 단어를 통과해서 각 단어의 숨겨진 특성을 대표하고 있다. 학습 시 Task 에 따라 다르겠지만, 분류라고 가정한다면 분류에 도움이 되는 히든 상태는 높은 값을 가지게 될 것이며, 이를 어떤 선형 변환 과정을 거쳐 softmax 취한다는 것은 한 문장에서 분류에 도움이 된 근거 단어 혹은 중요 단어의 확률을 구한다는 것이 된다. (그래서 attention 이라고 하는 것 같다.) 따라서 이는 한 문장에서 &lt;strong&gt;의미적인(semantic)&lt;/strong&gt; 부분을 나타내고 있다고 할 수 있다.&lt;/p&gt;

&lt;p&gt;이 확률 $a$ 를 기존의 hidden 상태와 곱해서 의미부분을 조금더 강조하게 되는 벡터 $m$ 을 구했다고 보면 된다.&lt;/p&gt;

&lt;ul id=&quot;light-slider2&quot;&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/nsmc/Self_Attention5.png&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/nsmc/Self_Attention6.png&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;하지만 한 문장 내에서 중요한 부분 혹은 의미가 있는 부분은 여러군데 일 수가 있다. (여러 의미가 하나의 문장을 구성한다.) 특히 긴 문장일 수록 그렇다. 예를 들어 “아이언맨과 캡틴아메리카” 면 “과”로 이어진, “아이언맨”, “캡틴아메리카” 두 단어는 중요한 의미가 있는 단어 일 수 있다. 따라서 한 문장에서 의미가 있는 부분을 나타내려면 $m$ 이란 벡터를 여러 번 수행해서 문장의 다른 부분까지 커버해야 한다. 이는 우리가 &lt;strong&gt;attention&lt;/strong&gt; 을 &lt;strong&gt;여러번(hops)&lt;/strong&gt; 하게 되는 이유다.&lt;/p&gt;

&lt;p&gt;따라서, 문장에서 우리가 정하는 어떤 수 $r$ 번의 다른 부분을 추출 해낸다고 하면, 기존의 $w_{s2}$ 는 $r \times d_a$ 크기를 가진 $W_{s2}$ 라는 매트릭스로 확장된다. 이에따라 기존에 $a$ 벡터도 $r$ 번을 수행해 concatenate 한 $r \times n$ 크기의 매트릭스 $A$ 가 된다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;A=softmax(W_{s2}tanh(W_{s1}H^T))  \qquad\qquad (6)&lt;/script&gt;

&lt;p&gt;여기서 $softmax()$ 는 input $W_{s2}tanh(W_{s1}H^T)$ 의 2번째 차원을 기준으로 softmax 하게 된다. (즉, 각 row 별로 softmax 해줌)&lt;/p&gt;

&lt;p&gt;사실 $(6)$ 번 수식은 bias 가 없는 2-Layers MLP 로 간주할 수도 있다.&lt;/p&gt;

&lt;p&gt;위에 식에 따라 임베딩된 벡터 $m$ 도 $r \times 2u$ 크기의 매트릭스 $M$ 로 확장된다. 가중치를 담은 매트릭스 $A(r \times n)$ 와 LSTM 의 히든 상태들인 $H(n \times 2u)$를 곱해서 새로운 임베딩 매트릭스 $M$ 을 얻을 수 있다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;M=AH  \qquad\qquad (7)&lt;/script&gt;

&lt;p&gt;마지막으로 $M$을 Fully Connected MLP 에 넣어서 하고 싶은 분류를 하면 된다.&lt;/p&gt;

&lt;ul id=&quot;light-slider3&quot;&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/nsmc/Self_Attention7.png&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/nsmc/Self_Attention8.png&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/nsmc/Self_Attention9.png&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;penalization-term&quot;&gt;Penalization Term&lt;/h3&gt;

&lt;p&gt;임베딩된 매트릭스 $M$ 은 $r$ hops 동안 계속해서 같은 유사도 벡터 $a$ 를 곱하게 되면 &lt;strong&gt;중복 문제(redundancy problems)&lt;/strong&gt; 가 생길 수 있다. 즉, 같은 단어 혹은 구문만 계속해서 attention 하게 되는 문제다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/nsmc/penal.png&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;그림: 왼쪽(a)은 패널티를 안준 것, 오른쪽(b) 는 준것&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;따라서, $r$ hops 동안 weight 벡터들의 합을 다양성을 높히는 일종의 패널티를 줘야한다.&lt;/p&gt;

&lt;p&gt;제일 좋은 방법은 $r$ hops 안에 있는 아무 두 벡터 간의 &lt;strong&gt;&lt;a href=&quot;https://ko.wikipedia.org/wiki/%EC%BF%A8%EB%B0%B1-%EB%9D%BC%EC%9D%B4%EB%B8%94%EB%9F%AC_%EB%B0%9C%EC%82%B0&quot;&gt;쿨백-라이블러 발산 (Kullback–Leibler divergence)&lt;/a&gt;&lt;/strong&gt; 함수를 쓰는 것이다. 매트릭스 $A$ 의 각각의 행(row) 벡터들이 하나의 의미(semantic)를 가지는 단어 혹은 구문이 될 확률분포이기 때문에, 다양한 분포에서 나오는 것은 우리의 목적이 된다. (문장은 여러 단어/구문으로 구성되어 있기때문) 그러므로 KL divergence 값을 &lt;strong&gt;최대&lt;/strong&gt; 로 만들면 중복 문제는 해결된다.&lt;/p&gt;

&lt;p&gt;그러나 논문에서는 위와 같은 경우에 불안정(unstable) 한다는 것을 알아냈다. 논문 저자들은 어림짐작해 보았을 때, KL divergence 를 최대화 할때(보통의 경우 KLD를 최소화 하는 것을 한다.), 매트릭스 $A$ 구하는 단계에서 softmax 시 많은 값들이 0 이거나 아주 작은 값이라서 불안정한 학습을 야기했을 가능성이 있다는 것이다.&lt;/p&gt;

&lt;p&gt;따라서, 논문에서는 매트릭스의 &lt;strong&gt;&lt;a href=&quot;http://mathworld.wolfram.com/FrobeniusNorm.html&quot;&gt;Frobenius norm&lt;/a&gt;&lt;/strong&gt; 을 쓰게 되는데 아래와 같다. ($Norm_2$와 비슷해 보이지만 다르다)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P ={ {\|AA^T - I\|}_F}^2&lt;/script&gt;

&lt;p&gt;이 패널티 값과 기존의 Loss 와 같이 최소화 하는 방향으로 간다. 이 패널티의 뜻은 무엇일까?&lt;/p&gt;

&lt;p&gt;두 개의 다른 유사도 벡터의 합 $a^{i}$ 과 $a^{j}$ 를 생각해보자. Softmax 로 인해서 모든 $a$ 값들의 합은 1이 될 것이다. 따라서 이들을 일종의 이산 확률분포 (discrete probability distribution)에서 나오는 확률질량 함수로 간주할 수 있다.&lt;/p&gt;

&lt;p&gt;매트릭스 $AA^T$ 중, 모든 비대각 $a_{ij}\ (i \neq j)$ 원소에 대해서, 원소의 곱(elementary product)은 아래 두개의 분포를 가지고 있다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
0&lt; a_{ij} = \sum_{k=1}^{n} a_k^i a_k^j &lt;1 %]]&gt;&lt;/script&gt;

&lt;p&gt;여기서 $a_k^i, a_k^j$ 는 각각 $a^i, a^j$ 의 k 번째 원소다. 제일 극단적인 경우를 생각해보면, $a^i$ 와 $a^j$ 가 일치하지 않다면 (혹은 다른 분포를 나타내고 있다면) 0 이 되고, 완전이 일치해서 같은 단어 혹은 구문을 이야기 하고 있다면 (혹은 같은 분포를 나타내고 있다면) 1 에서 최대값을 가지게 될 것이다.&lt;/p&gt;

&lt;p&gt;따라서, $AA^T$ 의 대각 행렬(같은 단어 혹은 구문)을 대략 1 이 되게 강제한다. $I$ (Identity) 매트릭스를 빼줌으로써 달성하는데, 이는 자기 자신을 제외한 각기 다른 $a^i$ 간 원소들의 합인 $a_{ij}$ 들이 0 으로 최소화되게 만들어 버린다. 즉, 최대한 $a^i$ 간의 분포가 일치하지 않게 만드려고 노력하는 것이다. 이렇게 함으로써 $r$ 번의 hops 마다 각각 다른 단어에 집중하게 만드는 효과를 낼 수 있어서, 중복문제를 해결 할 수가 있다.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;네이버 영화 리뷰 테스트 결과 및 시각화&lt;/h2&gt;
&lt;p&gt;총 150000 개의 Train Set과 50000 개의 Test Set 으로 진행했고, 모델에서는 hyperparameter가 많기 때문에 몇 가지 실험을 진행 했다.&lt;/p&gt;

&lt;p&gt;간단한 실험을 위해서 사전에 단어들을 word2vec 으로 학습시키지 않고, mecab 으로 tokenizing 만해서 임베딩 시켰다. (실험을 안해봐서 사실 크게 상관있나 모르겠다. 나중에 여러가지로 실험해볼 예정)&lt;/p&gt;

&lt;p&gt;내가 주로 건드린건 LSTM 에서의 &lt;strong&gt;hidden layer의 갯수&lt;/strong&gt; 와 hops 인 &lt;strong&gt;$r$&lt;/strong&gt; 을 바꾸어 보았다.&lt;/p&gt;

&lt;h3 id=&quot;model-1-1--hidden-layer--5-hops&quot;&gt;model 1: 1 개의 Hidden Layer 와 5번의 hops&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/nsmc/model_1.png&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;model-2-1--hidden-layer--20-hops&quot;&gt;model 2: 1 개의 Hidden Layer 와 20번의 hops&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/nsmc/model_2.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;hops 가 많아지면 긍정/부정을 판단하게 되는 근거도 많아지고, 모델의 정확도도 향상되는 것을 2번에서 볼 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;model-3-3--hidden-layer--5-hops&quot;&gt;model 3: 3 개의 Hidden Layer 와 5번의 hops&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/nsmc/model_3.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;3번째 모델은 조금 이상하다고 느껴진 것이 있다. 그림을 보면 기계가 문장의 앞뒤만 보고 리뷰가 긍정인지 부정인지 판단했다는 것이다. 그림만 보면 과최적화된 느낌? 정확히 각 층의 layer 값을 보지는 못했지만, 층이 깊어 질 수록 기계가 이전 단계의 layer 에서 추출한 특징들로 학습해서 긍부정을 판단 했을 가능성이 있다. 점수는 높게 나왔으나 사람이 판단하기에는 부적절한 모델&lt;/p&gt;

&lt;h2 id=&quot;section-3&quot;&gt;향후 해볼 수 있는 과제들&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;전처리 단계에서 임베딩시 다양한 임베딩을 해볼 수 있을 것 같다. 예를 들어 word2vec으로 미리 선학습 후에 만든다던지, 아니면 N-hot 인코딩 (단어 원형 + 품사 + 어미) 등등 시도해볼 수 있는 것은 많다.&lt;/li&gt;
  &lt;li&gt;LSTM Cell 로 구현&lt;/li&gt;
  &lt;li&gt;이와 연관은 좀 덜하지만, CNN으로 분류하는 것과 비교해 성능이 더 잘나올지? &lt;strong&gt;김윤&lt;/strong&gt; 님의 논문 참고 : &lt;a href=&quot;http://emnlp2014.org/papers/pdf/EMNLP2014181.pdf&quot;&gt;링크 &lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;
&lt;p&gt;공부에 도움 주신 분들 및 공부에 도움 되었던 싸이트:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;김성동님: https://github.com/DSKSD&lt;/li&gt;
  &lt;li&gt;같은 논문을 Tensorflow로 구현하신 flrngel님: https://github.com/flrngel/Self-Attentive-tensorflow&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;감사합니다.&lt;/p&gt;
</description>
        <pubDate>Wed, 04 Apr 2018 01:01:13 +0900</pubDate>
        <link>http://simonjisu.github.io/datascience/2018/04/04/nsmcbidreclstmselfattn.html</link>
        <guid isPermaLink="true">http://simonjisu.github.io/datascience/2018/04/04/nsmcbidreclstmselfattn.html</guid>
        
        
        <category>DataScience</category>
        
      </item>
    
      <item>
        <title>Naver AI Colloquium 2018</title>
        <description>&lt;h1 id=&quot;naver-ai-colloquium-2018--&quot;&gt;Naver AI Colloquium 2018 참석 후기&lt;/h1&gt;
&lt;p&gt;&lt;del&gt;+ 클로바스피커 후기&lt;/del&gt;&lt;/p&gt;
&lt;h2 id=&quot;section&quot;&gt;개요&lt;/h2&gt;

&lt;ul id=&quot;light-slider1&quot;&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/naveraicol/logo.png&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/naveraicol/ment1.png&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/naveraicol/ment2.png&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/naveraicol/ment3.png&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;출처: &lt;a href=&quot;http://naveraiconf.naver.com/&quot;&gt;네이버 AI 콜로키움&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;운 좋게 기회가 되서 &lt;a href=&quot;http://naveraiconf.naver.com/&quot;&gt;&lt;strong&gt;Naver AI Colloquium 2018&lt;/strong&gt;&lt;/a&gt; 에 다녀왔다.
싸이트에 접속해서 프로그램 표를 자세히 보면 알겠지만, 이번 콜로키움에서는 크게 4가지 주제를 다뤘다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;언어 분야(Search &amp;amp; Natural Language)&lt;/li&gt;
  &lt;li&gt;비전 분야(Computer Vision, Mobility&amp;amp;Location Intelligence)&lt;/li&gt;
  &lt;li&gt;추천 분야(Recommendation)&lt;/li&gt;
  &lt;li&gt;데이터 엔지니어 분야(AI Algorithm, System&amp;amp;Platform)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;나는 언어 분야, 즉 자연어을 다루는 쪽에 관심이 많아서 Track A 만 거의 듣고, 추천 분야 하나 정도 들었다. 각 강의에서 다루는 내용은 차후 하나씩 정리해서 올릴 예정이다.&lt;/p&gt;

&lt;h2 id=&quot;section-1&quot;&gt;후기&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/naveraicol/professorsungkim.JPG&quot; /&gt;&lt;/p&gt;

&lt;p&gt;“모두의 딥러닝”으로 유명하신 Sung Kim 교수님!! (문제가 되면 사진 내리겠습니다~ 댓글 달아주세요)&lt;/p&gt;

&lt;p&gt;인상 깊었던 세션과 그 이유를 몇개 꼽자면, &lt;del&gt;어쩌다보니 다 네이버 직원분들이 발표하신거네ㅎㅎ&lt;/del&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Semantic Matching Model - 김선훈 (NAVER)
시멘틱 매칭의 필요성:
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;키워드(단어기반)&lt;/strong&gt; 매칭보다는 &lt;strong&gt;시멘틱(의미기반)&lt;/strong&gt; 매칭이 다양한 표현과 오타를 커버할 수 있는 가능성이 높다.&lt;/li&gt;
      &lt;li&gt;Sementic Gap: 인간이해와 기계이해의 차이, 이것을 줄이는게 큰 과제&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Neural Speed Reading - 서민준 (NAVER)
    &lt;ul&gt;
      &lt;li&gt;Skim-RNN: “속독”에서 나온 아이디어, 중요하지 않은 단어는 적게 업데이트!&lt;/li&gt;
      &lt;li&gt;Big RNN 과 Small RNN 의 결정 짓는 Decision Function&lt;/li&gt;
      &lt;li&gt;Layer를 쌓으면 중요한 정보를 캐치 (마치 글을 두번째 읽을 때는 주요 단어만 보게 되는 것과 같음)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Hybrid Natural Language Understanding 모델 - 김경덕 (NAVER)
    &lt;ul&gt;
      &lt;li&gt;문제 정의의 중요성: 잘해야 문제를 해결하기 쉽고 명확하다.&lt;/li&gt;
      &lt;li&gt;팬턴 기반 검색 NLU + 데이터 통계 기반 NLU, 뭐든지 하나만 고르는 것은 아니다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;자기학습 기반 챗봇(발표세션은 아님)
    &lt;ul&gt;
      &lt;li&gt;챗봇의 전체 과정:
  Query $\rightarrow$ 언어적 특징 추출 $\rightarrow$ 쿼리 분류기(대화여부 및 도메인 인지) $\rightarrow$ 여러 모델로 부터 답변 생성 $\rightarrow$ Answer&lt;/li&gt;
      &lt;li&gt;N-hot representation: 토큰원형 + 품사태깅 + 어미&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;이 정도인 것 같다.&lt;/p&gt;

&lt;h2 id=&quot;section-2&quot;&gt;클로바 스피커(프렌즈) 후기&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/naveraicol/speaker.jpeg&quot; /&gt;&lt;/p&gt;

&lt;p&gt;어쩌다 운좋게 경품에 당첨 되서 받았다. ㅎㅎㅎ 감사합니다.
이놈…생각보다 귀엽다. 아직까지 일본의 프렌즈보다 기능이 덜 있는 것 같다. 라인으로 메세지 보내는 기능 시도해보았는데, 안되드라…&lt;/p&gt;

&lt;p&gt;영상링크: &lt;a href=&quot;https://youtu.be/lK-9yDoHsZ8&quot;&gt;【公式】Clova Friendsができること &lt;/a&gt;&lt;/p&gt;

&lt;p&gt;아무튼 아직 개선할 사항이 많다. 예를 들어, “레미제라블 Do you hear the people sing? 노래틀어줘”라고 말하면, 말씀하신 사항을 찾지 못했다고 대답한다.
어떤 세션에서 들었던것 같은데, 내 생각에는 레미제라블, 노래틀어줘는 노래틀어주는 분야로 의도로 분류되고, 나머지 영어는 번역하는 의도로 분류된 것 같다. (스피커에 말한 내용을 볼 수 있는데, 음성인식을 진짜 제대로 잘 된다. 괜히 1위라고 말한게 아닌듯 ㅋㅋ)&lt;/p&gt;

&lt;hr /&gt;
&lt;p&gt;내년에 또 하게되면 참가하고싶다~&lt;/p&gt;

&lt;p&gt;관심 있었던 세션들을 정리하면 바로 올리겠다.&lt;/p&gt;
</description>
        <pubDate>Fri, 30 Mar 2018 20:14:21 +0900</pubDate>
        <link>http://simonjisu.github.io/naverai2018/2018/03/30/naveraicolloquium2018.html</link>
        <guid isPermaLink="true">http://simonjisu.github.io/naverai2018/2018/03/30/naveraicolloquium2018.html</guid>
        
        
        <category>NaverAI2018</category>
        
      </item>
    
      <item>
        <title>RNN &amp; LSTM - 2: Numpy with RNN</title>
        <description>&lt;h1 id=&quot;rnn--lstm----2&quot;&gt;자세하게 설명한 RNN 과 LSTM 시리즈 - 2&lt;/h1&gt;

&lt;h2 id=&quot;numpy--rnn-&quot;&gt;Numpy 로 RNN 만들어보기&lt;/h2&gt;
&lt;p&gt;모든 코드는 Github: &lt;a href=&quot;https://github.com/simonjisu/NUMPYwithNN&quot;&gt;NUMPYwithNN&lt;/a&gt; 에 올려져 있습니다.&lt;/p&gt;

&lt;p&gt;Jupyter Notebook 으로 전체과정 보기: &lt;a href=&quot;https://nbviewer.jupyter.org/github/simonjisu/NUMPYwithNN/blob/master/Notebook/Character_Predicting_RNN.ipynb&quot;&gt;링크 &lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;rnn-forward--backward--&quot;&gt;RNN Forward 와 Backward의 계산 그래프&lt;/h2&gt;

&lt;ul id=&quot;light-slider1&quot;&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/graph_forward0.png&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/graph_forward1.png&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/graph_forward2.png&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;ul id=&quot;light-slider1&quot;&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/graph_backward0.png&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/graph_backward1.png&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/graph_backward2.png&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/graph_backward3.png&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/graph_backward4.png&quot; /&gt;&lt;/li&gt;
  &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/graph_backward5.png&quot; /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;backward에서 잊지 말아야 할 부분은 $t=T$일 때(마지막 Step일 때) $d h_T$는 0으로 초기화 되며, 구해진 $d h_{t-1}^{raw}$ 가 이 다음 역전파로 들어가기 전에 이전 단계로 부터 얻은 $dh_{t-1}$ 와 더해져 계산한다는 점이다. 그 이유는 forward 시 다음 step으로 hidden 값($h_t$)을 전파하기 때문이라는 것을 잊지 말자.&lt;/p&gt;

&lt;p&gt;위 그림은 &lt;a href=&quot;https://ratsgo.github.io/natural%20language%20processing/2017/03/09/rnnlstm/&quot;&gt;ratsgo’s blog&lt;/a&gt; 님의 포스트에서 많은 참조를 하고 새로 만들었음을 밝힙니다.&lt;/p&gt;

&lt;h3 id=&quot;bptt--&quot;&gt;참고) BPTT 수식적 이해&lt;/h3&gt;
&lt;p&gt;$tanh$의 미분을 $f(x) = 1 - tanh^2(x)$ 라고 하면,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
dh_{0} = \dfrac{\partial L}{\partial h_{0}}
&amp;= \dfrac{\partial L}{\partial y_t} \dfrac{\partial y_t}{\partial h_0} + \dfrac{\partial L}{\partial y_{t-1}} \dfrac{\partial y_{t-1}}{\partial h_0} \cdots + \dfrac{\partial L}{\partial y_1} \dfrac{\partial y_1}{\partial h_0}\\
&amp;= \dfrac{\partial L}{\partial y_t} \dfrac{\partial y_t}{\partial h_t} \dfrac{\partial h_t}{\partial a_t} \dfrac{\partial a_t}{\partial h_{t-1}} \cdots \dfrac{\partial a_1}{\partial h_{0}} + \cdots +
\dfrac{\partial L}{\partial y_1} \dfrac{\partial y_1}{\partial h_1} \dfrac{\partial h_1}{\partial a_1} \dfrac{\partial a_1}{\partial h_0} \\
&amp;= W_{hy} dy_t W_{hh} f(a_t) W_{hh} f(a_{t-1}) \cdots W_{hh} f(a_1) + \cdots + W_{hy} dy_2 W_{hh} f(a_2) W_{hh} f(a_1) + W_{hy} dy_1 W_{hh} f(a_1) \\
&amp;= \sum_{i=1}^{t} \Big( dy_i W_{hy} {(W_{hh})}^{i} \prod_{j=1}^{i} f(a_j) \Big)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;위 식을 위에 있는 그림대로 그려보자, 뒤에 $W_{hh} f(a_1)$ 부처 차근차근 묶어서 아래의 식을 얻을 수 있다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\dfrac{\partial L}{\partial h_{0}}
&amp;= W_{hh} f(a_1) \bigg( W_{hy} dy_t  W_{hh} f(a_t) W_{hh} f(a_{t-1}) \cdots W_{hh} f(a_2) + \cdots + W_{hy} dy_2 W_{hh} f(a_2) + W_{hy} dy_1 \bigg) \\
&amp;= W_{hh} f(a_1) \bigg( W_{hh} f(a_2) \Big( W_{hy} dy_t W_{hh} f(a_t) W_{hh} f(a_{t-1}) \cdots W_{hh} f(a_3) + \cdots + W_{hy} dy_2 \Big) + W_{hy} dy_1 \bigg) \\
&amp;= W_{hh} f(a_1) \bigg( W_{hh} f(a_2) \Big( \cdots W_{hh} f(a_{t-1}) \big( \underbrace{W_{hh} f(a_t) (\underbrace{ W_{hy} dy_t }_{dh_t^{raw}} + 0)}_{dh_{t-1}} + \underbrace{ W_{hy} dy_{t-1} }_{dh_{t-1}^{raw}} \big) \cdots + W_{hy} dy_2 \Big) + W_{hy} dy_1 \bigg) \\
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;위에 그림과 비교해보면 이런 식으로 계속 더해진다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;backpropagation-through-time-bptt-&quot;&gt;BackPropagation Through Time (BPTT) 구현&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Single_Layer_RNN&lt;/strong&gt; 의 코드는 &lt;a href=&quot;https://github.com/simonjisu/NUMPYwithNN/blob/master/common/SimpleRNN.py&quot;&gt;여기&lt;/a&gt;에 있습니다.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Layer&lt;/strong&gt; 의 구현을 참고하려면 Github의 &lt;a href=&quot;https://github.com/simonjisu/NUMPYwithNN/blob/master/common/layers.py&quot;&gt;common/layers&lt;/a&gt; 참고하세요!&lt;/li&gt;
  &lt;li&gt;처음 Layer를 짜보시는 분은 &lt;a href=&quot;https://simonjisu.github.io/deeplearning/2017/12/07/numpywithnn_1.html&quot;&gt;Numpy로 짜보는 Neural Network Basic&lt;/a&gt; 시리즈를 참고하세요!&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;우선 미분한 값의 합을 구하기 위해 각각 Layer의 파라미터와같은 형태(shape)로 만들어 준다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def _params_summation_init(self):
    self.params_summ = {}
    self.params_summ['W_xh'] = np.zeros_like(self.params['W_xh'])
    self.params_summ['W_hh'] = np.zeros_like(self.params['W_hh'])
    self.params_summ['W_hy'] = np.zeros_like(self.params['W_hy'])
    self.params_summ['b_h'] = np.zeros_like(self.params['b_h'])
    self.params_summ['b_y'] = np.zeros_like(self.params['b_y'])
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;또한, $dh_T$ 를 0으로 초기화 한다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;dht = np.zeros_like(self.h0)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;그후에 총 길이 $T$의 역순으로 각 Layer 의 Back Propagation 을 진행한다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;for t in np.arange(self.T)[::-1]:
    dout = self.last_layers[t].backward()
    dht_raw = self.layers['Affine_hy'][t].backward(dout)
    dat = self.layers['Activation'][t].backward(dht_raw + dht)
    dht = self.layers['Affine_hh'][t].backward(dat)
    dx = self.layers['Affine_xh'][t].backward(dat)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;또한, 파라미터 $W$ 와 $b$ 의 합도 같이 구해준다. 그 이유는 전편에서 설명되어 있지만, 다시 한번 이야기 하자면, 최종 Loss Function은 각 Output Loss의 평균이기 때문에, 각 Output 마다 파라미터들을 summation 하는 과정이 있다. (평균을 구할때 우선 summation을 한다는 것을 잊지 말자.)&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;self.params_summ['W_xh'] += self.layers['Affine_xh'][t].dW
self.params_summ['W_hh'] += self.layers['Affine_hh'][t].dW
self.params_summ['W_hy'] += self.layers['Affine_hy'][t].dW
self.params_summ['b_h'] += self.layers['Affine_hh'][t].db
self.params_summ['b_y'] += self.layers['Affine_hy'][t].db
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;전체 Backward 과정&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def backward(self):
    # BPTT
    self._params_summation_init()
    dht = np.zeros_like(self.h0)

    for t in np.arange(self.T)[::-1]:
        dout = self.last_layers[t].backward()
        dht_raw = self.layers['Affine_hy'][t].backward(dout)
        dat = self.layers['Activation'][t].backward(dht_raw + dht)
        dht = self.layers['Affine_hh'][t].backward(dat)
        dx = self.layers['Affine_xh'][t].backward(dat)

        self.params_summ['W_xh'] += self.layers['Affine_xh'][t].dW
        self.params_summ['W_hh'] += self.layers['Affine_hh'][t].dW
        self.params_summ['W_hy'] += self.layers['Affine_hy'][t].dW
        self.params_summ['b_h'] += self.layers['Affine_hh'][t].db
        self.params_summ['b_y'] += self.layers['Affine_hy'][t].db
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;truncate-backpropagation-through-time-t-bptt&quot;&gt;Truncate BackPropagation Through Time (T-BPTT)&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Truncate BackPropagation Through Time (T-BPTT)&lt;/strong&gt; 은 기존 BPTT 에서 과거 모든 미분값을 참조하는 대신 고정된 길이로 참조 할 수 있도록 만든 알고리즘이다.&lt;/p&gt;

&lt;p&gt;왜 이런것을 만들었을 까? BPTT 알고리즘의 미분식을 다시 생각해보자.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
dh_{0} = \dfrac{\partial L}{\partial h_{0}}
&amp;= \sum_{i=1}^{t} \Big( dy_i W_{hy} {(W_{hh})}^{i} \prod_{j=1}^{i} f(a_j) \Big)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;위에서 설명했지만, BPTT 과정에서 Time-step이 길어질 수록, 많은 양의 곱셈이 이루어 진다. 계산량을 줄이기 위해서 이런 알고리즘이 나왔을 수 있다.&lt;/p&gt;

&lt;p&gt;다른 접근 방법으로, 학습하고 싶은 Sequence의 일정 길이만큼만 과거를 참조하고 싶기 때문일 수도 있다.&lt;/p&gt;

&lt;p&gt;예를 들어 “I live in Seoul. (중략) I am Korean.” 이라는 문장을 생각해보자. 학습 데이터는 아래와 같을 것이다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[&quot;I&quot;, &quot;live&quot;, &quot;in&quot;, &quot;Seoul&quot;, &quot;.&quot;, (중략), &quot;I&quot;, &quot;am&quot;, &quot;Korean&quot;, &quot;.&quot;]
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Forward 할때는 순차적으로 들어갈텐데, Backward 할때는 데이터의 역순으로(“.”, “Korean”) 진행될 것이다. 그러나 내가 한국인이라는 것은 내가 서울에 살고 있기 때문인데, 굳이 앞단의 “I”, “live”, “in” 까지 참조할 필요는 없는 것이다. 그렇다면 위에 식은 아래와 같이 변할 것이다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
dh_{0} = \dfrac{\partial L}{\partial h_{0}}
&amp;= \sum_{i=1}^{t} \Big( dy_i W_{hy} {(W_{hh})}^{k} \prod_{j=k}^{t} f(a_j) \Big) \\
where \quad k &amp;= \max(1, t - truncate)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;h3 id=&quot;t-bptt-&quot;&gt;T-BPTT 구현&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;/assets/ML/rnn/normal_truncate.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그림 출처: &lt;a href=&quot;https://r2rt.com/styles-of-truncated-backpropagation.html&quot;&gt;r2rt.com&lt;/a&gt;&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def backward_truncate(self):
    # TBPTT
    self._params_summation_init()
    dht = np.zeros_like(self.h0)

    for t in np.arange(self.T)[::-1]:
        dout = self.last_layers[t].backward()
        dht_raw = self.layers['Affine_hy'][t].backward(dout)
        self.params_summ['W_hy'] += self.layers['Affine_hy'][t].dW
        self.params_summ['b_y'] += self.layers['Affine_hy'][t].db

        for bptt_step in np.arange(max(0, t + 1 - self.bptt_truncate), t + 1)[::-1]:
            dat = self.layers['Activation'][bptt_step].backward(dht_raw + dht)
            dht = self.layers['Affine_hh'][bptt_step].backward(dat)  # dh_t-1
            dx = self.layers['Affine_xh'][bptt_step].backward(dat)  # dx
            self.params_summ['W_xh'] += self.layers['Affine_xh'][bptt_step].dW
            self.params_summ['W_hh'] += self.layers['Affine_hh'][bptt_step].dW
            self.params_summ['b_h'] += self.layers['Affine_hh'][bptt_step].db
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;그러나 Tensorflow 에서는 아래와 같이 구현한다고 한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/rnn/tensorflow_truncate.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그림 출처: &lt;a href=&quot;https://r2rt.com/styles-of-truncated-backpropagation.html&quot;&gt;r2rt.com&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;실습&lt;/h2&gt;

&lt;h3 id=&quot;section-1&quot;&gt;목적&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;“hello world! nice to meet you! i love iron-man”&lt;/strong&gt; 을 RNN 으로 학습시키기.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Input&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt; &lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Output&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;h&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;→&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;e&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;e&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;→&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;l&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;l&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;→&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;l&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;l&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;→&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;o&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;⋮&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;⋮&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;⋮&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;m&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;→&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;a&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;a&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;→&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;n&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;section-2&quot;&gt;데이터 및 우리가 만든 패키지 준비&lt;/h3&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import numpy as np
from common.SimpleRNN import Single_layer_RNN
from common.optimizer import Adam
from common.train_graph import loss_graph
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;x = 'hello world! nice to meet you! i love iron-man'
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;인코딩 클래스 하나를 만들어서 문자열을 one-hot 인코딩 해준다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;class chr_coding(object):
    def __init__(self):
        self._dict = None
        self._one_hot_matrix = None
        self._dict_reversed = None

    def fit(self, x):
        if isinstance(x, str):
            x = list(x)

        self._one_hot_matrix = np.eye(len(set(x)))
        self._dict = {d: i for i, d in enumerate(list(set(x)))}
        self._dict_reversed = {v: k for k, v in self._dict.items()}

    def encode(self, x):
        encoded_data = np.array([self._one_hot_matrix[self._dict[d]] for d in x])
        return encoded_data

    def decode(self, x, probs=None):
        if probs is None:
            decoded_data = self._dict_reversed[x]
        else:
            decoded_data = self._dict_reversed[np.argmax(probs)]
        return decoded_data
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;encoder = chr_coding()
encoder.fit(x)
one_hot_data = encoder.encode(x)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;학습 데이터 x, y를 지정해준다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;train_x = one_hot_data[:-1]
train_y = one_hot_data[1:]
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;hyperparameters&quot;&gt;hyperparameters&lt;/h3&gt;

&lt;p&gt;INPUT_SIZE 와 OUTPUT_SIZE 는 중복되지 않는 문자열 사전의 길이라는 것을 잊지 말자.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;NUM_EPOCHS = 600
PRINT_EPOCH = 30
INPUT_SIZE = one_hot_data.shape[1]
OUTPUT_SIZE = one_hot_data.shape[1]
HIDDEN_SIZE = 20
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;accuracy--train-&quot;&gt;필요한 함수 설정: accuracy 와 train 함수&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def get_accuracy(x, test_string):
    bool_ = np.array(list(x))[1:] == np.array(list(test_string))[1:]
    return bool_.sum() / len(bool_)

def train(rnn, optim, print_epoch=20):
    total_loss_list = []
    total_acc_list = []
    for epoch in range(NUM_EPOCHS):
        test_string = 'h'
        # forward
        total_loss = rnn.loss(train_x, train_y)

        # backward
        rnn.backward()

        optim.update(rnn.params, rnn.params_summ)

        # test string
        predicted_idx = rnn.predict(train_x)
        for idx in predicted_idx:
            test_string += encoder.decode(idx)

        # get accuracy
        acc = get_accuracy(x, test_string)

        if epoch % print_epoch == 0:
            print('#{0}, Loss: {1:.6f}, Acc: {2:.6f}, Test_string: &quot;{3}&quot;'\
                  .format(epoch, total_loss, acc, test_string))
        elif epoch == (NUM_EPOCHS-1):
            print('#{0}, Loss: {1:.6f}, Acc: {2:.6f}, Test_string: &quot;{3}&quot;'\
                  .format(epoch, total_loss, acc, test_string))

        total_loss_list.append(total_loss)
        total_acc_list.append(acc)
    return total_loss_list, total_acc_list
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;section-3&quot;&gt;학습하기&lt;/h3&gt;

&lt;p&gt;rnn 모델을 만들고, 어떤 방식으로 업데이트 할 것인지 정하자. 여기서는 Adam을 썼다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Optimizer&lt;/strong&gt; 의 설명은 &lt;a href=&quot;https://github.com/simonjisu/NUMPYwithNN/blob/master/common/SimpleRNN.py&quot;&gt;Numpy로 짜보는 Neural Network Basic - 5&lt;/a&gt;에 있습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;rnn = Single_layer_RNN(input_size=INPUT_SIZE,
                       hidden_size=HIDDEN_SIZE,
                       output_size=OUTPUT_SIZE)
optim = Adam()
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;학습시키기!&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;total_loss_list, total_acc_list = train(rnn, optim, print_epoch=PRINT_EPOCH)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/assets/ML/rnn/rnn_bptt.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Loss Graph 도 찍어보자&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;loss_graph(train_loss_list=total_loss_list, train_acc_list=total_acc_list)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/rnn/rnn_bptt_loss.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section-4&quot;&gt;공부에 도움 되었던 싸이트:&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://gist.github.com/karpathy/d4dee566867f8291f086&quot;&gt;karpathy github RNN part&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://ratsgo.github.io/natural%20language%20processing/2017/03/09/rnnlstm/&quot;&gt;ratsgo’s blog&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Wed, 14 Mar 2018 22:05:37 +0900</pubDate>
        <link>http://simonjisu.github.io/deeplearning/2018/03/14/rnnlstm2.html</link>
        <guid isPermaLink="true">http://simonjisu.github.io/deeplearning/2018/03/14/rnnlstm2.html</guid>
        
        
        <category>DeepLearning</category>
        
      </item>
    
      <item>
        <title>RNN &amp; LSTM - 1: RNN</title>
        <description>&lt;h1 id=&quot;rnn--lstm----1&quot;&gt;자세하게 설명한 RNN 과 LSTM 시리즈 - 1&lt;/h1&gt;

&lt;h2 id=&quot;rnnrecurrent-neural-network&quot;&gt;RNN(Recurrent Neural Network)&lt;/h2&gt;
&lt;p&gt;우리가 사는 세상에 연속된 일들, 혹은 시간과 연관된 일은 매우매우 많을 것이다. 예를 들자면, 지금 이 글을 읽은 당신도 앞에 있는 내용을 기억하면서 글을 읽고 있을 것이다. 일반적인 신경망 구조에서는 이 ‘기억’ 이라는 시스템이 존재 하지 않는다. 하지만 RNN은 다르다. 이놈은 ‘기억’을 할 수가 있다. 그렇다면 RNN과 기존 신경망과 어떻게 다른지를 한번 살펴보자.&lt;/p&gt;

&lt;h2 id=&quot;rnn-&quot;&gt;RNN 구조&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;/assets/ML/rnn/rnn.png&quot; alt=&quot;Drawing&quot; style=&quot;width=500px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;RNN은 중간의 Hidden 층이 순환한다고해서 순환 신경망이라고 한다. 왼쪽의 구조를 펼쳐서 보면, 중간의 Hidden 노드가 어떤 방향으로 계속 이어진 다는 것을 알 수 있다. 이러한 쇠사슬 같은 성격은 RNN으로 하여금 연속된 이벤트와 리스트에 적합한 구조로 만들어 준다.&lt;/p&gt;

&lt;p&gt;이렇게 보면 엄청 어렵게 느껴질 수 있다. 그렇다면 예시를 들어서 RNN이 어떻게 돌아가는지 수학적으로 살펴보자.&lt;/p&gt;

&lt;h3 id=&quot;section&quot;&gt;기본 신경망 구조&lt;/h3&gt;

&lt;p&gt;기존의 신경 구조를 한번 다시 되새겨보자.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/rnn/stick.png&quot; alt=&quot;Drawing&quot; height=&quot;200&quot; width=&quot;200&quot; /&gt;&lt;/p&gt;

&lt;p&gt;여러개의 노드로 구성된 작은 블럭을 하나의 층이라고 가정하자. 기존의 신경망 구조는 아래와 같다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/rnn/basic_nn_mnist.png&quot; alt=&quot;Drawing&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Input $x$ 가 선형 결합 후, Hidden 에 Activation function을 거쳐 다시 선형결합을 통해 Output $y$를 구해 예측하는 알고리즘이다. 여기서 첫번째 데이터($x_1$)와 그 다음 데이터($x_2$ 등)간의 구조는 독립적이라고 할 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;forward&quot;&gt;Forward&lt;/h3&gt;
&lt;p&gt;예시로 time step($T$)이 3인 RNN을 살펴보자. (좌우 클릭으로 프로세스 과정 볼 수 있다)&lt;/p&gt;

&lt;ul id=&quot;light-slider1&quot;&gt;
    &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/rnn_0.png&quot; /&gt;&lt;/li&gt;
    &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/rnn_1.png&quot; /&gt;&lt;/li&gt;
    &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/rnn_2.png&quot; /&gt;&lt;/li&gt;
    &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/rnn_3.png&quot; /&gt;&lt;/li&gt;
    &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/rnn_4.png&quot; /&gt;&lt;/li&gt;
    &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/rnn_5.png&quot; /&gt;&lt;/li&gt;
    &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/rnn_6.png&quot; /&gt;&lt;/li&gt;
    &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/rnn_7.png&quot; /&gt;&lt;/li&gt;
    &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/rnn_8.png&quot; /&gt;&lt;/li&gt;
  &lt;/ul&gt;

&lt;p&gt;Time step = 0 일때, 각각 Layer들의 Weight를 초기화하게 된다. $h_0$ 층은 0으로, 나머지는 Xavier 가중치 초기값으로 초기화한다. 또한 각 가중치는 각각 layer에서 공유하게 된다.
(가중치 초기화를 잊어 버렸다면 &lt;a href=&quot;https://simonjisu.github.io/datascience/2018/01/24/numpywithnn_6.html&quot;&gt;여기&lt;/a&gt;로)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
h_t &amp;= \tanh(W_{hh} h_{t-1}+W_{xh}x_t+b_h) \\
y_t &amp;= W_{hy} h_t + b_y
\end{aligned}
\quad for\ t\ in\ T %]]&gt;&lt;/script&gt;

&lt;p&gt;그리고, 시간이 지날때마 위의 식 처럼 Forward가 진행된다.&lt;/p&gt;

&lt;p&gt;최종 Cost는 모든 Cost Function의 평균으로 구해진다.&lt;/p&gt;

&lt;h3 id=&quot;backward&quot;&gt;Backward&lt;/h3&gt;
&lt;p&gt;RNN에서는 일반적인 신경망과 다른 Backward 알고리즘을 쓴다. 시간 경과에 따른 BackPropagation을 BPTT(BackPropagation Through Time)이라고 부른다.&lt;/p&gt;

&lt;ul id=&quot;light-slider1&quot;&gt;
    &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/rnn_back0.png&quot; /&gt;&lt;/li&gt;
    &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/rnn_back1.png&quot; /&gt;&lt;/li&gt;
    &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/rnn_back2.png&quot; /&gt;&lt;/li&gt;
    &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/rnn_back3.png&quot; /&gt;&lt;/li&gt;
    &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/rnn_back4.png&quot; /&gt;&lt;/li&gt;
    &lt;li&gt;&lt;img src=&quot;/assets/ML/rnn/rnn_back5.png&quot; /&gt;&lt;/li&gt;
  &lt;/ul&gt;

&lt;p&gt;최종적으로 학습 될 값은 Loss Function에서 각 미분한 ${\frac{\partial L}{\partial W}}^{(1)}$, ${\frac{\partial L}{\partial W}}^{(2)}$, ${\frac{\partial L}{\partial W}}^{(3)}$ 의 합으로 구해진다.&lt;/p&gt;

&lt;h3 id=&quot;long-term-dependency-&quot;&gt;장기 의존성(Long-Term Dependency) 문제&lt;/h3&gt;
&lt;p&gt;RNN이 이론상으로는 sequence의 첫번째 항부터 끝까지(즉, $x_1 \cdots x_T$ 까지) 학습 할 수 있을 것으로 보이나, 실제로는 장기기억, 즉 Time Step이 길어 질 수록 예전에 있던 정보를 기억 못한다. 이를 &lt;strong&gt;장기 의존성(Long-Term Dependency)&lt;/strong&gt; 문제라고 한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/rnn/rnn_bad.png&quot; alt=&quot;Drawing&quot; /&gt;&lt;/p&gt;

&lt;p&gt;그 이유는 우리가 업데이트 하려는 미분 식을 살펴보면 알 수 있다. 예를 들어 $W_{hh}$ 를 업데이트 한다고 하자.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\dfrac{\partial L}{\partial W_{hh}}  
&amp;= \dfrac{\partial L}{\partial Cost_T} \dfrac{\partial Cost_T}{\partial W_{hh}} + \cdots +
\dfrac{\partial L}{\partial Cost_1} \dfrac{\partial Cost_1}{\partial W_{hh}} \\
&amp;= \dfrac{\partial L}{\partial Cost_T} \dfrac{\partial Cost_T}{\partial y_T} \dfrac{\partial y_T}{\partial h_T} \dfrac{\partial h_T}{\partial h_{T-1}}  \cdots \dfrac{\partial h_2}{\partial h_1} \dfrac{\partial h_1}{\partial W_{hh}} +
\cdots + \dfrac{\partial L}{\partial Cost_1} \dfrac{\partial Cost_1}{\partial y_1} \dfrac{\partial y_1}{\partial h_1} \dfrac{\partial h_1}{\partial W_{hh}} \\
&amp;= \dfrac{\partial L}{\partial Cost_T} \dfrac{\partial Cost_T}{\partial y_T} \dfrac{\partial y_T}{\partial h_T} \prod_{i=1}^{T-1} \dfrac{\partial h_{T-i+1}}{\partial h_{T-i}} \dfrac{\partial h_1}{\partial W_{hh}} + \cdots + \dfrac{\partial L}{\partial Cost_1} \dfrac{\partial Cost_1}{\partial y_1} \dfrac{\partial y_1}{\partial h_1} \dfrac{\partial h_1}{\partial W_{hh}}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;위의 식중에 $\prod_{i=1}^{T-1} \dfrac{\partial h_{T-i+1}}{\partial h_{T-i}}$ 부분을 자세히 펼쳐보면 아래와 같다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\prod_{i=1}^{T-1} \dfrac{\partial h_{T-i+1}}{\partial h_{T-i}}
&amp;= \prod_{i=1}^{T-1} \dfrac{\partial h_{T-i+1}}{\partial a_{T-i+1}} \dfrac{\partial a_{T-i+1}}{\partial h_{T-i}} \\
&amp;= \prod_{i=1}^{T-1} \dfrac{\partial h_{T-i+1}}{\partial a_{T-i+1}} W_{hh}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;여기서 $a_t=W_{hh}h_{t-1} + W_{xh}x_t + b_h$ 이다.&lt;/p&gt;

&lt;p&gt;앞부분 $\frac{\partial h_{T-i+1}}{\partial a_{T-i+1}}$은 &lt;strong&gt;tanh&lt;/strong&gt; 의 미분 값이다. 아래 그림과 같이 tanh의 미분 값은 0과 1사이의 값이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/rnn/tanh.png&quot; style=&quot;width=500px&quot; /&gt;
(그림출처: http://nn.readthedocs.io/en/latest/transfer/)&lt;/p&gt;

&lt;p&gt;뒷부분인 $W_{hh}$의 값들은 세가지 경우가 있다. 1과 같게 되면 Gradient가 수렴될 가능성이 높다. 그러나 1보다 클 경우 gradient가 무한대로 발산하는 &lt;strong&gt;Exploding Gradient&lt;/strong&gt; 문제가 발생한다. 그러나 보통의 경우 $W_{hh}$ 의 값들은 1보다 작다. (아래 논문 참고)&lt;/p&gt;

&lt;p&gt;0과 1사이의 작은 값을 계속 곱하게 되면 0으로 수렴한다. 따라서, 두 가지를 종합 해보았을 때, 출력값과 멀리 떨어진 Time Step일 수록 역전파가 전달 되지 않는 &lt;strong&gt;Vanishing Gradient&lt;/strong&gt; 문제가 생기게 된다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://proceedings.mlr.press/v28/pascanu13.pdf&quot;&gt;On the difficulty of training recurrent neural networks&lt;/a&gt; 논문에서는 Vanishing &amp;amp; Exploding Gradient 문제를 자세히 다루고 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;장기기억을 하지 못한다는 문제가 생기면서, 이를 해결하기 위해서 몇 가지 방법이 나왔다. 첫째로, Activation Function을 &lt;strong&gt;tanh&lt;/strong&gt; 을 쓰면 기울기가 0과 1사이의 값으로 고정되니 &lt;strong&gt;ReLU&lt;/strong&gt; 를 쓰자는 방법이 있었다. 둘째로, &lt;strong&gt;LSTM&lt;/strong&gt;, &lt;strong&gt;GRU&lt;/strong&gt; 등 새로운 방법들이 등장했다. 이 방법은 다음 시간에 설명하겠다. 더불어 Backward 의 계산 그래프도 같이 첨부하겠다.&lt;/p&gt;
</description>
        <pubDate>Wed, 07 Mar 2018 10:46:04 +0900</pubDate>
        <link>http://simonjisu.github.io/deeplearning/2018/03/07/rnnlstm.html</link>
        <guid isPermaLink="true">http://simonjisu.github.io/deeplearning/2018/03/07/rnnlstm.html</guid>
        
        
        <category>DeepLearning</category>
        
      </item>
    
      <item>
        <title>NUMPY with NN - 8: Summary</title>
        <description>&lt;h1 id=&quot;numpy--neural-network-basic---8&quot;&gt;Numpy로 짜보는 Neural Network Basic - 8&lt;/h1&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;section&quot;&gt;총 정리&lt;/h2&gt;
&lt;p&gt;지금까지 우리는 Neural Network의 기원부터 Feedforward 과정, BackPropogation 과정, 그리고 다양한 학습 관련 기술을 배웠다. 이들을 총 정리해서 Mnist 데이터를 다시 학습 시켜보자.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/simonjisu/ML/tree/master/NeuralNetwork/common&quot;&gt; 모든 코드 링크&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;package-load&quot;&gt;Package Load&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from common.Multilayer import MLP
from dataset.mnist import load_mnist
from common.optimizer import *
import time
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;data-load&quot;&gt;Data Load&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;(x_train, y_train), (x_test, y_test) = load_mnist(normalize=True, one_hot_label=True)
print(x_train.shape)
print(y_train.shape)
print(x_test.shape)
print(y_test.shape)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;(60000, 784)&lt;br /&gt;(60000, 10)&lt;br /&gt;(10000, 784)&lt;br /&gt;(10000, 10)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;network--optimizer-settings&quot;&gt;Network &amp;amp; Optimizer settings&lt;/h3&gt;

&lt;p&gt;우리의 네트워크는 총 3층이며 Input Size가 784, Hidden node는 각각 100, 50개, Output 은 10(숫자 0~9까지의 손글씨 분류이기 때문)이다.&lt;/p&gt;

&lt;p&gt;활성화 함수는 &lt;strong&gt;ReLu&lt;/strong&gt;, 초기값도 이에 따라 &lt;strong&gt;He&lt;/strong&gt; 를 써준다. 그리고 중간에 Batch Normalization을 써준다.&lt;/p&gt;

&lt;p&gt;가중치 업데이트를 위한 옵티마이저는 &lt;strong&gt;Adam&lt;/strong&gt; 을 쓰고, Loss Function은 &lt;strong&gt;Cross Entropy&lt;/strong&gt; 를 쓰게 된다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;nn = MLP(input_size=784, hidden_size=[100, 50], output_size=10,
         activation='relu', weight_init_std='he', use_batchnorm=True)
optimizer = Adam()
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;training--test&quot;&gt;Training &amp;amp; test&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;train_loss_list = []
train_acc_list = []
test_acc_list = []
epoch_list = []

epoch_num=3000
train_size = x_train.shape[0]
batch_size = 100
epsilon = 1e-6

iter_per_epoch = max(train_size / batch_size, 1)

start = start = time.time()

for epoch in range(epoch_num):
    # get mini batch:
    batch_mask = np.random.choice(train_size, batch_size) # shuffle 효과
    x_batch = x_train[batch_mask]
    y_batch = y_train[batch_mask]

    grads = nn.gradient(x_batch, y_batch)

    optimizer.update(nn.params, grads)

    # 1에폭당 정확도 계산
    if epoch % iter_per_epoch == 0:
        loss = nn.loss(x_batch, y_batch)
        train_loss_list.append(loss)
        train_acc = nn.accuracy(x_train, y_train)
        train_acc_list.append(train_acc)
        test_acc = nn.accuracy(x_test, y_test)
        test_acc_list.append(test_acc)
        epoch_list.append(epoch)
        print('# {0} | loss: {1:.5f} | trian acc: {2:.5f} | test acc: {3:.5f}'.format(epoch, loss, train_acc, test_acc))
    elif epoch == (epoch_num - 1):
        loss = nn.loss(x_batch, y_batch)
        train_loss_list.append(loss)
        train_acc = nn.accuracy(x_train, y_train)
        train_acc_list.append(train_acc)
        test_acc = nn.accuracy(x_test, y_test)
        test_acc_list.append(test_acc)
        epoch_list.append(epoch)
        print('# {0} | loss: {1:.5f} | trian acc: {2:.5f} | test acc: {3:.5f}'.format(epoch, loss, train_acc, test_acc))

end = time.time()
print('total time:', (end - start))        
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;blockquote&gt;
  &lt;p&gt;# 0 | loss: 11.06622 | trian acc: 0.11408 | test acc: 0.11910&lt;br /&gt;# 600 | loss: 0.23165 | trian acc: 0.92055 | test acc: 0.92020&lt;br /&gt;# 1200 | loss: 0.19112 | trian acc: 0.93975 | test acc: 0.94180&lt;br /&gt;# 1800 | loss: 0.08235 | trian acc: 0.95188 | test acc: 0.95040&lt;br /&gt;# 2400 | loss: 0.09155 | trian acc: 0.95898 | test acc: 0.95600&lt;br /&gt;# 2999 | loss: 0.09883 | trian acc: 0.96513 | test acc: 0.96150&lt;br /&gt;total time: 27.169809818267822&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/nn/train_test-graph.png&quot; alt=&quot;Drawing&quot; style=&quot;width=500px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;시간은 3000 Epoch를 도는데 약 30초가 안걸렸으며, 테스트 결과도 우수하게 나오는 것으로 확인된다. CNN으로 하면 더 높아질 것으로 예상된다.&lt;/p&gt;

&lt;h3 id=&quot;model-check&quot;&gt;Model Check&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def check(x, y, model):
    pred_y = model.predict(x)
    if x.ndim != 2:
        x = x.reshape(28, 28)

    print('Predict Answer: {}'.format(np.argmax(pred_y)))
    print('Real Answer: {}'.format(np.argmax(y)))
    plt.imshow(x, cmap='binary')
    plt.grid(False)
    plt.axis('off')
    plt.show()
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;테스트 데이터중 하나 골라서 실험해보자&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;check(x_test[45], y_test[45], nn)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;Predict Answer: 5&lt;br /&gt;Real Answer: 5&lt;/p&gt;

  &lt;p&gt;&lt;img src=&quot;/assets/ML/nn/num5.png&quot; alt=&quot;Drawing&quot; height=&quot;100&quot; width=&quot;100&quot; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;
</description>
        <pubDate>Thu, 08 Feb 2018 15:13:40 +0900</pubDate>
        <link>http://simonjisu.github.io/deeplearning/2018/02/08/numpywithnn_8.html</link>
        <guid isPermaLink="true">http://simonjisu.github.io/deeplearning/2018/02/08/numpywithnn_8.html</guid>
        
        
        <category>DeepLearning</category>
        
      </item>
    
      <item>
        <title>NUMPY with NN - 7: Batch Normalization</title>
        <description>&lt;h1 id=&quot;numpy--neural-network-basic---7&quot;&gt;Numpy로 짜보는 Neural Network Basic - 7&lt;/h1&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;part-3&quot;&gt;학습관련 기술 Part 3&lt;/h2&gt;

&lt;h3 id=&quot;batch-normalization&quot;&gt;배치 정규화 (Batch Normalization)&lt;/h3&gt;
&lt;p&gt;배치 정규화란 미니배치 단위로 선형합인 &lt;strong&gt;$a$&lt;/strong&gt; 값을 정규화하는 것이다. 즉, 미니배치에 한해서 데이터 분포가 평균이 0 분산이 1이 되도록 한다. 이는 데이터 분포가 덜 치우치게 하는 효과가 있어서 가중치 초기화 값의 영향을 덜 받게한다. 또한, 학습속도를 증가시키고 regularizer 역할을 하여 Overfitting을 방지함으로 Dropout의 필요성을 줄인다. &lt;del&gt;자세한 내용은 논문을 참고하자!&lt;/del&gt;&lt;/p&gt;

&lt;p&gt;Paper: &lt;a href=&quot;https://arxiv.org/abs/1502.03167&quot;&gt;Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;기본적인 아이디어는 아래와 같다. $D$ 차원의 미니배치 데이터 $x = (x^{(1)}, \cdots, x^{(k)}, \cdots, x^{(D)})$에 대해서 각각의 평균과 분산을 구한 후, 정규화를 통해 새로운 $x^{(k)}$ ($\hat{x}^{(k)}$) 를 구한 후에 Scaling($\gamma$) 과 Shifting($\beta$)을 거쳐 새로운 $y$ 를 기존의 선형합성 곱인 $a$ 를 대신해 활성화 함수에 넣는 것이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/nn/6/batch_norm_idea.png&quot; alt=&quot;Drawing&quot; style=&quot;width=500px&quot; /&gt;&lt;/p&gt;

&lt;p&gt;따라서, 하나의 Hidden Layer 는 $Affine \rightarrow BatchNorm \rightarrow Activation$ 으로 구성된다.&lt;/p&gt;

&lt;h3 id=&quot;backpropogation-&quot;&gt;배치 정규화의 BackPropogation 이해하기&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/nn/NN_batchnorm.png&quot; alt=&quot;Drawing&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;forward&quot;&gt;Forward:&lt;/h4&gt;

&lt;p&gt;x 부터 out 까지 차근차근 진행해보자. 헷갈리지 말아야할 점은 위에 공식에서 $i$ 는 batch를 iteration 한 것이라는 점이다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;## Forward Process
# step-1: mu (D,)
mu = x.mean(axis=0)
# step-2: xmu (N, D)
xmu = x - mu
# step-3: sq (N, D)
sq = xmu**2
# step-4: var (D,)
var = np.mean(sq, axis=0)
# step-5: std (D,)
std = np.sqrt(var + 1e-6)
# step-6: invstd (D,)
invstd = 1.0 / std
# step-7: xhat (N, D)
xhat = xmu * invstd
# step-8: scale (N, D)
scale = gamma * xhat
# step-9: out (N, D)
out = scale + beta
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;backward&quot;&gt;Backward:&lt;/h4&gt;

&lt;p&gt;우리의 목표는 $\dfrac{\partial L}{\partial x}, \dfrac{\partial L}{\partial \gamma}, \dfrac{\partial L}{\partial \beta}$ 를 구해서, $\dfrac{\partial L}{\partial x}$ 는 Affine Layer로 역전파 시키고 $\gamma, \beta$ 는 학습 시키는 것이다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step-9:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Forward : $out(scale, \beta) = scale + \beta$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;더하기 노드의 역전파는 그대로 흘러간다.&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{cases} dscale = \dfrac{\partial L}{\partial scale} = \dfrac{\partial L}{\partial out} \dfrac{\partial out}{\partial scale} = 1 * dout \\
\\
d\beta = \dfrac{\partial L}{\partial \beta} = \dfrac{\partial L}{\partial out} \dfrac{\partial out}{\partial \beta} = 1 * \sum_i^N dout \end{cases}&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Step-8:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Forward : $scale(\gamma, \hat{x}_i) = \gamma \ * \ \hat{x}_i$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;곱의 노드의 역전파는 들어왔던 신호를 역으로 곱해서 흘려 보낸다.&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{cases}
d\hat{x}_i = \dfrac{\partial L}{\partial \hat{x}_i} = \dfrac{\partial L}{\partial scale} \dfrac{\partial scale}{\partial \hat{x}_i} = 1 * \sum_i^N dout \\
\\
d\gamma = \dfrac{\partial L}{\partial \gamma} = \dfrac{\partial L}{\partial scale} \dfrac{\partial scale}{\partial \gamma} = \sum_i^N dout \ * \ \hat{x}_i
\end{cases}&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Step-7:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Forward : $\hat{x}_i(xmu, invstd) = xmu \ * \ invstd$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$xmu$는 윗쪽(step-7 $\rightarrow$ step-2)과 아래쪽(step-3 $\rightarrow$ step-2) 으로 두 번 돌아가기 때문에 첨자를 단다.&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{cases}
dxmu_1= \dfrac{\partial L}{\partial xmu_1} = \dfrac{\partial L}{\partial \hat{x}_i} \dfrac{\partial \hat{x}_i}{\partial xmu_1} = d\hat{x}_i \ * \ invstd \\
\\
dinvstd = \dfrac{\partial L}{\partial \hat{x}_i} = \dfrac{\partial L}{\partial \hat{x}_i} \dfrac{\partial \hat{x}_i}{\partial invstd} = d\hat{x}_i \ * \ xmu
\end{cases}&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Step-6:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Forward : $invstd(\sigma) = \dfrac{1}{\sigma}$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$f(x) = \dfrac{1}{x}$ 의 미분은 $f’(x) = -\dfrac{1}{x^2} = -f(x)^2$ 이기 때문에 아래와 같다.&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;d\sigma = \dfrac{\partial L}{\partial \sigma} = \dfrac{\partial L}{\partial invstd} \dfrac{\partial invstd}{\partial \sigma} = dinvstd \ * \ (-invstd^2)&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Step-5:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Forward : $\sigma(var) = \sqrt{var + \epsilon}$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$f(x) = \sqrt{x + \epsilon}$ 의 미분은 $f’(x) = -\dfrac{1}{2}(x+\epsilon)^{-\frac{1}{2}}$ 이기 때문에 아래와 같다.&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;dvar = \dfrac{\partial L}{\partial var} = \dfrac{\partial L}{\partial \sigma} \dfrac{\partial \sigma}{\partial var} = d\sigma \ * \ (-\dfrac{1}{2}(var+\epsilon)^{-\frac{1}{2}})&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Step-4:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Forward : $var(sq) = \dfrac{1}{N} \sum_i^N sq$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$f(x) = \dfrac{1}{N} \sum_i^N x_i$ 의 미분은 $f’(x) = \dfrac{1}{N} \sum_i^N 1$ 이기 때문에 아래와 같다. 단, x의 형상(shape)이 같아야한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
dsq = \dfrac{\partial L}{\partial sq} = \dfrac{\partial L}{\partial var} \dfrac{\partial var}{\partial sq} = \dfrac{1}{N} dvar \ * \ \begin{bmatrix} 1 &amp; \cdots &amp; 1 \\ \vdots &amp; \ddots &amp; \vdots \\ 1 &amp; \cdots &amp; 1 \end{bmatrix}_{(N, D)} = \dfrac{1}{N} dvar \ * \ ones(N, D) %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Step-3:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Forward : $sq = xmu^2$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$f(x) = x^2$ 의 미분은 $f’(x) = 2x$ 이기 때문에 아래와 같다.&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;dxmu_2 = \dfrac{\partial L}{\partial xmu_2} = \dfrac{\partial L}{\partial sq} \dfrac{\partial sq}{\partial xmu_2} = dsq \ * \ 2 \ xmu&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Step-2:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Forward : $xmu = x_i - \mu$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$dxmu = dxmu_1 + dxmu_2$ 로 정의 된다. 곱의 미분 법칙 생각해보면 된다. $h(x) = f(x) g(x)$ 를 $x$ 에 대해서 미분하면 $f’(x)g(x) + f(x)g’(x)$ 기 때문이다. &lt;br /&gt;
또한 이것도 덧셈과 마찬가지로 그대로 흘러 보내는다 밑에 쪽은 -1 을 곱해서 흘려 보낸다.&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{cases}
dx_1= \dfrac{\partial L}{\partial x_1} = \dfrac{\partial L}{\partial xmu} \dfrac{\partial xmu}{\partial x_1} = dmu \ * \ 1 \\
\\
d\mu = \dfrac{\partial L}{\partial \mu} = \dfrac{\partial L}{\partial xmu} \dfrac{\partial xmu}{\partial \mu} = \sum_i^N dxmu \ * \ (-1)
\end{cases}&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Step-1:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Forward : $\mu = \dfrac{1}{N} \sum_i^N x_i$&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;step-4에서 설명했다.&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
dx_2 = \dfrac{\partial L}{\partial x_2} = \dfrac{\partial L}{\partial \mu} \dfrac{\partial \mu}{\partial x_2} = \dfrac{1}{N} d\mu \ * \ \begin{bmatrix} 1 &amp; \cdots &amp; 1 \\ \vdots &amp; \ddots &amp; \vdots \\ 1 &amp; \cdots &amp; 1 \end{bmatrix}_{(N, D)} = \dfrac{1}{N} d\mu \ * \ ones(N, D) %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;Step-0:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;최종적으로 구하는 $dx = \dfrac{\partial L}{\partial x} = dx_1 + dx_2$ 로 정의 된다.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;## Backward Process
# step-9: out = scale + beta
dbeta = dout.sum(axis=0)
dscale = dout
# step-8: scale = gamma * xhat
dgamma = np.sum(xhat * dout, axis=0)
dxhat = gamma * dscale
# step-7: xhat = xmu * invstd
dxmu1 = dxhat * invstd
dinvstd = np.sum(dxhat * xmu, axis=0)
# step-6: invstd = 1 / std
dstd = dinvstd * (-invstd**2)
# step-5: std = np.sqrt(var + 1e-6)
dvar = -0.5 * dstd * (1 / np.sqrt(var + 1e-6))
# step-4: var = sum(sq)
dsq = (1.0 / batch_size) * np.ones(input_shape) * dvar
# step-3: sq = xmu**2
dxmu2 = dsq * 2 * xmu
# step-2: xmu = x - mu
dxmu = dxmu1 + dxmu2
dmu = -1 * np.sum(dxmu, axis=0)
dx1 = dxmu * 1
# step-1: mu = mean(x)
dx2 = (1.0 / batch_size) * np.ones(input_shape) * dmu
# step-0:
dx = dx1 + dx2
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h4 id=&quot;section&quot;&gt;실제 구현&lt;/h4&gt;
&lt;p&gt;그러나 실제 구현 시에는 training 과 testing을 나눠서 아래와 같이 진행된다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/nn/6/batch_norm_al.png&quot; alt=&quot;Drawing&quot; style=&quot;width=500px&quot; /&gt;&lt;/p&gt;

&lt;hr /&gt;
&lt;h3 id=&quot;backpropogation---&quot;&gt;첨부: Backpropogation 전체 미분 수학식&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;수식의 이해는 이분의 블로그에서 많은 참조를 했다. Blog: [&lt;a href=&quot;http://cthorey.github.io/backpropagation/&quot;&gt;Clement Thorey&lt;/a&gt;]&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
Y &amp;= \gamma \hat{X} + \beta \\
\hat{X} &amp;= (X - \mu)(\sigma^2+\epsilon)^{-1/2}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;strong&gt;size:&lt;/strong&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
Y, \hat{X}, X &amp;= (N, D) \\
\mu, \sigma, \gamma, \beta &amp;= (D,)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;$N$은 미니 배치 싸이즈고, $D$는 데이터의 차원 수다.&lt;/p&gt;

&lt;p&gt;Matrix 로 정의한 수식을 다시 원소별로 표기를 정의 해보자. 매트릭스 $Y, X, \hat{X}$ 와 벡터 $\gamma, \beta$ 그리고 위에 수식은 아래와 같이 다시 정의 해볼 수 있다. (왜 매트릭스와 벡터인지는 Forward 과정에 나와있다. 각 차원별로 평균과 분산을 구하는걸 잊지말자)&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
y_{kl} &amp;= \gamma_l \hat{x}_{kl} + \beta_l \\
\hat{x}_{kl} &amp;= (x_{kl} - \mu_l)(\sigma_l^2+\epsilon)^{-1/2}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;where\quad \mu_l = \dfrac{1}{N} \sum_{p=1}^{N} x_{pl} , \quad \sigma_l^2 = \dfrac{1}{N} \sum_{p=1}^{N} (x_{pl}-\mu_l)^2&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;with\quad k = [1, \cdots, N] \ ,\  l = [1, \cdots, D]&lt;/script&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;이제 우리고 구하려고 하는 미분 값들$(\dfrac{\partial L}{\partial x}, \dfrac{\partial L}{\partial \gamma}, \dfrac{\partial L}{\partial \beta})$을 하나씩 구해보자.&lt;/p&gt;

&lt;h4 id=&quot;xij---&quot;&gt;$x_{ij}$ 에 대한 미분&lt;/h4&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}\dfrac{\partial L}{\partial x_{ij}}
&amp;= \sum_{k,l} \dfrac{\partial L}{\partial y_{kl}} \dfrac{\partial y_{kl}}{\partial x_{ij}} \\
&amp;= \sum_{k,l} \dfrac{\partial L}{\partial y_{kl}} \dfrac{\partial y_{kl}}{\partial \hat{x}_{kl}} \dfrac{\partial \hat{x}_{kl}}{\partial {x}_{ij}} \\
&amp;= \sum_{k,l} \dfrac{\partial L}{\partial y_{kl}} \cdot \gamma_l \cdot \dfrac{\partial \hat{x}_{kl}}{\partial {x}_{ij}} \end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;\dfrac{\partial \hat{x}_{kl}}{\partial {x}_{ij}} = \dfrac{\partial f}{\partial {x}_{ij}} g + f \dfrac{\partial g}{\partial {x}_{ij}} \quad where \quad \begin{cases} f = (x_{kl} - \mu_l) \\ g = (\sigma_l^2+\epsilon)^{-1/2} \end{cases}&lt;/script&gt; 에 대한 미분을 구해보자.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;우선 분자 $f = (x_{kl} - \mu_l)$ 에 대한 미분을 하면 아래와 같다.&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\dfrac{\partial f}{\partial {x}_{ij}} = \delta_{ik} \delta_{jl} - \frac{1}{N} \delta_{jl}&lt;/script&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\delta_{m,n} = \begin{cases} 1 \quad where \quad m = n \\ 0 \quad otherwise \end{cases}&lt;/script&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;$\delta_{m,n}$ 은 앞첨자 $m$ 이 뒷첨자 $n$과 같다면 1이 된다는 뜻이다.&lt;/p&gt;

&lt;p&gt;즉, 여기서 $i$ 가 $[1 \cdots k \cdots D]$ 까지, $j$ 가 $[1 \cdots l \cdots D]$ 까지 iteration 할 것인데, 오직 $i=k, j=l$ 일때만 앞 항인 $\delta_{il} \delta_{jl} = 1$ 이 될 것이고, $j=l$ 일때만 뒷항인 $\frac{1}{N} \delta_{jl} = \frac{1}{N}$ 이 될 것이다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;분모 $g = (\sigma_l^2+\epsilon)^{-1/2}$ 에 대한 미분은 아래와 같다.&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\dfrac{\partial g}{\partial {x}_{ij}} = -\dfrac{1}{2}(\sigma_l^2 + \epsilon)^{-3/2} \dfrac{\partial \sigma_l^2}{\partial x_{ij}}&lt;/script&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned} where \quad \sigma_l^2
&amp;= \dfrac{1}{N} \sum_{p=1}^{N} (x_{pl}-\mu_l)^2 \\
\dfrac{\partial \sigma_l^2}{\partial x_{ij}}
&amp;= \dfrac{1}{N} \sum_{p=1}^{N} 2(x_{pl}-\mu_l)(\delta_{ip} \delta_{jl} - \frac{1}{N} \delta_{jl}) \\
&amp;= \dfrac{2}{N} (x_{il}-\mu_l) \delta_{jl} - \dfrac{2}{N^2} \sum_{p=1}^N (x_{pl}-\mu_l) \delta_{jl} \\
&amp; = \dfrac{2}{N} (x_{il}-\mu_l) \delta_{jl} - \dfrac{2}{N} \delta_{jl} (\dfrac{1}{N}  \sum_{p=1}^N  (x_{pl}-\mu_l)) \cdots (1) \\
&amp; = \dfrac{2}{N} (x_{il}-\mu_l) \delta_{jl}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;(1) 번 식을 잠깐 이야기 하면 $\dfrac{1}{N} \sum_{p=1}^N  (x_{pl}-\mu_l) = 0$ 인것은 어떤 값들을 평균을 빼고 다시 평균 시키면 0이 된다.&lt;/p&gt;

&lt;p&gt;$e.g)\quad \frac{(1-2)+(2-2)+(3-2)}{3}=0$&lt;/p&gt;

&lt;p&gt;이제 드디어 &lt;script type=&quot;math/tex&quot;&gt;\dfrac{\hat{x}_{kl}}{\partial {x}_{ij}}&lt;/script&gt; 에 대해 구할수 있다. 곱의 미분 법칙을 사용하면 아래와 같이 전개 된다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned} \dfrac{\hat{x}_{kl}}{\partial {x}_{ij}}
&amp;= (\delta_{ik} \delta_{jl} - \frac{1}{N} \delta_{jl})(\sigma_l^2+\epsilon)^{-1/2}  -\dfrac{1}{N} (x_{kl} - \mu_l)(\sigma_l^2 + \epsilon)^{-3/2} (x_{il}-\mu_l) \delta_{jl} \\
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;최종적으로 우리의 목적 &lt;script type=&quot;math/tex&quot;&gt;\dfrac{\partial L}{\partial x_{ij}}&lt;/script&gt; 를 구해보자.&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}\dfrac{\partial L}{\partial x_{ij}}
&amp;= \sum_{k,l} \dfrac{\partial L}{\partial y_{kl}} \cdot \gamma_l \cdot [(\delta_{ik} \delta_{jl} - \frac{1}{N} \delta_{jl})(\sigma_l^2+\epsilon)^{-1/2} - \dfrac{1}{N} (x_{kl} - \mu_l)(\sigma_l^2 + \epsilon)^{-3/2} (x_{il}-\mu_l) \delta_{jl}] \\
&amp;= \sum_{k,l} \dfrac{\partial L}{\partial y_{kl}} \gamma_l [(\delta_{ik} \delta_{jl} - \frac{1}{N} \delta_{jl})(\sigma_l^2+\epsilon)^{-1/2}] - \sum_{k,l} \dfrac{\partial L}{\partial y_{kl}} \gamma_l [\dfrac{1}{N} (x_{kl} - \mu_l)(\sigma_l^2 + \epsilon)^{-3/2} (x_{il}-\mu_l) \delta_{jl}] \\
&amp;= \sum_{k,l} \dfrac{\partial L}{\partial y_{kl}} \gamma_l (\delta_{ik} \delta_{jl})(\sigma_l^2+\epsilon)^{-1/2} - \frac{1}{N} \sum_{k,l} \dfrac{\partial L}{\partial y_{kl}} \gamma_l \delta_{jl}(\sigma_l^2+\epsilon)^{-1/2} - \sum_{k,l} \dfrac{\partial L}{\partial y_{kl}} \gamma_l [\dfrac{1}{N} (x_{kl} - \mu_l)(\sigma_l^2 + \epsilon)^{-3/2} (x_{il}-\mu_l) \delta_{jl}] \\
&amp;= \dfrac{\partial L}{\partial y_{ij}} \gamma_l \delta_{ii} \delta_{jj} (\sigma_l^2+\epsilon)^{-1/2} - \frac{1}{N} \sum_k \dfrac{\partial L}{\partial y_{kj}} \gamma_l \delta_{jj}(\sigma_j^2+\epsilon)^{-1/2} - \dfrac{1}{N} \sum_{k} \dfrac{\partial L}{\partial y_{kj}} \gamma_l [ (x_{kj} - \mu_j)(\sigma_j^2 + \epsilon)^{-3/2} (x_{ij}-\mu_j) \delta_{jj}] \cdots (2) \\
&amp;= \dfrac{\partial L}{\partial y_{ij}} \gamma_l (\sigma_l^2+\epsilon)^{-1/2} - \frac{1}{N} \sum_k \dfrac{\partial L}{\partial y_{kj}} \gamma_l (\sigma_j^2+\epsilon)^{-1/2} - \dfrac{1}{N} \sum_{k} \dfrac{\partial L}{\partial y_{kj}} \gamma_l (x_{kj} - \mu_j)(\sigma_j^2 + \epsilon)^{-3/2} (x_{ij}-\mu_j) \\
&amp;= \dfrac{1}{N} \gamma_l (\sigma_l^2+\epsilon)^{-1/2} [N \dfrac{\partial L}{\partial y_{ij}} - \sum_k \dfrac{\partial L}{\partial y_{kj}} - (x_{ij}-\mu_j)(\sigma_j^2 + \epsilon)^{-1} \sum_{k} \dfrac{\partial L}{\partial y_{kj}}(x_{kj} - \mu_j)]
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;(2) 번 식으로 도출 되는 과정을 잘 살펴보면, 각 항마다 곱으로 구성되어 있다. 첫번째 항은 $\sum_{k, l}$ 에서 오직 $k=i, l=j$ 일때 남아 있고 나머지는 전부다 0 이고, 두번째 항은 오직 $l=j$ 일때 남아있고 나머지는 전부다 0 이다. 그리고 마지막도 마친가지로 $l=j$ 일때만 남아있는다.&lt;/p&gt;

&lt;h4 id=&quot;gammaj---&quot;&gt;$\gamma_j$ 에 대한 미분&lt;/h4&gt;

&lt;p&gt;위에 까지 이해했으면 $\gamma_l$ 에 대한 미분은 간단하다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}\dfrac{\partial L}{\partial \gamma_j}
&amp;= \sum_{k,l} \dfrac{\partial L}{\partial y_{kl}} \dfrac{\partial y_{kl}}{\partial \gamma_j} \\
&amp;= \sum_{k,l} \dfrac{\partial L}{\partial y_{kl}} \hat{x}_{kl} \delta_{jl} \\
&amp;= \sum_k \dfrac{\partial L}{\partial y_{kj}} \hat{x}_{kj} \\
&amp;= \sum_k \dfrac{\partial L}{\partial y_{kj}} (x_{kj} - \mu_j)(\sigma_j^2+\epsilon)^{-1/2}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;h4 id=&quot;betaj---&quot;&gt;$\beta_j$ 에 대한 미분&lt;/h4&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}\dfrac{\partial L}{\partial \beta_j}
&amp;= \sum_{k,l} \dfrac{\partial L}{\partial y_{kl}} \dfrac{\partial y_{kl}}{\partial \gamma_j} \\
&amp;= \sum_{k,l} \dfrac{\partial L}{\partial y_{kl}} \delta_{jl} \\
&amp;= \sum_k \dfrac{\partial L}{\partial y_{kj}}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;여기서 우리는 왜 위에 step-9, 8 코드 구현에서 dgamma와 dbeta를 summation 하는지 알 수 있다.&lt;/p&gt;

&lt;p&gt;다음 마지막 시간에는 모든걸 종합해서 학습하는 과정을 코드로 살펴보자.&lt;/p&gt;
</description>
        <pubDate>Thu, 25 Jan 2018 12:54:15 +0900</pubDate>
        <link>http://simonjisu.github.io/deeplearning/2018/01/25/numpywithnn_7.html</link>
        <guid isPermaLink="true">http://simonjisu.github.io/deeplearning/2018/01/25/numpywithnn_7.html</guid>
        
        
        <category>DeepLearning</category>
        
      </item>
    
      <item>
        <title>NUMPY with NN - 6: Weight Initialization</title>
        <description>&lt;h1 id=&quot;numpy--neural-network-basic---6&quot;&gt;Numpy로 짜보는 Neural Network Basic - 6&lt;/h1&gt;

&lt;hr /&gt;
&lt;h2 id=&quot;part-2&quot;&gt;학습관련 기술 Part 2&lt;/h2&gt;

&lt;h3 id=&quot;weight-initialization&quot;&gt;가중치 초기값 설정(Weight Initialization)&lt;/h3&gt;
&lt;p&gt;이전에 활성화 함수가 왜 중요한지 이야기 했었다. 다시 한 번 이야기 하면, 비 선형 활성화 함수를 사용해서 선형으로만 표현할 수 없는 값을 표현할 수 있게 되며, 그로 인해 은닉층을 쌓는 의미가 생긴다. 이런 비 선형 함수의 가중치 미분을 구해서 학습하고자 하는 파라미터를 업데이트 하게 된다.&lt;/p&gt;

&lt;p&gt;[&lt;a href=&quot;https://simonjisu.github.io/datascience/2017/12/08/numpywithnn_2.html&quot;&gt;Numpy로 짜보는 Neural Network Basic - 2&lt;/a&gt;] 참고&lt;/p&gt;

&lt;p&gt;그렇다면 Sigmoid를 예를 들어서 이야기 해보자, 아래 그림은 Sigmoid 함수와 미분의 그래프다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned} \sigma(a) &amp; = \dfrac{1}{1+e^{-a}} \\ \sigma'(a) &amp;= \sigma(a)(1 - \sigma(a))\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/nn/6/sigmoid_prime.png&quot; alt=&quot;Drawing&quot; /&gt;&lt;/p&gt;

&lt;p&gt;선형결합을 통해 구해진 값 a은 뉴런을 거쳐서 Sigmoid로 활성화 된 함수는 대부분 $[0, 1]$ 사이의 값을 가지게 될 것이다. 선형결합을 통해 구해진 값이 조금만 커져도 (약 $[-5, 5]$ 이외 값) Gradient 값이 0으로 되는 경우가 많아진다. 이를 &lt;strong&gt;Gradient Vanishing Problem&lt;/strong&gt;, 즉 가중치 0에 가까워져 업데이트 안되는 현상을 말한다. 따라서 가중치 초기 값이 엄청 작게 설정 했다고 해도 dot product해진 값이 커지면 이런 현상이 일어날 수가 있다.&lt;/p&gt;

&lt;h4 id=&quot;mnist--&quot;&gt;Mnist 데이터로 살펴보기&lt;/h4&gt;

&lt;p&gt;실제로 활성화 함수 값이 어떤 분포인지 mnist 데이터로 살펴보자. 내가 만든 뉴럴 네트워크의 구조는 아래와 같다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned} Input_{(784)}
&amp;\rightarrow [Affine1 \rightarrow Activation1]_{hidden1: (100)} \\
&amp;\rightarrow [Affine2 \rightarrow Activation2]_{hidden2: (50)} \\
&amp;\rightarrow [Affine3 \rightarrow SoftmaxwithLoss]_{output:(10)_{}}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;Hidden Node 는 각 100개와 50개로 설정하고 Activation Fucntion은 simgoid로 했다.
아래는 200 epoch까지 중간에 Activation 값들의 분포를 찍어본 것이다. 가중치 초기 값은 1을 곱한 것으로써 랜덤 Initialization 되었다고 생각하면 된다.(= $W$에다 1을 곱했다.)&lt;/p&gt;

&lt;video controls=&quot;controls&quot; autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot;&gt; &lt;source type=&quot;video/mp4&quot; src=&quot;/assets/ML/nn/6/sig_act1.mp4&quot; /&gt; &amp;lt;/source&amp;gt; &lt;/video&gt;

&lt;p&gt;대부분의 값이 0과 1로 이루어져 있다는 것을 알 수 있다. 이는 즉 대부분의 값이 미분을 했을 때 0이될 가능성이 높다는 뜻이다.&lt;/p&gt;

&lt;video controls=&quot;controls&quot; autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot;&gt; &lt;source type=&quot;video/mp4&quot; src=&quot;/assets/ML/nn/6/sig_back1.mp4&quot; /&gt; &amp;lt;/source&amp;gt; &lt;/video&gt;

&lt;p&gt;앞쪽의 Layer로 backward 할 수록 가중치 미분 값이 0에 가까워지는 것을 볼 수 있다.&lt;/p&gt;

&lt;p&gt;우리는 &lt;a href=&quot;https://simonjisu.github.io/datascience/2017/12/15/numpywithnn_4.html&quot;&gt;4편&lt;/a&gt;에서 가중치 값을 0.01 초기화 시켰더니 학습이 전혀 안된 모습을 볼 수 있었다. 그렇다면 0.01로 가중치 값을 초기화 하면 어떻게 될까?&lt;/p&gt;

&lt;video controls=&quot;controls&quot; autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot;&gt; &lt;source type=&quot;video/mp4&quot; src=&quot;/assets/ML/nn/6/sig_act2.mp4&quot; /&gt; &amp;lt;/source&amp;gt; &lt;/video&gt;

&lt;p&gt;가중치 활성화 값이 0.5로 치우쳐져 두 레이어의 분포가 거의 비슷해졌다. 다수의 뉴런이 같은 값을 출력하고 있다는 뜻으로 우리가 비선형함수를 써서 예측 불가능하게 만드려고 한 노력을 물거품으로 만들어 버렸다. 즉, 위에서 이야기 했던 층을 여러게 쌓은 의미가 없어진다. 이를 &lt;strong&gt;“표현력이 제한된다”&lt;/strong&gt; 라고 말한다.&lt;/p&gt;

&lt;video controls=&quot;controls&quot; autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot;&gt; &lt;source type=&quot;video/mp4&quot; src=&quot;/assets/ML/nn/6/sig_back2.mp4&quot; /&gt; &amp;lt;/source&amp;gt; &lt;/video&gt;

&lt;p&gt;가중치의 미분 값들이 대부분 0 근처에 있는 것을 확인 할 수가 있다.&lt;/p&gt;

&lt;p&gt;따라서 초기 값을 잘 설정해주어야 하는데, Sigmoid 함수에 대해서 자주 사용하는 Xavier 초기 값이 있다.&lt;/p&gt;

&lt;p&gt;Paper: &lt;a href=&quot;http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf&quot;&gt;Understanding the difficulty of training deep feedforward neural networks&lt;/a&gt;&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;W \sim Uniform(n_{in}, n_{out})&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Var(W)=\dfrac{1}{n_{in}}&lt;/script&gt;

&lt;p&gt;즉 가중치 초기화를 할때 각 파라미터 $W$ 에 대하여 $\dfrac{1}{\sqrt{n_{in}}}$ 를 곱해주는 것이다.&lt;/p&gt;

&lt;p&gt;아래는 Xavier 가중치 초기값을 설정했을 때의 Activation 분포다. 두 층이 전혀 다른 분포가 되어있는 것을 볼 수가 있다.&lt;/p&gt;

&lt;video controls=&quot;controls&quot; autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot;&gt; &lt;source type=&quot;video/mp4&quot; src=&quot;/assets/ML/nn/6/sig_act3.mp4&quot; /&gt; &amp;lt;/source&amp;gt; &lt;/video&gt;

&lt;video controls=&quot;controls&quot; autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot;&gt; &lt;source type=&quot;video/mp4&quot; src=&quot;/assets/ML/nn/6/sig_back3.mp4&quot; /&gt; &amp;lt;/source&amp;gt; &lt;/video&gt;

&lt;p&gt;각각의 가중치 초기화 값에 대한 학습 결과를 살펴보자. 총 10000번의 epochs를 돌린 결과다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;학습결과&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;img src=&quot;/assets/ML/nn/6/sig1.png&quot; alt=&quot;Drawing&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$w_{std} = 1$: 처음에 빠른것 같지만 나중에 굉장히 천천히 학습 되는 것을 확인 할 수 있다. &lt;br /&gt; 또한 매번 실행시 학습 속도가 다르다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;img src=&quot;/assets/ML/nn/6/sig2.png&quot; alt=&quot;Drawing&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$w_{std} = 0.01$: 학습이 전혀 안되는 것을 확인 할 수 있다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;img src=&quot;/assets/ML/nn/6/sig3.png&quot; alt=&quot;Drawing&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;$w_{std} = \dfrac{1}{\sqrt{n}}$: test 성적이 조금 더 좋아 졌다.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&quot;relu&quot;&gt;활성화 함수를 바꿔보자: ReLu&lt;/h4&gt;
&lt;p&gt;ReLu의 미분 값은 $x &amp;gt; 0$ 에서 $1$ 이고 나머지는 $0$ 이다. ReLu는 &lt;strong&gt;He&lt;/strong&gt; 라는 초기값을 설정하게 된다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;W \sim Uniform(n_{in}, n_{out})&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;Var(W)=\dfrac{2}{n_{in}}&lt;/script&gt;

&lt;p&gt;즉, 가중치 $W$ 에 $\sqrt{\dfrac{2}{n_{in}}}$ 을 곱하게 된다. 아래 동영상을 보면 0보다 큰 부분에서 꾸준히 활성화 되는 모습을 볼 수 있다.&lt;/p&gt;

&lt;video controls=&quot;controls&quot; autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot;&gt; &lt;source type=&quot;video/mp4&quot; src=&quot;/assets/ML/nn/6/relu_act3.mp4&quot; /&gt; &amp;lt;/source&amp;gt; &lt;/video&gt;

&lt;video controls=&quot;controls&quot; autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot;&gt; &lt;source type=&quot;video/mp4&quot; src=&quot;/assets/ML/nn/6/relu_back3.mp4&quot; /&gt; &amp;lt;/source&amp;gt; &lt;/video&gt;

&lt;p&gt;다음 시간에는 배치 정규화에 대해서 알아보자.&lt;/p&gt;
</description>
        <pubDate>Wed, 24 Jan 2018 12:31:37 +0900</pubDate>
        <link>http://simonjisu.github.io/deeplearning/2018/01/24/numpywithnn_6.html</link>
        <guid isPermaLink="true">http://simonjisu.github.io/deeplearning/2018/01/24/numpywithnn_6.html</guid>
        
        
        <category>DeepLearning</category>
        
      </item>
    
      <item>
        <title>NUMPY with NN - 5: Optimizer</title>
        <description>&lt;h1 id=&quot;numpy--neural-network-basic---5&quot;&gt;Numpy로 짜보는 Neural Network Basic - 5&lt;/h1&gt;
&lt;hr /&gt;
&lt;h2 id=&quot;part-1&quot;&gt;학습관련 기술 Part 1&lt;/h2&gt;

&lt;h3 id=&quot;optimizer&quot;&gt;Optimizer&lt;/h3&gt;

&lt;p&gt;손실 함수 값을 가능한 낮게 만들어 매개변수 최적값을 찾는 과정을 &lt;strong&gt;최적화&lt;/strong&gt; 라고 한다. 여기서 몇가지 방법을 한번 살펴본다.&lt;/p&gt;

&lt;h4 id=&quot;sgd--&quot;&gt;SGD(확률적 경사 하강법)&lt;/h4&gt;
&lt;p&gt;$W \leftarrow W - \eta \dfrac{\partial L}{\partial W}$&lt;/p&gt;

&lt;p&gt;$\eta$ 는 학습률로 얼만큼 가중치를 업데이트 할지 정하는 하이퍼파라미터다. 즉 우리가 미리 정해줘야하는 변수다. 그러나 SGD 알고리즘에서는 이 변수에 따라서 학습되는 모양이 다르다.&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;class SGD(object):
    def __init__(self, lr=0.01):
        self.lr = lr

    def update(self, params, grads):
        for key in params.keys():
            params[key] -= self.lr * grads[key]
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;장점&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;일부 데이터로 업데이트를 해서 진동이 심할 수도 있지만, 전체 데이터의 Gradient를 구하는 것보다 빠르다&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;단점&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;learning rate에 따라서 global min을 찾지 못하고 local min에 갇힐 가능서 존재&lt;/li&gt;
  &lt;li&gt;Oscilation(발진 현상): 해에 접근 할 수록 수렴 속도($\dfrac{\partial L}{\partial W}$)가 느려짐, 따라서 협곡 같은 모양에서 헤매는 경우 존재한다. 그렇다고 lr을 너무 높히면 발산 할 수도 있음(loss값이 커지는 현상)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;아래와 같은 함수의 최적값을 찾아보자.&lt;/p&gt;

&lt;p&gt;$f(x, y) = \dfrac{1}{20} x^2 + y^2$&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def f(x, y):
    return np.array((1/20)*(x**2) + (y**2))
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;$f$ 를 미분하면 아래와 같다.&lt;/p&gt;

&lt;p&gt;$\dfrac{\partial f}{\partial x}, \dfrac{\partial f}{\partial y} = \dfrac{x}{10}, 2y$&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def f_prime(x, y, grads=None):
    if grads is None:
        grads = {}

    grads['x'] = (1/10)*x
    grads['y'] = 2*y
    return grads
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;시작은 &lt;strong&gt;(-7, 2)&lt;/strong&gt; 점부터 시작한다고 하면 아래처럼 그림으로 표현할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/nn/fgraph.png&quot; alt=&quot;Drawing&quot; style=&quot;width: 400px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;이 함수의 최저점은 (0, 0) 점으로 볼 수 있다.&lt;/p&gt;

&lt;p&gt;이제 learning rate 를 0.1 과 0.9로 각각 정해서 SGD를 적요해보자. 총 30 epoch동안 Gradient를 구하고 이를 조금씩 업데이트 하는 방식을 취했다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Video&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Graph&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;video controls=&quot;controls&quot; style=&quot;width: 400px;&quot; autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot;&gt; &lt;source type=&quot;video/mp4&quot; src=&quot;/assets/ML/nn/SGD_0.1.mp4&quot; /&gt; &amp;lt;/source&amp;gt;&lt;/video&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;img src=&quot;/assets/ML/nn/SGD_0.1.png&quot; alt=&quot;Drawing&quot; style=&quot;width: 400px;&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;learning rate 가 0.1 일때 학습이 조금씩 진행 되는 것을 볼 수 있다. 그러나 epoch 횟수가 너무 적어 최적의 값까지 도달을 못했다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Video&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Graph&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;video controls=&quot;controls&quot; style=&quot;width: 400px;&quot; autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot;&gt; &lt;source type=&quot;video/mp4&quot; src=&quot;/assets/ML/nn/SGD_0.9.mp4&quot; /&gt; &amp;lt;/source&amp;gt;&lt;/video&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;img src=&quot;/assets/ML/nn/SGD_0.9.png&quot; alt=&quot;Drawing&quot; style=&quot;width: 400px;&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;learning rate 가 0.9 일때 학습이 크게 진행 되는 것을 볼 수 있다. 그러나 변동이 심해서 크게 흔들리면서 최저점으로 가는 모습을 볼 수 있다.&lt;/p&gt;

&lt;p&gt;학습률이 다르다는 것은 한 번 나아갈때 폭의 길이를 보면 그 차이를 알 수 가 있다.&lt;/p&gt;

&lt;h4 id=&quot;momentum&quot;&gt;Momentum&lt;/h4&gt;
&lt;p&gt;$v \leftarrow \gamma v - \eta \dfrac{\partial L}{\partial W}$&lt;/p&gt;

&lt;p&gt;$W \leftarrow W + v$&lt;/p&gt;

&lt;p&gt;모멘텀 방식은 gradient 방향에 일종의 관성을 더해줘서 기존의 이동 방향에 힘들 실어줘 더 이동할 수 있게 만들어준다. $v$ 의 초기값은 0으로 설정하고 진행한다. 따라서 첫 step이 후 기존에 이동했던 방향을 저장해둔 $v$ 가 추가로 저장 되어 다음 step에 더해져 조금 더 움직이게 된다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Video&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Graph&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;video controls=&quot;controls&quot; style=&quot;width: 400px;&quot; autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot;&gt; &lt;source type=&quot;video/mp4&quot; src=&quot;/assets/ML/nn/Momentum.mp4&quot; /&gt; &amp;lt;/source&amp;gt;&lt;/video&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;img src=&quot;/assets/ML/nn/Momentum.png&quot; alt=&quot;Drawing&quot; style=&quot;width: 400px;&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;learning rate가 0.1 일때 SGD보다 더 많이 가는 것을 알 수 있다.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Video&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Graph&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;video controls=&quot;controls&quot; style=&quot;width: 400px;&quot; autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot;&gt; &lt;source type=&quot;video/mp4&quot; src=&quot;/assets/ML/nn/Momentum_0.9.mp4&quot; /&gt; &amp;lt;/source&amp;gt;&lt;/video&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;img src=&quot;/assets/ML/nn/Momentum_0.9.png&quot; alt=&quot;Drawing&quot; style=&quot;width: 400px;&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;learning rate가 0.9 일때 주변을 헤매면서 가는 모습을 볼 수 있다. 하이퍼파라미터를 잘 조정해야 학습이 빠르게 진행 된 다는 것을 알 수 있다.&lt;/p&gt;

&lt;h4 id=&quot;adagrad&quot;&gt;Adagrad&lt;/h4&gt;
&lt;p&gt;$h \leftarrow h + \dfrac{\partial L}{\partial W} \odot \dfrac{\partial L}{\partial W}$&lt;/p&gt;

&lt;p&gt;$W \leftarrow W - \eta \dfrac{1}{\sqrt{h +\epsilon}} \dfrac{\partial L}{\partial W}$&lt;/p&gt;

&lt;p&gt;학습률($\eta$)에 대한 고민이 많이지자 이를 해결해보기 위해 나온 알고리즘이 AdaGrad 다.&lt;/p&gt;

&lt;p&gt;학습률을 처음에 크게 했다 나중에 차차 줄여가는 &lt;strong&gt;학습률 감소(learning rate decay)&lt;/strong&gt; 기술이 이 알고리즘의 특징이다. 각각의 매개변수에 맞춤형 학습률 값을 맞춰 줄 수가 있다.&lt;/p&gt;

&lt;p&gt;$\odot$ 는 여기서 dot product가 아닌 element-wise multiplication를 말한다. 수식을 보면 gradient를 제곱하여 h에 저장한다. 업데이트시 여태까지 저장해온 gradient 제곱 값을 분모로 두게 된다. 따라서 시간이 지날 수록 gradient 누적 값이 큰 것은 learning rate 가 반대로 작아지게 된서 학습률이 조정 된다. 이를 적응적으로(adaptive) 학습률을 조정한다고 한다.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;class Adagrad(object):
    def __init__(self, lr=0.01):
        self.lr = lr
        self.h = None
        self.epsilon = 1e-6  # 0으로 나누눈 것을 방지

    def update(self, params, grads):
        if self.h is None:
            self.h = {}
            for key, val in params.items():
                self.h[key] = np.zeros_like(val)

        for key in params.keys():
            self.h[key] += grads[key] * grads[key]
            params[key] -= self.lr * grads[key] / np.sqrt(self.h[key] + self.epsilon)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Video&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Graph&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;video controls=&quot;controls&quot; style=&quot;width: 400px;&quot; autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot;&gt; &lt;source type=&quot;video/mp4&quot; src=&quot;/assets/ML/nn/Adagrad.mp4&quot; /&gt; &amp;lt;/source&amp;gt;&lt;/video&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;img src=&quot;/assets/ML/nn/Adagrad.png&quot; alt=&quot;Drawing&quot; style=&quot;width: 400px;&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;학습률을 1.5로 크게 주었는데도 차차 감소하면서 학습되는 과정을 볼 수 가 있다.&lt;/p&gt;

&lt;p&gt;그러나 이렇게 좋아보이는 방법도 &lt;strong&gt;단점&lt;/strong&gt; 이 있다.&lt;/p&gt;

&lt;p&gt;과거의 기울기 값들을 전부 누적해서 더하기 때문에 h 값이 많이 커지게 되면 학습률 부분($\dfrac{1}{\sqrt{h +\epsilon}}$)이 1에 가까워져 업데이트 할 때 발산하는 형태로 가기 때문에 더 이상 학습이 진행이 안되는 상황이 발생할 수 있다.&lt;/p&gt;

&lt;p&gt;이를 개선하기 위해서 RMSProp과 Adadelta라는 방법이 있다. (코드는 기본 알고리즘 원리만 구현해놨다. 구체적으로 효율적인 학습을 위해서 조금씩 변형이 가해진다. 논문 참조 할 것, &lt;del&gt;아직 이해중&lt;/del&gt;)&lt;/p&gt;

&lt;p&gt;RMSProp:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;class RMSProp(object):
    def __init__(self, lr=0.01, gamma=0.9):
    &quot;&quot;&quot;G는 이동평균의 개념으로 과거 1보다 작은 gamma값을 곱해서 서서히 잊게 하고 새로운 값을 조금씩 더 해준다.&quot;&quot;&quot;
        self.lr = lr
        self.gamma = gamma  # decay term
        self.G = None
        self.epsilon = 1e-6  # 0으로 나누눈 것을 방지

    def update(self, params, grads):
        if self.G is None:
            self.G = {}
            for key, val in params.items():
                self.G[key] = np.zeros_like(val)

        for key in params.keys():
            self.G[key] += self.gamma * self.G[key] + (1 - self.gamma) * (grads[key] * grads[key])
            params[key] -= self.lr * grads[key] / np.sqrt(self.G[key] + self.epsilon)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;AdaDelta:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;class AdaDelta(object):
    def __init__(self, gamma=0.9):
        &quot;&quot;&quot;
        https://arxiv.org/pdf/1212.5701
        &quot;&quot;&quot;
        self.gamma = gamma  # decay term
        self.G = None  # accumulated gradients
        self.s = None  # accumulated updates
        self.del_W = None
        self.epsilon = 1e-6  # 0으로 나누눈 것을 방지
        self.iter = 0

    def update(self, params, grads):
        if (self.G is None) | (self.s is None) | (self.del_W is None):
            # Initialize accumulation variables
            self.G = {}
            self.s = {}  
            self.del_W = {}
            for key, val in params.items():
                self.G[key] = np.zeros_like(val)
                self.s[key] = np.zeros_like(val)
                self.del_W[key] = np.zeros_like(val)

        for key in params.keys():
            self.G[key] += self.gamma * self.G[key] + (1 - self.gamma) * (grads[key] * grads[key])
            self.del_W[key] = -(np.sqrt(self.s[key] + self.epsilon) / np.sqrt(self.G[key] + self.epsilon)) * grads[key]
            self.s[key] += self.gamma * self.s[key] + (1 - self.gamma) * self.del_W[key]**2
            params[key] += self.del_W[key]
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;h4 id=&quot;adamadaptive-moment-estimation&quot;&gt;Adam(Adaptive Moment Estimation)&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;Adam&lt;/strong&gt; (Adaptive Moment Estimation)은 RMSProp과 Momentum 방식을 합친 것 같은 알고리즘이다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/ML/nn/Algorithm_Adam.png&quot; alt=&quot;Drawing&quot; style=&quot;width: 800px;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;출처: &lt;a href=&quot;https://arxiv.org/abs/1412.6980v8&quot;&gt;https://arxiv.org/abs/1412.6980v8&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$m_t$: the exponential moving averages of the gradient (Momentum쪽)&lt;/li&gt;
  &lt;li&gt;$v_t$: the squared gradient (RMSProp쪽)&lt;/li&gt;
  &lt;li&gt;$\beta_1$: the exponential decay rates for $m_t$, 보통 0.9 취함&lt;/li&gt;
  &lt;li&gt;$\beta_2$: the exponential decay rates for $v_t$, 보통 0.999 취함&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;알고리즘 그대로 짜는게 아니라 조금더 효율적인 계산을 하기 위해서 아래와 같은 내용을 이해하고 보정해줘야 한다…(자세한 건 논문에 더 있음)&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;initialization-bias-correction&quot;&gt;추가 설명:(18.01.16) Initialization Bias Correction&lt;/h4&gt;
&lt;p&gt;우리가 구한 $m_t$, $v_t$ 값이 초기 값이 0으로 설정하고, $\beta$ 도 1에 가깝기 때문에 처음에 적용하는 gradient($g_t$) 값이 적용이 잘 안되서(즉, 업데이트가 안된다), 초기 epoch에서는 학습 진행이 안되는 경우가 있다.&lt;/p&gt;

&lt;p&gt;이는 $m_t$, $v_t$ 값이 실제로 $g_t$, $g_t^2$ 가 맞는지 확인하는 작업이 필요하다. 따라서 각각 기대값(Expectation)을 씌워서&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{cases}
E[m_t] = E[g_t] \\
E[v_t] = E[g_t^2]
\end{cases}&lt;/script&gt;

&lt;p&gt;가 성립하는지 확인해야 된다. $v_t$를 보면,&lt;/p&gt;

&lt;p&gt;$v_0 = 0$ (0 vector) 으로 초기 값을 주었기 때문에, $t = 1 \cdots t$ 까지 아래와 같이 정리해서 쓸 수가 있다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
v_0 &amp;= 0 \\
v_1 &amp;= \beta_2 v_0 + (1-\beta_2) g_1^2 = (1-\beta_2) g_1^2 \\
v_2 &amp;= \beta_2 v_1 + (1-\beta_2) g_2^2 = \beta_2 (1-\beta_2) g_1^2 + (1-\beta_2) g_2^2 = (1-\beta_2)(\beta_2^1 g_1^2 + \beta_2^0 g_2^2)\\
\vdots \\
v_t &amp;= \beta_2 v_{t-1} + (1-\beta_2) g_t^2 = (1-\beta_2)(\beta_2^{t-1} g_1^2 + \cdots + \beta_2^0 g_t^2) = (1-\beta_2) \sum_{i=1}^{t} \beta_2^{t-i}g_i^2 \cdots (1)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;(1) 식에서 $g_i^2$ 를 $g_i^2 - g_t^2 + g_t^2$ 로 바꿔 줄 수가 있다. 그후 양변에 Expectation을 취하게 된다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
E[v_t] &amp;= E[(1-\beta_2) \sum_{i=1}^{t} \beta_2^{t-i}(g_i^2 - g_t^2 + g_t^2))] \\
&amp;= E[(1-\beta_2) \sum_{i=1}^{t} \beta_2^{t-i}g_t^2] + E[(1-\beta_2) \sum_{i=1}^{t} \beta_2^{t-i}(g_i^2 - g_t^2))] \\
&amp;= E[g_t^2](1-\beta_2) \sum_{i=1}^{t} \beta_2^{t-i} + \zeta \\
&amp;= E[g_t^2](1-\beta_2)(\beta_2^{t-1} + \cdots + \beta_2^{0}) + \zeta \\
&amp;= E[g_t^2]\{(\beta_2^{t-1} + \cdots + \beta_2^{0}) - (\beta_2^{t} + \cdots + \beta_2^{1})\} + \zeta \\
&amp;= E[g_t^2](1-\beta_2^t) + \zeta \cdots (2)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;$E[g_t^2]$가 stationary 할때 $\zeta = 0$ 이 되고, 아니더라도 $\zeta$ 값은 이동평균의 특성상 따라 멀리 있는 $\beta_2^{t-i}$ 값이 아주 작아 0에 가까워 진다. 따라서 (2) 식만 남게 되는데, 우리가 원하는 $E[g_t^2]$ 를 구하기 위해서는 $E[g_t^2] = \dfrac{E[v_t]}{1-\beta_2^t}$ 를 해주면 초기값 0으로 설정하게 되어 생긴 bias를 조정 할 수 있게 된다.&lt;/p&gt;

&lt;p&gt;수식의 이해는 아래 블로그에서 도움을 조금 받았습니다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://dalpo0814.tistory.com/29#comment5316278&quot;&gt;http://dalpo0814.tistory.com&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;기존 알고리즘 코드:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;class Adam(object):
    &quot;&quot;&quot;Adam (http://arxiv.org/abs/1412.6980v8)&quot;&quot;&quot;

    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):
        self.lr = lr
        self.beta1 = beta1
        self.beta2 = beta2
        self.iter = 0
        self.m = None
        self.unbias_m = None
        self.v = None
        self.unbias_v = None

    def update(self, params, grads):
        if self.m is None:
            self.m, self.v = {}, {}
            for key, val in params.items():
                self.m[key] = np.zeros_like(val)
                self.v[key] = np.zeros_like(val)

        self.iter += 1

        for key in params.keys():
            self.m[key] = self.beta1*self.m[key] + (1-self.beta1)*grads[key]
            self.v[key] = self.beta2*self.v[key] + (1-self.beta2)*(grads[key]**2)

            self.unbias_m = self.m[key] / (1 - self.beta1**self.iter) # correct bias
            self.unbias_v = self.v[key] / (1 - self.beta2**self.iter) # correct bias
            params[key] -= self.lr * self.unbias_m / (np.sqrt(self.unbias_v) + 1e-7)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;아래는 다른 사람의 코드를 따와서 개조했다. 출처: &lt;a href=&quot;https://github.com/WegraLee/deep-learning-from-scratch/blob/master/common/optimizer.py&quot;&gt;https://github.com/WegraLee/deep-learning-from-scratch/&lt;/a&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;class Adam(object):
    &quot;&quot;&quot;Adam (http://arxiv.org/abs/1412.6980v8)&quot;&quot;&quot;

    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):
        self.lr = lr
        self.beta1 = beta1
        self.beta2 = beta2
        self.iter = 0
        self.m = None
        self.v = None

    def update(self, params, grads):
        if self.m is None:
            self.m, self.v = {}, {}
            for key, val in params.items():
                self.m[key] = np.zeros_like(val)
                self.v[key] = np.zeros_like(val)

        self.iter += 1
        lr_t = self.lr * np.sqrt(1.0 - self.beta2 ** self.iter) / (1.0 - self.beta1 ** self.iter)

        for key in params.keys():
            self.m[key] += (1 - self.beta1) * (grads[key] - self.m[key])
            self.v[key] += (1 - self.beta2) * (grads[key] ** 2 - self.v[key])

            params[key] -= lr_t * self.m[key] / (np.sqrt(self.v[key]) + 1e-7)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;조금 더 효율 적으로 개선된 것을 볼 수 있다. &lt;strong&gt;lr_t&lt;/strong&gt; 는 위에 unbias 항들을 넣어서 정리해주면 아래와 같이 정의 할 수 있다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
m_t &amp;= \beta_1 m_{t-1} + (1-\beta_1) g_t \\
&amp;= \beta_1 m_{t-1} + m_{t-1} - m_{t-1} + (1-\beta_1) g_t\\
&amp;= m_{t-1} - (1-\beta_1) m_{t-1} + (1-\beta_1) g_t\\
&amp;= m_{t-1} + (1-\beta_1)(g_t-m_{t-1})\\
v_t &amp;= v_{t-1} + (1-\beta_1)(g_t^2-v_{t-1}) \\
\alpha_t &amp;= \alpha \dfrac{\sqrt{1-\beta_2^t}}{1-\beta_1} \\
\theta_t &amp; \leftarrow \theta_{t-1} - \alpha_t \dfrac{m_t}{\sqrt{v_t} + \epsilon}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;h4 id=&quot;signal-to-noisesnr&quot;&gt;Signal-to-Noise(SNR)&lt;/h4&gt;
&lt;p&gt;보통의 경우 $\hat{v}_t$ (gradient 제곱의 지수 평균) 이 $\hat{m}_t$ (gradient의 지수 평균) 보다 크기 때문에 $\dfrac{\hat{m}_t}{\sqrt{\hat{v}_t}} \leq 1$ ($\epsilon = 0$ 이라 가정) 가 되서 learning rate 보다 작은 값으로 업데이트 될 것이라는 점이다.&lt;/p&gt;

&lt;p&gt;이를 논문에서는 $\dfrac{\hat{m}_t}{\sqrt{\hat{v}_t}}$ 를 &lt;strong&gt;signal-to-noise ratio(SNR)&lt;/strong&gt; 라고 하며, SNR 값이 작아질 수록 step size도 0에 근접하게 된다. 즉, learning rate 가 점점 작아져 자동적으로 수렴하게 된다는 이야기다. 지금까지 고민하던 고정 학습률의 고민을 해결해 준다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;step size : $\Delta_t = \theta_t - \theta_{t-1}$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그러나 조금 주의할 점은 데이터가 굉장히 sparse한 데이터 경우, 대부분의 $m_{t-1}$, $v_{t-1}$ 의 값은 0이 될 것이고, epoch($t$) 가 커질수록 $\hat{m}_t$, $\hat{v}_t$ 는 그 시점에서의 gradient 로 구성되어 있게 된다. 따라서 업데이트 식은 아래와 같게 된다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\theta_t \leftarrow \theta_{t-1} - \alpha \dfrac{1-\beta_1}{\sqrt{1-\beta_2}}&lt;/script&gt;

&lt;p&gt;이런 상황에서는 $\dfrac{1-\beta_1}{\sqrt{1-\beta_2}}$ 값이 1 보다 크기 때문에($beta_1 = 0.9, \beta_2 = 0.999$, 계산하면 약 3.16) 발산할 가능성이 높아진다. 이런 상황은 거의 드물다고 한다.&lt;/p&gt;

&lt;hr /&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Video&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Graph&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;video controls=&quot;controls&quot; style=&quot;width: 400px;&quot; autoplay=&quot;&quot; loop=&quot;&quot; muted=&quot;&quot;&gt; &lt;source type=&quot;video/mp4&quot; src=&quot;/assets/ML/nn/Adam.mp4&quot; /&gt; &amp;lt;/source&amp;gt; &lt;/video&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;img src=&quot;/assets/ML/nn/Adam.png&quot; alt=&quot;Drawing&quot; style=&quot;width: 400px;&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;논문 결론 부에는 Adam 알고리즘이 큰 데이터 셋이나 고차원 파라미터 공간을 학습하는데 효율적이다라고 이야기 하고 있다.&lt;/p&gt;

&lt;p&gt;다음 시간에는 가중치 초기화와 배치 노말라이제이션에 대에서 이야기 해보도록 하겠다.&lt;/p&gt;
</description>
        <pubDate>Sat, 13 Jan 2018 14:17:06 +0900</pubDate>
        <link>http://simonjisu.github.io/deeplearning/2018/01/13/numpywithnn_5.html</link>
        <guid isPermaLink="true">http://simonjisu.github.io/deeplearning/2018/01/13/numpywithnn_5.html</guid>
        
        
        <category>DeepLearning</category>
        
      </item>
    
  </channel>
</rss>
