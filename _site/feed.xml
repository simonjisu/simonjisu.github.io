<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Soopace</title>
    <description>Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.
</description>
    <link>https://simonjisu.github.io/</link>
    <atom:link href="https://simonjisu.github.io/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Tue, 11 Aug 2020 17:48:11 +0900</pubDate>
    <lastBuildDate>Tue, 11 Aug 2020 17:48:11 +0900</lastBuildDate>
    <generator>Jekyll v3.7.3</generator>
    
      <item>
        <title>[XAI] Classifier-agnostic saliency map extraction</title>
        <description>&lt;p&gt;Paper Link: &lt;a href=&quot;https://arxiv.org/abs/1805.08249&quot;&gt;Classifier-agnostic saliency map extraction&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;1-introduction&quot;&gt;1. Introduction&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;기존의 몇몇 논문에서 특정 클래스 점수에 대한 gradient가 네트워크의 내부 작동을 밝히는 수단으로 사용할 수 있다는 것을 증명했다.
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1312.6034&quot;&gt;Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps&lt;/a&gt;(Simonyan et al., 2013): vanilla gradient를 사용한 saliency map 생성, 관련 논문 리뷰 &lt;a href=&quot;https://simonjisu.github.io/paper/2020/03/12/deepinsidecnn.html&quot;&gt;링크&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1412.6806&quot;&gt;Striving for Simplicity: The All Convolutional Net&lt;/a&gt;(Springenberg et al., 2014): guided backpropagation을 사용하여 정교한 saliency map 생성&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;이러한 추세에 따라서 saliency map을 정교하게 만들기 위한 몇몇 테크닉이 적용되었다.
    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1610.02391&quot;&gt;Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization&lt;/a&gt;(Selvaraju et al., 2017): GradCAM 논문, 여러개의 saliency map을 평균내서 조금더 smooth 한 맵을 형성&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;논문의 저자들은 이러한 트릭들은 유용한 증거를 가지고 있는 saliency map을 찾는데 원칙적인 방법이 아니라고 주장한다.&lt;/li&gt;
  &lt;li&gt;이 논문에서는 저자들의 목표는 분류에 도움이 되는 픽셀을 알려주는 saliency map을 찾는 것이다. 문제는 기존의 방법들이 분류기(훈련된 모델)에 너무 의존한다는 것이다. 이러한 문제점을 저자들은 해결하려고 했고, &lt;strong&gt;“class-agnostic saliency map extraction”&lt;/strong&gt;이라는 것을 제시한다.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;이 방법은 모델에 의존하지 않고 오직 입력데이터에만 더 집중할 수 있도록 했다. 결과는 Figure2 처럼 질적으로 더 좋은 saliency map을 생성함. 각 행이 어떤 그림을 그린건지는 파트5에서 설명한다.&lt;/p&gt;

    &lt;figure class=&quot;image&quot;&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1SJcqwn25JiuD4LHO-yPILhwvaxOi7Qp6&quot; alt=&quot;Paper Figure 2&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;figcaption&gt;Paper Figure 2&lt;/figcaption&gt;&lt;/figure&gt;
  &lt;/li&gt;
  &lt;li&gt;ImageNet 데이터로 weakly-supervised 방법중에서 SOTA를 달성, strongly supervised 모델과 비슷한 성과를 냈다고 주장한다. 심지어, 훈련하지 않은 class에 대해서 잘 작동하는 모습도 보여줬다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;2-related-work&quot;&gt;2. Related work&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;생략&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;3-classifier-agnostic-saliency-map-extraction&quot;&gt;3. Classifier-Agnostic Saliency Map Extraction&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;이 논문에서 다루는 문제는 다음과 같이, 주어진 이미지에 해당하는 salient region을 추출하는 매핑(mapping)을 찾는 것이다. 이 매핑은 분류기(모델)에 도움이 되는 픽셀은 1을 유지하고 그렇지 않은 픽셀은 0으로 masking되어야 한다.&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;m: \Bbb{R}^{W\times H\times3} \rightarrow [0, 1]^{W\times H} \text{ over } x \in \Bbb{R}^{W\times H\times3}&lt;/script&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;31-classifier-dependent-saliency-map-extraction&quot;&gt;3.1 Classifier-Dependent Saliency Map Extraction&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;기존의 연구(&lt;a href=&quot;https://arxiv.org/abs/1704.03296&quot;&gt;Fong &amp;amp; Vedaldi, 2017&lt;/a&gt;과 &lt;a href=&quot;https://arxiv.org/abs/1705.07857&quot;&gt;Dabkowski &amp;amp; Gal, 2017&lt;/a&gt;)들은 주로 분류기 $f$ 가 주어진 상태에서 최적의 masking을 찾는 형태가 많았다.&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;m = \arg \underset{m'}{\max} S(m', f) \qquad \cdots (1)&lt;/script&gt;

    &lt;p&gt;이러한 방법을 &lt;strong&gt;Classifier-Dependent Saliency Map Extraction&lt;/strong&gt; 이라고 하며 자세한 방법은 다음과 같다.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$S$는 일종의 score function인데, 분류 오차와 연관이 있다.&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;S(m, f) = \dfrac{1}{N} \sum_{n=1}^{N} \bigg[ l\Big( f\big( (1-m(x_n))\odot x_n \big), y_n \Big) + R\big(m(x_n)\big) \bigg] \qquad \cdots (2)&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;수식을 하나씩 보자. $m(x_n)$는 마스크로 매핑된 값들이고, $1-m(x_n)$은 자연스럽게 마스크로 지워지지 않은 지역이다. 여기어 $\odot x_n$은 element-wise product로 입력 이미지에 덧씌움으로써 마스크 되지 않은 픽셀들을 가르킨다. 따라서 분류기 $f$ 의 입력으로 지워지지 않은 픽셀을 넣고, 그 예측값과 타겟을 비교한 Loss가 수식의 앞부분 $l(f( * ), y_n)$이다(분류의 경우 보통 Cross-Entropy Loss 다). 뒤에 $R( * )$ 항목은 정규화 항목이다.&lt;/li&gt;
  &lt;li&gt;같은 입력에서 특정 분류기 $f$로부터 생성된 매핑 $m$은, 다른 분류기 $f’$ 로부터 생성된 $m’$과 다를 수도 있다(심지어 같은 성능을 지녀도).&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;예를 들어, 다음 수식 $L$을 성능으로 측정한다면, 마스크를 씌우지 않았을 경우 $L(0, f) = L(0, f’)$와 마스크가 씌워진 경우 $L(m, f) = L(m’, f’)$의 성능이 같다고 해도, $m$과 $m’$은 다른 형태를 보여줄 수가 있다는 말이다.&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;L(m, f) = \dfrac{1}{N} \sum_{n=1}^{N} l\Big( f\big( (1-m(x_n))\odot x_n \big), y_n \Big) \qquad \cdots (3)&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;이런 현상의 원인은 두 개의 성능은 동일하나 가중치가 완전히 다른 분류기들이, 같은 입력에 대해서 각자 이미지의 다른 부분집합(픽셀들)을 사용하여 분류할 가능성이 있기 때문이다.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;극단적인 예시로 이미지의 너비를 반으로 줄이고 옆으로 복사해서 각기 다른 구조의 분류기에 넣는다면, 하나는 이미지의 왼쪽에 saliency map을 생성하고, 다른 분류기는 이미지의 오른쪽에 saliency map을 생성할 수도 있다는 것이다.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;코멘트:&lt;/strong&gt; 이 부분은 실험결과가 없어서 실제로 해봐야 할것 같다. 두 개다 탐지할 수도 있는것 아닌가?&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;32-classifier-agnostic-saliency-map-extraction&quot;&gt;3.2 Classifier-Agnostic Saliency Map Extraction&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;2.1&lt;/code&gt;에서 제기한 문제를 해결하려고 모든 분류기에 대한 사후확률의 평균을 최적화는 방식으로 전환하여, 수식(1)을 다음과 같이 변형했다.&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;m = \arg \underset{m'}{\max} \Bbb{E}_f \big[ S(m', f) \big] \qquad \cdots (4)&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;코멘트:&lt;/strong&gt; 아래는 공부한 것을 토대로 풀어써봤는데, 틀릴 수도 있으니 주의..&lt;/p&gt;

    &lt;p&gt;사후확률 $p(f \vert D, m’)$은 masking된 이미지가 주어졌을 때, 해당하는 분류기의 확률이라고 생각할 수 있겠다.&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;$D, m’$ 부분은 $(1-m’(x_n))\odot x_n \text{ where } x_n \in D$ 부분이라고 생각할 수 있다.&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;따라서 $p(f \vert D, m’) \propto p(f) p(D, m’ \vert f) = p(f) \exp(-L(m’, f))$ 처럼 쓸 수 있다(아마 수식(3) 형태로 가져가려고 $L$에서 입력 이미지 $x_n\in D$는 생략한듯 하다).&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;$p(D, m’ \vert f)$의 뜻은 특정 분류기 $f$가 주어졌을 때, masking된 이미지를 생성할 확률이다. 이는 Classifier-Dependent Saliency Map Extraction의 목적함수를 확률로 표현한 것이다.&lt;/li&gt;
      &lt;li&gt;$p(D, m’ \vert f) = \exp(-L(m’, f))$로 쓸수 있는 이유는 해당 항이 Likelihood 인데,  $\log$를 취하고 마이너스를 곱해줌으로써 Negative Log Likelihood로 바뀐다. $-\log p(D, m’ \vert f)$는 곧 수식(3)인 $L(m’,f)$와 일치한다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;수식(4)는 모든 가능한 분류기의 공간(the space of all possible classifiers)을 탐색하고, 그 중에서 잘 작동하는 매핑 $m$을 찾는 과정이다. 모든 가능한 분류기의 공간은 모든 분류기의 파라미터($\theta_f$)의 공간과 동일하다.&lt;/li&gt;
  &lt;li&gt;이러한 과정을 저자들은 &lt;strong&gt;Classifier-Agnostic Saliency Map Extraction&lt;/strong&gt;라고 부르기로 했다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;33-algorithm&quot;&gt;3.3 Algorithm&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;수식(4)의 최적화 문제는 불행하게도 풀수가 없다(intractable). 특히 기댓값안에 있는 매핑 $m$을 loop를 통해 최적화 해야한다는 것이 이 문제를 더 난해하게 만든다. 따라서 논문에서는 이 문제를 매핑 $m$과 기댓값 목적함수를 동시에 추정함으로써 해결하려고 한다.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;구체적인 알고리즘은 다음과 같다.&lt;/p&gt;

    &lt;figure class=&quot;image&quot;&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1xCajsDh2yozXxhMwYy82TzJ702BMv6BA&quot; alt=&quot;Paper Algorithm 1&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;figcaption&gt;Paper Algorithm 1&lt;/figcaption&gt;&lt;/figure&gt;

    &lt;ul&gt;
      &lt;li&gt;
        &lt;p&gt;먼저  $\theta_f$ 대해 classification loss $L$의 미분을 구함으로써, 사후확률 $p(f \vert D, m^{(k-1)})$를 가지는 $f^{(k)}$를 샘플링한다.&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;\theta_{f^{(k)}} \leftarrow \theta_{f^{(k-1)}} - \eta_f \triangledown_{\theta_f} L(m^{(k-1)}, f^{(k-1)})&lt;/script&gt;

        &lt;p&gt;이러한 방법은 &lt;a href=&quot;https://www.ics.uci.edu/~welling/publications/papers/stoclangevin_v6.pdf&quot;&gt;Welling &amp;amp; Teh, 2011&lt;/a&gt;와 &lt;a href=&quot;https://arxiv.org/abs/1704.04289&quot;&gt;Mandt et al., 2017&lt;/a&gt; 연구에서 SGD에 noise를 일부 주면  Bayesian Posterior Inference를 수행할 수 있다는 점에서 착안했다. &lt;strong&gt;공부가 더 필요한 부분..&lt;/strong&gt;&lt;/p&gt;

        &lt;p&gt;EM 알고리즘이랑 비슷한데, SGD로 한다는 점이 다른듯하다. 참고자료: &lt;a href=&quot;http://norman3.github.io/prml/docs/chapter09/4.html&quot;&gt;4. The EM Algorithm in General&lt;/a&gt;&lt;/p&gt;
      &lt;/li&gt;
      &lt;li&gt;업데이트된 파라미터 공간을 $F^{(k-1)}$와 합친뒤에 $F^{(k)}$에서 새로운 파라미터 $f’$를 샘플링한다.&lt;/li&gt;
      &lt;li&gt;
        &lt;p&gt;새로운 모델을 score function $S$에 넣어서 다시 마스크 네트워크 $\theta_{m^{(k-1)}}$값을 $\theta_{m^{(k)}}$로 업데이트 한다.&lt;/p&gt;

        &lt;script type=&quot;math/tex; mode=display&quot;&gt;\theta_{m^{(k)}} \leftarrow \theta_{m^{(k-1)}} + \eta_m \triangledown_{\theta_m} S(m^{(k-1)}, f')&lt;/script&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;score-function&quot;&gt;Score Function&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Score Function은 saliency map의 퀄리티를 측정하는 도구다.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;또한, Precision 과 Recall의 조건을 동시에 만족하게 디자인 되어야한다.&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\text{precision} = \dfrac{TP}{TP + FP} \quad \text{recall}=\dfrac{TP}{TP+FN}&lt;/script&gt;

    &lt;figure class=&quot;image&quot;&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1OEpXqK1p1lwdTLJHzHbliw_EScvBBjO2&quot; alt=&quot;Confusion Matrix&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;figcaption&gt;Confusion Matrix&lt;/figcaption&gt;&lt;/figure&gt;

    &lt;ul&gt;
      &lt;li&gt;Precision: 마킹된 픽셀들 중에서 연관된 픽셀이 얼마나 있는지&lt;/li&gt;
      &lt;li&gt;Recall: 실제 연관된 픽셀들중에서 얼마나 정확하게 마킹되었는지&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;기존의 score 함수를 살펴보면, $A$파트는 연관된 픽셀이 더 많이 마킹되게 만들어주는 항이다(high recall). 마스킹된 이미지를 넣어서 classification loss가 높아지면 분류에 도움되는 픽셀들을 잡아주고 있다는 뜻이고, 낮아지면 마스킹이 잘 안되고 있다는 뜻으로 해석할 수 있다.&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;S(m, f) = \dfrac{1}{N} \sum_{n=1}^{N} \bigg[ \underbrace{ l\Big( f\big( (1-m(x_n))\odot x_n \big), y_n \Big)}_{A} + \underbrace{ R\big(m(x_n)\big) }_{B}\bigg] \qquad \cdots (2)&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;하지만 단순히 $A$파트를 쓰기에는 문제가 있는데, sampling할때 마스킹된 입력을 넣어서 파라미터 $\theta_f$를 업데이트하기 때문에, 모델의 성능을 저하시킬 가능성이 있다. 변형된 파라미터에 같은 classification loss를 그대로 사용하는 것은 이치에 안맞을 수도 있다.&lt;/li&gt;
  &lt;li&gt;추가로 연관된 픽셀이 마스킹된 이미지를 분류기에게 넣었을 때, 정답 클래스가 아니라는 것만 판단해야지, 다른 클래스로 예측하면 안되기 때문에, classification loss를 그대로 사용하는 것은 문제가 있어 보인다.&lt;/li&gt;
  &lt;li&gt;따라서 저자들은 $A$파트를 $\mathcal{H}\big( f( (1-m(x)) \odot x_n) \big)$ Entropy로 바꿨다. 즉, 마스킹을 찾아내는 작업은 정확도를 최소화하는 것이 아닌 불확실성(uncertainty)을 최대화하는 방향으로 진행해야한다.&lt;/li&gt;
  &lt;li&gt;또한, Entropy로 바꾸면서 ground-truth label의 필요성을 제거했다.&lt;/li&gt;
  &lt;li&gt;$B$파트는 정규화 항목인데, trivial solution을 배제하고 있다. 만약에 마스크 $m$이 전부 1인 경우, 최대 recall 및 아주 낮은 precision을 달성할 수가 있다. 그래서 total variation(&lt;a href=&quot;https://www.sciencedirect.com/science/article/abs/pii/016727899290242F&quot;&gt;Rudin et al., 1992&lt;/a&gt;)과 L1 Norm을 사용하기로 한다.
    &lt;ul&gt;
      &lt;li&gt;임성빈님의 자료 참고: &lt;a href=&quot;https://www.slideshare.net/ssuser7e10e4/wasserstein-gan-i&quot;&gt;링크&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;따라서 수식(2)는 다음과 같이 변한다&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;S(m, f) = \dfrac{1}{N} \sum_{n=1}^{N} \bigg[ \mathcal{H}\Big( f\big( (1-m(x_n))\odot x_n \big) \Big) + \lambda_R \Vert m(x_n) \Vert_1 \bigg] \qquad \cdots (7)&lt;/script&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;thining&quot;&gt;Thining&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;알고리즘이 사후확률 분포에서 분류기 집합 $f^{(k)}$을 저장해서 많은 양의 데이터를 수집하기 때문에, 그중 작은 부분집합만 보존하는 전략을 취하기로 했다.&lt;/li&gt;
  &lt;li&gt;고정된 크기 $F^{(k)}$를 취하는 방식으로 다음과 같이 정한다.
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;F&lt;/strong&gt;: 첫번째 분류기만 저장 $F^{(k)} = { f^{(0)}}$&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;L&lt;/strong&gt;: 마지막 분류기만 저장 $F^{(k)} = { f^{(k)}}$&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;FL&lt;/strong&gt;: 첫번째와 마지막 분류기만 저장 $F^{(k)} = { f^{(0)}, f^{(k)}}$&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;L1000&lt;/strong&gt;: 1000번째 iteration 마다 저장하고, $\vert F^{(k)} \vert =30$ 을 넘어갈때, 랜덤하게 하나를 제거한다.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;L100&lt;/strong&gt;: 100번째 iteration 마다 저장하고, $\vert F^{(k)} \vert =30$ 을 넘어갈때, 랜덤하게 하나를 제거한다.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;classification-loss&quot;&gt;Classification loss&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;수식(3)처럼 classification loss를 정의해도 되지만 꼭 그럴 필요도 없다.&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;L(m, f) = \dfrac{1}{N} \sum_{n=1}^{N} l\Big( f\big( (1-m(x_n))\odot x_n \big), y_n \Big) \qquad \cdots (3)&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;대신 &lt;a href=&quot;https://arxiv.org/abs/1312.6199&quot;&gt;Szegedy et al., 2013&lt;/a&gt; 방식이 더 잘 됐다.&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;L(m, f) = \dfrac{1}{2N} \sum_{n=1}^{N} \bigg[ l\Big( f\big( (1-m(x_n))\odot x_n \big), y_n \Big) + l\big( f(x_n), y_n \big) \bigg] \qquad \cdots (8)&lt;/script&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;4-training-and-evaluation-details&quot;&gt;4. Training and evaluation details&lt;/h1&gt;

&lt;h3 id=&quot;dataset&quot;&gt;Dataset&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Official ImageNet Training Set&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;classifier-f-and-mapping-m&quot;&gt;Classifier $f$ and mapping $m$&lt;/h3&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1FHVgUhAdmJqAlJ0UE1l55lbnna070zJq&quot; alt=&quot;Paper Figure 1&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;figcaption&gt;Paper Figure 1&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;모델 $f$는 ResNet-50을 사용했다. 그리고 Encoder-Decoder 구조를 취해서 마스크 $m$를 생성한다.&lt;/li&gt;
  &lt;li&gt;Encoder는 ResNet-50 구조를 사용하고, 가중치는 $f$와 공유할 수도 있고 아닐수도 있다(실험결과 공유하는게 더 유리하다).&lt;/li&gt;
  &lt;li&gt;Decoder는 Deconvolutional Network를 사용하여 마스크를 생성한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;regularization-coeffieient-lambda_r&quot;&gt;Regularization coeffieient $\lambda_R$&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://lld-workshop.github.io/2017/papers/LLD_2017_paper_64.pdf&quot;&gt;Fan et al. 2017&lt;/a&gt; 에서 최적의 $\lambda_R$는 쉽게 찾을 수 없다고(not trivial)하다고 이야기하면서, adaptive 전략을 취해서 인위적인 $\lambda_R$을 고르는 것을 배제했다.&lt;/li&gt;
  &lt;li&gt;저자들을 같은 방법을 사용하면 saliency map의 평균 크기를 제어하기가 어려워 $f(x)$와 $f((1-m(x)) \odot x)$간에 차이가 있을 때만 $\lambda_R$를 적용했다.&lt;/li&gt;
  &lt;li&gt;각 실험에서 대략 50%의 픽셀이 연관되게 하도록 마스크 $m$를 생성했다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;baseline-and-casm&quot;&gt;Baseline and CASM&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Baseline 모델은 CASM과 같은 모델 구조를 가지지만 CDSM(classifier-dependent saliency mapping) 방법으로 훈련킨 모델이(Thinning은 &lt;strong&gt;F&lt;/strong&gt;를 사용).&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;mask-discretization&quot;&gt;Mask discretization&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;마스크는 다음과 같이 생성한다. $\bar{m}(x)$은 마스크의 평균값이고, $\alpha$는 하이퍼파라미터다.&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;b_{ij}(x) = \begin{cases} 1, \quad \text{if } m_{ij}(x) \geq \alpha \bar{m}(x) \\ 0, \quad \text{otherwise} \end{cases}&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$\alpha$를 1로 설성하면 마스크 평균값이 그대로 binary mask를 생성한다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;5-qualitative-comparisons&quot;&gt;5. Qualitative comparisons&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;논문의 그림에 대해서 설명한다. 각 행에 대하여 다음과 같은 visualization을 했다.
    &lt;ol&gt;
      &lt;li&gt;&lt;strong&gt;original image&lt;/strong&gt;: 원본 이미지&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;masked-in image&lt;/strong&gt;( $b(x) \odot x$ ): 마스크안의 이미지&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;masked-out image&lt;/strong&gt;( $(1-b(x)) \odot x$ ): 마스킹된 이미지&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;inpainted masked-out image&lt;/strong&gt;: inpainting 알고리즘 &lt;a href=&quot;https://www.researchgate.net/publication/238183352_An_Image_Inpainting_Technique_Based_on_the_Fast_Marching_Method&quot;&gt;Telea, 2004&lt;/a&gt;을 사용해서 마스크 내부 이미지를 채웠다.&lt;/li&gt;
    &lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;Random 하게 7개의 연속된 그림을 골라서 visualization 했다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;6-evaluation&quot;&gt;6. Evaluation&lt;/h1&gt;

&lt;h2 id=&quot;61-basic-statistics&quot;&gt;6.1 Basic statistics&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Validation Set로 saliency map을 만들었다.&lt;/li&gt;
  &lt;li&gt;CASM 모델로 마스크를 추출시 total variation이 더 낮았다( $2.5 \times 10^3$ vs $7.0 \times 10 ^3$ ). 즉, total variation 정규화를 적게 줘도 CASM이 더 많은 mask를 생성한다. &amp;gt; 무슨말이냐&lt;/li&gt;
  &lt;li&gt;Entropy는 Baseline 보다 많이 작았는데( $0.05$ vs $0.21$ ), 이는 mask intensities가 거의 0과 1 사이의 값을 평균적으로 가진다는 것을 뜻한다.&lt;/li&gt;
  &lt;li&gt;masked out volume의 표준편차가 더 컸는데( $0.19$ vs $0.14$ ), 이를 통해 CASM이 입력 이미지에 따라서 더 다양한 크기의 saliency map을 생성할 수 있다는 것을 알 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;62-classification-by-multiple-classifiers&quot;&gt;6.2 Classification by multiple classifiers&lt;/h2&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;img src=&quot;https://drive.google.com/uc?id=11zPpcGsV3JDEPhvOBVGsIm9uO-mtIcGz&quot; alt=&quot;Paper Figure 3&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;figcaption&gt;Paper Figure 3&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;CASM이 정말로 classifier-agnostic인지 &lt;code class=&quot;highlighter-rouge&quot;&gt;torchvision.models&lt;/code&gt;에 있는 모델들로 주장을 확인해봤다. 자신들이 기대한 것은 CASM을 통해 만든 inpainted masked-out 이미지로 해당 모델들의 정확도를 깎아 내리고, masked-in 이미지들은 좋은 성능을 내는거다. 그리고 그 기대는 맞아 떨어졌다.&lt;/li&gt;
  &lt;li&gt;Masked-out 이미지에서 Baseline 모델이 성능이 굉장히 낮게 나왔는데, 저자들이 어림짐작으로 보았을때 Baseline 모델이 생성한 saliency map의 적대적인 성질인것 겉다. 그 이유는 masked-out 이미지를 채운 inpainted masked-out 이미지와 비교했을 때, Baseline 모델은 성능이 드라마틱하게 향상하는데, CASM 모델은 그 혜택을 많이 못보기 때문이다.
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;코멘트&lt;/strong&gt;: 기존에 완전한 이미지로 모델을 학습 할 때, 주변 사물등 다른 정보를 사용하여 물체를 분류했을 가능성이 있는데, Baseline 모델은 일부 연관된 물체도 지워버리니까 오히려 더 CASM 보다 성능이 하락하는 것 같음. 예를 들어, 아래 그림 처럼 나무를 아예 지워버리니까, 판별을 더 못하는 듯. 어떻게 생각하면 훈련 데이터가 다양하지 못했다는 것이, &lt;code class=&quot;highlighter-rouge&quot;&gt;f(나무 + 새) = 새&lt;/code&gt; 라는 것이 되니까, 주변 사물이 분류기에 많은 영향을 끼치는 것을 알 수 있음.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;figure class=&quot;image&quot;&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1UAR_h0c0RE4uLM5LK3SBu21qj3rcuQLL&quot; alt=&quot;Comparing CASM vs Baseline&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;figcaption&gt;Comparing CASM vs Baseline&lt;/figcaption&gt;&lt;/figure&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;코멘트&lt;/strong&gt;: 자신들이 만든 baseline과 비교한것도 좋지만, 다른 방법(CAM방식) 등 하고 비교해보았어도 괜찮을 것 같음&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;63-object-localization&quot;&gt;6.3 Object localization&lt;/h2&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1WZ6W1xGCCfgnpA-8irC-_l-3Fljbe3aY&quot; alt=&quot;Paper Table 1&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;figcaption&gt;Paper Table 1&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;saliency map으로 weakly supervised localization도 같이 수행했다.&lt;/li&gt;
  &lt;li&gt;3가지 metrics으로 localization을 계량했다.
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;OM&lt;/strong&gt;: ImageNet Localization 챌린지에서 사용하는 official metric, 예측 bounding box와 정답 bounding box의 IOU가 0.5 이상이여야하고, 클래스를 맞춰야한다. 맞췄을 경우 0, 그렇지 않을 경우 1이 되서, OM이 낮을 수록 좋다.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;LE&lt;/strong&gt;: OM방식은 분류기에 따라 다르다. 저자들은 분류기와 상관없이 훈련했기에 bounding box만 예측하는 “Localization Error”라는 다른 방법을 사용했다. (Cao et al. 2015, Fong &amp;amp; Vedaldi 2017) 이 방법도 낮을 수록 좋다.&lt;/li&gt;
      &lt;li&gt;마지막으로 원본 saliency map을 conintious F1 score로 평가했다.
        &lt;ul&gt;
          &lt;li&gt;
            &lt;p&gt;Precision과 Recall은 다음과 같이 정해진다.&lt;/p&gt;

            &lt;script type=&quot;math/tex; mode=display&quot;&gt;P=\dfrac{\sum_{(i,j) \in B^*(x)} m_{ij}(x)}{\sum_{ij} m_{ij}(x)} \quad \text{and} \quad R=\dfrac{\sum_{(i,j) \in B^*(x)} m_{ij}(x)}{\vert B^*(x) \vert}&lt;/script&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;supervised 보다 성능이 대부분 뛰어났다고 주장, 다만 전제 자체가 조금 다르기에 적절한 비교가 힘들다고 함&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;thinning-strategies--score-function--sharing-the-encoder-and-classifier&quot;&gt;Thinning strategies &amp;amp; Score function &amp;amp; Sharing the encoder and classifier&lt;/h3&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1YPJ_KmdfPrHgIeZOSAB1m0ZDi97zsamg&quot; alt=&quot;Paper Table 2&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;figcaption&gt;Paper Table 2&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;$S$: score function 의 선택 (E: entropy loss, C: classification loss)&lt;/li&gt;
  &lt;li&gt;$SHR$: Encoder와 Classifier를 공유 했는지 여부&lt;/li&gt;
  &lt;li&gt;$THIN$: Thinning 전략&lt;/li&gt;
  &lt;li&gt;Entropy 쓰고, parameter sharing하고, L100 thinning 전략인 E가 제일 좋음&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;64-unseen-classes&quot;&gt;6.4 Unseen classes&lt;/h2&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1pyIiM1Np5OWJB85TAczggvXwdFl69pdX&quot; alt=&quot;Paper Table 3&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;figcaption&gt;Paper Table 3&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;제안한 방법이 클래스의 정답을 필요로 하지 않기 때문에, 학습하지 않았던 데이터의 localization을 수행할 수 있다.&lt;/li&gt;
  &lt;li&gt;이를 테스트하기 위해서 1000개의 클래스를 5개(6개아닌가..?)의 서로소 부분집합(disjoint subset)으로 쪼갠다. 즉, 각각의 집합에 서로 다른 클래스가 들어가 있다. 그리고 각 집합에는 다음과 같은 크기의 데이터를 담고, 각각 해당하는 % 만큼 CASM 모델을 훈련시킨다(Thinning은 &lt;strong&gt;L&lt;/strong&gt; 전략 사용).
    &lt;ul&gt;
      &lt;li&gt;A: 50, B: 50, C: 100, D: 300, E: 300, F: 200&lt;/li&gt;
      &lt;li&gt;95%: B, C, D, E, F&lt;/li&gt;
      &lt;li&gt;90%: C, D, E, F&lt;/li&gt;
      &lt;li&gt;80%: D, E, F&lt;/li&gt;
      &lt;li&gt;50%: E, F&lt;/li&gt;
      &lt;li&gt;20%: F&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;모든 모델들의 일반화가 좋은 편이었고, 정확도는 무시할정도 수준으로 작았다(20% 훈련한 모델을 제외).&lt;/li&gt;
  &lt;li&gt;seen과 unseen의 &lt;strong&gt;LE&lt;/strong&gt; 차이는 훈련 데이터가 적어질 수록 높아졌다. 그러나 적당한 크기의 traning set 이라면 차이는 크게 나지 않는다.&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Thu, 23 Jul 2020 11:38:38 +0900</pubDate>
        <link>https://simonjisu.github.io/paper/2020/07/23/casm.html</link>
        <guid isPermaLink="true">https://simonjisu.github.io/paper/2020/07/23/casm.html</guid>
        
        
        <category>paper</category>
        
      </item>
    
      <item>
        <title>[NLP] Mask-Predict: Parallel Decoding of Conditional Masked Language Models</title>
        <description>&lt;p&gt;Paper Link: &lt;a href=&quot;https://arxiv.org/abs/1904.09324&quot;&gt;Mask-Predict: Parallel Decoding of Conditional Masked Language Models&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;모두의 연구소에서 진행하는 “beyondBERT” 프로그램에서 참여하다가 본 논문을 정리해보려고 한다. 흥미롭게 생각했던 논문이라 중요 부분만 일단 정리했다.&lt;/p&gt;

&lt;p&gt;기존의 기계번역등 작업을 진행할때 Seq2Seq 모델(with Attention)을 사용할 경우 보통 autoregressive하게 토큰을 하나씩 디코딩했다. 예를 들어, “내가 아이언맨이다.”라는 문장을 번역하려면, Encoder에 다음과 같이 &lt;code class=&quot;highlighter-rouge&quot;&gt;source&lt;/code&gt; 토큰들을 넣어주고, Decoder는 문장의 시작을 알리는 &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;lt;SOS&amp;gt;&lt;/code&gt; 토큰으로 시작하여 &lt;code class=&quot;highlighter-rouge&quot;&gt;&quot;I&quot;&lt;/code&gt;를 예측하고, 예측한 &lt;code class=&quot;highlighter-rouge&quot;&gt;&quot;I&quot;&lt;/code&gt;로 &lt;code class=&quot;highlighter-rouge&quot;&gt;&quot;am&quot;&lt;/code&gt;을 예측하고, 마지막에 &lt;code class=&quot;highlighter-rouge&quot;&gt;&quot;&amp;lt;EOS&amp;gt;&quot;&lt;/code&gt; 토큰이 등장하면 끝나는 구조다. sudo-code로 다음과 같이 작성 할 수 있겠다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;source&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;나는&quot;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;아이언맨&quot;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;이다&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;.&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&amp;lt;SOS&amp;gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;I&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;am&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;IronMan&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;.&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&amp;lt;EOS&amp;gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;hiddens&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Encoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;source&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;token&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&amp;lt;EOS&amp;gt;&quot;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;token&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&amp;lt;EOS&amp;gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Decoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;token&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hiddens&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;token&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to_token&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predict&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;이 논문에서는 non-autoregressive하게 decoding하는 방법을 제시했는데, 구체적인 방법은 &lt;code class=&quot;highlighter-rouge&quot;&gt;그림1&lt;/code&gt;을 보면 단번에 이해가 되리라고 믿는다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;ul&gt;
    &lt;li&gt;일부 스터디에서 나온 의견 및 개인 의견이 섞여서 들어가 있음을 밝힌다.&lt;/li&gt;
    &lt;li&gt;Model Distillation 부분은 비교군이 적절하지 않다고 스터디에서 나온 의견이 있어서 다루지 않았다.&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;1-introduction&quot;&gt;1. Introduction&lt;/h1&gt;

&lt;p&gt;생략&lt;/p&gt;

&lt;h1 id=&quot;2-cmlmconditional-masked-language-models&quot;&gt;2. CMLM(Conditional Masked Language Models)&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;CMLM은 입력 토큰 $X$와 일부 타겟 토큰 $Y_{obs}$가 주어지면 마스크가 된 타겟 토큰 $Y_{mask}$를 맞추는 문제다.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;강한 가정: 마스크된 타겟 토큰들 $Y_{mask}$은 입력데이터에 대해서 조건부 독립이다.&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\text{Predict: } P(y \vert X, Y_{obs}) \ \forall y \in Y_{mask}&lt;/script&gt;

    &lt;p&gt;이를 분해해보면 다음과 같다.&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned} P(Y_{mask} \vert X, Y_{obs}) &amp;= P(Y_{mask}^{K};Y_{mask}^{1:(K-1)} \vert X, Y_{obs}) P(Y_{mask}^{1:(K-1)} \vert X, Y_{obs}) \\ &amp;= P(Y_{mask}^{K};Y_{mask}^{1:(K-1)} \vert X, Y_{obs}) \cdots P(Y_{mask}^{2};Y_{mask}^{1} \vert X, Y_{obs}) P(Y_{mask}^{1} \vert X, Y_{obs}) \end{aligned} \\ \text{if } Y_{mask} \text{ is conditionally independent by each other } \rightarrow \\ \begin{aligned} P(Y_{mask} \vert X, Y_{obs}) &amp;\approx P(Y_{mask}^{K} \vert X, Y_{obs}) P(Y_{mask}^{K-1} \vert X, Y_{obs}) \cdots P(Y_{mask}^{2} \vert X, Y_{obs}) P(Y_{mask}^{1} \vert X, Y_{obs}) \end{aligned} %]]&gt;&lt;/script&gt;

    &lt;p&gt;(beyondBERT 에서 나온 리뷰: 이러한 최종 예측파트에서는 가정이 맞지만, 훈련시킬때는 아닐 것이다)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;추가로 마스크 개수는 정해져 있기 때문에 토큰 길이에 대한 제약도 명시적으로 달려있는 셈이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;21-architecture&quot;&gt;2.1 Architecture&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;클래식한 Transformer에 Decoder만 Masked-self attention을 제거하기로함&lt;/li&gt;
  &lt;li&gt;fair-style Transformer&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;22-training-objective&quot;&gt;2.2 Training Objective&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;$1$~$N$(토큰길이) 만큼의 uniform distribution에서 랜덤하게 숫자를 고른다음에 그 개수만큼 $Y_{mask}$를 선택&lt;/li&gt;
  &lt;li&gt;Cross-entropy Loss로 최적화, parallel하게 할 수 있는 이유는 이전의 $Y_{mask}$에 취한 conditionally independent 가정 때문이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;23-predicting-target-sequence-length&quot;&gt;2.3 Predicting Target Sequence Length&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;전통적인 left-to-right 기계번역의 경우, 이전 예측 토큰이 다음 예측 토큰으로 들어가게 된다. 그리고 최종적으로 &lt;code class=&quot;highlighter-rouge&quot;&gt;EOS&lt;/code&gt;이 나오면 종료가 되는 형태라서 자동적으로 문장의 길이를 알 수 있었지만 , CMLMs에서는 전체 시퀀스를 parallel하게 예측하기 때문에 타겟 문장 전체의 길이를 예측해야한다.&lt;/li&gt;
  &lt;li&gt;논문에서는 BERT 의 &lt;code class=&quot;highlighter-rouge&quot;&gt;CLS&lt;/code&gt; 토큰처럼, &lt;code class=&quot;highlighter-rouge&quot;&gt;LENGTH&lt;/code&gt; 토큰을 Encoder에 집어넣기로 한다. 해당 토큰의 loss도 마지막에 추가한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;3-decoding-with-mask-predict&quot;&gt;3. Decoding with Mask-Predict&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;요약하면 각 iteration마다 알고리즘은 토큰의 부분집합을 선택하여 masking하고, CMLM으로 예측한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;31-formal-description&quot;&gt;3.1 Formal Description&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;타겟 시퀀스 $(y_1, \cdots, y_N)$ 와 각 토큰의 확률 $(p_1, \cdots, p_N)$이라는 두 변수가 있고, 미러 정의된 $T$번 동안 알고리즘을 돌린다(이는 상수거나 $N$에 관련된 간단한 함수로 결정된다).&lt;/li&gt;
  &lt;li&gt;각 iteration마다 &lt;code class=&quot;highlighter-rouge&quot;&gt;mask&lt;/code&gt; 작업을 수행하고, 예측(&lt;code class=&quot;highlighter-rouge&quot;&gt;predict&lt;/code&gt;)한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;mask&quot;&gt;&lt;strong&gt;Mask&lt;/strong&gt;&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;첫 iteration에는 모든 토큰을 마스킹한다. 그 이후부터는 가장 낮은 확률을 가진 $n$개의 토큰을 masking한다.&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned} Y_{mask}^{(t)} &amp;= \arg \underset{i}{\min} (p_i, n) \\ Y_{obs}^{(t)} &amp;= Y \setminus Y_{mask}^{(t)}\end{aligned} %]]&gt;&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;$n$은 $t$의 함수이며 논문에서는 $n=N \cdot \dfrac{T-t}{T}$를 사용했다($T$는 iteration 횟수).&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;predict&quot;&gt;&lt;strong&gt;Predict&lt;/strong&gt;&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Masking후, CMLM은 주어진 입력$X$와 masking 안된 $Y_{obs}^{(t)}$를 기반으로 $Y_{mask}^{(t)}$를 예측하는데, 각 마스킹된 토큰 $y_i \in Y_{mask}^{(t)}$에 대해서 확률이 가장 높은 것을 예측값으로 선택한다.&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned} y_i^{(t)} &amp;= \arg \underset{w}{\max} P(y_i = w \vert X, Y_{obs}^{(t)} ) \\ p_i^{(t)} &amp;= \underset{w}{\max} P(y_i = w \vert X, Y_{obs}^{(t)} ) \end{aligned} %]]&gt;&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;마스크가 안된 token들은 이전 스텝의 값을 그대로 따라간다.&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned} y_i^{(t)} &amp;=y_i^{(t-1)} \\ p_i^{(t)} &amp;= p_i^{(t-1)} \end{aligned} %]]&gt;&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;특정 토큰의 확률이 계속 희박하여 이러한 휴리스틱한 작업에도 불구하고 잘 작동했다.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;32-example&quot;&gt;3.2 Example&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;그림으로 보면 조금더 이해가 쉬운데, 차후 3.3에서 이야기하는 Length predict 이후의 예시를 들은 것이다.&lt;/li&gt;
  &lt;li&gt;그림에서 나오는 용어들이 있다.
    &lt;ul&gt;
      &lt;li&gt;각 $t$ 스텝 마다 &lt;code class=&quot;highlighter-rouge&quot;&gt;Mask &amp;gt; Predict&lt;/code&gt; 의 과정을 반복한다.&lt;/li&gt;
      &lt;li&gt;$t$: 현재 스텝&lt;/li&gt;
      &lt;li&gt;$n$: masking 해야할 토큰의 수&lt;/li&gt;
      &lt;li&gt;$probability$(보라색): 각 예측의 확률을 담는 container&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;img src=&quot;https://drive.google.com/uc?id=12HUzuQzCWwkaO4B6H07EOkEIJlKpjMnv&quot; alt=&quot;[그림1] Example of parallel decoding&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;figcaption&gt;[그림1] Example of parallel decoding&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;&lt;strong&gt;장점&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;마스킹되지 않았던 것들도 차후에 확률이 다른 토큰에 비해 상대적으로 낮아지면 다시 마스킹될 수도 있다. 즉, 초기에 잘못 예측했더라도, iteration을 통해 점차 바른 예측으로 고쳐질 수도 있다는 것&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;문제점: Multi-modality Problem&lt;/strong&gt;&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1VSrcpclqKZ5KxqJF7yKAw-AP8u-hIuFQ&quot; alt=&quot;[그림2] Paper Figure 1&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;figcaption&gt;[그림2] Paper Figure 1&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;논문의 Figure 1 처럼, t=0 인 상황에서 중복된 단어가 생성 될 수가 있음(“completed”) 이는 non-autoregressive 모델에서 자주 등장하는 문제다. 이는 &lt;code class=&quot;highlighter-rouge&quot;&gt;5.1&lt;/code&gt;에서 자세히 다룬다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;33-deciding-target-sequence-length&quot;&gt;3.3 Deciding Target Sequence Length&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;타켓 문장의 길이인 &lt;code class=&quot;highlighter-rouge&quot;&gt;LENGTH&lt;/code&gt; 토큰을 예측하기 때문에 배치 연산을 할 수 있다.&lt;/li&gt;
  &lt;li&gt;확률이 가장 높은 길이를 여러개 뽑아서 배치 연산으로 3.2의 과정을 할 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1WPZ4xsitujEWF9yfeacc6V587DmjGZ2x&quot; alt=&quot;[그림3] Length Predict&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;figcaption&gt;[그림3] Length Predict&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;차후에 제일 높은 평균 로그 확률로 길이를 선택하게 된다(beam search 와 연관)&lt;/li&gt;
&lt;/ul&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\dfrac{1}{N} \sum_i \log p_i^{(T)}&lt;/script&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;experiments&quot;&gt;Experiments&lt;/h1&gt;

&lt;h2 id=&quot;41-experimental-setup&quot;&gt;4.1 Experimental Setup&lt;/h2&gt;

&lt;h3 id=&quot;translation-benchmarks&quot;&gt;Translation Benchmarks&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;총 3개의 데이터 세트를 사용: WMT’14 EN-DE (4.5M sentence pairs), WMT’16 EN-RO (610k pairs), WMT’17 EN-ZH (20M pairs)&lt;/li&gt;
  &lt;li&gt;모든 데이터는 BPE로 인코딩했으며, 퍼포먼스는 BELU score를 계산했다.&lt;/li&gt;
  &lt;li&gt;EN-ZH 만 ScareBLEU를 사용했다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;hyperparameters&quot;&gt;Hyperparameters&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Attention is All you Need 논문과 똑같이 각 stack마다 6개의 layer, 각 layer마다 8개의 attention heads, 모델 $h_{model}, h_{ffn}$ hidden size는 각 512, 2048로 진행했다.&lt;/li&gt;
  &lt;li&gt;가중치 초기화는 BERT 논문에서 진행한 $\mathcal{N}(0, 0.02)$, bias는 0으로 초기화 했다.&lt;/li&gt;
  &lt;li&gt;LayerNorm은 $\beta=0, \gamma=1$&lt;/li&gt;
  &lt;li&gt;Regularization은 $\text{dropout}=0.3, \text{weight decay}=0.01$ 로 실험했다.&lt;/li&gt;
  &lt;li&gt;Smoothed CV Loss $\varepsilon=0.1$&lt;/li&gt;
  &lt;li&gt;훈련은 Adam에 $\beta=(0.9, 0.999), \varepsilon=10^{-6}$으로 진행, warm up 은 $10000$ 스텝에 $5\cdot 10^{-4}$까지 피크로 가다가 역제곱근의 형태로 내려간다.&lt;/li&gt;
  &lt;li&gt;훈련 스텝은 300k 각 epoch 마다 validation 진행하고, 가장 좋은 5개의 checkpoint를 평균내서 최종모델을 만든다.&lt;/li&gt;
  &lt;li&gt;Decoding을 비교하기 위해서 autoregressive 모델에서 beam search($b=5$), 논문의 모델은 $l=5$개의 후보를 사용해서 decoding했다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;42-translation-quality&quot;&gt;4.2 Translation Quality&lt;/h2&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1sdffQlPXdG9Fgs_O_xgE1xfn-kxIPKmL&quot; alt=&quot;[그림4] Paper Table 1 &amp;amp; 2&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;figcaption&gt;[그림4] Paper Table 1 &amp;amp; 2&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;같은 non-autoregressive 방법들 중에서 논문의 모델이 가장 높은 BLEU score를 달성했다고 주장하고 있다.&lt;/li&gt;
  &lt;li&gt;다른 non-autoregressive 방법들을 확인 해봐야 더 자세히 알것 같다.
    &lt;ul&gt;
      &lt;li&gt;NAT w/ Fertility (&lt;a href=&quot;https://arxiv.org/abs/1802.06901&quot;&gt;Gu et al., 2018&lt;/a&gt;)&lt;/li&gt;
      &lt;li&gt;CTC Loss (&lt;a href=&quot;https://arxiv.org/abs/1811.04719&quot;&gt;Libovicky et al., 2018&lt;/a&gt;)&lt;/li&gt;
      &lt;li&gt;Iterative Refinement(&lt;a href=&quot;https://www.aclweb.org/anthology/D18-1149/&quot;&gt;Lee et al., 2018&lt;/a&gt;)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;43-decoding-speed&quot;&gt;4.3 Decoding Speed&lt;/h2&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1pqAa4SEq-SNleVeUp0IUkcTrzQFqpjLr&quot; alt=&quot;[그림5] Paper Figure 2&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;figcaption&gt;[그림5] Paper Figure 2&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;파란점은 논문저자들의 실험 결과며, &lt;code class=&quot;highlighter-rouge&quot;&gt;L2R b=1&lt;/code&gt;는 beam search(b=1)를 사용한 Left-to-Right(autoregressive) 모델이다.&lt;/li&gt;
  &lt;li&gt;Decoding 스피드와 퍼포먼스간의 trade-off 를 이야기하면, $T=4, l=2$인 경우 2 point의 퍼포먼스를 대가로 &lt;code class=&quot;highlighter-rouge&quot;&gt;L2R b=5&lt;/code&gt;모델 보다 3배의 스피드를 끌어 올릴 수 있다고 주장한다.&lt;/li&gt;
  &lt;li&gt;beyondBERT에서 나온 리뷰중에 하나가 2 point BELU score 면 엄청나게 큰 점수라고 한다(quality 가 상당히 떨어질 수도?!).&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;5-analysis&quot;&gt;5. Analysis&lt;/h1&gt;

&lt;h2 id=&quot;51-why-are-multiple-iterataions-necessary&quot;&gt;5.1 Why Are Multiple Iterataions Necessary?&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Various non-autoregressive 모델에서는 각 예측 토큰들이 서로 조건부 독립이라는 큰 가정이 들어간다. 때문에 예측할때 서로 다른 토큰에 영향을 받지 않아서 다른 위치라도 높은 확률로 같은 토큰을 반복적으로 예측하는 문제가 생긴다.&lt;/li&gt;
  &lt;li&gt;이러한 문제를 Multi-modality 문제라고 &lt;a href=&quot;https://arxiv.org/abs/1711.02281&quot;&gt;Gu et al., 2018&lt;/a&gt;의 논문에서 이야기 한적이 있다.&lt;/li&gt;
  &lt;li&gt;저자들은 예측한 토큰을 모델의 입력으로 사용하여, 반복적인 masking-predict 수행을 통해(multi-modal distribution을 uni-modal distribution으로 전환) 이 문제를 완화시키려고 했다.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1G5DV3t-J1dp6-nOdx9Nh1Vwo-XXy6xpx&quot; alt=&quot;[그림6] Paper Table 3&quot; width=&quot;75%&quot; height=&quot;auto&quot; /&gt;&lt;figcaption&gt;[그림6] Paper Table 3&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;가설을 검증하기 위해서, Proxy Metric으로 중복 된 예측 토큰의 개수가 몇 퍼센트를 차지하는지 살펴보았다. 확실히 $T$가 높아질 수록 해당 비율은 현저하게 줄어든다.&lt;/li&gt;
  &lt;li&gt;$T$가 작을 수록(중복된 토큰 예측이 많아질 수록) BLEU score가 현저하게 낮아지는 것도 이해가 된다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;52-do-longer-sequence-need-more-iterations&quot;&gt;5.2 Do Longer Sequence Need More Iterations?&lt;/h2&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1qf97x-hNgWXtl8NbHJ-z7iUG0KZ-uNg2&quot; alt=&quot;[그림7] Paper Table 4&quot; width=&quot;75%&quot; height=&quot;auto&quot; /&gt;&lt;figcaption&gt;[그림7] Paper Table 4&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;긴 문장일 수록 더 많은 iteration이 도움이 되긴했다. 그러나 $T$가 많아질 수록 연산비용이 많아지는 것을 고려해야 할 것이다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;53-do-more-length-candidates-help&quot;&gt;5.3 Do More Length Candidates Help?&lt;/h2&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;img src=&quot;https://drive.google.com/uc?id=127K3YP4LlTrPHEiu9XO5v7U_rlrByMlA&quot; alt=&quot;[그림8] Paper Table 5&quot; width=&quot;75%&quot; height=&quot;auto&quot; /&gt;&lt;figcaption&gt;[그림8] Paper Table 5&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;적당한 길이 후보($\mathcal{l}$)는 번역에 도움이 되지만 너무 많은 후보를 두면 도움이 안된다.&lt;/li&gt;
  &lt;li&gt;상식적으로 후보들이 비슷한 길이를 가진다면 예측에 도움이 되겠지만, 많은 후보들 중에 비슷하지 않은 길이들이 있다면, 번역의 품질이 떨어질 수밖에 없을 것 같다.&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;개인적-리뷰-및-결론&quot;&gt;개인적 리뷰 및 결론&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;non-autoregressive 모델의 decoding은 실무에서 빠르게 decoding 할 수있기 때문에 앞으로 연구할 가치가 있는 분야인것 같다.&lt;/li&gt;
  &lt;li&gt;이런 분야도 있다는 것을 처음 접해서 신선한 decoding 방법이라고 생각했다. 다른 decoding 방법들(&lt;a href=&quot;https://www.facebook.com/groups/ChatbotDevKR/permalink/1000241780393951/&quot;&gt;챗봇 코리아 게시물&lt;/a&gt;)도 참고하면 좋을 것 같다.&lt;/li&gt;
  &lt;li&gt;그러나 해결되지 않은 몇 가지 문제(multi-modality)를 해결할 필요가 있어 보인다.&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sun, 19 Jul 2020 11:38:38 +0900</pubDate>
        <link>https://simonjisu.github.io/paper/2020/07/19/maskpredict.html</link>
        <guid isPermaLink="true">https://simonjisu.github.io/paper/2020/07/19/maskpredict.html</guid>
        
        
        <category>paper</category>
        
      </item>
    
      <item>
        <title>대학원 1학기 후기</title>
        <description>&lt;p&gt;2020년이 시작한지 얼마 안된것 같은데, 벌써 데이터 사이언스 대학원에 들어온 지 거의 4개월이 지났다. 올해 첫 개설하는 대학원으로 기대반 걱정반으로 시작했는데, 우선 첫 학기는 잘 마무리한것 같다. 숨가쁘게 달려온 첫학기에 어떻게 지냈는지 이야기를 해보려고 한다.&lt;/p&gt;

&lt;h1 id=&quot;한-학기동안-배운것&quot;&gt;한 학기동안 배운것&lt;/h1&gt;

&lt;p&gt;이번 학기에 총 4개의 수업들 들었다. 사실상 수업이 많지 않아 보이지만, 올해 코로나로 인해, 수업 방식이 100% 온라인으로 전환되면서, 사실상 온라인 수업-과제 및 프로젝트의 무한 루프였다. 여유로울것 같아 보이는데, 생각보다 빠듯했다. 앞으로 연구까지하면 시간을 잘 배분해야 할 것 같다.&lt;/p&gt;

&lt;p&gt;1학기 후기를 요약하자면&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;프로젝트에 사용되는 데이터를 전처리 하거나 탐색하는 시간이 제일 많았던 것 같았다.&lt;/li&gt;
  &lt;li&gt;머리속에 있는 로직을 코드로 구현하는데 시간이 생각보다 오래걸린 다는 것을 다시 한번 확인하게 됐다.&lt;/li&gt;
  &lt;li&gt;다양한 프로그램을 사용해보았는데(Neo4j, SAP HANA, Spark 등등), 튜토리얼과 Documentation의 중요성을 다시 한번 깨달은 수업들이 있었다(왠만하면 사람들이 많이 쓰는 것을 쓰자).&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;1학기에 들었던 수업을 간략하게 정리하면 다음과 같다.&lt;/p&gt;

&lt;h2 id=&quot;빅데이터-및-지식-관리-시스템&quot;&gt;빅데이터 및 지식 관리 시스템&lt;/h2&gt;

&lt;p&gt;이 수업은 “데이터가 어떻게 저장되고 관리되어야하는가?” 라고 한마디로 표현할 수 있겠다. 밑단에서 데이터 저장을 위해, 필요한 정보를 효율적으로 저장하는 방법을 배웠다. 주요 개념들을 나열하면 다음과 같다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;relational model: (In-Memory) DBMS, SQL&lt;/li&gt;
  &lt;li&gt;storage: 데이터가 저장되는 방식 contiguous vs paged, row store vs column store&lt;/li&gt;
  &lt;li&gt;concurrency control: 데이터베이스의 버전 관리 시스템&lt;/li&gt;
  &lt;li&gt;logging: 컴퓨터가 예기치 못한 상황에서 종료 됐을 때 복구하는 방법, undo logging vs redo logging&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;데이터-사이언스를-위한-소프트웨어-플랫폼&quot;&gt;데이터 사이언스를 위한 소프트웨어 플랫폼&lt;/h2&gt;

&lt;p&gt;이 수업은 초중반에는 알고리즘 및 자료구조를 배우고, 중후반에는 데이터 분석 및 딥러닝에 사용되는 NumPy, pandas, PyTorch, Tensorflow 등 패키지를 다룬다.&lt;/p&gt;

&lt;p&gt;개인적으로 학부전공이 경제학이라 자료구조 및 알고리즘등을 몰랐는데, 이번 수업을 통해서 일부이지만 조금 체계적으로 배운것 같다. 매주 과제를 내줘서 컴공에 근접한 수업(실제로 들어보진 않았지만 소문으로는 ㅎㅎ)인것 같다.&lt;/p&gt;

&lt;h2 id=&quot;데이터-사이언스를-위한-머신러닝-및-딥러닝&quot;&gt;데이터 사이언스를 위한 머신러닝 및 딥러닝&lt;/h2&gt;

&lt;p&gt;사실상 머신러닝과 딥러닝 알고리즘을 전체적으로 훑어보는 과정이다. 너무 많은 것을 다루다보니 초심자에게는 조금 버거웠던 수업인것 같다. 다만 다양한 생각해보지 못했던 프로젝트들을 경험해서 좋았다. 예를 들어, 코로나와 관련된 CNN 뉴스 등을 보고 분석글을 쓴다던지, “오늘 저녁에 뭐먹지?”라는 주제로 수도코드를 작성하기 등이 있었다. 이런 프로젝트를 통해서 데이터를 다루는 사람은 어떤 생각을 가져야하는지 배운것 같다. 이미 주어진 문제에 대해서 모델링 하는것도 중요하지만, 실생활과 연관된 다양한 프로젝트를 통해, 문제를 어떻게 정의할 것인지, 데이터 탐색을 하고 어떻게 해결할 것인지를 더 많이 배운 수업이다.&lt;/p&gt;

&lt;h2 id=&quot;데이터-사이언스-세미나-특강&quot;&gt;데이터 사이언스 세미나 특강&lt;/h2&gt;

&lt;p&gt;세미나 특강은 Google, IBM, NYU 등 유명한 기업이나 대학교에서 다양한 분야의 전문가 분들께서 오셔서 강의를 해주시는 수업이다. 개인적으로 조경현 교수님의 “learning to finding evidence” 강의가 제일 좋았었는데, 이전 회사에서 했던 일도 있고, 앞으로 하고싶은 분야의 이야기를 해주셔서 더 관심을 가졌던것 같다.&lt;/p&gt;

&lt;p&gt;일부 세미나 영상은 아래 사이트에서 공개하고 있으니 관심가지는 주제가 있다면 시청을 추천한다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://gsds.snu.ac.kr/ko/board/seminar_info/view/122&quot;&gt;데이터 사이언스 세미나 특강 링크&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;지도교수-시스템&quot;&gt;지도교수 시스템&lt;/h1&gt;

&lt;p&gt;이 대학원은 일반 대학원과 약간 다른 지도교수 시스템을 가지고 있다. 기존에는 입학전에 다른 교수님에게 컨택해서 이야기를 나누는 반면, 여기는 입학 후 1학기가 지난 시점에서 지도교수를 선택하는 시스템이다. 2학기가 끝나기 전에 한번더 선택할 수 있는 기간이 있어서, 1학기에 선택하지 못했다면 미뤄도 된다. 다만 이번이 첫 개설이고 첫학기라 더 다양한 수업과 다른 교수님들을 만나지 못해서 조금 아쉬운 점이 있다. 차후에 다양한 분야의 교수님께서 오신다면 선택의 폭이 조금 넓어질 것 같다.&lt;/p&gt;

&lt;h1 id=&quot;향후-계획과-다짐&quot;&gt;향후 계획과 다짐&lt;/h1&gt;

&lt;p&gt;앞으로 올해 초에 공부 했던 XAI 쪽으로 더 공부와 연구를 해볼 생각이다(물론 NLP 도 놓고 싶지 않아서 현재 논문스터디도 하고 있다만… 욕심가득…). 이 분야의 발전이 워낙 빨라서 끈기있게 더 달려야할 시기인것 같다. 나 자신을 뒤돌아 봤을 때 후회가 남지 않도록, 남은 일년 반 동안 더 열심히 성장 해야겠다.&lt;/p&gt;
</description>
        <pubDate>Sun, 05 Jul 2020 11:38:38 +0900</pubDate>
        <link>https://simonjisu.github.io/others/2020/07/05/gsds1.html</link>
        <guid isPermaLink="true">https://simonjisu.github.io/others/2020/07/05/gsds1.html</guid>
        
        
        <category>others</category>
        
      </item>
    
      <item>
        <title>[Algorithms] Comparison Sort</title>
        <description>&lt;h1 id=&quot;comparison-sort&quot;&gt;Comparison Sort&lt;/h1&gt;

&lt;p&gt;지금까지 봐온 정렬 알고리즘들은 원소들간의 어떤 추상적인 비교연산을 통해 순서를 정하기 때문에 &lt;a href=&quot;https://en.wikipedia.org/wiki/Comparison_sort&quot;&gt;비교 정렬(comparison sort)&lt;/a&gt;이라고 한다. 이번 포스팅에서는 각 정렬방법들의 비교를 해보려고 한다.&lt;/p&gt;

&lt;h2 id=&quot;각-정렬-방법들간-비교&quot;&gt;각 정렬 방법들간 비교&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Sort&lt;/th&gt;
      &lt;th&gt;Worst $T(N)$&lt;/th&gt;
      &lt;th&gt;Best $T(N)$&lt;/th&gt;
      &lt;th&gt;Stability&lt;/th&gt;
      &lt;th&gt;Inplace&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Bubble&lt;/td&gt;
      &lt;td&gt;$O(N^2)$&lt;/td&gt;
      &lt;td&gt;$O(N^2)$&lt;/td&gt;
      &lt;td&gt;Yes&lt;/td&gt;
      &lt;td&gt;Yes&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Insertion&lt;/td&gt;
      &lt;td&gt;$O(N^2)$&lt;/td&gt;
      &lt;td&gt;$O(N^2)$&lt;/td&gt;
      &lt;td&gt;Yes&lt;/td&gt;
      &lt;td&gt;Yes&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Selection&lt;/td&gt;
      &lt;td&gt;$O(N^2)$&lt;/td&gt;
      &lt;td&gt;$O(N^2)$&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;Yes&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Merge&lt;/td&gt;
      &lt;td&gt;$O(N\log N)$&lt;/td&gt;
      &lt;td&gt;$O(N\log N)$&lt;/td&gt;
      &lt;td&gt;Yes&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Quick&lt;/td&gt;
      &lt;td&gt;$O(N^2)$&lt;/td&gt;
      &lt;td&gt;$O(N\log N)$&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;Yes&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;각-정렬-방법들의-시간-복잡도-비교&quot;&gt;각 정렬 방법들의 시간 복잡도 비교&lt;/h2&gt;

&lt;p&gt;각 정렬 방법들의 시간 복잡도를 비교하기 위해서 다음과 같은 실험을 하였다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;입력 리스트의 크기 n 은 2000 부터 시작하여 17000 까지 1000 개씩 추가하여, 총 16 개 크기로 진행한다.&lt;/li&gt;
  &lt;li&gt;각 입력 크기마다 10회 실험을 진행하고, 리스트는 0 ~ 2000 사이의 숫자로 랜덤 샘플링을 하여 구성한다(2000 포함). 최종 수치는 10회 실험의 평균 값으로 결정한다.&lt;/li&gt;
  &lt;li&gt;각 알고리즘이 실행되는 실제 시간(t로 표기)은 time 패키지로 시작시간과 끝나는 시간의 차이로 측정한다.&lt;/li&gt;
  &lt;li&gt;입력크기에 따라 차이나 너무 크게 나서 기존 수치과 log로 변환한 수치를 같이 본다. 각 복잡도 수치를 log로 치환하면 &lt;code class=&quot;highlighter-rouge&quot;&gt;그림1&lt;/code&gt;과 같다.&lt;/li&gt;
&lt;/ol&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;img src=&quot;https://drive.google.com/uc?id=129gdSPce6z6nLokn6uJPZszfBt9Qa4G-&quot; alt=&quot;[그림1] Sorting Experiment&quot; width=&quot;110%&quot; height=&quot;auto&quot; /&gt;&lt;figcaption&gt;[그림1] Sorting Experiment&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;실험진행의 결과는 &lt;code class=&quot;highlighter-rouge&quot;&gt;그림2&lt;/code&gt;와 같다. selection sort와 insertion sort는 비슷한 시간을 가진다는 것을 알 수있다. 반면 bubble sort는 두 번의 for문을 모두 꼭 돌아야하기 때문에 이들 보다 실행히간이 많이 걸린다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1dPN8TOjaW3wzEEz62i80fVOj0WOjmJQc&quot; alt=&quot;[그림2] 모든 알고리즘의 Time Complexity&quot; width=&quot;110%&quot; height=&quot;auto&quot; /&gt;&lt;figcaption&gt;[그림2] 모든 알고리즘의 Time Complexity&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;merge sort와 quick sort는 비슷한 실행시간을 가진다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1HQsKgKLFKRSrK8hyRzIKtlyAK9gFP3fk&quot; alt=&quot;[그림3] merge sort와 quick sort의 Time Complexity&quot; width=&quot;110%&quot; height=&quot;auto&quot; /&gt;&lt;figcaption&gt;[그림3] merge sort와 quick sort의 Time Complexity&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 id=&quot;stability&quot;&gt;Stability&lt;/h2&gt;

&lt;p&gt;Stability는 Stable 과 Unstable 두 가지로 나뉘는데, 정렬 후에도 기존 입력 시퀀스의 특성 또한 그 순서을 유지하는 것이 stable sort, 그렇지 않은 것을 unstable sort라고 한다. 다음 &lt;code class=&quot;highlighter-rouge&quot;&gt;그림4&lt;/code&gt;처럼 카드를 숫자의 순서대로 정렬하려고 한다. 각 카드는 고유의 문양이 같이 있다. 기존의 문양 순서대로 정렬되면 stable sort라고 한다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1fPY3iG4szY1UxiB6D6c_yn4x7aL_yFfr&quot; alt=&quot;[그림4] 카드 정렬하기&quot; width=&quot;110%&quot; height=&quot;auto&quot; /&gt;&lt;figcaption&gt;[그림4] 카드 정렬하기&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;각 정렬 알고리즘의 stability를 확인해보면 Bubble, Insertion, Merge는 stable sort고, Selection과 Quick은 unstable sort다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;colver&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;diamond&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;diamond&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;heart&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;spade&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;spade&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bubble_sort_key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'diamond'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'spade'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'diamond'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'heart'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'colver'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'spade'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;insertion_sort_key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'diamond'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'spade'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'diamond'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'heart'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'colver'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'spade'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;selection_sort_key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'diamond'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'spade'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'heart'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'diamond'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'colver'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'spade'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;merge_sort_key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'diamond'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'spade'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'diamond'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'heart'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'colver'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'spade'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;quick_sort_key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
&lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'spade'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'diamond'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'diamond'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'heart'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'colver'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'spade'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h1 id=&quot;references&quot;&gt;References:&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;본 글은 기본적으로 서울대학교 이재진 교수님의 강의를 듣고 제가 공부한 것을 정리한 글입니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;관련-포스팅&quot;&gt;관련 포스팅:&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://simonjisu.github.io/python/2020/05/02/bubbleinsertion.html&quot;&gt;Bubble Sort &amp;amp; Insertion Sort&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://simonjisu.github.io/python/2020/05/02/selection.html&quot;&gt;Selection Sort&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://simonjisu.github.io/python/2020/05/03/merge.html&quot;&gt;Merge Sort&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://simonjisu.github.io/python/2020/05/04/quick.html&quot;&gt;Quick Sort&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;(현재글)&lt;a href=&quot;https://simonjisu.github.io/python/2020/06/06/comparisonsort.html&quot;&gt;Comparsion Sort&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sat, 06 Jun 2020 11:38:38 +0900</pubDate>
        <link>https://simonjisu.github.io/python/2020/06/06/comparisonsort.html</link>
        <guid isPermaLink="true">https://simonjisu.github.io/python/2020/06/06/comparisonsort.html</guid>
        
        
        <category>python</category>
        
      </item>
    
      <item>
        <title>Binary Relation</title>
        <description>&lt;p&gt;이번 포스팅에서는 이항관계(Binary Relation)의 수학적 정의에 대해서 알아보려고 한다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Binary_relation&quot;&gt;이항관계(Binary Relation)&lt;/a&gt;&lt;/strong&gt; 란 다음과 같은 두 집합의 곱집합의 부분집합으로 정의된다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;순서쌍(Ordered pairs): 두 집합($A, B$)이 있고, 두 집합의 곱집합(Cartesian product, $A\times B$)에 속한 원소 $\lbrace (a, b) \vert a \in A, b\in B \rbrace$ 를 순서쌍이라고 한다.&lt;/li&gt;
  &lt;li&gt;관계 집합 $R$의 원소가 순서쌍이라면, $R$을 이항관계라고 한다. $(a, b) \in R$를 $aRb$로 표기한다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;어떤 집합 $A$에 이항관계 $R$이 있다고 말하는 것은 $R$은 $A\times A$의 부분 집합이라고 말하는 것과 같다.&lt;/p&gt;

&lt;p&gt;예를 들어, 자연수 집합($\Bbb{N}$)에 대하여 “…보다 작다”라는 관계 $\lt$는 다음과 같이 정의된다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\lt =\{ (a, b): a, b \in \Bbb{N} \text{  and  } a \lt b \}&lt;/script&gt;

&lt;p&gt;예를 들어, 순서쌍 $(1, 3)$은 $aRb = 1 \lt 3$ 이라는 관계를 만족하기 때문에(당연히 자연수 집합의 원소 조건도 만족), 따라서 $(1, 3)$은 이항관계 $\lt$에 속한다고 말할 수 있다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;properties-of-relations&quot;&gt;Properties of Relations&lt;/h1&gt;

&lt;h2 id=&quot;reflexive-binary-relations&quot;&gt;Reflexive Binary Relations&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://ko.wikipedia.org/wiki/반사관계&quot;&gt;반사(Reflexive) 이항관계&lt;/a&gt;&lt;/strong&gt;란 모든 집합 $A$에 속하는 원소 $a$에 대하여 $aRa$ 관계를 만족하는 이항관계를 말한다. 자기 자신과의 relation 성립여부로 생각하면 편하다.&lt;/p&gt;

&lt;p&gt;예를 들어 이항관계 $\leq$은 다음과 같이 정의되는데, 순서쌍 $a=4$일 경우 $aRa = 4 \leq 4$이기 때문에 reflexive하다고 말할 수 있다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\leq = \lbrace (a, b): a, b \in \Bbb{N} \text{  and  } a \leq b \rbrace&lt;/script&gt;

&lt;p&gt;반면, 이전에 본 이항관계 $\lt$는 $aRa$를 만족할 수 없기 때문에 reflexive 하지 않다고 말할 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;symmetric--antisymmetric-binary-relations&quot;&gt;Symmetric &amp;amp; Antisymmetric Binary Relations&lt;/h2&gt;

&lt;p&gt;$a, b \in A$에서 $aRb$이면 $bRa$일 경우, 이러한 관계 $R$을 &lt;strong&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Symmetric_relation&quot;&gt;대칭(Symmetric)관계&lt;/a&gt;&lt;/strong&gt;라고 한다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\forall a, b \in A, aRb \Rightarrow bRa&lt;/script&gt;

&lt;p&gt;예를 들어, 순서쌍 $(1, 1)$과 “같다”($=$)라는 관계에 대해서, $1^{ left } = 1^{ right }$ 는 $1^{ right } = 1^{ left }$를 의미하기 때문에, “같다”관계는 Symmetric Relation 이다.&lt;/p&gt;

&lt;p&gt;$a, b \in A$에서 $aRb$와 $bRa$가 $a=b$를 도출한다면, $R$은 &lt;strong&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Antisymmetric_relation&quot;&gt;반대칭(Antisymmetric)관계&lt;/a&gt;&lt;/strong&gt;라고 한다. 반대칭관계는 대칭관계의 반대가 아니라는 점을 명심하자(한글보다는 영어로 쓰는게 더 이해가 쉽다).&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\forall a, b \in A, aRb \land bRa \Rightarrow a=b&lt;/script&gt;

&lt;p&gt;예를 들어, 순서쌍 $(1, 1)$과 “…보다 작거나 같다”라는 관계 $\leq$는 $1^{ left } \leq 1^{ right }$ 와 $1^{ right } \leq  1^{ left }$ 로부터 $1^{ left } = 1^{ right }$ 를 도출할 수 있기 때문에, Antisymmetric Relation 이다.&lt;/p&gt;

&lt;h2 id=&quot;transitive-binary-relations&quot;&gt;Transitive Binary Relations&lt;/h2&gt;

&lt;p&gt;모든 $a, b, c \in A$에 대해서 $aRb$와 $bRc$ 관계로부터 $aRc$를 도출할 경우 &lt;strong&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Transitive_relation&quot;&gt;추이적(Transitive) 관계&lt;/a&gt;&lt;/strong&gt;라고 한다(영어가 더 직관적이다).&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\forall a, b, c \in A, aRb \land bRc \Rightarrow aRc&lt;/script&gt;

&lt;p&gt;예를 들어, $a=1, b=2, c=3$일때, “…보다 작거나 같다”라는 관계 $\leq$는 Transitive Relation이다. 왜냐면 $1 \leq 2$와 $2 \leq 3$로부터 $1 \leq 3$을 추론할 수 있기 때문이다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;equivalence-relations&quot;&gt;Equivalence Relations&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Equivalence_relation&quot;&gt;동치(Equivalence) 관계&lt;/a&gt;&lt;/strong&gt;는 Reflexive, Symmetric, Transitive 관계를 모두 만족하는 관계를 말한다.&lt;/p&gt;

&lt;p&gt;예를 들어, 자연수 $a, b, c$에 대하여($\lbrace a, b, c \rbrace \in \Bbb{N}$), “같다”($=$)는 동치 관계라고 말할 수 있다. 그 이유는 다음과 같다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Reflexive: $a = a$&lt;/li&gt;
  &lt;li&gt;Symmetric: $a=b$는 곧 $b=a$이다.&lt;/li&gt;
  &lt;li&gt;Transitive: $a=b$와 $b=c$로부터 $a=c$를 알 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;equivalence-classes&quot;&gt;Equivalence Classes&lt;/h2&gt;

&lt;p&gt;관계 $R$이 집합 $A$($a\in A$)에 대하여 동치 관계를 만족하는 경우, $a$의 &lt;strong&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Equivalence_class&quot;&gt;동치류(Equivalence Class)&lt;/a&gt;&lt;/strong&gt;는 집합 $[a]={b\in A : aRb}$으로 정의할 수 있는데, 이는 해당 집합의 모든 원소가 $a$와 동등(equivalent)하다고 할 수 있다.&lt;/p&gt;

&lt;p&gt;자연수 $a, b$와 $a+b$가 짝수인 관계 $R$을 예로 들어본다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;R = \lbrace (a, b): a, b \in \Bbb{N} \text{  and  } a+b \ \text{ is even number} \rbrace&lt;/script&gt;

&lt;p&gt;해당 관계에 만족하는  equivalence relation&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Reflexive: $aRa$가 짝수 인지, 예)&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;3 + 3 = 6(\text{even})&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Symmetric: $aRb$가 짝수 일때 $bRa$도 짝수인지, 예)&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;3 + 5 = 8(\text{even}) \Rightarrow 5 + 3 = 8(\text{even})&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Transitive: $aRb$, $bRc$가 짝수 일때, $aRc$도 짝수인지, 예)&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;[3+5=8(\text{even})] \land [5+7=12(\text{even})] \Rightarrow 3+7 = 10(\text{even})&lt;/script&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Transitive의 증명 예시: &lt;a href=&quot;https://math.stackexchange.com/questions/311151/equivalence-relation-even-number&quot;&gt;링크&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;이때 자연수 4의 equivalence class는 $[4] = \lbrace 0, 2, 4, 6, \cdots \rbrace$라고 할 수 있다. 왜냐면 $b = 0, 2, 4, \cdots$등 짝수와 $4$를 더하면($4Rb$) 짝수가 나오기 때문이다.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;partial-order--total-order&quot;&gt;Partial Order &amp;amp; Total Order&lt;/h1&gt;

&lt;h2 id=&quot;partial-order&quot;&gt;Partial Order&lt;/h2&gt;

&lt;p&gt;집합 $X$에서 Reflexive, Antisymmetric, Transitive를 만족하는 관계 $R$을 &lt;strong&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Partially_ordered_set&quot;&gt;부분 순서(Partial Order)&lt;/a&gt;&lt;/strong&gt;라고 한다. 또한, $(X, R)$을 부분 순서 집합(Partial Ordered Set)이라고 한다.&lt;/p&gt;

&lt;p&gt;예를 들어, 집합 $X = \lbrace a, b, c \rbrace$의 멱집합(power set) $P$와 포함 관계$\subseteq$는 부분 순서 집합이라고 할 수 있다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P = \lbrace 
 \emptyset , \lbrace a \rbrace, \lbrace b \rbrace, \lbrace c \rbrace, \lbrace a, b \rbrace, \lbrace b, c \rbrace, \lbrace c, a \rbrace, \lbrace a, b, c \rbrace
\rbrace&lt;/script&gt;

&lt;p&gt;그 이유는 다음과 같다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Reflexive:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\forall \lbrace x \rbrace \in P,\quad \lbrace x \rbrace \subseteq \lbrace x \rbrace&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Antisymmetric:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\forall \lbrace x \rbrace, \lbrace y \rbrace \in P,\quad (\lbrace x \rbrace \subseteq \lbrace y \rbrace) \land (\lbrace y \rbrace \subseteq \lbrace x \rbrace) \Rightarrow (\lbrace x \rbrace = \lbrace y \rbrace)&lt;/script&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Transitive:&lt;/p&gt;

    &lt;script type=&quot;math/tex; mode=display&quot;&gt;\forall \lbrace x \rbrace, \lbrace y \rbrace, \lbrace z \rbrace \in P,\quad (\lbrace x \rbrace \subseteq \lbrace y \rbrace) \land (\lbrace y \rbrace \subseteq \lbrace z \rbrace) \Rightarrow (\lbrace x \rbrace \subseteq \lbrace z \rbrace)&lt;/script&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;total-order&quot;&gt;Total Order&lt;/h2&gt;

&lt;p&gt;모든 $a, b \in A$에 대해서 $aRb$ 혹은 $bRa$을 만족할 때(혹은 둘다 만족), 집합 $A$에 대한 관계 $R$을 &lt;strong&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Total_order&quot;&gt;전순서(Total Order)&lt;/a&gt;&lt;/strong&gt;라고 한다. 또한, $(A, R)$을 전순서 집합(Total Ordered Set)이라고 한다.&lt;/p&gt;

&lt;p&gt;이전에 이야기한 $X = \lbrace a, b, c \rbrace$의 부분 순서 집합 $(P, \subseteq)$의 예시 경우, $\lbrace a \rbrace \not\subseteq \lbrace b \rbrace$ 이기 때문에 전순서 집합이 아니라고 할 수 있다.&lt;/p&gt;

&lt;p&gt;전순서 집합의 예시를 들자면 다음과 같다. 만약 $Y = \emptyset$ 라면, $Y$의 멱집합 $P = \lbrace \emptyset \rbrace$ 인데, 이때 $\emptyset \subseteq \emptyset$ 이기 때문에(반대도 마찬가지), 집합 $Y$에 대한 관계 $\subseteq$는 전순서(Total Order)이라고 할 수 있다.&lt;/p&gt;

&lt;p&gt;증명 예시: &lt;a href=&quot;https://math.stackexchange.com/questions/2454424/showing-that-px-subseteq-is-a-partial-order-total-order-or-lattice&quot;&gt;링크&lt;/a&gt;&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&quot;references&quot;&gt;References:&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;본 글은 기본적으로 서울대학교 이재진 교수님의 강의를 듣고 제가 공부한 것을 정리한 글입니다.&lt;/li&gt;
  &lt;li&gt;Introduction to Algorithms, by Thomas H. Cormen (In Appendix)&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Thu, 14 May 2020 11:38:38 +0900</pubDate>
        <link>https://simonjisu.github.io/math/2020/05/14/relation.html</link>
        <guid isPermaLink="true">https://simonjisu.github.io/math/2020/05/14/relation.html</guid>
        
        
        <category>math</category>
        
      </item>
    
      <item>
        <title>[Algorithms] Quick Sort</title>
        <description>&lt;h1 id=&quot;quick-sort&quot;&gt;Quick Sort&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;퀵 정렬(Quick Sort)&lt;/strong&gt;도 분할정복(devide &amp;amp; conquer) 알고리즘 중에 하나다. 전체 프로세스는 합병 정렬과 같은데 프로세스는 다음과 같다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Devide
 피벗(pivot)원소를 골라서, 입력을 피벗원소보다 작은 쪽은 왼쪽, 피벗보다 큰쪽은 오른쪽으로 나눈다. 따라서 무조건 반으로 나뉘는 합병 정렬과 달리 좌우 입력의 길이가 달라질 수 도 있다.&lt;/li&gt;
  &lt;li&gt;Conquer
 재귀적으로 두 파트를 다시 분할하고 정렬 한다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;그림1&lt;/code&gt;과 같이 알고리즘의 각 스텝을 표현할 수 있다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1EhKY4ujGLYJk7J5sX-IjTpuPSKI_1w1Q&quot; alt=&quot;[그림1] Quick Sort-1&quot; width=&quot;75%&quot; height=&quot;auto&quot; /&gt;&lt;figcaption&gt;[그림1] Quick Sort-1&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;각 스텝에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;partition&lt;/code&gt;이라는 함수를 재귀적으로 호출하게 된다. 예를 들어 첫번째 스텝의 결과는 &lt;code class=&quot;highlighter-rouge&quot;&gt;그림2&lt;/code&gt;의 과정을 통해 얻는다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;img src=&quot;https://drive.google.com/uc?id=17ikyWsTHY_CgYu28Y2ciahXoi_Id5sCe&quot; alt=&quot;[그림2] Quick Sort-2&quot; width=&quot;75%&quot; height=&quot;auto&quot; /&gt;&lt;figcaption&gt;[그림2] Quick Sort-2&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;보통 입력의 제일 첫번째 원소를 피벗(pivot)으로 두고 정렬을 시작한다. 그리고 비교대상의 인덱스 &lt;strong&gt;j&lt;/strong&gt;의 순환을 통해 피벗의 위치 인덱스 &lt;strong&gt;m&lt;/strong&gt;을 찾는 과정을 거친다. &lt;strong&gt;j&lt;/strong&gt;가 순환하면서 피벗보다 작으면, &lt;strong&gt;j-1&lt;/strong&gt;번째 원소와 교환(swap)을 하고, &lt;strong&gt;m&lt;/strong&gt;을 하나씩 증가 시킨다. 마지막으로 &lt;strong&gt;j&lt;/strong&gt;의 순환이 끝나면 &lt;strong&gt;m&lt;/strong&gt;의 위치해 있는 원소와 피벗을 교환한다&lt;/p&gt;

&lt;p&gt;재귀함수가 호출 될때마다 하나의 원소가 피벗으로 위치가 정해지기 때문에, 원소가 하나가 남게되면 재귀가 끝나게 된다. 조금더 큰 예시를 들면 &lt;code class=&quot;highlighter-rouge&quot;&gt;그림3&lt;/code&gt; 과 같다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1gvg6cfbe2loulMnOcQwO8BIursi03Uf3&quot; alt=&quot;[그림3] Quick Sort-3&quot; width=&quot;75%&quot; height=&quot;auto&quot; /&gt;&lt;figcaption&gt;[그림3] Quick Sort-3&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;퀵 정렬은 새로운 메모리가 필요하지 않은 inplace 알고리즘이다. 코드로 구현하면 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;quick_sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;r&quot;&quot;&quot;
    Quick Sort
    Args: 
        l: input list
    Return:
        sorted list by ascending
    &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;partition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;low&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;high&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;r&quot;&quot;&quot;
        Partitioin the list into small and large part by pivot
        Args:
            l: input list
            low: lowest index of the partitioned list
            high: highest index of the partitioned list
        Return:
            pivot index in the list
        &quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;swap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;s&quot;&gt;r&quot;&quot;&quot;swap p-th element and q-th element&quot;&quot;&quot;&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;pivot&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;low&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;low&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;low&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;high&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pivot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;swap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;swap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;low&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;low&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;high&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;r&quot;&quot;&quot;
        stop sorting when the `low` index is higher then `high` index 
        &quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;low&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;high&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;pivot_idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;low&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;high&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;low&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pivot_idx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pivot_idx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;high&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;알고리즘-복잡도&quot;&gt;알고리즘 복잡도&lt;/h2&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;pivot&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;low&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 1&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;low&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 1&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;low&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;high&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# k-1&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pivot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 비교: k-1&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# k-1&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;swap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 교환: k-1&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;swap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;low&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 교환: 1&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;먼저 &lt;code class=&quot;highlighter-rouge&quot;&gt;partition&lt;/code&gt; 함수의 복잡도를 분석하면 다음과 같다. 만약 정렬해야할 입력 원소의 개수가  $k$ 라면, 비교와 교환을 하는데 각 $k-1$ 번이 필요하기에 총 $c \times k$ 번이 필요하다. 따라서, $T(k) = O(k)$라고 할 수 있다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;low&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;high&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pivot_idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;partition&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;low&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;high&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;low&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pivot_idx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pivot_idx&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;high&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;이제 &lt;code class=&quot;highlighter-rouge&quot;&gt;sort&lt;/code&gt; 함수가 몇번 재귀적으로 호출 되었는지만 계산하면 모든 계산이 끝난다. $N$ 개의 입력 원소가 있다면, 각 i 단계(level)에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;partition&lt;/code&gt; 함수가 얼마나 호출 되는지 생각해보자.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1Q9xmO9uGQ8791Nd_RGuzfCt7HdwL7s-r&quot; alt=&quot;[그림4] Quick Sort-4&quot; width=&quot;60%&quot; height=&quot;auto&quot; /&gt;&lt;figcaption&gt;[그림4] Quick Sort-4&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;그림4&lt;/code&gt;와 같이 최악의 경우, 가령 이미 정렬되어 있을 때, 피벗원소와 피벗원소보다 큰 파트로 나뉠 것이며, &lt;code class=&quot;highlighter-rouge&quot;&gt;sort&lt;/code&gt;함수는 총 $N$ 번이 호출된다. 즉, 총 단계의 깊이는 $N$ 이라고 생각할 수 있다. 또한, 각 단계에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;partition&lt;/code&gt;은 입력 길이 $k$에 의존하기 때문에, 이를 고려하면 $T(N) = O(N + (N-1) + (N-2) + \cdots + 1)) = O(N^2)$ 만큼의 복잡도를 가진다고 할 수 있다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1FZn63RSPIkIgJKMc958mpD8jdsUxPck6&quot; alt=&quot;[그림5] Quick Sort-5&quot; width=&quot;75%&quot; height=&quot;auto&quot; /&gt;&lt;figcaption&gt;[그림5] Quick Sort-5&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;최상의 경우는 &lt;code class=&quot;highlighter-rouge&quot;&gt;그림5&lt;/code&gt;와 같이 모든 원소가 균등하게 나눠졌을 경우, 더이상 &lt;code class=&quot;highlighter-rouge&quot;&gt;partition&lt;/code&gt;함수를 호출하지 않는 1개의 피벗을 제외하면, 총 $\log_2 N$ 단계가 있다. 각 i 단계(level)에서 $O(2(N-(2\log_2 N -1))) = O(N)$ 만큼의 시간이 걸려서, 최종적인 시간 복잡도는 $T(N) = O(N \times \log_2 N)$ 이다.&lt;/p&gt;

&lt;h1 id=&quot;references&quot;&gt;References:&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;본 글은 기본적으로 서울대학교 이재진 교수님의 강의를 듣고 제가 공부한 것을 정리한 글입니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;관련-포스팅&quot;&gt;관련 포스팅:&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://simonjisu.github.io/python/2020/05/02/bubbleinsertion.html&quot;&gt;Bubble Sort &amp;amp; Insertion Sort&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://simonjisu.github.io/python/2020/05/02/selection.html&quot;&gt;Selection Sort&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://simonjisu.github.io/python/2020/05/03/merge.html&quot;&gt;Merge Sort&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;(현재글)&lt;a href=&quot;https://simonjisu.github.io/python/2020/05/04/quick.html&quot;&gt;Quick Sort&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Mon, 04 May 2020 11:38:38 +0900</pubDate>
        <link>https://simonjisu.github.io/python/2020/05/04/quick.html</link>
        <guid isPermaLink="true">https://simonjisu.github.io/python/2020/05/04/quick.html</guid>
        
        
        <category>python</category>
        
      </item>
    
      <item>
        <title>[Algorithms] Merge Sort</title>
        <description>&lt;h1 id=&quot;merge-sort&quot;&gt;Merge Sort&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;합병 정렬(Merge Sort)&lt;/strong&gt;의 아이디어는 분할정복(devide &amp;amp; conquer)이다. 말 그대로 두 스텝으로 나뉜다.&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Devide
 들어온 입력을 반으로 쪼갠 다음에 반으로 나눠진 입력에 대해서 재귀적으로 합병 정렬을 실행 한다.&lt;/li&gt;
  &lt;li&gt;Conquer
 두 개의 정렬된 데이터가 입력으로 들어온다. 그러면 새로운 공간에 두 입력을 하나로 합치(merge)면서 정렬한다.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;그림1&lt;/code&gt;과 같이 알고리즘의 각 스텝을 표현할 수 있다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1rrgsIUkDOKgSC3cDj8X5vT3bicah_aaz&quot; alt=&quot;[그림1] Merge Sort-1&quot; width=&quot;75%&quot; height=&quot;auto&quot; /&gt;&lt;figcaption&gt;[그림1] Merge Sort-1&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;먼저 순차적으로 입력 시퀀스의 중간에 있는 값을 찾아서 원소가 1개가 될때까지 좌/우로 나눈다(devide 과정). 그 후 하나씩 합치면서 정렬을 하게되는데, 그 예시로 &lt;code class=&quot;highlighter-rouge&quot;&gt;[2]&lt;/code&gt;와 &lt;code class=&quot;highlighter-rouge&quot;&gt;[1, 3]&lt;/code&gt;의 합치는 과정은 &lt;code class=&quot;highlighter-rouge&quot;&gt;그림2&lt;/code&gt;와 같다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1NCdPs94V6ooeidUhCX-jzIbsWDg-M8Cq&quot; alt=&quot;[그림2] Merge Sort-2&quot; width=&quot;80%&quot; height=&quot;auto&quot; /&gt;&lt;figcaption&gt;[그림2] Merge Sort-2&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;좌측(left)과 우측(right)의 원소를 하나씩 비교한 뒤에 새로운 리스트에 담는다. 더이상 비교할 원소가 없을때 합치는 과정은 끝난다. 이부분에서 알수 있듯이, 합병 정렬은 이전에 소개했던 알고리즘과 달리 inplace 알고리즘이 아니다. 코드로 구현하면 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;merge_sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;r&quot;&quot;&quot;
    Merge Sort
    Args: 
        l: input list
    Return:
        sorted list by ascending
    &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;merge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;r&quot;&quot;&quot;
        Merge two sorted list into one
        Args: 
            left, right: sorted list
        Return:
            sorted list
        &quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;li&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;idx_left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idx_right&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;len_left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;len_right&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx_left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;len_left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx_right&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;len_right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx_left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx_right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;li&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx_left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;idx_left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;li&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx_right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;idx_right&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idx_left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;len_left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;li&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx_left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;idx_left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idx_right&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;len_right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;li&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx_right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;idx_right&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;li&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;idx_mid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;merge_sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx_mid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;merge_sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx_mid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;li&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;merge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;li&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;알고리즘-복잡도&quot;&gt;알고리즘 복잡도&lt;/h2&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;li&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 1&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;idx_left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idx_right&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 1&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;len_left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;len_right&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 1&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx_left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;len_left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx_right&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;len_right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# k-1&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx_left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx_right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 비교: k-1&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;li&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx_left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# (k-1/2)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;idx_left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# (k-1/2)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;li&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx_right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# (k-1/2)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;idx_right&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# (k-1/2)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idx_left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;len_left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 마지막 남은 원소가 왼쪽인 경우: 1&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;li&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx_left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 1&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;idx_left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 1&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idx_right&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;len_right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 마지막 남은 원소가 오른쪽인 경우: 1&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;li&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx_right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 1&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;idx_right&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 1&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;먼저 &lt;code class=&quot;highlighter-rouge&quot;&gt;merge&lt;/code&gt; 함수의 복잡도를 분석하면 다음과 같다. 만약 입력 좌/우 리스트를 합쳐서 총 $k$ 개의 원소가 있다면, 비교를 하는데 $k-1$ 번이 필요하고, 새로운 리스트에 담는데 총 $k-1=(k-1/2)+(k-1/2)$이 걸려서 전부 합치면 대략 $c \times k$ 정도 걸린다. 따라서, $T(k) = O(k)$라고 할 수 있다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;idx_mid&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;left&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;merge_sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx_mid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;right&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;merge_sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx_mid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;li&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;merge&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;left&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;right&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1yWlItt2_BSJLBd_DwH7BOdDqDAPpO0CX&quot; alt=&quot;[그림3] Merge Sort-3&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;figcaption&gt;[그림3] Merge Sort-3&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;이제 &lt;code class=&quot;highlighter-rouge&quot;&gt;merge&lt;/code&gt; 함수가 몇번 호출 되었는지만 계산하면 모든 계산이 끝난다. $N$ 개의 입력 원소가 있다면, 각 i 단계(level)에서 &lt;code class=&quot;highlighter-rouge&quot;&gt;merge&lt;/code&gt; 함수가 $2^{i-1}$ 번만큼 호출 된다.&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Level-1 에서는 $2^0=1$번 호출되고, 각 분리된 2 파트에서 걸리는 시간 복잡도는 $O(\dfrac{N}{2})$이기 때문에, 총 시간 복잡도는 $O(1 \times 2\times \dfrac{N}{2}) = O(N)$가 된다.&lt;/li&gt;
  &lt;li&gt;Level-2 에서는 $2^1=2$번 호출되고 시간 복잡도는 $O(2 \times 2\times \dfrac{N}{2^2}) = O(N)$가 된다.&lt;/li&gt;
  &lt;li&gt;Level-3 에서는 $2^2=4$번 호출되고 시간 복잡도는 $O(2^2 \times 2\times \dfrac{N}{2^3}) = O(N)$가 된다.&lt;/li&gt;
  &lt;li&gt;…&lt;/li&gt;
  &lt;li&gt;Level-$(\log_2N)$ 에서는 $2^{(\log_2 N)-1}=\dfrac{N}{2}$번 호출되고 시간 복잡도는 $O(\dfrac{N}{2} \times 2\times \dfrac{N}{2^{\log_2 N}}) = O(N)$가 된다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;즉, 총 $\log_2 N$ 번의 단계를 거치기 때문에, 최종 시간 복잡도는 $T(N) = O(N \log_2 N)$으로 계산된다.&lt;/p&gt;

&lt;h1 id=&quot;references&quot;&gt;References:&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;본 글은 기본적으로 서울대학교 이재진 교수님의 강의를 듣고 제가 공부한 것을 정리한 글입니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;관련-포스팅&quot;&gt;관련 포스팅:&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://simonjisu.github.io/python/2020/05/02/bubbleinsertion.html&quot;&gt;Bubble Sort &amp;amp; Insertion Sort&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://simonjisu.github.io/python/2020/05/02/selection.html&quot;&gt;Selection Sort&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;(현재글)&lt;a href=&quot;https://simonjisu.github.io/python/2020/05/03/merge.html&quot;&gt;Merge Sort&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://simonjisu.github.io/python/2020/05/04/quick.html&quot;&gt;Quick Sort&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sun, 03 May 2020 14:38:38 +0900</pubDate>
        <link>https://simonjisu.github.io/python/2020/05/03/merge.html</link>
        <guid isPermaLink="true">https://simonjisu.github.io/python/2020/05/03/merge.html</guid>
        
        
        <category>python</category>
        
      </item>
    
      <item>
        <title>[Algorithms] Selection Sort</title>
        <description>&lt;h1 id=&quot;selection-sort&quot;&gt;Selection Sort&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;선택 정렬(Selection Sort)&lt;/strong&gt;의 아이디어는 정말 간단하다. 원소들중 가장 작은 원소를 찾아 첫번째 자리부터 채워넣는 것이다. 마지막 한자리가 남을 때까지 알고리즘은 계속된다. &lt;code class=&quot;highlighter-rouge&quot;&gt;그림1&lt;/code&gt;과 같이 알고리즘의 각 스텝을 표현할 수 있다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1kvETAdY2928P8c1-5gBcCaaTcRkDz_ZE&quot; alt=&quot;[그림1] Selection Sort&quot; width=&quot;75%&quot; height=&quot;auto&quot; /&gt;&lt;figcaption&gt;[그림1] Selection Sort&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;각 스텝별로 Index &lt;strong&gt;j&lt;/strong&gt;가 가르키는 원소를 기준으로 나머지 원소들중 가장 작은 값을 찾아내서 그 값과 교환한다. 코드로 구현하면 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;selection_sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;r&quot;&quot;&quot;
    Selection Sort
    Args: 
        l: input list
    Return:
        sorted list by ascending
    &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;swap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;r&quot;&quot;&quot;swap p-th element and q-th element&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;smallest_idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;smallest_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;smallest_idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;swap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;smallest_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;선택 정렬 또한 간단한 아이디어로써 구현이 쉬운 편이며, 추가 공간이 필요하지 않는 inplace 알고리즘이다.&lt;/p&gt;

&lt;h2 id=&quot;알고리즘-복잡도&quot;&gt;알고리즘 복잡도&lt;/h2&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 1&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# n-1&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;smallest_idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# n-1&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# (n-1) + (n-2) + ... + 1&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;smallest_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 비교: (n-1) + (n-2) + ... + 1&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;smallest_idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# (n-1) + (n-2) + ... + 1&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;swap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;smallest_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 교환: n-1&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;최악의 경우에, 제일 큰 원소가 제일 앞으로 나와 있고, 나머지 모든 원소가 정렬되어 있을 때를 생각할 수 있다. Index &lt;strong&gt;j&lt;/strong&gt;가 순환하면서 나머지 모든 원소와는 한번씩 비교해야하는데, 횟수는 $N-1, N-2 \cdots, 1$이다 index를 찾으면 교환은 한번씩만 하면 되기 때문에 $n-1$번이다. 따라서, 총 $T(N) = c \times \dfrac{N(N-1)}{2}$이 된다($c$는 상수). 즉, $T(N) = O(N^2)$ 이다.&lt;/p&gt;

&lt;h1 id=&quot;references&quot;&gt;References:&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;본 글은 기본적으로 서울대학교 이재진 교수님의 강의를 듣고 제가 공부한 것을 정리한 글입니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;관련-포스팅&quot;&gt;관련 포스팅:&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://simonjisu.github.io/python/2020/05/02/bubbleinsertion.html&quot;&gt;Bubble Sort &amp;amp; Insertion Sort&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;(현재글)&lt;a href=&quot;https://simonjisu.github.io/python/2020/05/02/selection.html&quot;&gt;Selection Sort&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://simonjisu.github.io/python/2020/05/03/merge.html&quot;&gt;Merge Sort&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://simonjisu.github.io/python/2020/05/04/quick.html&quot;&gt;Quick Sort&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sat, 02 May 2020 14:38:38 +0900</pubDate>
        <link>https://simonjisu.github.io/python/2020/05/02/selection.html</link>
        <guid isPermaLink="true">https://simonjisu.github.io/python/2020/05/02/selection.html</guid>
        
        
        <category>python</category>
        
      </item>
    
      <item>
        <title>[Algorithms] Bubble Sort &amp; Insertion Sort</title>
        <description>&lt;h1 id=&quot;sorting-problem&quot;&gt;Sorting Problem&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Sorting_algorithm&quot;&gt;&lt;strong&gt;정렬(Sorting) 문제&lt;/strong&gt;&lt;/a&gt;는 입력 시퀀스 $(x_1, x_2, \cdots, x_n)$를 오름차순의 순열(permutation)으로 만드는 문제를 말한다. 예를 들면 다음과 같이 &lt;code class=&quot;highlighter-rouge&quot;&gt;input_seq&lt;/code&gt;를 &lt;code class=&quot;highlighter-rouge&quot;&gt;output_seq&lt;/code&gt;로 바꾸는 형태다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_seq&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# Before Sorting&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output_seq&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sorted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output_seq&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# After Sorting&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;p&gt;가장 많이 사용되는 순서의 종류는 숫자 순서(numerical order), &lt;a href=&quot;https://en.wikipedia.org/wiki/Lexicographical_order&quot;&gt;사전 순서(lexicographical order)&lt;/a&gt; 다.&lt;/p&gt;

&lt;h2 id=&quot;inplace-algorithms&quot;&gt;Inplace Algorithms&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://simonjisu.github.io/python/2020/04/20/algorithmintro.html&quot;&gt;알고리즘 Introduction 글&lt;/a&gt;에서 알고리즘의 효율을 따지기 위해 시간 이외에 중요한 요소가 &lt;strong&gt;메모리 공간&lt;/strong&gt; 이라고 언급했었다. 이와 연관된 용어가 바로 알고리즘의 Inplace 여부다.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Inplace Algorithms&lt;/strong&gt; 이란, 실행하는데 추가로 공간이 필요하지 않는(혹은 거의 필요하지 않는) 알고리즘을 말한다. 앞으로 다뤄볼 정렬 문제에 사용되는 알고리즘은 대부분은 Inplace 알고리즘들이다.&lt;/p&gt;

&lt;h2 id=&quot;stable-or-unstable&quot;&gt;Stable or Unstable&lt;/h2&gt;

&lt;p&gt;이외에도 정렬 문제에서 자주 나오는 용어는 &lt;strong&gt;안정성(stability)&lt;/strong&gt;다. Stable 과 Unstable 두 가지로 나누는데, 정렬 후에도 기존 입력 시퀀스의 특성 또한 그 순서을 유지하는 것이 stable sort, 그렇지 않은 것을 unstable sort라고 한다.&lt;/p&gt;

&lt;p&gt;다음 그림 처럼, 숫자 순서로 정렬한 포커 그림을 보자. 정렬 후에도 하트, 스페이드라는 특성이 기존의 “하트5 &amp;gt; 스페이드5” 순서로 유지되는 것이 stable sort, 밑에 그림 처럼 그 순서가 유지되지 않는 것이 unstable sort다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1JAW-0E7H5Dh2C_BMfI6vP9r4q5czRFAf&quot; alt=&quot;[출처] Wikipedia: Sorting algorithm&quot; width=&quot;50%&quot; height=&quot;auto&quot; /&gt;&lt;figcaption&gt;[출처] Wikipedia: Sorting algorithm&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;이러한 특성을 유지하는 정렬 알고리즘이 있고 그렇지 않은 것들이 있다. 어떤 것이 Stable 하고 아닌지는 마지막에 한번에 정리하고, 지금부터 각 알고리즘을 하나씩 알아보기로 한다.&lt;/p&gt;

&lt;h1 id=&quot;bubble-sort&quot;&gt;Bubble Sort&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;버블 정렬(Bubble Sort)&lt;/strong&gt;은 각 스텝에서 서로 인접한(adjacent) 두 원소를 크기를 비교하여 바르지 않은 순서일 경우 두 원소를 교환(swap)하는 알고리즘이다. &lt;code class=&quot;highlighter-rouge&quot;&gt;그림1&lt;/code&gt;과 같이 알고리즘의 각 스텝을 표현할 수 있다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1JoOMFOFarMnqXIUpKmRQDnWbCEkPsfUI&quot; alt=&quot;[그림1] Bubble Sort&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;figcaption&gt;[그림1] Bubble Sort&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;각 스텝별로 Index &lt;strong&gt;j&lt;/strong&gt;가 가르키는 원소와 &lt;strong&gt;j+1&lt;/strong&gt;번째 원소와 비교하여 &lt;strong&gt;j&lt;/strong&gt;번째 원소가 더 크면 &lt;strong&gt;j+1&lt;/strong&gt;번째 원소와 swap하게 된다. 스텝이 지날수록 &lt;strong&gt;j&lt;/strong&gt;가 가질수 있는 최대 크기는 점점 줄어드며, 최대값이 0이 되었을 때 비로소 멈추게 된다. 코드로 구현하면 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;bubble_sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;r&quot;&quot;&quot;
    Bubble Sort
    Args: 
        l: input list
    Return:
        sorted list by ascending
    &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;swap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;s&quot;&gt;r&quot;&quot;&quot;swap p-th element and q-th element&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;  
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;swap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;버블 정렬의 특징은 구현이 간단하며, 추가 공간이 필요하지 않는 inplace 알고리즘이다.&lt;/p&gt;

&lt;h2 id=&quot;알고리즘-복잡도&quot;&gt;알고리즘 복잡도&lt;/h2&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 1&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# n&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# (n-1) + (n-2) + ... + 1&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 비교: (n-1) + (n-2) + ... + 1&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;swap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 교환: (n-1) + (n-2) + ... + 1&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;최악의 경우만 생각해보면 모든 원소가 역순으로 정렬되어 있을 때, Index &lt;strong&gt;j&lt;/strong&gt;가 순환하면서 모든 원소와 비교와 교환하게 되는데, 각각의 스텝 횟수는 $N-1, N-2 \cdots, 1$라서 총 $T(N) = c \times \dfrac{N(N-1)}{2}$이 된다($c$는 상수). 따라서 $T(N) = O(N^2)$ 이다.&lt;/p&gt;

&lt;h1 id=&quot;insertion-sort&quot;&gt;Insertion Sort&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;삽입 정렬(Insertion Sort)&lt;/strong&gt;은 정렬된 부분과 정렬되지 않는 부분을 따로 두어 정렬되지 않은 부분의 첫 원소부터 차례대로 정렬된 부분으로 넣는 알고리즘이다. 정렬된 부분은 보통 리스트의 첫번째 원소를 택한다. &lt;code class=&quot;highlighter-rouge&quot;&gt;그림2&lt;/code&gt;과 같이 알고리즘의 각 스텝을 표현할 수 있다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1uN_BaCpFNpFS1ZD3HtkqigMI9scolVEJ&quot; alt=&quot;[그림2] Insertion Sort&quot; width=&quot;75%&quot; height=&quot;auto&quot; /&gt;&lt;figcaption&gt;[그림2] Insertion Sort&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p&gt;각 스텝별로 Index &lt;strong&gt;j&lt;/strong&gt;가 가르키는 원소와 파란색으로 표시된 정렬된 부분의 원소와 비교하여 삽입할 index를 찾는 것이다. 실제로는 삽입할 index를 찾게 될때까지 비교가 완료된 원소를 오른쪽으로 미는 작업(Shift)을 한다. 코드로 구현하면 다음과 같다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;insertion_sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;r&quot;&quot;&quot;
    Insertion Sort
    Args: 
        l: input list
    Return:
        sorted list by ascending
    &quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;삽입 정렬도 상대적으로 구현이 간단하며, 추가 공간이 필요하지 않는 inplace 알고리즘이다.&lt;/p&gt;

&lt;h2 id=&quot;알고리즘-복잡도-1&quot;&gt;알고리즘 복잡도&lt;/h2&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 1&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# n-1&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# n-1&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# n-1&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# 비교: 1 + 2 + ... + (n-1)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# Shift: 1 + 2 + ... + (n-1)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 1 + 2 + ... + (n-1)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 삽입: n-1&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;최악의 경우만 생각해보면 모든 원소가 역순으로 정렬되어 있을 때, Index &lt;strong&gt;j&lt;/strong&gt;가 순환하면서 앞의 정렬된 부분과 모두 비교하고 Shift하는 횟수는 $1, 2, \cdots, N-1$라서 총 $T(N) = c \times \dfrac{N(N-1)}{2}$이 된다($c$는 상수). 따라서 $T(N) = O(N^2)$ 이다.&lt;/p&gt;

&lt;h1 id=&quot;references&quot;&gt;References:&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;본 글은 기본적으로 서울대학교 이재진 교수님의 강의를 듣고 제가 공부한 것을 정리한 글입니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;관련-포스팅&quot;&gt;관련 포스팅:&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;(현재글)&lt;a href=&quot;https://simonjisu.github.io/python/2020/05/02/bubbleinsertion.html&quot;&gt;Bubble Sort &amp;amp; Insertion Sort&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://simonjisu.github.io/python/2020/05/02/selection.html&quot;&gt;Selection Sort&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://simonjisu.github.io/python/2020/05/03/merge.html&quot;&gt;Merge Sort&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://simonjisu.github.io/python/2020/05/04/quick.html&quot;&gt;Quick Sort&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Sat, 02 May 2020 14:19:38 +0900</pubDate>
        <link>https://simonjisu.github.io/python/2020/05/02/bubbleinsertion.html</link>
        <guid isPermaLink="true">https://simonjisu.github.io/python/2020/05/02/bubbleinsertion.html</guid>
        
        
        <category>python</category>
        
      </item>
    
      <item>
        <title>Introduction of Algorithms &amp; Data Structures</title>
        <description>&lt;h1 id=&quot;algorithms-and-data-structures&quot;&gt;Algorithms and Data Structures&lt;/h1&gt;

&lt;h2 id=&quot;알고리즘algorithm이란&quot;&gt;알고리즘(Algorithm)이란?&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Algorithm&quot;&gt;위키백과&lt;/a&gt;에 따르면 &lt;strong&gt;알고리즘(Algorithm)&lt;/strong&gt;은 수학과 컴퓨터 과학분야에서 잘 정의(well-defined)되어진 컴퓨터로 실행 가능한 유한한 명령 시퀀스(sequence)다.&lt;/p&gt;

&lt;p&gt;다음과 같은 특징을 가진다고 볼 수 있다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;하나의 값 혹은 여러 값의 집합을 &lt;strong&gt;입력(input)&lt;/strong&gt;으로 받고, 궁극적으로 하나의 값 혹은 여러 값의 집합을 &lt;strong&gt;출력(output)&lt;/strong&gt;으로 뱉어낸다.&lt;/li&gt;
  &lt;li&gt;모든 입력에 대해서 정확한 출력을 뱉어낼 경우, “알고리즘이 정확하다”라고 말 할 수 있다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;또한 알고리즘은 잘 정의된 문제를 해결하기 위한 도구(tool)로 볼 수 있다. 단, “잘 정의된 문제”이라는 문구에는 일반적인(general) 입력-출력 관계가 정의되어야 한다. 잘 정의만 되면, 알고리즘은 곧 문제를 해결하는 일련의 과정을 서술한다고 볼 수 있다.&lt;/p&gt;

&lt;h2 id=&quot;자료구조data-structures란&quot;&gt;자료구조(Data Structures)란?&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Data_structure&quot;&gt;위키백과&lt;/a&gt;에 따르면 &lt;strong&gt;자료구조(Data Structure)&lt;/strong&gt;는 컴퓨터 과학에서 효율적인 접근 및 수정을 가능케 하는 자료의 조직, 관리, 저장을 의미한다.&lt;/p&gt;

&lt;p&gt;자료구조에는 여러 종류가 있으며, 이러한 각각의 자료구조는 각자의 연산 및 목적에 맞추어져 있다. 향후 다뤄볼 자료구조들을 나열해보았다(더 추가할 예정).&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;배열(array)&lt;/li&gt;
  &lt;li&gt;해시 테이블(hash table)&lt;/li&gt;
  &lt;li&gt;B-트리(B-Tree)&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;알고리즘의-분석&quot;&gt;알고리즘의 분석&lt;/h1&gt;

&lt;p&gt;효율적인 알고리즘이란 무엇인지 알려면 “효율”을 정의해야 될 것이다. 그렇다면 알고리즘을 측정하고 분석 해야하는데, 알고리즘을 분석한다는 것은 곧 이에 소요되는 자원(resources)을 예측한다는 것이다. 대부분의 경우 &lt;strong&gt;실행시간(running time)&lt;/strong&gt;과 &lt;strong&gt;메모리 공간(memmory space)&lt;/strong&gt;를 측정한다. 따라서, 한 문제 대해서 여러 알고리즘을 실행하여 사용되는 자원들을 비교하여 제일 적은 자원을 소모하는 것이 곧 효율적인(effective) 알고리즘이다.&lt;/p&gt;

&lt;h2 id=&quot;실행시간running-time&quot;&gt;실행시간(Running time)&lt;/h2&gt;

&lt;p&gt;다른 말로 &lt;strong&gt;알고리즘 복잡도(algorithm complexity)&lt;/strong&gt;이라 하는데, 알고리즘의 실행 횟수(primitive operations or steps)을 뜻하며, 입력 크기가 커질 수록 실행시간도 커진다. 사실 여기에는 실행 횟수만이 복잡도에 비례한다는 강력한 가정이 들어간다. 여담으로 실제 실행시간은 컴퓨터 CPU의 cache의 접근 속도, cache에 사용했던 메모리의 존재 여부등이 관여를 한다.&lt;/p&gt;

&lt;p&gt;실행시간을 측정했을 때, 가장 빨리된 경우를 best case, 최악의 경우를 worst case라고 하는데, 보통 worst case를 기준으로 복잡도를 측정하고 비교한다.&lt;/p&gt;

&lt;p&gt;또한, 실행시간은 횟수에 관련있다고 했기에 수식으로 $T(N)$으로 표기되며, $N$은 입력의 크기다.&lt;/p&gt;

&lt;h2 id=&quot;order-of-growth-classification&quot;&gt;Order of Growth Classification&lt;/h2&gt;

&lt;p&gt;증가 기준(Order-of-Growth)은 자료 개수의 증가에 따라 소요시간이 변하는 정도를 나타내며, 실제 걸린 시간을 무시하고 표기하자는 것이다. 예를 들어, 어떤 알고리즘의 실행시간이 $T(N) = C\times N^2 + D\times N + E$ 정도 걸린다면 뭉뚱그려서 $C\times N^2$ 정도 시간이 걸린다 라고 말할 수 있다($C$는 알수 없는 반복에 걸리는 시간을 말한다). 이렇게 상대적으로 큰 값을 취하여 시간을 근사하는 방법을 &lt;strong&gt;점근법(asymptote)&lt;/strong&gt;이라고 한다.&lt;/p&gt;

&lt;p&gt;점근 표기법(Asymptotic Notation)은 알고리즘의 복잡도를 단순화할 때나 무한급수의 뒷부분을 간소화할 때 쓰이며 $\Theta, O, \Omega$ 등이 있다. 보통 “빅오” 라고 많이 들어봤을 것이다.&lt;/p&gt;

&lt;p&gt;Order of Growth의 분류로 다음과 같은 표를 그릴 수 있다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1xH_B7ndU6XNlZY1lUnIom_q2Tdv7hNi2&quot; alt=&quot;[출처] Robert-Sedgewick 교수의 Algoritms 강의&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;figcaption&gt;[출처] Robert-Sedgewick 교수의 Algoritms 강의&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 id=&quot;asymptotic-notation&quot;&gt;Asymptotic Notation&lt;/h2&gt;

&lt;p&gt;평소에 Big O Notation이라는 말을 많이 들어보는데, 무슨 뜻인지 잘 이해가 안됐었다. 여기서 Big O를 포함하여 3가지 점근 표기법을 정확한 알아본다.&lt;/p&gt;

&lt;p&gt;알아보기 전에 중요한 가정이 있는데 아주 작은 입력크기 $N$에 대해서는 이러한 점근법이 작동하지 않는다. 즉, 우리가 말하는 “효율”이 좋다는 언제까지나 아주 큰 입력 $N$에 대해서 적용되는 말이다.&lt;/p&gt;

&lt;h3 id=&quot;theta-notation&quot;&gt;$\Theta$ Notation&lt;/h3&gt;

&lt;p&gt;$\text{Big-}\Theta$: $g(n)$와 양의 상수$c_1, c_2, n_0$가 주어졌을 때, 모든 $n_0$보다 크거나 같은 $n$에 대해서, $0 \leq c_1 g(n) \leq f(n) \leq c_2 g(n)$ 식을 만족하는 $f(n)$을 $\Theta \big( g(n) \big)$ 로 표기한다.&lt;/p&gt;

&lt;p&gt;위 정의는 간단히 말해, “$n_0$보다 큰 $n$크기의 입력에 대해서, 함수 $f(n)$의 값이 $(c_1 g(n), c_2 g(n))$ 구간에 존재한다”라고 추정하는 것이다. 즉, 아무리 커봐야 $c_2 g(n)$과 같거나 작을 것이고, 작아봐야 $c_1 g(n)$보다 같거나 클 것이다. 그림으로 표시하면 다음과 같다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1OM8KllT_GcAt-wB7FtzulsoN3e13v0w3&quot; alt=&quot;Big Theta Notation&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;figcaption&gt;Big Theta Notation&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h3 id=&quot;o-notation&quot;&gt;$O$ Notation&lt;/h3&gt;

&lt;p&gt;$\text{Big-}O$: $g(n)$와 양의 상수$c, n_0$가 주어졌을 때, 모든 $n_0$보다 크거나 같은 $n$에 대해서, $0 \leq f(n) \leq c g(n)$ 식을 만족하는 $f(n)$을 $O \big( g(n) \big)$ 로 표기한다.&lt;/p&gt;

&lt;p&gt;위 정의는 간단히 말해, “$n_0$보다 큰 $n$크기의 입력에 대해서, 함수 $f(n)$의 값이 $(0, c g(n))$ 구간에 존재한다”라고 추정하는 것이다. 즉, 아무리 커봐야 $c g(n)$과 같거나 작을 것이다. 그림으로 표시하면 다음과 같다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1cPpJQJqrJ-orjTNDQCLWYQiCib_5kF1m&quot; alt=&quot;Big O Notation&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;figcaption&gt;Big O Notation&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h3 id=&quot;omega-notation&quot;&gt;$\Omega$ Notation&lt;/h3&gt;

&lt;p&gt;$\text{Big-}\Omega$: $g(n)$와 양의 상수$c, n_0$가 주어졌을 때, 모든 $n_0$보다 크거나 같은 $n$에 대해서, $0 \leq c g(n) \leq f(n)$ 식을 만족하는 $f(n)$을 $\Omega \big( g(n) \big)$ 로 표기한다.&lt;/p&gt;

&lt;p&gt;위 정의는 간단히 말해, “$n_0$보다 큰 $n$크기의 입력에 대해서, 함수 $f(n)$의 값이 $(c g(n), +\infty)$ 구간에 존재한다”라고 추정하는 것이다. 즉, 아무리 작아도 $c g(n)$보다는 클 것이다. 그림으로 표시하면 다음과 같다.&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1D03BHXbVlkYqf_EIgCcQ-TTT-fkC38IH&quot; alt=&quot;Big Omega Notation&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;figcaption&gt;Big Omega Notation&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h3 id=&quot;예시&quot;&gt;예시&lt;/h3&gt;

&lt;p&gt;$T(n) = 5n^2 + 12n + 4$만큼 실행시간이 걸리는 알고리즘이 있을 때, 각 표기법으로 표현해보자. 실제로는 근사 값이지만 보통 등호(=)를 사용한다(이번 예시에서는 n이 엄청 크다는 가정을 한다).&lt;/p&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1cNJKtz7dJmN03nsc_6R3ca5vOZuvMw6I&quot; alt=&quot;Big Theta Notation Example&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;figcaption&gt;Big Theta Notation Example&lt;/figcaption&gt;&lt;/figure&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;표기 가능여부&lt;/th&gt;
      &lt;th&gt;이유&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$T(n) \neq \Theta(n)$&lt;/td&gt;
      &lt;td&gt;$f(n)$값(파란선)이 $c_1g(n), c_2g(n)$사이에 들어와야 하는데 그렇지 않다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;$T(n) = \Theta(n^2)$&lt;/td&gt;
      &lt;td&gt;$f(n)$값(파란선)이 $c_1g(n), c_2g(n)$사이에 들어간다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;$T(n) \neq \Theta(n^3)$&lt;/td&gt;
      &lt;td&gt;$f(n)$값(파란선)이 $c_1g(n), c_2g(n)$사이에 들어와야 하는데 그렇지 않다.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1Zx82-4p5KNf1UmVejUe4ibuv5ZdUpCZn&quot; alt=&quot;Big O Notation Example&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;figcaption&gt;Big O Notation Example&lt;/figcaption&gt;&lt;/figure&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;표기 가능여부&lt;/th&gt;
      &lt;th&gt;이유&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$T(n) \neq O(n)$&lt;/td&gt;
      &lt;td&gt;$f(n)$값(파란선)이 $cg(n)$보다 작아야 하는데 그렇지 않다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;$T(n) = O(n^2)$&lt;/td&gt;
      &lt;td&gt;$f(n)$값(파란선)이 $cg(n)$보다 작다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;$T(n) = O(n^3)$&lt;/td&gt;
      &lt;td&gt;$f(n)$값(파란선)이 $cg(n)$보다 작다.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;figure class=&quot;image&quot;&gt;&lt;img src=&quot;https://drive.google.com/uc?id=1k4DPvz1TYW_Kp8CdbTuNzT6XCXR6TbCS&quot; alt=&quot;Big Omega Notation Example&quot; width=&quot;100%&quot; height=&quot;auto&quot; /&gt;&lt;figcaption&gt;Big Omega Notation Example&lt;/figcaption&gt;&lt;/figure&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;표기 가능여부&lt;/th&gt;
      &lt;th&gt;이유&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$T(n) \neq \Omega (n)$&lt;/td&gt;
      &lt;td&gt;$f(n)$값(파란선)이 $cg(n)$보다 크다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;$T(n) = \Omega (n^2)$&lt;/td&gt;
      &lt;td&gt;$f(n)$값(파란선)이 $cg(n)$보다 커야 하는데 그렇지 않다.&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;$T(n) = \Omega (n^3)$&lt;/td&gt;
      &lt;td&gt;$f(n)$값(파란선)이 $cg(n)$보다 커야 하는데 그렇지 않다.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;그래프 관련 코드를 첨부한다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;plt&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;g1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;g2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;g3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;BigTheta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g_fn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c_1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g_fn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c_2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g_fn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;BigO&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g_fn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g_fn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;BigOmega&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g_fn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g_fn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;draw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;typ&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g_fns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c_upper&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c_lower&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ylim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;35000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;colors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'#1f77b4'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'#ff7f0e'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'#2ca02c'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'#d62728'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;fig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subplots&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;f_values&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;$f(n)$&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;colors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g_fn&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g_fns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;plot_bignotation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;typ&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;typ&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g_fn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g_fn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                         &lt;span class=&quot;n&quot;&gt;c_1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_upper&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c_2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_lower&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;colors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;$n$&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fontsize&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fontsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_ylim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ylim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;set_title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;typ&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fontsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;return_fig&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fig&lt;/span&gt;
    
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;plot_bignotation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;typ&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g_fn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;typ_fn_dict&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Big-Theta&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BigTheta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Big-O&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BigO&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Big-Omega&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BigOmega&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;g_dict&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;n&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;n^2&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;n^3&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;fn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;typ_fn_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;typ&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;g_str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g_fn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;typ&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Big-Theta&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;upper&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lower&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g_fn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lower&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;$c_1*g(n): g={g_str}, c_1={c_1}$&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;upper&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;$c_2*g(n): g={g_str}, c_2={c_2}$&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;typ&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Big-O&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;upper&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g_fn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;upper&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;$c*g(n): g={g_str}, c={c_1}$&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;typ&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Big-Omega&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;lower&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g_fn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lower&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;color&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;$c*g(n): g={g_str}, c={c_2}$&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
&lt;span class=&quot;n&quot;&gt;notations&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Big-Theta&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Big-Omega&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Big-O&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ylims&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;g_fns&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;g1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;c_upper&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;c_lower&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;typ&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ylim&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;notations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ylims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;draw&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;typ&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;g_fns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c_upper&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c_lower&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ylim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h1 id=&quot;references&quot;&gt;References:&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;본 글은 기본적으로 서울대학교 이재진 교수님의 강의를 듣고 제가 공부한 것을 정리한 글입니다.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.programiz.com/dsa/asymptotic-notations&quot;&gt;Asymptotic Analysis&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Mon, 20 Apr 2020 14:19:38 +0900</pubDate>
        <link>https://simonjisu.github.io/python/2020/04/20/algorithmintro.html</link>
        <guid isPermaLink="true">https://simonjisu.github.io/python/2020/04/20/algorithmintro.html</guid>
        
        
        <category>python</category>
        
      </item>
    
  </channel>
</rss>
