<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>End-to-End Memory Network 논문 요약 및 정리</title>
  <meta name="description" content="End-to-End Memory Network 논문 요약 및 정리">
  
  <meta name="author" content="Soo">
  <meta name="copyright" content="&copy; Soo 2017">
  

  <!-- External libraries -->
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css">
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/styles/monokai-sublime.min.css">
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/lightbox2/2.7.1/css/lightbox.css">

  <!-- Favicon and other icons (made with http://www.favicon-generator.org/) -->
  <link rel="shortcut icon" href="/assets/icons/favicon.ico" type="image/x-icon">
  <link rel="icon" href="/assets/icons/favicon.ico" type="image/x-icon">
  <link rel="apple-touch-icon" sizes="57x57" href="/assets/icons/apple-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="/assets/icons/apple-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/assets/icons/apple-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="/assets/icons/apple-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="/assets/icons/apple-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="/assets/icons/apple-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/assets/icons/apple-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/assets/icons/apple-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/assets/icons/apple-icon-180x180.png">
  <link rel="icon" type="image/png" sizes="192x192"  href="/assets/icons/android-icon-192x192.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/assets/icons/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="96x96" href="/assets/icons/favicon-96x96.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/icons/favicon-16x16.png">
  <link rel="manifest" href="/assets/icons/manifest.json">
  <meta name="msapplication-TileColor" content="#ffffff">
  <meta name="msapplication-TileImage" content="/assets/icons/ms-icon-144x144.png">
  <meta name="theme-color" content="#ffffff">

  
  <!-- Facebook OGP cards -->
  <meta property="og:description" content="End-to-End Memory Network 논문 요약 및 정리" />
  <meta property="og:url" content="http://simonjisu.github.io" />
  <meta property="og:site_name" content="Soo" />
  <meta property="og:title" content="End-to-End Memory Network 논문 요약 및 정리" />
  <meta property="og:type" content="website" />
  <meta property="og:image" content="http://simonjisu.github.io/assets/logo.png" />
  <meta property="og:image:type" content="image/png" />
  <meta property="og:image:width" content="612" />
  <meta property="og:image:height" content="605" />
  

  
  <!-- Twitter: card tags -->
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="End-to-End Memory Network 논문 요약 및 정리">
  <meta name="twitter:description" content="End-to-End Memory Network 논문 요약 및 정리">
  <meta name="twitter:image" content="http://simonjisu.github.io/assets/logo.png">
  <meta name="twitter:url" content="http://simonjisu.github.io">
  

  

  <!-- Site styles -->
  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://simonjisu.github.io/datascience/2017/08/04/E2EMN.html">
  <link rel="alternate" type="application/rss+xml" title="Soo" href="http://simonjisu.github.io/feed.xml" />

  <!-- Latex -->
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
      MathJax.Hub.Insert(MathJax.InputJax.TeX.Definitions.macros,{
        cancel: ["Extension","cancel"],
        bcancel: ["Extension","cancel"],
        xcancel: ["Extension","cancel"],
        cancelto: ["Extension","cancel"]
      });
    });
    MathJax.Hub.Config({
        TeX: {
            extensions: ["mhchem.js", "cancel.js"]
        },
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true,
            ignoreClass: "no-mathjax",
        },
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            linebreaks: { automatic: true }
        },
        menuSettings: {
            zoom: "Click",
            zscale: "200%"
        }
    });
  </script>

</head>


  <body>

    <header class="navigation" role="banner">
  <div class="navigation-wrapper">
    <a href="/" class="logo">
      
      <img src="/assets/logo.png" alt="Soo">
      
    </a>
    <a href="javascript:void(0)" class="navigation-menu-button" id="js-mobile-menu">
      <i class="fa fa-bars"></i>
    </a>
    <nav role="navigation">
      <ul id="js-navigation-menu" class="navigation-menu show">
        
          
          <li class="nav-link"><a href="/about/">About</a>
          
        
          
        
          
        
          
        
          
          <li class="nav-link"><a href="/posts/">Posts</a>
          
        
          
          <li class="nav-link"><a href="/typography/">Typography</a>
          
        
          
        
          
        
      </ul>
    </nav>
  </div>
</header>


    <div class="page-content">
        <div class="post">

<div class="post-header-container " >
  <div class="scrim ">
    <header class="post-header">
      <h1 class="title">End-to-End Memory Network 논문 요약 및 정리</h1>
      <p class="info">by <strong>Soo</strong></p>
    </header>
  </div>
</div>

<div class="wrapper">

 <span class="page-divider">
  <span class="one"></span>
  <span class="two"></span>
</span>
 

<section class="post-meta">
  <div class="post-date">August 4, 2017</div>
  <div class="post-categories">
  in 
    
    <a href="/category/DataScience">Datascience</a>
    
  
  </div>
</section>

<article class="post-content">
  <h1 id="end-to-end-memory-network----"><strong>End-to-End Memory Network 논문 요약 및 정리</strong></h1>

<hr />
<h2 id="a-single-layer">A. Single layer</h2>

<p><img src="/assets/E2EMN.png" alt="" /></p>
<h3 id="input">Input</h3>
<ol>
  <li>n 개의 단어가 포함된 한 <strong>문장 sentence i</strong> 는 $x_i = [x_{i1}, x_{i2}, \cdots, x_{in}]$ 로 표현 할 수 있으며, 하나의 <strong>단어</strong>는 BoW(Bag-of-Words)방식으로 인코딩 하여 vector로 바꿔준다. 이렇게 구성된 여러 문장들의 집합을 Context ${x_i}$라고 한다.
    <blockquote>
      <script type="math/tex; mode=display">x_{ij} = [0, 0, \cdots, 1 , \cdots, 0, 0]\quad for\ j^{th}\ words\ in\ sentence\ i</script>
    </blockquote>
  </li>
  <li>t 개의 단어가 포함된 질문 question q도 마찬가지로 BoW방식으로 인코딩해준다.</li>
</ol>

<blockquote>
  <p>sentence $x_1$ = Mary journeyed to the den. 을 예제로 들면,</p>

  <script type="math/tex; mode=display">x_{i1} = mary = [1, 0, \cdots, 0, 0]</script>

  <script type="math/tex; mode=display">x_{i2} = journeyed = [0, 1, \cdots, 0, 0]</script>

  <script type="math/tex; mode=display">x_{i3} = to = [0, \cdots, 1, \cdots, 0, 0]</script>

  <p>이런식으로 인코딩이 된다.</p>
</blockquote>

<p>주의: Mary혹은 mary와 같이 같은 단어를 두 번 세는 것을 피하기 위해서, 모든 단어는 소문자로 바꿔준다.</p>

<h3 id="input-memory">Input Memory</h3>
<ol>
  <li>하나의 문장 $x_i$ 각각의 단어에 Embedding matrix $A$를 곱하여 각각의 단어를 Embedding Vectors로 변환하고 이를 모두 더하여 메모리 벡터(Memory Vector) $m_i$를 구한다. 이렇게 구성된 여러개의 메모리 벡터 $m_i$들 중 일부를 사용하게 된다.
    <blockquote>
      <script type="math/tex; mode=display">m_i = \sum_{j}^{n} Ax_{ij} = Ax_{i1} + Ax_{i2} + \cdots + Ax_{in}</script>
    </blockquote>
  </li>
  <li>Question도 마찬가지로 Embedding matrix $B$를 곱하여 각각의 단어를 Embedding Vectors로 변환하고 이를 모두 더하여 Internal state $u$를 구한다.
    <blockquote>
      <script type="math/tex; mode=display">u = \sum_{j} Bx_{ij} = Bx_{i1} + Bx_{i2} + \cdots + Bx_{in}</script>
    </blockquote>
  </li>
  <li>이후 Context와 Question의 유사성(match)를 구하기 위해 inner product를 시행한 후, Softmax Function으로 출력해준다. 이러한 결과로 input에 대한 확률을 도출 해낼 수 있다.
    <blockquote>
      <script type="math/tex; mode=display">p_i = Softmax(u^Tm_i)</script>
    </blockquote>
  </li>
</ol>

<p>즉 $p_i$가 높을 수록 높은 유사성을 띈다.</p>

<p>이러한 과정을 통해서 <strong>Input Memory</strong> 에는 Context 문장들(${x_i}$)과 질문($q$)의 축약된 정보가 들어가게 된다.</p>

<h3 id="output-memory">Output Memory</h3>
<ol>
  <li>모든 Context 문장들 ${x_i}$ 의 각각의 단어에  다시 Embedding matrix C를 곱하고 더하여 $c_i$로 변환한다.
    <blockquote>
      <script type="math/tex; mode=display">c_i = \sum_{j} Cx_{ij} = Cx_{i1} + Cx_{i2} + \cdots + Cx_{in}</script>
    </blockquote>
  </li>
  <li>이는 출력으로 나오는 Response vector 인$o$ 를 구하기 위해서 인데, $o$는 아래와 같이 Input Memory에서 나오는 유사성(match, $p_i$)와 가중평균합을 진행한다.
    <blockquote>
      <script type="math/tex; mode=display">o = \sum_{i} p_ic_i</script>
    </blockquote>
  </li>
</ol>

<h3 id="final-prediction">Final Prediction</h3>
<p>output $o$와 질문으로부터 추출한 Internal state $u$에 가중치값 $W$를 곱하여 더한뒤에 Softmax Function을 적용하여 답 $\hat{a}$을 추론한다.</p>
<blockquote>
  <script type="math/tex; mode=display">\hat{a} = Softmax(W(o+u))</script>
</blockquote>

<h3 id="weight-updating">Weight Updating</h3>
<p>Loss Function은 standard cross-entropy loss를 사용하여 예측치 $\hat{a}$ 와 정답인 true 값 $a$ 간의 오차를 최소화해서 학습 시킨다.</p>

<p>Input에서 Output까지 함수들은 무한정미분가능(function is smooth)하기 때문에, 손쉽게 Gradient와 back-propagate을 진행할 수 있다.</p>

<p>업데이트 되는 weight Matrix는 $A$, $B$, $C$ 그리고 $W$다.</p>

<p><br /></p>
<p><br /></p>

<hr />
<h2 id="b-multiple-layers">B. Multiple layers</h2>

<p>위와 같은 Final Prediction 전 단계까지를 1 hop라고 규정하며, Multiple layers $K$ hops까지 확장 시킨다.</p>

<ul>
  <li>첫번째, k번째 layer에서 나온 output으로 나온 $o^k$과 input $u^k$ 는 합쳐져서 새로운 input $u^{k+1}$ 가 되어서 k + 1 layer로 들어가게 된다.
    <blockquote>
      <script type="math/tex; mode=display">u^{k+1} = u^k + o^k</script>
    </blockquote>
  </li>
  <li>각 layer마다 input에 embed로 사용된 embedding matrices $A^k$ 와 $C^k$ 가 존재한다. 그러나 이들은 쉽게 트레이닝하고, parameter 갯수를 줄이기 위해서 제약이 존재한다.</li>
  <li>Network의 마지막 부분에서만 W를 곱해서 Softmax 로 출력한다.
    <blockquote>
      <script type="math/tex; mode=display">\hat{a} = Softmax(Wu^{K+1}) = Softmax(W(o^K + u^K))</script>
    </blockquote>
  </li>
</ul>

<h3 id="section">두 가지 가중치 버젼</h3>
<ol>
  <li>Adjacent:
    <blockquote>
      <p>$k_{th}$ output layer embedding matrix가 다음 input layer의 embedding matrix가 된다. 예를 들면, $A^{k+1} = C^k$. 또한, 두 가지 제약 조건을 추가했는데, (a) answer prediction matrix가 최종 output embedding과 같고 ($W^T = C^K)$, (b) question embedding 과 첫번째 layer의 input embedding과 같게 했다($B = A^1$).</p>
    </blockquote>
  </li>
  <li>Layer-wise (RNN - like):
    <blockquote>
      <p>Input 과 Output embedding들이 layer마다 다 같다. 예를 들면, $A^1 = A^2 = \cdots = A^K$ 과 $C^1 = C^2 = \cdots = C^K$ 같은 것들. 또한, hops간 u를 업데이트하기위한 linear mapping $H$ 를 추가하는 것이 도움이 된다는 것을 알아냈다. $u^{k+1} = Hu^k + o^k$.</p>
    </blockquote>
  </li>
</ol>

<p>층별로 가중치를 묶는 두 번째 방법은, tranditional 한 RNN 방식으로 생각할 수가 있다. Internal output($u$)을 내보내는 것은 memory에 해당하고, external outputs($\hat{a}$)는 라벨을 예측하는 것과 같다. RNN 관점에서 보면, $u$, $u^{k+1}$ 은 hidden state고, 모델은 $A$ 를 사용하여internal output $p$ 를 생성한다. 모델은 $C$ 를 사용해서 $p$ 의 정보를 흡수하고, hidden state를 업데이트면서 이런 식으로 계속 진행한다. 여기서 표준 RNN과 다르게 output들을 $K$ hops 동안 계속 메모리에 저장하고, sampling하는 대신에 soft하게 둔다. 그렇게 하여 답변이 “진짜 세상”에 나오기 전에 여러번 계산을 거치게 된다.</p>

<p><br /></p>
<p><br /></p>

<hr />
<h2 id="c-synthetic-question-and-answering-experiments">C. Synthetic Question and Answering Experiments</h2>

<ul>
  <li>예시1:
    <blockquote>
      <p>Sam walks into the kitchen.</p>

      <p>Sam picks up an apple.</p>

      <p>Sam walks into the bedroom.</p>

      <p>Sam drops the apple.</p>

      <p><span style="color: #7d7ee8">Q: Where is the apple?</span></p>

      <p><span style="color: #e87d7d">A. Bedroom</span></p>
    </blockquote>
  </li>
  <li>예시2:
    <blockquote>
      <p>Brian is a lion.</p>

      <p>Julius is white.</p>

      <p>Julius is a lion.</p>

      <p>Bernhard is green.</p>

      <p><span style="color: #7d7ee8">Q: What color is Brian?</span></p>

      <p><span style="color: #e87d7d">A. White</span></p>
    </blockquote>
  </li>
  <li>예시3:
    <blockquote>
      <p>Mary journeyed to the den.</p>

      <p>Mary went back to the kitchen.</p>

      <p>John journeyed to the bedroom.</p>

      <p>Mary discarded the milk.</p>

      <p><span style="color: #7d7ee8">Q: Where was the milk before the den?</span></p>

      <p><span style="color: #e87d7d">A. Hallway</span></p>
    </blockquote>
  </li>
</ul>

<p>예시에도 보듯이 문장의 일부만 답변의 정답정보를 가지고 있다. 이를 support subset이라고 하며, training 할때 support subset을 명시한다. 그러나 실제 테스트할 때는 이 support subset이 표시되지 않는다.</p>

<h3 id="model-details">Model details</h3>
<p>$K=3$ hops이고 weight sharing(Layer-wise) 모델을 쓸 것이다.  모든 output lists(답변에 여러 단어가 있는 경우)에 대하여 단어별로 분리하여 가능성을 나타낸다.</p>

<h4 id="sentence-representaion">Sentence Representaion:</h4>
<p>문장들을 표현할 때 두 가지 방법을 쓰기로 한다. 첫번째로는 BoW가 하나의 문장을 표현하는 것인데, 이 방법은 문장에서 단어의 순서(the order of the words in sentence)라는 특징을 잡을 수가 없다. 따라서 두 번째 방법으로, 문장에서 단어의 순서(the position of words)를 인코딩 한다. $m_i = \sum_{j} l_j \cdot Ax_{ij}$ 여기서 $l_j$ 연산은 element-wise multiplication이다. 또한, $l_j$ 는 $l_{kj} = (1-j/J) - (k/d)(1-2j/J)$, J는 문장에 있는 단어 갯수인 column vector 구조를 가지고 있다. 이것을 $PE$ (position encoding)이라고 하며, 이는 단어의 순서가 얼만큼 문장$m_i$에 영향을 주는지 알려준다. 나머지 question, memory inputs 그리고 memory outputs에서도 두 번째 방법으로 문장을 표현할 것이다.</p>

<h4 id="temporal-encoding">Temporal Encoding:</h4>
<p>많은 QA tasks에서는 temporal context라는 개념이 필요한데, 예를 들어 첫 번째 예시에서 Sam이 kitchen에 간 다음에 bedroom에 들어간 것을 알 수 있다. 이것을 모델에 적용하려면, memory vector를 약간 변형시킨다. $m_i = \sum_{j} Ax_{ij} + T_A(i)$, 여기서 $T_A(i)$ 는 일시적인 정보를 저장할 특별한 행렬 $T_A$ 의 i 번째 행이다. Ouput embedding할 때도 마찬가지로 해준다. $c_i = \sum_{j} Cx_{ij} + T_C(i)$. $T_A$ 와 $T_C$ 둘다 training 할 때 갱신한다. 그리고 A 와 C 랑 마찬가지로 제약 또한 같이 공유한다. 여기서 주의할 점은 문장들이 역순으로 인덱싱되어있다.  문장이 질문으로부터 상대적인 거리를 반영한다, 즉 $x_1$ 은 이야기의 마지막 문장이 된다.</p>

<h4 id="learning-time-invariance-by-injecting-random-noise">Learning time invariance by injecting random noise:</h4>
<p>$T_A$ 를 정규화 시킬때 더미 변수를 넣는 것이 도움이 된다. 즉, 트레이닝할 때는 랜덤으로 10%의 빈 메모리를 스토리에 넣는 것이다. 여기서 이를 Random Noise (RN)라고 한다</p>

<h3 id="training-details">Training Details</h3>
<p>bAbI training set중 10%는 Validation용으로 쓴다. 이는 optimal model architecture 과 hyperparameters를 선택하기 위해서다. Learning rate $\eta$는 0.01로 설정하고, 100번째 epoch가 될때 까지, 매 25번째 epochs 마다, $\eta$ 를 2로 나눠준다. Momentum 이나 weight decay는 사용되지 않았다. 가중치들은 $\mu = 0$, $\sigma = 0.1$ 인 가우시안 정규분포로 초기값을 설정했다. 모든 training에 사용된 batch size는 32 이며, gradients는 L2로 정규화해서 40이 넘으면 어떤 스칼라를 나눠서 norm을 40으로 만들어준다.</p>

<p>어떤 모델에서는 처음시작에 softmax를 안쓰다가 (linear하게 만드는 것) 나중에 최종 예측시에 softmax를 썼다. 그러다 validation loss가 더 이상 떨어지지 않을 때, 다시 softmax 층이 다시 입력이 되서 트레이닝을 한다. 이를 Linear Start (LS) training이라고 하며, 이때 초기 learning rate 를 $\eta = 0.005$ 로 설정한다.</p>

<h3 id="baselines">Baselines</h3>
<ul>
  <li>MemNN: strongly supervised, softmax대신 max operation사용</li>
  <li>MemNN-WSH: weakly supervised, 트레이닝시 supporting sentence labels를 안씀</li>
  <li>LSTM: weakly supervised</li>
</ul>

<h3 id="result">Result</h3>
<p>모델 선택을 다양하게 했다.</p>

<p>1) BoW vs Position Encoding</p>

<p>2) 20 tasks를 독립적으로 트레이닝공유($d = 20$) vs joint 트레이닝 ($d = 50$)</p>

<p>3) Linear Start Training(Softmax처음에 없엔 것) vs Softmax가 처음부터 있는 것</p>

<p>4) hops를 1 ~ 3까지 설정</p>

<p>결과는 논문 참조. 퍼포먼스는 supervised models이 제일 좋게 나왔으나, MemN2N with position encoding + linear start + random noise, jointly trained 도 근접하게 나옴</p>

<p><br /></p>
<p><br /></p>

<hr />
<h2 id="d">D.참고문헌</h2>

<p><a href="https://arxiv.org/abs/1503.08895">End-To-End Memory Networks: Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, Rob Fergus</a></p>

</article>





<section class="rss">
  <p class="rss-subscribe text"><strong>Subscribe <a href="/feed.xml">via RSS</a></strong></p>
</section>

<!-- section class="share">
  <span>Share: </span>
  
    
    
    
      <a href="//www.facebook.com/sharer.php?t=End-to-End+Memory+Network+%EB%85%BC%EB%AC%B8+%EC%9A%94%EC%95%BD+%EB%B0%8F+%EC%A0%95%EB%A6%AC&u=http%3A%2F%2Fsimonjisu.github.io%2Fdatascience%2F2017%2F08%2F04%2FE2EMN.html"
        onclick="window.open(this.href, 'facebook-share', 'width=550,height=255');return false;">
        <i class="fa fa-facebook-square fa-lg"></i>
      </a>
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
      <a href="//plus.google.com/share?title=End-to-End+Memory+Network+%EB%85%BC%EB%AC%B8+%EC%9A%94%EC%95%BD+%EB%B0%8F+%EC%A0%95%EB%A6%AC&url=http%3A%2F%2Fsimonjisu.github.io%2Fdatascience%2F2017%2F08%2F04%2FE2EMN.html"
        onclick="window.open(this.href, 'google-plus-share', 'width=550,height=255');return false;">
        <i class="fa fa-google-plus-square fa-lg"></i>
      </a>
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
      <a href="//www.pinterest.com/pin/create/button/?description=End-to-End+Memory+Network+%EB%85%BC%EB%AC%B8+%EC%9A%94%EC%95%BD+%EB%B0%8F+%EC%A0%95%EB%A6%AC&url=http%3A%2F%2Fsimonjisu.github.io%2Fdatascience%2F2017%2F08%2F04%2FE2EMN.html&media=http://simonjisu.github.io/assets/star.jpg"
        onclick="window.open(this.href, 'pinterest-share', 'width=550,height=255');return false;">
        <i class="fa fa-pinterest-square fa-lg"></i>
      </a>
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
    
  
    
    
    
    
    
    
    
      <a href="//www.reddit.com/submit" onclick="window.location = '//www.reddit.com/submit?url=' + encodeURIComponent('http://simonjisu.github.io/datascience/2017/08/04/E2EMN.html') + '&title=End-to-End Memory Network 논문 요약 및 정리'; return false">
        <i class="fa fa-reddit-square fa-lg"></i>
      </a>
    
    
  
    
    
    
    
    
    
    
    
  
</section -->





</div>
</div>

    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h3 class="footer-heading">Soo</h3>

    <div class="site-navigation">

      <p><strong>Site Map</strong></p>
      <ul class="pages">
        
        
          <li class="nav-link"><a href="/about/">About</a>
        
        
        
        
        
        
        
        
        
          <li class="nav-link"><a href="/posts/">Posts</a>
        
        
        
          <li class="nav-link"><a href="/typography/">Typography</a>
        
        
        
        
        
        
      </ul>
    </div>

    <div class="site-contact">

      <p><strong>Contact</strong></p>
      <ul class="social-media-list">
        <li>
          <a href="mailto:simonjisu@gmail.com">
            <i class="fa fa-envelope-o"></i>
            <span class="username">simonjisu@gmail.com</span>
          </a>
        </li>

        
          
          <li>
            <a href="https://www.facebook.com/simonjisu" title="Friend me on Facebook">
              <i class="fa fa-facebook"></i>
              <span class="username">simonjisu</span>
            </a>
          </li>
          
        
          
          <li>
            <a href="https://github.com/simonjisu" title="Fork me on GitHub">
              <i class="fa fa-github"></i>
              <span class="username">simonjisu</span>
            </a>
          </li>
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        

      </ul>
    </div>

    <div class="site-signature">
      <p class="rss-subscribe text"><strong>Subscribe <a href="/feed.xml">via RSS</a></strong></p>
      <p class="text">My Blog
</p>
    </div>

  </div>

</footer>

<!-- Scripts -->
<script src="//code.jquery.com/jquery-1.11.2.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/8.5/highlight.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/lightbox2/2.7.1/js/lightbox.min.js"></script>

<script type="text/javascript">
$(document).ready(function() {
  // Default syntax highlighting
  hljs.initHighlightingOnLoad();

  // Header
  var menuToggle = $('#js-mobile-menu').unbind();
  $('#js-navigation-menu').removeClass("show");
  menuToggle.on('click', function(e) {
    e.preventDefault();
    $('#js-navigation-menu').slideToggle(function(){
      if($('#js-navigation-menu').is(':hidden')) {
        $('#js-navigation-menu').removeAttr('style');
      }
    });
  });
});

</script>




  </body>

</html>
