<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>[PyTorch] ConvTranspose2d 와 Conv2d 의 관계</title>
  <meta name="description" content="ConvTranspose2d 와 Conv2d">
  
  <meta name="author" content="Soo">
  <meta name="copyright" content="&copy; Soo 2019">
  

  <!-- External libraries -->
  <link rel="stylesheet" href="//maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css">
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/atom-one-dark.min.css">
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/lightbox2/2.7.1/css/lightbox.css">

  <!-- Favicon and other icons (made with http://www.favicon-generator.org/) -->
  <link rel="shortcut icon" href="/assets/icons/favicon.ico" type="image/x-icon">
  <link rel="icon" href="/assets/icons/favicon.ico" type="image/x-icon">
  <link rel="apple-touch-icon" sizes="57x57" href="/assets/icons/apple-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="/assets/icons/apple-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/assets/icons/apple-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="/assets/icons/apple-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="/assets/icons/apple-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="/assets/icons/apple-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/assets/icons/apple-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/assets/icons/apple-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/assets/icons/apple-icon-180x180.png">
  <link rel="icon" type="image/png" sizes="192x192"  href="/assets/icons/android-icon-192x192.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/assets/icons/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="96x96" href="/assets/icons/favicon-96x96.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/icons/favicon-16x16.png">
  <link rel="manifest" href="/assets/icons/manifest.json">
  <meta name="msapplication-TileColor" content="#ffffff">
  <meta name="msapplication-TileImage" content="/assets/icons/ms-icon-144x144.png">
  <meta name="theme-color" content="#ffffff">

  
  <!-- Facebook OGP cards -->
  <meta property="og:description" content="ConvTranspose2d 와 Conv2d" />
  <meta property="og:url" content="http://simonjisu.github.io" />
  <meta property="og:site_name" content="Soo" />
  <meta property="og:title" content="[PyTorch] ConvTranspose2d 와 Conv2d 의 관계" />
  <meta property="og:type" content="website" />
  <meta property="og:image" content="http://simonjisu.github.io/assets/logo.png" />
  <meta property="og:image:type" content="image/png" />
  <meta property="og:image:width" content="612" />
  <meta property="og:image:height" content="605" />
  

  
  <!-- Twitter: card tags -->
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="[PyTorch] ConvTranspose2d 와 Conv2d 의 관계">
  <meta name="twitter:description" content="ConvTranspose2d 와 Conv2d">
  <meta name="twitter:image" content="http://simonjisu.github.io/assets/logo.png">
  <meta name="twitter:url" content="http://simonjisu.github.io">
  

  

  <!-- Site styles -->
  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://simonjisu.github.io/datascience/2019/10/27/convtranspose2d.html">
  <link rel="alternate" type="application/rss+xml" title="Soo" href="http://simonjisu.github.io/feed.xml" />


  <!-- <script type="text/javascript"
          src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" ></script> -->

  <!-- Latex -->
  <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
      MathJax.Hub.Insert(MathJax.InputJax.TeX.Definitions.macros,{
        cancel: ["Extension","cancel"],
        bcancel: ["Extension","cancel"],
        xcancel: ["Extension","cancel"],
        cancelto: ["Extension","cancel"]
      });
    });
    MathJax.Hub.Config({
        TeX: {
            extensions: ["mhchem.js", "cancel.js"]
        },
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true,
            ignoreClass: "no-mathjax",
        },
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            // linebreaks: { automatic: true }
        },
        menuSettings: {
            zoom: "Click",
            zscale: "200%"
        }
    });
  </script>

  <!--lightSlider-->
  <link rel="stylesheet" href="/css/lightslider.css" />

  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
  new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
  j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
  'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
  })(window,document,'script','dataLayer','GTM-5GSH93K');</script>
  <!-- End Google Tag Manager -->

  <!-- Google Ad -->
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({
      google_ad_client: "ca-pub-5855917513482122",
      enable_page_level_ads: true
    });
  </script>

  <script async custom-element="amp-auto-ads"
    src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
  </script>
  
  <!-- End Google Ad -->

</head>


  <body>
    <header class="navigation" role="banner">
  <div class="navigation-wrapper">
    <a href="/" class="logo">
      
      <img src="/assets/logo.png" alt="Soo">
      
    </a>
    <a href="javascript:void(0)" class="navigation-menu-button" id="js-mobile-menu">
      <i class="fa fa-bars"></i>
    </a>
    <nav role="navigation">
      <ul id="js-navigation-menu" class="navigation-menu show">
        
          
        
          
        
          
        
          
          <li class="nav-link"><a href="/posts/">Posts</a>
          
        
          
        
          <li class="nav-link"><a href="https://simonjisu.gitbook.io/resume/"> ME </a>
          <li class="nav-link"><a href="https://github.com/simonjisu"> GitHub </a>
      </ul>
    </nav>
  </div>
</header>


    <!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5GSH93K"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->


    <div class="page-content">
        <div class="post">
<div class="post-header-container " >
  <div class="scrim ">
    <header class="post-header">
      <h1 class="title">[PyTorch] ConvTranspose2d 와 Conv2d 의 관계</h1>
      <p class="info">by <strong>Soo</strong></p>
    </header>
  </div>
</div>

<div class="wrapper">

 <span class="page-divider">
  <span class="one"></span>
  <span class="two"></span>
</span>
 

<section class="post-meta">
  <div class="post-date">October 27, 2019</div>
  <div class="post-categories">
   in 
    
    <a href="/posts/#DataScience">Datascience</a>
    
  
  </div>
</section>

<article class="post-content">
  <h1 id="convtranspose2d--conv2d">ConvTranspose2d 와 Conv2d</h1>

<p>최근 XAI 에 관련된 공부를 하면서 비전쪽의 많은 논문을 살펴보고 있다. “Visualizing and Understanding Convolutional Networks (2013)” 논문에서는 이미지 처리에서는 CNN 알고리즘이 제일 좋지만, 그 이유에 대해서 탐구를 시도한 논문이다. 도대체 Convolution의 필터가 어떤 역할을 하는지, 이들이 어떤 부분을 살펴보는 지를 확인한다. 오늘은 이 논문에서 제안하는 Deconvolutional layers(정확히는 Fractionally-strided convolution 이지만 차후에 언급한다)의 실체를 낱낱이 살펴보도록 한다.</p>

<ul>
  <li>link: <a href="https://arxiv.org/abs/1311.2901">Visualizing and Understanding Convolutional Networks</a></li>
</ul>

<h2 id="convolution-layer">Convolution layer</h2>

<p>Deconvolutional layer을 알아보기 전에 합성곱 연산(Convolutional Operation)에 대해 알아볼 필요가 있다. 합성곱 연산은 필터가 조금씩 이동하면서 이미지의 일부와 필터간 연산을 통해 진행된다.</p>

<p><img src="https://drive.google.com/uc?id=17x4ZQ_r0FTa_mlDFiIWvMJcg22vRrBd6" /></p>

<p>일반적으로 CNN 알고리즘은 <code class="highlighter-rouge">Convolution</code> - <code class="highlighter-rouge">Activation</code> - <code class="highlighter-rouge">Maxpooling</code> 과정을 거친다. 예를 들어, 위 그림과 같이 4x4 이미지는 3x3 필터를 통해 2x2 의 선형변환 값을 갖는다(padding=0, stride=1 인 경우). 그리고 활성화 함수를 통과한 뒤에 Maxpool 과정을 거친다. 이때 <code class="highlighter-rouge">Convolution</code> - <code class="highlighter-rouge">Activation</code>을 거쳤을 때 나오는 텐서를 Activation Map이라고 하고, <code class="highlighter-rouge">Pooling</code> 과정을 거쳤을 때 나오는 텐서를 Pooled Map 이라고 한다.</p>

<p><img src="https://drive.google.com/uc?id=1Y4kIqXn7vUYQgoZWDdprrO-SP9a-Qogs" /></p>

<p>이 논문에서는 그 과정을 역으로 한번 해보는 것을 제안했다. 위 그림처럼 마지막 Pooled Maps 에서 풀링된 위치를 기억했다가(Max Locations “Switches” 부분), 이 위치를 기반으로 역으로 Unpooled Maps 를 재구축한다(이 부분에 관심있는 분들은 이 논문을 한번 살펴보는 것을 추천드린다). 이번 글에서는 그 다음 스텝인 Convolution layer 에서 역으로 돌아가는 방법에 대해서 설명하려고 한다.</p>

<p>먼저 이미지의 크기를 $N$, 필터(커널)의 크기를 $K$, 패딩의 크기를 $P$, 스트라이드를 $S$ 라고 정의하고, 여러 변수를 정의 한다.</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned} \text{input image size} &= N \times N =4 \times 4 \\ \text{filter size} &= K\times K = 3 \times 3 \\ \text{padding} &= P = 0 \\ \text{stride} &= S = 1 \\ \text{output image size} &= (\dfrac{N+2P-K}{S}+1, \dfrac{N+2P-K}{S}+1) \\&= 2 \times 2 \\ \text{input image} &: X^{(l)} = \begin{bmatrix} x_{11} & x_{12} & x_{13} &x_{14}\\  x_{21} & x_{22} & x_{23} &x_{24}\\ x_{31} & x_{32} & x_{33} &x_{34}\\ x_{41} & x_{42} & x_{43} &x_{44}\end{bmatrix}^{(l)} \\ \text{output image} &: x^{(l+1)} =\begin{bmatrix} x_{11} & x_{12}\\ x_{21} & x_{22} \end{bmatrix}^{(l+1)} \\ \text{filter} &: W = \begin{bmatrix} w_{11} & w_{12} & w_{13}\\  w_{21} & w_{22} & w_{23}\\ w_{31} & w_{32} & w_{33}\end{bmatrix} \end{aligned} %]]></script>

<p>이제 수식으로 합성곱 연산을 정의한다.</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned} x_{pq}^{(l+1)} &= \sum_{p=i}^{K+i-1} \sum_{q=j}^{K+j-1} w_{pq} x_{pq}^{(l)} \quad \text{for }i, j \in (1, 2, \cdots,  N-K+1)\end{aligned} %]]></script>

<p>위 수식으로는 어려워 보이지만 아래와 같은 연산을 <code class="highlighter-rouge">*</code> 라고 하면 결과는 2x2 행렬이 출력되며 다음과 같다.</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned} X^{(l+1)} &= X^{(l)}*W\\&=\begin{bmatrix}w_{11} x^{(l)}_{11} + w_{12} x^{(l)}_{12} + w_{13} x^{(l)}_{13} + w_{21} x^{(l)}_{21} + w_{22} x^{(l)}_{22} + w_{23} x^{(l)}_{23} + w_{31} x^{(l)}_{31} + w_{32} x^{(l)}_{32} + w_{33} x^{(l)}_{33} & w_{11} x^{(l)}_{12} + w_{12} x^{(l)}_{13} + w_{13} x^{(l)}_{14} + w_{21} x^{(l)}_{22} + w_{22} x^{(l)}_{23} + w_{23} x^{(l)}_{24} + w_{31} x^{(l)}_{32} + w_{32} x^{(l)}_{33} + w_{33} x^{(l)}_{34}\\ w_{11} x^{(l)}_{21} + w_{12} x^{(l)}_{22} + w_{13} x^{(l)}_{23} + w_{21} x^{(l)}_{31} + w_{22} x^{(l)}_{32} + w_{23} x^{(l)}_{33} + w_{31} x^{(l)}_{41} + w_{32} x^{(l)}_{42} + w_{33} x^{(l)}_{43} & w_{11} x^{(l)}_{22} + w_{12} x^{(l)}_{23} + w_{13} x^{(l)}_{24} + w_{21} x^{(l)}_{32} + w_{22} x^{(l)}_{33} + w_{23} x^{(l)}_{34} + w_{31} x^{(l)}_{42} + w_{32} x^{(l)}_{43} + w_{33} x^{(l)}_{44}\end{bmatrix} \end{aligned} %]]></script>

<p>파이토치에서 Convolution Layer 는 <code class="highlighter-rouge">Conv2d</code> 로 구현되어 있다.</p>

<ul>
  <li>link: <a href="https://pytorch.org/docs/stable/nn.html#conv2d">torch.nn.Conv2d - PyTorch master documentation</a></li>
</ul>

<h2 id="deconvolution-layer-transposed-convolution-layer">Deconvolution Layer? Transposed Convolution Layer!</h2>

<p>저자는 이미 2011 년도에 Deconvolution Layer 를 제안했다.</p>

<ul>
  <li>link: <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.849.3679&amp;rep=rep1&amp;type=pdf">Adaptive Deconvolutional Networks for Mid and High Level Feature Learning</a></li>
</ul>

<p>간단하게 생각해보면 다음 그림과 같이 필터를 이동시키면서 원래 4x4 이미지(초록색)를 복원하면 될것 같다. 이 과정이 맞는지 이후에 살펴볼 것이다.</p>

<p><img src="https://drive.google.com/uc?id=1R-C4g1zSpculTzC8w00IrM9CNM0vifN_" /></p>

<p>흥미로운 것은 파이토치에서는 <code class="highlighter-rouge">ConvTranspose2d</code> 라고 구현이 되어 있다. 그리고 다음과 같은 설명이 덧붙여져 있다.</p>

<blockquote>
  <p>This module can be seen as the gradient of <code class="highlighter-rouge">Conv2d</code> with respect to its input. It is also known as a fractionally-strided convolution or a deconvolution (although it is not an actual deconvolution operation).</p>
</blockquote>

<ul>
  <li>link: <a href="https://pytorch.org/docs/stable/nn.html#convtranspose2d">torch.nn.ConvTranspose2d - PyTorch master documentation</a></li>
</ul>

<p>왜 이름이 Deconvolution 이 아닐까? 읽어보면 이 연산은 <code class="highlighter-rouge">Conv2d</code>의 출력을 입력에 대해 미분을 연산하는 것과 같다고 한다. 미분을 한번 구해보고 이를 C 라고 하자.</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned} C = \dfrac{\partial X^{(l+1)}}{\partial X^{(l)}}  &= \dfrac{\partial Vec(X^{(l+1)})}{\partial Vec(X^{(l)})} \\ &= \begin{bmatrix}  \dfrac{\partial x_{11}^{(l+1)}}{\partial x_{11}^{(l)}} & \dfrac{\partial x_{12}^{(l+1)}}{\partial x_{11}^{(l)}} & \dfrac{\partial x_{13}^{(l+1)}}{\partial x_{11}^{(l)}} & \dfrac{\partial x_{14}^{(l+1)}}{\partial x_{11}^{(l)}} \\ \vdots & \vdots & \vdots & \vdots \\ \dfrac{\partial x_{11}^{(l+1)}}{\partial x_{44}^{(l)}} & \dfrac{\partial x_{12}^{(l+1)}}{\partial x_{44}^{(l)}} & \dfrac{\partial x_{13}^{(l+1)}}{\partial x_{44}^{(l)}} & \dfrac{\partial x_{14}^{(l+1)}}{\partial x_{44}^{(l)}} \end{bmatrix} \\ & = \begin{bmatrix}w_{11} & 0 & 0 & 0\\w_{12} & w_{11} & 0 & 0\\w_{13} & w_{12} & 0 & 0\\0 & w_{13} & 0 & 0\\w_{21} & 0 & w_{11} & 0\\w_{22} & w_{21} & w_{12} & w_{11}\\w_{23} & w_{22} & w_{13} & w_{12}\\0 & w_{23} & 0 & w_{13}\\w_{31} & 0 & w_{21} & 0\\w_{32} & w_{31} & w_{22} & w_{21}\\w_{33} & w_{32} & w_{23} & w_{22}\\0 & w_{33} & 0 & w_{23}\\0 & 0 & w_{31} & 0\\0 & 0 & w_{32} & w_{31}\\0 & 0 & w_{33} & w_{32}\\0 & 0 & 0 & w_{33}\end{bmatrix} \end{aligned} %]]></script>

<p>이 미분 과정을 파이썬의 <code class="highlighter-rouge">sympy</code> 패키지로 쉽게 만들 수 있다(Jupyter Notebook 에서 사용하길 권장). 다음 코드에서 C 매트릭스를 살펴보면 위와 같은 결과를 얻을 수 있다.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">sympy</span> <span class="kn">import</span> <span class="n">Symbol</span><span class="p">,</span> <span class="n">MatrixSymbol</span><span class="p">,</span> <span class="n">Matrix</span>

<span class="c"># 노트북에서 수학식의 LaTeX 표현 사용</span>
<span class="n">sympy</span><span class="o">.</span><span class="n">init_printing</span><span class="p">(</span><span class="n">use_latex</span><span class="o">=</span><span class="s">'mathjax'</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">convolution</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">K</span><span class="p">,</span> <span class="n">N</span><span class="p">):</span>
    <span class="n">res</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">-</span><span class="n">K</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="o">-</span><span class="n">K</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">a</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">Matrix</span><span class="p">(</span><span class="n">x</span><span class="p">)[</span><span class="n">i</span><span class="p">:(</span><span class="n">K</span><span class="o">+</span><span class="n">i</span><span class="p">),</span> <span class="n">j</span><span class="p">:(</span><span class="n">K</span><span class="o">+</span><span class="n">j</span><span class="p">)]</span><span class="o">.</span><span class="n">multiply_elementwise</span><span class="p">(</span><span class="n">Matrix</span><span class="p">(</span><span class="n">w</span><span class="p">)))</span>
            <span class="n">res</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Matrix</span><span class="p">(</span><span class="n">res</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">N</span><span class="o">-</span><span class="n">K</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">N</span><span class="o">-</span><span class="n">K</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>

<span class="n">x_input</span> <span class="o">=</span> <span class="n">MatrixSymbol</span><span class="p">(</span><span class="s">"x^{(l)}"</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">x_output</span> <span class="o">=</span> <span class="n">MatrixSymbol</span><span class="p">(</span><span class="s">"x^{(l+1)}"</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">MatrixSymbol</span><span class="p">(</span><span class="s">"w"</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

<span class="c"># Convolution Output</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">convolution</span><span class="p">(</span><span class="n">x_input</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">K</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">N</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>

<span class="c"># Calculate derivatives &amp; get matrix C</span>
<span class="n">C</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">Matrix</span><span class="p">(</span><span class="n">x_input</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
</code></pre>
</div>

<p>이 C 행렬은 재밌는 특징을 가진다. 매트릭스 형태의 입력 데이터를 한줄로 핀 후에 매트릭스 연산을 하고, 다시 형태를 변환 시켜주면 Convolution 의 출력값이 나온다. 정말 맞는지 살펴보기 위해서 다음 코드를 실행해보자.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># forward (1, 16) x (16, 4) = (1, 4) = (2, 2)</span>
<span class="p">(</span><span class="n">Matrix</span><span class="p">(</span><span class="n">x_input</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span> <span class="err">@</span> <span class="n">C</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</code></pre>
</div>
<p>반대로 출력값을 한줄로 피고 C의 전치행렬과 곱한 후 다시 형태를 변환 시켜주면 입력과 다른 행렬이 나온다.</p>

<div class="language-python highlighter-rouge"><pre class="highlight"><code><span class="c"># backward</span>
<span class="p">(</span><span class="n">Matrix</span><span class="p">(</span><span class="n">x_output</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span> <span class="err">@</span> <span class="n">C</span><span class="o">.</span><span class="n">transpose</span><span class="p">())</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
</code></pre>
</div>
<p>실행하면 다음과 같은 행렬이 나오는데 이 연산 과정을 Deconvolution 연산, 정확히는 <strong>Fractionally-strided convolution</strong> 혹은 <strong>Transpose convolution</strong> 이라고 한다. 어떻게 계산된 것이며 어떤 뜻일까?</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{bmatrix}w_{11} x^{(l+1)}_{11} & w_{11} x^{(l+1)}_{12} + w_{12} x^{(l+1)}_{11} & w_{12} x^{(l+1)}_{12} + w_{13} x^{(l+1)}_{11} & w_{13} x^{(l+1)}_{12}\\w_{11} x^{(l+1)}_{21} + w_{21} x^{(l+1)}_{11} & w_{11} x^{(l+1)}_{22} + w_{12} x^{(l+1)}_{21} + w_{21} x^{(l+1)}_{12} + w_{22} x^{(l+1)}_{11} & w_{12} x^{(l+1)}_{22} + w_{13} x^{(l+1)}_{21} + w_{22} x^{(l+1)}_{12} + w_{23} x^{(l+1)}_{11} & w_{13} x^{(l+1)}_{22} + w_{23} x^{(l+1)}_{12}\\w_{21} x^{(l+1)}_{21} + w_{31} x^{(l+1)}_{11} & w_{21} x^{(l+1)}_{22} + w_{22} x^{(l+1)}_{21} + w_{31} x^{(l+1)}_{12} + w_{32} x^{(l+1)}_{11} & w_{22} x^{(l+1)}_{22} + w_{23} x^{(l+1)}_{21} + w_{32} x^{(l+1)}_{12} + w_{33} x^{(l+1)}_{11} & w_{23} x^{(l+1)}_{22} + w_{33} x^{(l+1)}_{12}\\w_{31} x^{(l+1)}_{21} & w_{31} x^{(l+1)}_{22} + w_{32} x^{(l+1)}_{21} & w_{32} x^{(l+1)}_{22} + w_{33} x^{(l+1)}_{21} & w_{33} x^{(l+1)}_{22}\end{bmatrix} %]]></script>

<p>출력을 계산하는 Convolution 연산 과정에서 <strong>“입력 픽셀”</strong> 에서 <strong>“출력 픽셀”</strong> 과 연결된 가중치를 생각하면 편하다. 다음 그림을 살펴보면, 필터(노란색)가 지나가면서, <strong>“입력 픽셀”</strong> ($x_{12}^{(l)}$)과 <strong>“출력 픽셀”</strong> ($x_{11}^{(l+1)}$, $x_{12}^{(l+1)}$)사이에 연결된 두 개의 가중치 ($w_{11}$, $w_{12}$)를 통해 연산이 된다. 위 행렬에서 1행 2열에 있는 원소 값과 연관이 있는 것을 확인 할 수 있는데, fractionally-strided convolution 연산은 바로 <strong>“출력 픽셀”</strong> 에서 <strong>“입력 픽셀”</strong> 로 방향을 바꿔 연산하면 된다.</p>

<p><img src="https://drive.google.com/uc?id=1acZ6YvrW6xooXJd6nYpFYhm-eDHSe2f1" /></p>

<p>Fractionally-strided convolution 연산은 다음 그림과 같다. “fractionally” 의 단어 뜻 처럼 필터가 출력 이미지의 일부분을 걸치면서 이동(stride)하면서 연산된다. 또한 가중치도 기존의 형태와 달리 약간의 변형(transpose)이 된다(정확한 전치행렬은 아니다).</p>

<p><img src="https://drive.google.com/uc?id=1WumIP2aCDNJ4cCWQW_2_Q0e1LCx_WkdQ" /></p>

<p>따라서 다시 정리하면 Convolution Layer의 출력을 입력에 대한 미분을 구해서(C 행렬), 이를 한줄로 편 출력과 곱한 후에 형태를 입력 이미지로 변환해주는 것이 Convolution 의 반대 연산인 Fractionally-strided convolution 이다. 수식으로 다음과 같이 정리 할 수 있다.</p>

<script type="math/tex; mode=display">X^{(l)} = [Vec\big(X^{(l+1)}\big)C^T]^{(N)}</script>

<ul>
  <li>$^{(N)}$은 Vector Transpose이며, 이는 다음 노트북을 살펴보자. <a href="https://nbviewer.jupyter.org/github/simonjisu/pytorch_tutorials/blob/master/00_Basic_Utils/04_Backpropagation_Matrix_diff.ipynb">Vector Transpose</a></li>
</ul>

<h3 id="additional-reference">Additional Reference</h3>

<p><a href="https://arxiv.org/abs/1603.07285">A guide to convolution arithmetic for deep learning</a></p>

</article>



<section class="rss">
  <p class="rss-subscribe text"><strong>Subscribe <a href="/feed.xml">via RSS</a></strong></p>
</section>

<section class="share">
  <span>이 글이 도움이 되었다면? </span>
  <style>.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#000000 !important;background-color:#FFDD00 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:'Cookie', cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#000000 !important;}</style>
<link href="https://fonts.googleapis.com/css?family=Cookie" rel="stylesheet">
<a class="bmc-button" target="_blank" href="https://www.buymeacoffee.com/ZWoFwrh">
    <img src="https://bmc-cdn.nyc3.digitaloceanspaces.com/BMC-button-images/BMC-btn-logo.svg" alt="Buy me a coffee">
    <span style="margin-left:5px">Buy me a coffee</span>
</a>
  <!-- 
    
    
      <a href="//www.facebook.com/sharer.php?t=%5BPyTorch%5D+ConvTranspose2d+%EC%99%80+Conv2d+%EC%9D%98+%EA%B4%80%EA%B3%84&u=http%3A%2F%2Fsimonjisu.github.io%2Fdatascience%2F2019%2F10%2F27%2Fconvtranspose2d.html"
        onclick="window.open(this.href, 'facebook-share', 'width=550,height=255');return false;">
        <i class="fa fa-facebook-square fa-lg"></i>
      </a>
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
   -->
</section>



  
    
    <!-- <h2 id="DataScience">-1</h2> -->
    <!-- <h2 id="DataScience">/datascience/2017/08/04/E2EMN.html</h2> -->
    
    <!-- <h2 id="DataScience">1</h2> -->
    <!-- <h2 id="DataScience">/datascience/2019/09/18/introxai.html</h2> -->
    



  
	<section class="post-navigation">
		<span class="prev-post">
			
				<a href="/datascience/2019/09/18/introxai.html">
					<span class="fa-stack fa-lg">
						<i class="fa fa-square fa-stack-2x"></i>
						<i class="fa fa-angle-double-left fa-stack-1x fa-inverse"></i>
					</span>
					<span class="page-number">[논문 리뷰] XAI Introduction</span>
				</a>
			
		</span>
		<span class="next-post">
			
		</span>
	</section>




  
  <section class="disqus">
    <div id="disqus_thread"></div>
    <script type="text/javascript">
      var disqus_shortname = 'soopace';

      /* * * DON'T EDIT BELOW THIS LINE * * */
      (function() {
          var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
          dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
          (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
    <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
  </section>
  


<!-- AMP -->
<amp-auto-ads type="adsense"
    data-ad-client="ca-pub-5855917513482122">
</amp-auto-ads>
</div>
</div>

    </div>

    <footer class="site-footer">

  <div class="wrapper">

    <h3 class="footer-heading">Soo</h3>

    <div class="site-navigation">

      <p><strong>Site Map</strong></p>
      <ul class="pages">
        
        
        
        
        
        
        
        
          <li class="nav-link"><a href="/posts/">Posts</a>
        
        
        
        
      </ul>
    </div>

    <div class="site-contact">

      <p><strong>Contact</strong></p>
      <ul class="social-media-list">
        <li>
          <a href="mailto:simonjisu@gmail.com">
            <i class="fa fa-envelope-o"></i>
            <span class="username">simonjisu@gmail.com</span>
          </a>
        </li>

        
          
          <li>
            <a href="https://www.facebook.com/simonjisu" title="Friend me on Facebook">
              <i class="fa fa-facebook"></i>
              <span class="username">simonjisu</span>
            </a>
          </li>
          
        
          
          <li>
            <a href="https://github.com/simonjisu" title="Fork me on GitHub">
              <i class="fa fa-github"></i>
              <span class="username">simonjisu</span>
            </a>
          </li>
          
        
          
        
          
        

      </ul>
    </div>

    <div class="site-signature">
      <p class="rss-subscribe text"><strong>Subscribe <a href="/feed.xml">via RSS</a></strong></p>
      <p class="text">My Blog
</p>
    </div>

  </div>
</footer>

<!-- Scripts -->
<script src="//code.jquery.com/jquery-1.11.2.min.js"></script>

<!-- Mathjax -->
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/lightbox2/2.7.1/js/lightbox.min.js"></script>
<script type="text/javascript">
$(document).ready(function() {
  // Default syntax highlighting
  hljs.initHighlightingOnLoad();
  $("code").addClass("python")
  // Header
  var menuToggle = $('#js-mobile-menu').unbind();
  $('#js-navigation-menu').removeClass("show");
  menuToggle.on('click', function(e) {
    e.preventDefault();
    $('#js-navigation-menu').slideToggle(function(){
      if($('#js-navigation-menu').is(':hidden')) {
        $('#js-navigation-menu').removeAttr('style');
      }
    });
  });
});
$("code").addClass("python")
</script>

<!--lightSlider-->
<script src="/js/lightslider.js"></script>
<script src='/js/multi_slider.js' type="text/javascript"></script>





    <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-102691608-1', 'auto');
  ga('send', 'pageview');
</script>

  </body>

</html>
