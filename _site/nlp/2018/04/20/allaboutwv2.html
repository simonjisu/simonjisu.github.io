<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>All about Word Vectors: Word2Vec</title>
  <meta name="description" content="All about Word Vectors: Word2Vec본 포스팅은 CS224n Lecture 2 강의내용을 기반으로 강의 내용 이해를 돕고자 작성 됐습니다.자연어 처리 공부를 해보신 분이라면 한번쯤 접한 그림이 있을 것이다.  “king” - “man” + “woman” = ?...">

  <!-- evil icon -->
  <link rel="stylesheet" href="/assets/evil-icons.min.css">
  <script src="/assets/evil-icons.min.js"></script>

  <!-- todo: include this into main.css -->
  <link href='https://fonts.googleapis.com/css?family=' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="https://simonjisu.github.io/nlp/2018/04/20/allaboutwv2.html">
  <link rel="alternate" type="application/rss+xml" title="Soopace" href="https://simonjisu.github.io/feed.xml">
  
  <!-- Favicon and other icons (made with http://www.favicon-generator.org/) -->
  <link rel="shortcut icon" href="/assets/icons/favicon.ico" type="image/x-icon">
  <link rel="icon" href="/assets/icons/favicon.ico" type="image/x-icon">
  <link rel="apple-touch-icon" sizes="57x57" href="/assets/icons/apple-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="/assets/icons/apple-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/assets/icons/apple-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="/assets/icons/apple-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="/assets/icons/apple-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="/assets/icons/apple-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/assets/icons/apple-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/assets/icons/apple-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/assets/icons/apple-icon-180x180.png">
  <link rel="icon" type="image/png" sizes="192x192"  href="/assets/icons/android-icon-192x192.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/assets/icons/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="96x96" href="/assets/icons/favicon-96x96.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/icons/favicon-16x16.png">
  <link rel="manifest" href="/assets/icons/manifest.json">
  <meta name="msapplication-TileColor" content="#ffffff">
  <meta name="msapplication-TileImage" content="/assets/icons/ms-icon-144x144.png">
  <meta name="theme-color" content="#ffffff">

  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-5GSH93K');
  </script>
  <!-- End Google Tag Manager -->
  
  <!-- Google Ad -->
  
    
<script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<script>
(adsbygoogle = window.adsbygoogle || []).push({
    google_ad_client: "ca-pub-5855917513482122",
    enable_page_level_ads: true
});
</script>

<script async custom-element="amp-auto-ads"
src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
</script>
  
  <!-- End Google Ad -->
  <script type="text/javascript" async
src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
    MathJax.Hub.Insert(MathJax.InputJax.TeX.Definitions.macros,{
    cancel: ["Extension","cancel"],
    bcancel: ["Extension","cancel"],
    xcancel: ["Extension","cancel"],
    cancelto: ["Extension","cancel"]
    });
});
MathJax.Hub.Config({
    TeX: {
        extensions: ["mhchem.js", "cancel.js"]
    },
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true,
        processEnvironments: true,
        ignoreClass: "no-mathjax",
    },
    displayAlign: 'center',
    "HTML-CSS": {
        styles: {'.MathJax_Display': {"margin": 0}},
        // linebreaks: { automatic: true }
    },
    menuSettings: {
        zoom: "Click",
        zscale: "200%"
    }
});
</script>
  <!-- Latex -->
  
</head>

  <body>
    <!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5GSH93K"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->

    <div class="page-content">
      <div class="container">
        <div class="three columns">
          <!-- see if categories is exists -->


<header class="site-header">
  <h2 class="logo">
    <a href="/">Soopace</a>
    <div class="logoimage box" style="background: url(/assets/img/logo.png)"></div>
  </h2>
    
    
  <div class="nav">
    <label for="menu-toggle" class="menu-icon">
        <!--div data-icon="ei-navicon"></div-->
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
    </label>
    <input type="checkbox" id="menu-toggle">
    <div class="site-nav">
      <nav class="page-link">
      
      
        
          <ul class="">
            <li><a href="https://simonjisu.github.io/">Home</a></li>
          </ul>
        
      
        
          <ul class="dropdown">
            <li>
              <a href="https://simonjisu.github.io/archive" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Posts</a>
              <ul class="dropdown-menu">
              
              
                
                  <li role="separator" class="divider"></li>
                
              
              
                
                  
                  <li>
                    <a href="https://simonjisu.github.io/archive#xai" target="_self">Xai</a>
                  </li>
                  
                
              
              
                
                  
                  <li>
                    <a href="https://simonjisu.github.io/archive#nlp" target="_self">Nlp</a>
                  </li>
                  
                
              
              
                
                  
                
              
              
                
                  
                
              
              
                
                  
                  <li>
                    <a href="https://simonjisu.github.io/archive#study" target="_self">Study</a>
                  </li>
                  
                
              
              
                
                  
                  <li>
                    <a href="https://simonjisu.github.io/archive#others" target="_self">Others</a>
                  </li>
                  
                
              
              
                
                  
                  <li>
                    <a href="https://simonjisu.github.io/archive#programming" target="_self">Programming</a>
                  </li>
                  
                
              
              
                
                  
                  <li>
                    <a href="https://simonjisu.github.io/archive#numpyseries" target="_self">Numpyseries</a>
                  </li>
                  
                
              
              
                
                  <li role="separator" class="divider"></li>
                
              
              </ul>
            </li> 
          </ul>
        
      
        
          <ul class="">
            <li><a href="https://simonjisu.github.io/about">Abouts</a></li>
          </ul>
        
      
        
          <ul class="">
            <li><a href="https://simonjisu.github.io/feed.xml">RSS</a></li>
          </ul>
        
      
      </nav>
    </div>
  </div>
</header>

        </div>

        <div class="nine columns" style="z-index:100;">
          <div class="wrapper">
            <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="article_header">
    <h1 id="article_top" itemprop="name headline">All about Word Vectors: Word2Vec</h1>
    <p class="article_meta"><time datetime="2018-04-20T10:19:06+09:00" itemprop="datePublished">Apr 20, 2018</time> • <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name">Soo</span></span></p>
    <hr>
  </header>

  <div class="article-content" itemprop="articleBody">
    <h1 id="all-about-word-vectors-word2vec">All about Word Vectors: Word2Vec</h1>

<hr />
<p>본 포스팅은 <a href="http://web.stanford.edu/class/cs224n/">CS224n</a> Lecture 2 강의내용을 기반으로 강의 내용 이해를 돕고자 작성 됐습니다.</p>

<p>자연어 처리 공부를 해보신 분이라면 한번쯤 접한 그림이 있을 것이다.</p>

<p><img src="/assets/ML/nlp/L2_linear-relationships.png" /></p>

<blockquote>
  <p>“king” - “man” + “woman” = ?</p>
</blockquote>

<p>느낌상 “왕”에서 “남자”라는 속성을 빼주고, “여자”의 속성을 더해주면?</p>

<p>“queen” 이 나와야할 것 같다. Word Representation은 이런 것을 가능하게 했다.</p>

<p>이번 시간에는 <strong>Word2vec</strong> 에 대해서 알아보려고 한다.</p>

<h2 id="word2vec">Word2Vec</h2>

<p>Word2Vec은 두 가지 알고리즘이 있다.</p>

<blockquote>
  <ol>
    <li>Skip-grams(SG)
      <ul>
        <li>target 단어를 기반으로 context 단어들을 예측한다. (position independent)</li>
      </ul>
    </li>
    <li>Continuous Bag of Words (CBOW)
      <ul>
        <li>context 단어들 집합(bag-of-words context)으로부터 target 단어를 예측한다.</li>
      </ul>
    </li>
  </ol>
</blockquote>

<ul id="light-slider1">
  <li><img src="/assets/ML/nlp/L2_skipgram1.png" /></li>
  <li><img src="/assets/ML/nlp/L2_skipgram2.png" /></li>
  <li><img src="/assets/ML/nlp/L2_cbow1.png" /></li>
  <li><img src="/assets/ML/nlp/L2_cbow2.png" /></li>
</ul>

<p>그리고 몇 가지 효율적인 훈련 방법들이 있다.</p>

<blockquote>
  <p>Two (moderately efficient) training methods (vs Naive Softmax)</p>
  <ol>
    <li>Hierarchical softmax</li>
    <li>Negative sampling</li>
  </ol>
</blockquote>

<p>출처: <a href="http://web.stanford.edu/class/cs224n/syllabus.html">CS224n Lecture 2</a></p>

<p>이번 포스팅에서는 Skip-gram 과 Negative Sampling을 메인으로 소개하겠다.</p>

<hr />

<h2 id="skip-gram-model-with-naive-softmax">Skip-gram model with Naive Softmax</h2>
<p>Paper: <a href="https://arxiv.org/pdf/1310.4546.pdf">Distributed Representations of Words and Phrases
and their Compositionality</a> (Mikolov et al. 2013)</p>

<p><br /></p>

<h3 id="embedding-look-up">Embedding Look up</h3>

<p>모델 설명에 들어가기 앞서 <strong>Embedding Look up</strong> 이란 것을 알아보자. 이 용어는 이제 여기저기서 많이 나올텐데 알아두면 좋다.</p>

<p>우리가 하고 싶은 것은 엄청나게 차원이 큰 one-hot vector 를 고정된 작은 차원으로 넣고 싶은 것이다. 어떻게 하면 단어들을 <strong>2-dimension matrix</strong> 로 표현 할 수 있을까?</p>

<p>아래 그림의 예를 보자. 8차원 one-hot vector를 3차원으로 만들고 싶다. 그렇다면 $3\times 8$ 행렬을 만들어서 각 column vector 가 하나의 3차원 단어를 표현하면 2-D Matrix 가 되지 않는가? 이 Matrix를 <strong>Embedding Matrix</strong> 라고 부르기로 하자</p>

<ul id="light-slider2">
  <li><img src="/assets/ML/nlp/L2_embedlookup1.png" /></li>
  <li><img src="/assets/ML/nlp/L2_embedlookup2.png" /></li>
</ul>

<p>그렇다면 어떻게 각 단어와 이 Embedding Matrix 를 매칭 시킬수 있을까? 여기서 <strong>내적</strong> 을 활용하게 된다.</p>

<ul id="light-slider3">
  <li><img src="/assets/ML/nlp/L2_embedlookup3.png" /></li>
  <li><img src="/assets/ML/nlp/L2_embedlookup4.png" /></li>
  <li><img src="/assets/ML/nlp/L2_embedlookup5.png" /></li>
</ul>

<p>그런데 자세히 보니, one-hot vector의 숫자 $1$ 이 위치한 index 가 Embedding Matrix 의 column vector 의 index 와 같다. 따라서 중복되지 않는 단어사전을 만들고, 각 단어에 대해 index를 메긴 다음, 찾고 싶은 단어를 Embedding Matrix 에서 column vector index 만 <strong>조회(Look up)</strong> 하면 되는 것이다.</p>

<ul id="light-slider4">
  <li><img src="/assets/ML/nlp/L2_embedlookup6.png" /></li>
  <li><img src="/assets/ML/nlp/L2_embedlookup7.png" /></li>
</ul>

<p><strong>코드 예시:</strong></p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import numpy as np
sentence = "I am going to watch Avengers Infinity War".split()
embedding_matrix = np.array([[1,2,5,1,9,10,3,4], [5,1,4,1,8,1,2,5], [7,8,1,4,1,6,2,1]])
vocab = {w: i for i, w in enumerate(sentence)}
word = "I"
print(embedding_matrix)
print("="*30)
print("Word:", word)
print("Index:", vocab[word])
print("Vector:", embedding_matrix[:, vocab.get(word)])
</code></pre></div></div>
<blockquote>
  <p>[[ 1  2  5  1  9 10  3  4]</p>

  <p>[ 5  1  4  1  8  1  2  5]</p>

  <p>[ 7  8  1  4  1  6  2  1]]</p>

  <p>==============================</p>

  <p>Word: I</p>

  <p>Index: 0</p>

  <p>Vector: [1 5 7]</p>
</blockquote>

<p>이해가 됐으면 이제 모델로 들어가보자.</p>

<p><br /></p>

<p><img src="/assets/ML/nlp/L2_model_train.png" /></p>

<h3 id="요약">요약</h3>

<p>Skip-gram 모델을 한 마디로 설명하자면, 문장의 모든 단어가 한번 씩 중심단어 $c$ 가 되어, $c$ 주변 문맥 단어 $o$ 가 나올 확률을 최대화 하는 것이다.</p>

<h3 id="목적">목적</h3>

<p>각 중심단어 $c$ 에 대해서 아래의 <strong>가능도/우도 (Likelihood)</strong> 를 구해본다.</p>

<script type="math/tex; mode=display">L(\theta) = \prod_{t=1}^{T} \prod_{-m \leq j \leq m,\ j \neq 0} p(w_{t+j} | w_t; \theta) \quad \cdots\cdots \quad (1)</script>

<p>수식을 말로 풀어보자. 각 포지션 $(\prod_{t=1}^{T})$ 의 중심단어 $c$ = $w_t$ 에 대해서, $w_t$ 가 주어졌을 때 다른 문맥단어 $o$ = $w_{t+j}$ 가 나오는 확률 $\big( p (w_{t+j} \vert w_t; \theta) \big)$ 을 가능하게 만드는 $\theta$ 를 구하는 것이다. 단 $j$ 는 윈도우 크기 $m$ 을 넘지 않으며, $0$ 이 될 수 없다.</p>

<p>따라서 <strong>Likelihood</strong> 를 <strong>최대화</strong> 하는 것이 우리의 목적이 되겠다.</p>

<p>그러나 여기서는 우리가 좋아하는 Gradient Descent 를 사용하기 위해서 이 식을 <strong>Negative Log Likelihood</strong> 로 변형해서 쓰기로한다.</p>

<script type="math/tex; mode=display">\min J(\theta) = -\dfrac{1}{T} \sum_{t=1}^T \sum_{-m \leq j \leq m,\ j \neq 0} \log p(w_{t+j} | w_t) \quad \cdots\cdots \quad (2)</script>

<ul>
  <li>$(1)$ 식과 $(2)$ 식이 왜 동등한지는 밑에 <strong><span style="color: #e87d7d">참고 1</span></strong> 을 확인하길 바란다.</li>
</ul>

<p><br /></p>

<p>그렇다면 단어가 등장할 확률 $p(w_{t+j} \vert w_t)$ 는 어떻게 구할 것인가?</p>

<p><strong>Softmax</strong> 라는 input 값을 0과 1 사이로 만들어 주는 친근한 함수가 있다.</p>

<script type="math/tex; mode=display">p(o|c) = \dfrac{\exp(u_o^T V_c)}{\sum_{w=1}^V \exp(u_w^T V_c)} \quad \cdots\cdots \quad (3)</script>

<p>따라서 모델에 있는 모든 파라미터를 $\theta \in \Bbb{R}^{2dV}$ 로 두고, $(2)$ 식을 최적화 한다.</p>

<ul>
  <li>왜 $\theta \in \Bbb{R}^{2dV}$ 인가?
Center Word 의 Embedding Matrix $W$ Context Words 의 Embedding Matrix $W’$ 두개를 학습 시켜야하기 때문이다.</li>
  <li><strong><span style="color: #e87d7d">주의 )</span></strong> $W’$ 는 $W$ 의 전치 행렬이 아니라 완전히 새로운 Embedding Matrix 다.</li>
</ul>

<p><br /></p>

<h3 id="update">Update</h3>

<p>Gradient를 통해서 각 파라미터들을 업데이트 하게 된다. $(3)$ 식의 $\log$ 를 취하게 되면 아래와 같다.</p>

<script type="math/tex; mode=display">f = \log \dfrac{\exp(u_o^T V_c)}{\sum_{w=1}^V \exp(u_w^T V_c)}</script>

<p>이제 $f$ 의 Gradient 를 구해보자.</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned} \dfrac{\partial f}{\partial V_c}
&= \dfrac{\partial }{\partial V_c} \big(\log(\exp(u_o^T V_c)) - \log(\sum_{w=1}^V \exp(u_w^T V_c))\big) \\
&= u_o - \dfrac{1}{\sum_{w=1}^V \exp(u_w^T V_c)}(\sum_{x=1}^V \exp(u_x^T V_c) u_x ) \\
&= u_o - \sum_{x=1}^V \dfrac{\exp(u_x^T V_c)}{\sum_{w=1}^V \exp(u_w^T V_c)} u_x \\
&= u_o - \sum_{x=1}^V P(x | c) u_x
\end{aligned} %]]></script>

<ul>
  <li>$u_o$ : observed word, output context word</li>
  <li>$P(x\vert c)$: probs context word $x$ given center word $c$</li>
  <li>$P(x\vert c)u_x$: Expectation of all the context words: likelihood occurance probs $\times$ context vector</li>
</ul>

<p>흥미로운 점: <strong>미분 값</strong> 은 관측된 context word 벡터 $u_o$ 에서 center word $c$ 가 주어졌을 때 나올 수 있는 모든 단어의 기대치를 빼준 다는 것이다.</p>

<hr />

<h3 id="참고-1-why-mle-is-equivalent-to-minimize-nll">참고 1: Why MLE is equivalent to minimize NLL?</h3>

<p><strong>Likelihood</strong> 의 정의:</p>

<script type="math/tex; mode=display">L(\theta|x_1,\cdots,x_n) = f(x_1, \cdots, x_n|\theta) = \prod_{i=1}^n f(x_i|\theta)</script>

<p>log를 취하게 되면 아래와 같다.</p>

<script type="math/tex; mode=display">\log L(\theta|x_1,\cdots,x_n) =  \sum_{i=1}^n log f(x_i|\theta)</script>

<p><strong>MLE(maximum likelihood estimator)</strong> 의 정의:</p>

<script type="math/tex; mode=display">\hat{\theta}_{MLE} = \underset{\theta}{\arg \max} \sum_{i=1}^n \log f(x_i|\theta)</script>

<script type="math/tex; mode=display">\underset{x}{\arg \max} (x) = \underset{x}{\arg \min}(-x)</script>

<p>때문에 우리는 아래의 식을 얻을 수 있다.</p>

<script type="math/tex; mode=display">\hat{\theta}_{MLE} = \underset{\theta}{\arg \max} \sum_{i=1}^n \log f(x_i|\theta) = \underset{\theta}{\arg \min} -\sum_{i=1}^n \log f(x_i|\theta)</script>

<ul>
  <li>왜 log 로 바꾸는 것인가?
    <ol>
      <li>컴퓨터 연산시 곱하기 보다 더하기를 쓰면 <strong>복잡도</strong> 가 훨씬 줄어들어 계산이 빠르다. ($O(n) \rightarrow O(1)$)</li>
      <li><strong>언더플로우</strong> 를 방지할수 있다. 언더플로우란 1보다 작은 수를 계속곱하면 0에 가까워져 컴퓨터에서 0 으로 표시되는 현상을 말한다.</li>
      <li>자연로그함수는 <strong>단조증가함수(monotonic increase function)</strong> 라서 대소관계가 바뀌지 않는다. 예를 들자면, $5 &lt; 10 \Longleftrightarrow log(5) &lt; log(10)$ 의 관계가 바뀌지 않는 다는 것. 따라서 언제든지 지수를 취해서 다시 원래의 값으로 복귀 가능.</li>
    </ol>
  </li>
  <li>참고
    <ul>
      <li><a href="https://quantivity.wordpress.com/2011/05/23/why-minimize-negative-log-likelihood/">why minimize negative log likelihood</a></li>
      <li><a href="https://ratsgo.github.io/deep%20learning/2017/09/24/loss/">(ratsgo 님) 손실함수</a></li>
    </ul>
  </li>
</ul>

<hr />

<p><br /></p>

<p>다음 시간에는 <strong>Naive Softmax</strong> 로 훈련 시켰을 때의 단점과 이를 보완 해준 <strong><span style="color: #e87d7d">Negative Sampling</span></strong> 에 대해서 알아보자.</p>

  </div>

  <footer class="article-footer">

  <div class="pagination to-top-post"><a href="https://simonjisu.github.io/archive#nlp">
    <data data-icon="ei-arrow-up"></data> Go to Posts  </a>
</div>
  <section class="buymecoffee">
    <p>이 글이 도움이 되었다면?</p> 
<style>.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#000000 !important;background-color:#FFDD00 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:'Cookie', cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#000000 !important;}</style >
<link href="https://fonts.googleapis.com/css?family=Cookie" rel="stylesheet">
<a class="bmc-button" 
target="_blank" 
href="https://www.buymeacoffee.com/ZWoFwrh">
    <img src="https://bmc-cdn.nyc3.digitaloceanspaces.com/BMC-button-images/BMC-btn-logo.svg" alt="Buy me a coffee">
    <span style="margin-left:5px">Buy me a coffee</span>
</a>
</section>
  <section class="author">
  <div class="authorimage box" style="background: url(/assets/img/author.jpg)"></div>
  <div class="authorinfo box">
    <p>Writer | Soopace</p>
    <p class="bio">
      Machine Learning Learner.
    </p>
  </div>
</section>
  
  </footer>
  
<section class="disqus">
  <div id="disqus_thread"></div>
  <script type="text/javascript">
    var disqus_shortname = 'soopace';

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>


  <!-- AMP -->
<amp-auto-ads type="adsense"
    data-ad-client="ca-pub-5855917513482122">
</amp-auto-ads>
</article>

          </div>
        </div>
      </div>
      <footer class="site-footer">
  <div class="container">
    <div class="footer left column one-half">
      <section class="small-font">
        Facebook: <a href="https://www.facebook.com/simonjisu">simonjisu</a>
        © Powered by <a href="https://github.com/jekyll/jekyll">jekyll</a>
      </section>
    </div>

    <div class="footer right column one-half">
      <section class="small-font">
        
        <a href="https://github.com/simonjisu"><span class="icon icon--github"><svg viewBox="0 0 16 16"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span></a>

        
        
      </section>
    </div>
  </div>
</footer>
 
      
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-102691608-1', 'auto');
  ga('send', 'pageview');
</script>


    </div>
  </body>
</html>
