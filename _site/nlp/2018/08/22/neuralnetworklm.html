<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>[Paper] A Neural Probabilistic Language Model</title>
  <meta name="description" content="[PAPER] A Neural Probabilistic Language Model클릭하면 링크를 따라갑니다.paper: A Neural Probabilistic Language Model - Yoshua Bengio, 2003  Slide Share  Code Repo  Noteb...">

  <!-- evil icon -->

  <link rel="stylesheet" href="/assets/evil-icons.min.css">
  <script src="/assets/evil-icons.min.js"></script>

  <!-- todo: include this into main.css -->
  <link href='https://fonts.googleapis.com/css?family=' rel='stylesheet' type='text/css'>
  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://localhost:4000/nlp/2018/08/22/neuralnetworklm.html">
  <link rel="alternate" type="application/rss+xml" title="Soopace" href="http://localhost:4000/feed.xml">
  
  <!-- Favicon and other icons (made with http://www.favicon-generator.org/) -->
  <link rel="shortcut icon" href="/assets/icons/favicon.ico" type="image/x-icon">
  <link rel="icon" href="/assets/icons/favicon.ico" type="image/x-icon">
  <link rel="apple-touch-icon" sizes="57x57" href="/assets/icons/apple-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="/assets/icons/apple-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="/assets/icons/apple-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="/assets/icons/apple-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="/assets/icons/apple-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="/assets/icons/apple-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="/assets/icons/apple-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="/assets/icons/apple-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="/assets/icons/apple-icon-180x180.png">
  <link rel="icon" type="image/png" sizes="192x192"  href="/assets/icons/android-icon-192x192.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/assets/icons/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="96x96" href="/assets/icons/favicon-96x96.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/icons/favicon-16x16.png">
  <link rel="manifest" href="/assets/icons/manifest.json">
  <meta name="msapplication-TileColor" content="#ffffff">
  <meta name="msapplication-TileImage" content="/assets/icons/ms-icon-144x144.png">
  <meta name="theme-color" content="#ffffff">



  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-5GSH93K');
  </script>
  <!-- End Google Tag Manager -->
  
  <!-- Google Ad -->
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
  <script>
    (adsbygoogle = window.adsbygoogle || []).push({
      google_ad_client: "ca-pub-5855917513482122",
      enable_page_level_ads: true
    });
  </script>

  <script async custom-element="amp-auto-ads"
    src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
  </script>
  <!-- End Google Ad -->

  <!-- Latex -->
  <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
      MathJax.Hub.Insert(MathJax.InputJax.TeX.Definitions.macros,{
        cancel: ["Extension","cancel"],
        bcancel: ["Extension","cancel"],
        xcancel: ["Extension","cancel"],
        cancelto: ["Extension","cancel"]
      });
    });
    MathJax.Hub.Config({
        TeX: {
            extensions: ["mhchem.js", "cancel.js"]
        },
        tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
            processEscapes: true,
            processEnvironments: true,
            ignoreClass: "no-mathjax",
        },
        displayAlign: 'center',
        "HTML-CSS": {
            styles: {'.MathJax_Display': {"margin": 0}},
            // linebreaks: { automatic: true }
        },
        menuSettings: {
            zoom: "Click",
            zscale: "200%"
        }
    });
  </script>
</head>

  <body>
    <!-- Google Tag Manager (noscript) -->
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-5GSH93K"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
<!-- End Google Tag Manager (noscript) -->

    <div class="page-content">
      <div class="container">
        <div class="three columns">
          <!-- see if categories is exists -->


<header class="site-header">
  <h2 class="logo">
    <a href="/">Soopace</a>
    <div class="logoimage box" style="background: url(/assets/img/logo.png)"></div>
  </h2>
    
    
  <div class="nav">
    <label for="menu-toggle" class="menu-icon">
        <!--div data-icon="ei-navicon"></div-->
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
    </label>
    <input type="checkbox" id="menu-toggle">
    <div class="site-nav">
      <nav class="page-link">
      
      
        
          <ul class="">
            <li><a href="http://localhost:4000/">Home</a></li>
          </ul>
        
      
        
          <ul class="dropdown">
            <li>
              <a href="http://localhost:4000/archive" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Posts</a>
              <ul class="dropdown-menu">
              
              
                
                  <li role="separator" class="divider"></li>
                
              
              
                
                  
                  <li>
                    <a href="http://localhost:4000/archive#xai" target="_self">Xai</a>
                  </li>
                  
                
              
              
                
                  
                  <li>
                    <a href="http://localhost:4000/archive#nlp" target="_self">Nlp</a>
                  </li>
                  
                
              
              
                
                  
                
              
              
                
                  
                
              
              
                
                  
                  <li>
                    <a href="http://localhost:4000/archive#study" target="_self">Study</a>
                  </li>
                  
                
              
              
                
                  
                  <li>
                    <a href="http://localhost:4000/archive#others" target="_self">Others</a>
                  </li>
                  
                
              
              
                
                  
                  <li>
                    <a href="http://localhost:4000/archive#programming" target="_self">Programming</a>
                  </li>
                  
                
              
              
                
                  
                  <li>
                    <a href="http://localhost:4000/archive#numpyseries" target="_self">Numpyseries</a>
                  </li>
                  
                
              
              
                
                  <li role="separator" class="divider"></li>
                
              
              </ul>
            </li> 
          </ul>
        
      
        
          <ul class="">
            <li><a href="http://localhost:4000/about">Abouts</a></li>
          </ul>
        
      
        
          <ul class="">
            <li><a href="http://localhost:4000/feed.xml">RSS</a></li>
          </ul>
        
      
      </nav>
    </div>
  </div>
</header>

        </div>

        <div class="nine columns" style="z-index:100;">
          <div class="wrapper">
            <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="article_header">
    <h1 id="article_top" itemprop="name headline">[Paper] A Neural Probabilistic Language Model</h1>
    <p class="article_meta"><time datetime="2018-08-22T23:26:14+09:00" itemprop="datePublished">Aug 22, 2018</time> • <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name">Soo</span></span></p>
    <hr>
  </header>

  <div class="article-content" itemprop="articleBody">
    <h1 id="paper-a-neural-probabilistic-language-model">[PAPER] A Neural Probabilistic Language Model</h1>
<hr />

<p>클릭하면 링크를 따라갑니다.</p>

<p><strong>paper: <a href="http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf">A Neural Probabilistic Language Model</a> - Yoshua Bengio, 2003</strong></p>

<ul>
  <li><a href="http://bit.ly/2OkYFkY">Slide Share</a></li>
  <li><a href="http://bit.ly/2PsEPpg">Code Repo</a></li>
  <li><a href="https://nbviewer.jupyter.org/github/simonjisu/deepnlp_study/blob/master/notebook/01_NNLM.ipynb">Notebook</a></li>
</ul>

<hr />

<h2 id="메인-아이디어">메인 아이디어</h2>

<p>기존의 통계 기반의 Language Modeling 은 N-Gram 을 기반으로, 이전 토큰의 나오는 단어를 기반으로 다음 단어의 확률을 극대화 작업이었다. 처음부터 끝까지 보지 않고 N-Gram으로 잘라서 예측하게된 이유는 예측해야할 단어와 아주 오래된 단어간의 상관관계가 적다(혹은 분포가 다르다)라고 생각했기 때문이다.</p>

<script type="math/tex; mode=display">P(w_t \vert w_1, w_2, \cdots, w_{t-1}) \approx P(w_t \vert t_{t-(n-1)}, \cdots t_{t-1})</script>

<p>확률을 정의 할때는 Counting 을 사용했다. 예를 들어, “New York” 뒤에 “University” 가 나올  확률을 예측한다고 해보자. 데이터에서 “New York University” 가 등장한 횟수를 세고, “New York” 뒤에 올 수있는 다른 모든 단어의 등장 횟수를 다 Count 한다.</p>

<script type="math/tex; mode=display">P(University \vert New, York) = \dfrac{Count(New, York, University)}{\sum_w Count(New, York, w)}</script>

<p>해당 방법은 간단하나 문제점이 있다.</p>

<ul>
  <li>첫째, 훈련데이터에서 보지 못한 새로운 단어 조합이 등장하게 되면 확률이 0 이 된다.</li>
  <li>둘째, N-Gram 의 N 은 작은 수로 적을 수 밖에 없다. 1만개의 단어가 있으면 1-Gram 은 1만, 2-Gram 은 약 5천만 ($C_{10000}^{2}$), 3-Gram 은 약 1700억 ($C_{10000}^{3}$) 이 된다. 즉, N 이 커질수록 계산을 하기 위한 더 많은 컴퓨터 자원이 필요하다. (논문이 나온 2003년때 쯤에는 요즘같이 계산을 하기 위한 GPU 도 없었을 것이다.)</li>
</ul>

<p>따라서 논문에는 위 두가지 문제점을 해결하기 위해 N 을 더 늘리고, 새로 등장한 단어에 대해서도 예측가능한 모델을 만들고자 했다.</p>

<p>Yoshua Bengio 교수님이 제안한 모델의 특징은 3 가지로 요약 할 수 있다.</p>

<blockquote>
  <ol>
    <li>단어를 m 차원에 벡터와 연관 짓는다.</li>
    <li>m 차원 벡터로 표현된 단어들의 조건부 확률을 표현한다.</li>
    <li>조건부 확률과 m 차원의 벡터를 동시에 학습한다.</li>
  </ol>
</blockquote>

<p>아래에서 더 풀어서 설명한다.</p>

<hr />

<h2 id="모델-설명">모델 설명</h2>

<p><img src="https://dl.dropbox.com/s/8thdipjnc7bl95f/0826_nnlm.png" /></p>

<p>두 가지 단계로 모델이 구성되 있다.</p>

<h3 id="1-단계-distributed-feature-vectors">1 단계: Distributed feature vectors</h3>

<blockquote>
  <p>각 단어를 $C$ 행렬을 통해 $m$ 차원 벡터로 표현한다.</p>
</blockquote>

<p>단어를 $m$ 차원 실수 벡터로 연관 지어야 한다. 최근에는 이 방법을 임베딩 (Embedding)이라고 하는데 논문에서는 분산된 특징 벡터 (Distributed feature vectors) 라고 했다.</p>

<script type="math/tex; mode=display">C(i) \in \Bbb{R}^m</script>

<p>$C$ 행렬의 $i$ 번째 행을, $i$ 번째 단어의 벡터라고 규정 지었으며, $C$ 의 형태는 $\vert V \vert \times m$ 다.</p>

<h3 id="2-단계-probability-functions">2 단계: Probability functions</h3>

<blockquote>
  <p>$m$ 차원으로 표현된 벡터를 2 층의 신경망을 사용해서 조건부 확률을 구성한다.</p>
</blockquote>

<p>우선 임베딩된 $m$ 차원의 벡터들을 concatenate 하여 하나의 벡터로 만든다. 이를 context 라고 한다.</p>

<script type="math/tex; mode=display">x = \big( C(w_{t-n+1}), \cdots, C(w_{t-2}), C(w_{t-1}) \big)</script>

<p>그 후 2층의 신경망에 통과시켜 Softmax 로 최종적인 확률을 구한다.</p>

<script type="math/tex; mode=display">y = U \tanh(d + Hx)</script>

<script type="math/tex; mode=display">P(w_i = i \vert context) = \dfrac{\exp(y_{w_t})}{\sum_i \exp(y_i)}</script>

<h3 id="기타-direct-connection">기타: direct connection</h3>

<p>논문에서는 실험적으로 선형적인 관계식을 하나 더 넣어서 context 와 y 사이의 선형관계를 알아내고자 했다.</p>

<script type="math/tex; mode=display">y = \underbrace{b + Wx}_{\text{direct connection}} +U \tanh(d + Hx)</script>

<hr />

<h2 id="실험결과">실험결과</h2>

<h3 id="perplexity">Perplexity</h3>

<p>Test Measurement 로 <strong>Perplexity</strong> 를 선택했다. 정의는 아래와 같다.</p>

<blockquote>
  <p>A measurement of how well a probability distribution or probability model (q) predicts a sample</p>
</blockquote>

<script type="math/tex; mode=display">PP = \exp(-\dfrac{1}{N} \sum_{i=1}^N \log_e q(x_i))</script>

<p>자세히 보면 지수안에 엔트로피 함수가 들어가 있는 것을 볼 수 있다.</p>

<p>해당 수식을 말로 풀어보면, 모든 테스트 세트에서 확률 모델 $q$ 의 불확실 정도가 어떻게 되는지를 측정한다. 즉, 이 값이 높을 수록 모델이 예측을 잘 못하며, 낮을 수록 해당테스트 토큰을 확실하게 측정한다는 뜻이다.</p>

<h3 id="time">Time</h3>

<p>시간을 측정한 이유는 학습할 파라미터 숫자가 생각보다 많기 때문이다.</p>

<script type="math/tex; mode=display">\theta = (b, d, W, U, H, C)</script>

<p>총 학습해야할 파라미터 수는 $\vert V \vert(1+mn+h)+h(1+(n-1)m)$ 로 계산된다.</p>

<p>각 행렬의 크기를 아래에 표시해 두었다.</p>

<blockquote>
  <script type="math/tex; mode=display">% <![CDATA[
\begin{aligned} b &= \vert V \vert \\
d &= h \\
U &= \vert V \vert \times h \\
W &= \vert V \vert \times (n-1)m \\
H &= h \times (n-1)m \\
C &= \vert V \vert \times m
\end{aligned} %]]></script>
</blockquote>

<h3 id="result">Result</h3>

<p><img src="https://dl.dropbox.com/s/c975f2j26kzj715/0826_nnlmresult.png" /></p>

<p>영어 단어 Brown corpus (약 16000개의 단어)에 대해서, 은닉층 유닛수를 100, 임베딩 차원을 30, direct connection이 없고, 5-Gram 을 사용했을 때 결과는 Perplexity 가 제일 낮았다.</p>

<p>개인적인 실험으로 네이버 영화 corpus [<a href="https://github.com/e9t/nsmc">링크</a>]를 사용하여 평균 perplexity 측정해보았다. [<a href="https://nbviewer.jupyter.org/github/simonjisu/deepnlp_study/blob/master/notebook/01_NNLM.ipynb">노트북링크</a>]</p>

<p>한글 데이터를 사용해 최대한 단어갯수를 줄이려고 문장당 부호 및 단일 한글자음모음을 하나로 제약했다. 따라서 총 약 6만개의 단어가 사용됐다. 10 번의 epoch를 훈련 시킨 결과 Perplexity는 계속 떨어지지만 accuracy 는 20% 이후 상승이 멈췄다. 또한 훈련시간이 34 분 가량 걸렸다. 그만큼 학습할 파라미터가 많다는 뜻이다.</p>

<p>아래 문장으로 언어모델링을 해보았다.</p>

<blockquote>
  <p>요즘 나오는 어린이 영화보다 수준 낮은 시나리오 거기다 우리가 아는 윌스미스 보다 어린 윌스미스에 발연기는 보너스</p>
</blockquote>

<table>
  <thead>
    <tr>
      <th style="text-align: center">input</th>
      <th style="text-align: center">predict</th>
      <th style="text-align: center">target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">요즘/Noun 나오는/Verb 어린이/Noun 영화/Noun</td>
      <td style="text-align: center">가/Josa</td>
      <td style="text-align: center">보다/Josa</td>
    </tr>
    <tr>
      <td style="text-align: center">나오는/Verb 어린이/Noun 영화/Noun 보다/Josa</td>
      <td style="text-align: center">더/Noun</td>
      <td style="text-align: center">수준/Noun</td>
    </tr>
    <tr>
      <td style="text-align: center">어린이/Noun 영화/Noun 보다/Josa 수준/Noun</td>
      <td style="text-align: center">이/Josa</td>
      <td style="text-align: center">낮은/Adjective</td>
    </tr>
    <tr>
      <td style="text-align: center">영화/Noun 보다/Josa 수준/Noun 낮은/Adjective</td>
      <td style="text-align: center">영화/Noun</td>
      <td style="text-align: center">시나리오/Noun</td>
    </tr>
    <tr>
      <td style="text-align: center">보다/Josa 수준/Noun 낮은/Adjective 시나리오/Noun</td>
      <td style="text-align: center">가/Josa</td>
      <td style="text-align: center">거기/Noun</td>
    </tr>
    <tr>
      <td style="text-align: center">수준/Noun 낮은/Adjective 시나리오/Noun 거기/Noun</td>
      <td style="text-align: center">에/Josa</td>
      <td style="text-align: center">다/Josa</td>
    </tr>
    <tr>
      <td style="text-align: center">낮은/Adjective 시나리오/Noun 거기/Noun 다/Josa</td>
      <td style="text-align: center">./Punctuation</td>
      <td style="text-align: center">우리/Noun</td>
    </tr>
    <tr>
      <td style="text-align: center">시나리오/Noun 거기/Noun 다/Josa 우리/Noun</td>
      <td style="text-align: center">는/Josa</td>
      <td style="text-align: center">가/Josa</td>
    </tr>
    <tr>
      <td style="text-align: center">거기/Noun 다/Josa 우리/Noun 가/Josa</td>
      <td style="text-align: center">뭐/Noun</td>
      <td style="text-align: center">아는/Verb</td>
    </tr>
    <tr>
      <td style="text-align: center">다/Josa 우리/Noun 가/Josa 아는/Verb</td>
      <td style="text-align: center">사람/Noun</td>
      <td style="text-align: center">윌스미스/Noun</td>
    </tr>
    <tr>
      <td style="text-align: center">우리/Noun 가/Josa 아는/Verb 윌스미스/Noun</td>
      <td style="text-align: center">인데/Josa</td>
      <td style="text-align: center">보다/Verb</td>
    </tr>
    <tr>
      <td style="text-align: center">가/Josa 아는/Verb 윌스미스/Noun 보다/Verb</td>
      <td style="text-align: center">가/Eomi</td>
      <td style="text-align: center">어린/Verb</td>
    </tr>
    <tr>
      <td style="text-align: center">아는/Verb 윌스미스/Noun 보다/Verb 어린/Verb</td>
      <td style="text-align: center">애/Noun</td>
      <td style="text-align: center">윌스미스/Noun</td>
    </tr>
    <tr>
      <td style="text-align: center">윌스미스/Noun 보다/Verb 어린/Verb 윌스미스/Noun</td>
      <td style="text-align: center">가/Josa</td>
      <td style="text-align: center">에/Josa</td>
    </tr>
    <tr>
      <td style="text-align: center">보다/Verb 어린/Verb 윌스미스/Noun 에/Josa</td>
      <td style="text-align: center">대한/Noun</td>
      <td style="text-align: center">발연기/Noun</td>
    </tr>
    <tr>
      <td style="text-align: center">어린/Verb 윌스미스/Noun 에/Josa 발연기/Noun</td>
      <td style="text-align: center">에/Josa</td>
      <td style="text-align: center">는/Josa</td>
    </tr>
    <tr>
      <td style="text-align: center">윌스미스/Noun 에/Josa 발연기/Noun 는/Josa</td>
      <td style="text-align: center">좋/Adjective</td>
      <td style="text-align: center">보너스/Noun</td>
    </tr>
  </tbody>
</table>

<p>결과를 살펴보면 문맥은 상당히 못맞추었으나 문장의 구조는 잘 학습한 것을 알 수 있다.</p>

  </div>

  <footer class="article-footer">
  <section class="buymecoffee">
<p>이 글이 도움이 되었다면?</p> 
<style>.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#000000 !important;background-color:#FFDD00 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:'Cookie', cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#000000 !important;}</style >
<link href="https://fonts.googleapis.com/css?family=Cookie" rel="stylesheet">
<a class="bmc-button" 
target="_blank" 
href="https://www.buymeacoffee.com/ZWoFwrh">
    <img src="https://bmc-cdn.nyc3.digitaloceanspaces.com/BMC-button-images/BMC-btn-logo.svg" alt="Buy me a coffee">
    <span style="margin-left:5px">Buy me a coffee</span>
</a>
</section>
  <section class="author">
  <div class="authorimage box" style="background: url(/assets/img/author.jpg)"></div>
  <div class="authorinfo box">
    <p>Writer | Soopace</p>
    <p class="bio">
      Machine Learning Learner.
    </p>
  </div>
</section>

  
  </footer>
  
<section class="disqus">
  <div id="disqus_thread"></div>
  <script type="text/javascript">
    var disqus_shortname = 'soopace';

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  <a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</section>


  <!-- AMP -->
<amp-auto-ads type="adsense"
    data-ad-client="ca-pub-5855917513482122">
</amp-auto-ads>
</article>

          </div>
        </div>
      </div>
      <footer class="site-footer">
  <div class="container">
    <div class="footer left column one-half">
      <section class="small-font">
        Facebook: <a href="https://www.facebook.com/simonjisu">simonjisu</a>
        © Powered by <a href="https://github.com/jekyll/jekyll">jekyll</a>
      </section>
    </div>

    <div class="footer right column one-half">
      <section class="small-font">
        
        <a href="https://github.com/simonjisu"><span class="icon icon--github"><svg viewBox="0 0 16 16"><path fill="#828282" d="M7.999,0.431c-4.285,0-7.76,3.474-7.76,7.761 c0,3.428,2.223,6.337,5.307,7.363c0.388,0.071,0.53-0.168,0.53-0.374c0-0.184-0.007-0.672-0.01-1.32 c-2.159,0.469-2.614-1.04-2.614-1.04c-0.353-0.896-0.862-1.135-0.862-1.135c-0.705-0.481,0.053-0.472,0.053-0.472 c0.779,0.055,1.189,0.8,1.189,0.8c0.692,1.186,1.816,0.843,2.258,0.645c0.071-0.502,0.271-0.843,0.493-1.037 C4.86,11.425,3.049,10.76,3.049,7.786c0-0.847,0.302-1.54,0.799-2.082C3.768,5.507,3.501,4.718,3.924,3.65 c0,0,0.652-0.209,2.134,0.796C6.677,4.273,7.34,4.187,8,4.184c0.659,0.003,1.323,0.089,1.943,0.261 c1.482-1.004,2.132-0.796,2.132-0.796c0.423,1.068,0.157,1.857,0.077,2.054c0.497,0.542,0.798,1.235,0.798,2.082 c0,2.981-1.814,3.637-3.543,3.829c0.279,0.24,0.527,0.713,0.527,1.437c0,1.037-0.01,1.874-0.01,2.129 c0,0.208,0.14,0.449,0.534,0.373c3.081-1.028,5.302-3.935,5.302-7.362C15.76,3.906,12.285,0.431,7.999,0.431z"/></svg>
</span></a>

        
        
      </section>
    </div>
  </div>
</footer>
 
      
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-102691608-1', 'auto');
  ga('send', 'pageview');
</script>


    </div>
  </body>
</html>
