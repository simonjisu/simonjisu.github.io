I"3<h1 id="ml-decisiontree">[ML] DecisionTree</h1>
<p>의사결정나무의 소개는 <a href="https://ko.wikipedia.org/wiki/%EA%B2%B0%EC%A0%95_%ED%8A%B8%EB%A6%AC_%ED%95%99%EC%8A%B5%EB%B2%95">링크</a>로 대체하고 어떻게 진행되는지만 알아보자</p>

<ul>
  <li>의사결정나무의 장점: 어떤 변수가 분류에 영향을 끼쳤는지 사람이 보기 쉽게 되어있다. 사람 입장에서 해석에 용이하다.</li>
  <li>의사결정나무의 단점: 오버피팅이 심하다. 따라서 보통 랜덤 포레스트라는 앙상블 방법론을 쓴다. 초기 단계에서 랜덤 요소를 넣어서 오버피팅을 방지한다.</li>
</ul>

<p>의사 결정나무모델은 분류를 할때 책상정리에 비유한다. 더러운 책상에 있는 물건을 어떤 기준에 따라서 하나씩 정리하는 거다.</p>

<p><img src="/assets/ML/DecisionTree_Desk.jpeg" alt="Drawing" style="width: 400px;" /></p>

<p>(사진출처: 네이버 블로그)</p>

<p>그렇다면 데이터를 분류하는 기준은 도대체 무엇인가?</p>

<h1 id="엔트로피entropy와-정보획득information-gain">엔트로피(Entropy)와 정보획득(Information Gain)</h1>
<p>데이터를 분류하는 기준은 아래와 같다.</p>

<ol>
  <li>어떤 기준으로 분류 후에 histogram으로부터 조건부 엔트로피를 계산 함</li>
  <li>이전 entropy와 새로구한 조건부 엔트로피의 차이(:=Infomation Gain)이 최대 인 것을 best feature로 선택한다</li>
</ol>

<p><a href="https://ko.wikipedia.org/wiki/%EC%97%94%ED%8A%B8%EB%A1%9C%ED%94%BC">엔트로피</a>를 이해하자면 정리안된 책상의 상태를 생각하면 편할 것이다. 엔트로피가 높으면 책상이 굉장히 정리가 안된 상태(혼돈의 상태)고, 엔트로피가 적을 수록 점점 정리되어가는 책상을 생각하면 된다.</p>

<p>엔트로피의 계산 방식은 아래와 같다.</p>
<blockquote>
  <p>엔트로피: $H[Y] = -\sum_{k=1}^K p(y_k) \log_2 p(y_k)$</p>

  <p>조건부 엔트로피: $H[Y \mid X] = - \sum_i \sum_j \,p(x_i, y_j) \log_2 p(y_j \mid x_i)$</p>
</blockquote>

<ul>
  <li>$y_k$: $k$ 카테고리에 속하는 $y$ 의 갯수</li>
  <li>$p(y_k)$: 변수 $y$ 가 카테고리 $k$ 에 속할 확률</li>
</ul>

<p>본격적인 계산을 위해 엔트로피를 아래와 같은 데이터가 있다고 가정하고 단계별로 진행 해보자.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">f1</th>
      <th style="text-align: center">f2</th>
      <th style="text-align: center">f3</th>
      <th style="text-align: center">y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">0</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">yes</td>
    </tr>
    <tr>
      <td style="text-align: center">0</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">no</td>
    </tr>
    <tr>
      <td style="text-align: center">1</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">no</td>
    </tr>
    <tr>
      <td style="text-align: center">0</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">no</td>
    </tr>
    <tr>
      <td style="text-align: center">0</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">no</td>
    </tr>
    <tr>
      <td style="text-align: center">1</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">yes</td>
    </tr>
  </tbody>
</table>

<h2 id="계산과정">계산과정</h2>
<h3 id="1-단계-base-entropy-분류가-안되었을-때의-entropy">[1 단계] base entropy: 분류가 안되었을 때의 entropy</h3>
<p>기초 엔트로피(base entropy), 즉 분류가 되기전의 상태를 계산해야 분류후에 엔트로피의 차이를 구할 수 있다.</p>

<p>기초 엔트로피를 $E_{base}$ 라고 하면,</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">y=yes</th>
      <th style="text-align: center">y=no</th>
      <th style="text-align: center">total</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">2</td>
      <td style="text-align: center">4</td>
      <td style="text-align: center">6</td>
    </tr>
  </tbody>
</table>

<p>class의 히스토그램을 그리고 갯수를 세어본다. 지금의 class는 $(yes, no)$ 2개로 $K=2$ 가 되고, 히스토그램에 따라서 계산하면 기초 엔트로피를 구할 수 있다.</p>
<blockquote>
  <p>$E_{base} = -[\ P(y_{=yes})\log{P(y_{=yes})} + P(y_{=no})\log{P(y_{=no})}\ ]<br />
= -(\frac{2}{6}\log{\frac{2}{6}}+\frac{4}{6}\log{\frac{4}{6}}) = 0.9182$</p>
</blockquote>

<h3 id="2-단계-feature별로-조건부-엔트로피를-구하고-infomation-gain구함">[2 단계] feature별로 조건부 엔트로피를 구하고 Infomation Gain구함</h3>
<p>Information Gain 은 이전 단계 엔트로피에서 각 feature의 엔트로피를 빼면 구할 수 있다. 즉, 각 feature가 기준이 되어서 엔트로피를 제일 작게 만드는, 혹은 Information Gain을 제일 크게 만드는 쪽으로 분류를 진행하는 것이다.</p>
<h4 id="feature-1">feature 1</h4>

<table>
  <thead>
    <tr>
      <th style="text-align: center">f1</th>
      <th style="text-align: center">y=yes</th>
      <th style="text-align: center">y=no</th>
      <th style="text-align: center">total</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">x=1</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">2</td>
    </tr>
    <tr>
      <td style="text-align: center">x=0</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">3</td>
      <td style="text-align: center">4</td>
    </tr>
    <tr>
      <td style="text-align: center">total</td>
      <td style="text-align: center">2</td>
      <td style="text-align: center">4</td>
      <td style="text-align: center">6</td>
    </tr>
  </tbody>
</table>

<blockquote>
  <p>$E_1 = -[\ P(y_{=yes},x_{=1})\log{P(y_{=yes}|x_{=1})} + P(y_{=no},x_{=1})\log{P(y_{=no}|x_{=1})} +P(y_{=yes},x_{=0})\log{P(y_{=yes}|x_{=0})} + P(y_{=no},x_{=0})\log{P(y_{=no}|x_{=0})}\ ]$
$= -[\ \frac{1}{6}\log{\frac{1}{2}}+\frac{1}{6}\log{\frac{1}{2}}+\frac{1}{6}\log{\frac{1}{4}}+\frac{3}{6}\log{\frac{3}{4}}\ ] = 0.8741$</p>

  <p>$IG_1 = E_{base} - E_1 = 0.0441$</p>
</blockquote>

<p>마찬가지로 feature2 와 feature3도 똑같이 구할 수 있다.</p>
<h4 id="feature-2">feature 2</h4>

<table>
  <thead>
    <tr>
      <th style="text-align: center">f2</th>
      <th style="text-align: center">y=yes</th>
      <th style="text-align: center">y=no</th>
      <th style="text-align: center">total</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">x=1</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">3</td>
      <td style="text-align: center">4</td>
    </tr>
    <tr>
      <td style="text-align: center">x=0</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">2</td>
    </tr>
    <tr>
      <td style="text-align: center">total</td>
      <td style="text-align: center">2</td>
      <td style="text-align: center">4</td>
      <td style="text-align: center">6</td>
    </tr>
  </tbody>
</table>

<blockquote>
  <p>$E_2 = -[\ \frac{1}{6}\log{\frac{1}{4}} + \frac{3}{6}\log{\frac{3}{4}} + \frac{1}{6}\log{\frac{1}{2}} + \frac{1}{6}\log{\frac{1}{2}}] = 0.8741$</p>

  <p>$IG_2 = E_{base} - E_2 = 0.0441$</p>
</blockquote>

<h4 id="feature-3">feature 3</h4>

<table>
  <thead>
    <tr>
      <th style="text-align: center">f3</th>
      <th style="text-align: center">y=yes</th>
      <th style="text-align: center">y=no</th>
      <th style="text-align: center">total</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">x=1</td>
      <td style="text-align: center">2</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">2</td>
    </tr>
    <tr>
      <td style="text-align: center">x=0</td>
      <td style="text-align: center">2</td>
      <td style="text-align: center">2</td>
      <td style="text-align: center">4</td>
    </tr>
    <tr>
      <td style="text-align: center">total</td>
      <td style="text-align: center">4</td>
      <td style="text-align: center">2</td>
      <td style="text-align: center">6</td>
    </tr>
  </tbody>
</table>

<blockquote>
  <p>$E_3 = -[\ \frac{2}{6}\log{\frac{2}{2}} + \frac{0}{6}\log{\frac{0}{2}} + \frac{2}{6}\log{\frac{2}{4}} + \frac{2}{6}\log{\frac{2}{4}}] = 0.6666$</p>

  <p>$IG_3 = E_{base} - E_3=0.2516$</p>
</blockquote>

<h3 id="3단계-결과-및-선택">[3단계] 결과 및 선택:</h3>

<table>
  <thead>
    <tr>
      <th style="text-align: center">f</th>
      <th style="text-align: center">Entropy</th>
      <th style="text-align: center">IG</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">base</td>
      <td style="text-align: center">0.9182</td>
      <td style="text-align: center">-</td>
    </tr>
    <tr>
      <td style="text-align: center">f1</td>
      <td style="text-align: center">0.8742</td>
      <td style="text-align: center">0.0441</td>
    </tr>
    <tr>
      <td style="text-align: center">f2</td>
      <td style="text-align: center">0.8742</td>
      <td style="text-align: center">0.0441</td>
    </tr>
    <tr>
      <td style="text-align: center">f3</td>
      <td style="text-align: center">0.6667</td>
      <td style="text-align: center">0.2516</td>
    </tr>
  </tbody>
</table>

<p>결과에 따라 첫번째 기준으로 엔트로피가 가장 많이 줄고, IG가 가장 높은 feature3를 선택하게 된다.</p>

<p>따라서 feature3 기준으로 feature값이 1인경우 y=yes, 0인 경우 y=no로 나눠지게 된다.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">f1</th>
      <th style="text-align: center">f2</th>
      <th style="text-align: center">f3</th>
      <th style="text-align: center">y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">0</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center"><span style="color: #7d7ee8">1</span></td>
      <td style="text-align: center"><span style="color: #7d7ee8">yes</span></td>
    </tr>
    <tr>
      <td style="text-align: center">0</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center"><span style="color: #e87d7d">0</span></td>
      <td style="text-align: center"><span style="color: #e87d7d">no</span></td>
    </tr>
    <tr>
      <td style="text-align: center">1</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">no</td>
    </tr>
    <tr>
      <td style="text-align: center">0</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center"><span style="color: #e87d7d">0</span></td>
      <td style="text-align: center"><span style="color: #e87d7d">no</span></td>
    </tr>
    <tr>
      <td style="text-align: center">0</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">no</td>
    </tr>
    <tr>
      <td style="text-align: center">1</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center"><span style="color: #7d7ee8">1</span></td>
      <td style="text-align: center"><span style="color: #7d7ee8">yes</span></td>
    </tr>
  </tbody>
</table>

<p>남은 데이터는 아래와 같다.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">f1</th>
      <th style="text-align: center">f2</th>
      <th style="text-align: center">y</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center">1</td>
      <td style="text-align: center">1</td>
      <td style="text-align: center">no</td>
    </tr>
    <tr>
      <td style="text-align: center">0</td>
      <td style="text-align: center">0</td>
      <td style="text-align: center">no</td>
    </tr>
  </tbody>
</table>

<p>이제 다시 위에 과정을 반복하게 된다.</p>
<blockquote>
  <p>$E_{base2} = -(0 + 1 \cdot \log{1}) =0$</p>
</blockquote>

<p>이 예제에서는 더이상 나눌 엔트로피가 없기 때문에 사실상 어떤 기준으로 선택해도 no가 나오지만 컴퓨터는 계산시 둘중 아무거나 기준으로 결과를 낼 것이다.</p>

<p>데이터를 없에지 않는 방법도 존재한다. feature3를 선택하고 남은 feature들 중에서 다시 선택하는 방법이다.</p>

<h2 id="코드">코드</h2>
<p>모든 코드는 Github<a href="https://github.com/simonjisu/ML/tree/master/DecisionTreeModel"><span style="color: #7d7ee8">링크</span></a>, DecisionTree.py에 공개되어 있다.</p>
:ET