I"ı <h1 id="pytorch-ì˜-packedsequence-object-ì•Œì•„ë³´ê¸°">Pytorch ì˜ PackedSequence object ì•Œì•„ë³´ê¸°</h1>

<hr />

<h2 id="packedsequence-ë€">PackedSequence ë€?</h2>

<blockquote>
  <p>ì•„ë˜ì˜ ì¼ë ¨ì˜ ê³¼ì •ì„ PackedSequence ë¼ê³  í•  ìˆ˜ ìˆë‹¤.</p>
</blockquote>

<p>NLP ì—ì„œ ë§¤ ë°°ì¹˜(batch)ë§ˆë‹¤ ê³ ì •ëœ ë¬¸ì¥ì˜ ê¸¸ì´ë¡œ ë§Œë“¤ì–´ì£¼ê¸° ìœ„í•´ì„œ <code class="highlighter-rouge">&lt;pad&gt;</code> í† í°ì„ ë„£ì–´ì•¼ í•œë‹¤. ì•„ë˜ ê·¸ë¦¼ì˜ íŒŒë€ìƒ‰ ì˜ì—­ì€ <code class="highlighter-rouge">&lt;pad&gt;</code> í† í°ì´ë‹¤.</p>

<p><img src="https://dl.dropbox.com/s/ctd209m9zlzs0cw/0705img1.png" /></p>

<blockquote>
  <p>ì‚¬ì§„ ì¶œì²˜: <a href="https://medium.com/huggingface/understanding-emotions-from-keras-to-pytorch-3ccb61d5a983">Understanding emotionsâ€Šâ€”â€Šfrom Keras to pyTorch</a></p>
</blockquote>

<p>ê·¸ë¦¼ê³¼ ê°™ì€ ë‚´ìš©ì„ ì—°ì‚°ì„ í•˜ê²Œ ë˜ë©´, ì“¸ëª¨ì—†ëŠ” <code class="highlighter-rouge">&lt;pad&gt;</code> í† í°ê¹Œì§€ ì—°ì‚°ì„ í•˜ê²Œ ëœë‹¤.
ë”°ë¼ì„œ <code class="highlighter-rouge">&lt;pad&gt;</code> ë¥¼ ê³„ì‚° ì•ˆí•˜ê³  íš¨ìœ¨ì ìœ¼ë¡œ ì§„í–‰í•˜ê¸° ìœ„í•´ ë³‘ë ¬ì²˜ë¦¬ë¥¼ í•˜ë ¤ê³ í•œë‹¤. ê·¸ë ‡ë‹¤ë©´ ì•„ë˜ì˜ ì¡°ê±´ì„ ë§Œì¡±í•´ì•¼í•œë‹¤.</p>

<ul>
  <li>RNNì˜ íˆë“  ìŠ¤í…Œì´íŠ¸ê°€ ì´ì „ íƒ€ì„ìŠ¤í…ì— ì˜ì¡´í•´ì„œ ìµœëŒ€í•œ ë§ì€ í† í°ì„ ë³‘ë ¬ì ìœ¼ë¡œ ì²˜ë¦¬í•´ì•¼í•œë‹¤.</li>
  <li>ê° ë¬¸ì¥ì˜ ë§ˆì§€ë§‰ í† í°ì´ ë§ˆì§€ë§‰ íƒ€ì„ìŠ¤í…ì—ì„œ ê³„ì‚°ì„ ë©ˆì¶°ì•¼í•œë‹¤.</li>
</ul>

<p>ì•„ì§ ì–´ë–¤ ëŠë‚Œì¸ì§€ ì˜ ëª¨ë¥´ê² ë‹¤ë©´ ì•„ë˜ì˜ ê·¸ë¦¼ì„ ë³´ì.</p>

<p><img src="https://dl.dropbox.com/s/3ze3svhdz05aakk/0705img3.gif" /></p>

<p>ì¦‰, ì»´í“¨í„°ë¡œ í•˜ì—¬ê¸ˆ ê° <strong>íƒ€ì„ìŠ¤í…</strong>(T=ë°°ì¹˜ë‚´ì—ì„œ ë¬¸ì¥ì˜ ìµœëŒ€ ê¸¸ì´) ë§ˆë‹¤ ì¼ë ¨ì˜ ë‹¨ì–´ë¥¼ ì²˜ë¦¬í•´ì•¼í•œë‹¤ëŠ” ëœ»ì´ë‹¤.</p>

<p>í•˜ì§€ë§Œ $T=2, 3$ ì¸ ë¶€ë¶„ì€ ì¤‘ê°„ì— <code class="highlighter-rouge">&lt;pad&gt;</code>ì´ ë¼ì–´ ìˆì–´ì„œ ì–´ì©”ìˆ˜ ì—†ì´ ì—°ì‚°ì„ í•˜ê²Œ ë˜ëŠ”ë°, ì´ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ì„œ, ì•„ë˜ì˜ ê·¸ë¦¼ê°™ì´ ê° ë°°ì¹˜ë‚´ì— ë¬¸ì¥ì˜ ê¸¸ì´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ <span style="color: #e87d7d">ì •ë ¬(sorting)</span> í›„, í•˜ë‚˜ì˜ í†µí•©ëœ ë°°ì¹˜ë¡œ ë§Œë“¤ì–´ì¤€ë‹¤.</p>

<p><img src="https://dl.dropbox.com/s/op87oonnoqegn5c/0705img2.png" /></p>

<blockquote>
  <p>ì‚¬ì§„ ì¶œì²˜: <a href="https://medium.com/huggingface/understanding-emotions-from-keras-to-pytorch-3ccb61d5a983">Understanding emotionsâ€Šâ€”â€Šfrom Keras to pyTorch</a></p>
</blockquote>

<ul>
  <li><strong>data:</strong> <code class="highlighter-rouge">&lt;pad&gt;</code> í† í°ì´ ì œê±°í›„ í•©ë³‘ëœ ë°ì´í„°</li>
  <li><strong>batch_sizes:</strong> ê° íƒ€ì„ìŠ¤í… ë§ˆë‹¤ ë°°ì¹˜ë¥¼ ëª‡ê°œë¥¼ ë„£ëŠ”ì§€ ê¸°ë¡í•´ ë‘ </li>
</ul>

<p>ì´ì²˜ëŸ¼ PackedSequence ì˜ <strong>ì¥ì </strong>ì€ <code class="highlighter-rouge">&lt;pad&gt;</code> í† í°ì„ ê³„ì‚° ì•ˆí•˜ê¸° ë•Œë¬¸ì— ë” ë¹ ë¥¸ ì—°ì‚°ì„ ì²˜ë¦¬ í•  ìˆ˜ ìˆë‹¤.</p>

<hr />

<h2 id="pytorch---packedsequence">Pytorch - PackedSequence</h2>

<p>Pytorch ì—ì„œ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì€ ì˜ì™¸ë¡œ ê°„ë‹¨í•˜ë‹¤. ì‹¤ìŠµ ì½”ë“œëŠ” <a href="https://nbviewer.jupyter.org/github/simonjisu/pytorch_tutorials/blob/master/00_Basic_Utils/02_PackedSequence.ipynb">nbviewer</a> í˜¹ì€ <a href="https://github.com/simonjisu/pytorch_tutorials/blob/master/00_Basic_Utils/02_PackedSequence.ipynb">github</a>ì— ìˆë‹¤.</p>

<h3 id="ê³¼ì •">ê³¼ì •</h3>

<p>ì „ì²˜ë¦¬ë¥¼ í†µí•´ ìœ„ ë°°ì¹˜ì˜ ë¬¸ì¥ë“¤ì„ ìˆ«ìë¡œ ë°”ê¿”ì£¼ì—ˆë‹¤.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>input_seq2idx
============================================
tensor([[  1,  16,   7,  11,  13,   2],
        [  1,  16,   6,  15,   8,   0],
        [ 12,   9,   0,   0,   0,   0],
        [  5,  14,   3,  17,   0,   0],
        [ 10,   0,   0,   0,   0,   0]])
</code></pre></div></div>

<p>í•˜ë‹¨ì˜ ì½”ë“œë¥¼ í†µí•´ì„œ ì •ë ¬ì„ í•´ì£¼ê³ , ê° ë¬¸ì¥ì˜ ê¸¸ì´ë¥¼ ë‹´ì€ listë¥¼ ë§Œë“¤ì–´ì¤€ë‹¤.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>input_lengths = torch.LongTensor([torch.max(input_seq2idx[i, :].data.nonzero())+1 for i in range(input_seq2idx.size(0))])
input_lengths, sorted_idx = input_lengths.sort(0, descending=True)
input_seq2idx = input_seq2idx[sorted_idx]
</code></pre></div></div>

<p>ëª¨ë“  <code class="highlighter-rouge">&lt;pad&gt;</code> í† í°ì˜ ì¸ë±ìŠ¤ì¸ 0 ì´ ë°‘ìœ¼ë¡œ ë‚´ë ¤ê°„ ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>input_seq2idx, input_lengths
============================================
tensor([[  1,  16,   7,  11,  13,   2],
        [  1,  16,   6,  15,   8,   0],
        [  5,  14,   3,  17,   0,   0],
        [ 12,   9,   0,   0,   0,   0],
        [ 10,   0,   0,   0,   0,   0]])

tensor([ 6,  5,  4,  2,  1])
</code></pre></div></div>

<p><strong>torch.nn.utils.rnn</strong> ì—ì„œ <strong>pack_padded_sequence</strong> ë¥¼ ì‚¬ìš©í•˜ë©´ PackedSequence objectë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤. packed_input ì—ëŠ” ìœ„ì—ì„œ ë§í•œ í•©ë³‘ëœ ë°ì´í„°ì™€ ê° íƒ€ì„ìŠ¤í…ì˜ ë°°ì¹˜ì‚¬ì´ì¦ˆë“¤ì´ ë‹´ê²¨ìˆë‹¤.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>packed_input = torch.nn.utils.rnn.pack_padded_sequence(input_seq2idx, input_lengths.tolist(), batch_first=True)
</code></pre></div></div>

<p><br /></p>

<h3 id="rnn-ì—ì„œì˜-ì‚¬ìš©-ë°©ë²•">RNN ì—ì„œì˜ ì‚¬ìš© ë°©ë²•</h3>

<p>ì‹¤ìˆ˜ ë²¡í„°ê³µê°„ì— ì„ë² ë”©ëœ ë¬¸ì¥ë“¤ì„ pack í•œ ë‹¤ìŒì— RNN ì— inputì„ ë„£ê¸°ë§Œ í•˜ë©´ ëœë‹¤.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>embed = nn.Embedding(vocab_size, embedding_size, padding_idx=0)
gru = nn.RNN(input_size=embedding_size, hidden_size=hidden_size, num_layers=num_layers, bidirectional=False, batch_first=True)

embeded = embed(input_seq2idx)
packed_input = pack_padded_sequence(embeded, input_lengths.tolist(), batch_first=True)
packed_output, hidden = gru(packed_input)
</code></pre></div></div>
<p>packed_output ì—ëŠ” í•©ë³‘ëœ output ê³¼ batch_sizes ê°€ í¬í•¨ë˜ì–´ ìˆë‹¤.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>packed_output[0].size(), packed_output[1]
=========================================================
(torch.Size([18, 2]), tensor([ 5,  4,  3,  3,  2,  1]))
</code></pre></div></div>

<p>ì´ë¥¼ ë‹¤ì‹œ ì›ë˜ í˜•íƒœì˜ <strong>(ë°°ì¹˜í¬ê¸°, ë¬¸ì¥ì˜ ìµœëŒ€ ê¸¸ì´, íˆë“ í¬ê¸°)</strong> ë¡œ ë°”ê¾¸ë ¤ë©´ <strong>pad_packed_sequence</strong> ë¥¼ ì‚¬ìš©í•˜ë©´ ëœë‹¤.</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>output, output_lengths = pad_packed_sequence(packed_output, batch_first=True)
output.size(), output_lengths
=========================================================
(torch.Size([5, 6, 2]), tensor([ 6,  5,  4,  2,  1]))
</code></pre></div></div>

<p>ì‹¤ìŠµì½”ë“œì—ì„œ ì¶œë ¥ ê²°ê³¼ë¥¼ ì‚´í´ë³´ë©´ <code class="highlighter-rouge">&lt;pad&gt;</code> í† í°ê³¼ ì—°ê´€ëœ í–‰ì€ ëª¨ë“œ 0ìœ¼ë¡œ ì±„ì›Œì ¸ ìˆë‹¤.</p>

<hr />

<h2 id="rnn-backend-ì‘ë™-ë°©ì‹">RNN Backend ì‘ë™ ë°©ì‹</h2>

<h3 id="rnn-ì•ˆì—ì„œ-ì–´ë–¤-ë°©ë²•ìœ¼ë¡œ-ì‹¤í–‰ë˜ëŠ”-ê²ƒì¼ê¹Œ">RNN ì•ˆì—ì„œ ì–´ë–¤ ë°©ë²•ìœ¼ë¡œ ì‹¤í–‰ë˜ëŠ” ê²ƒì¼ê¹Œ?</h3>

<p>ì•„ë˜ì˜ ê·¸ë¦¼ì„ ì‚´í´ë³´ì</p>

<p><img src="https://dl.dropbox.com/s/jl1iymxj6fdtvoe/0705img4.gif" /></p>

<p>ì€ë‹‰ì¸µì—ì„œëŠ” ë§¤ íƒ€ì„ìŠ¤í…ë§ˆë‹¤ batch_sizes ë¥¼ ì°¸ê³ í•´ì„œ ë°°ì¹˜ìˆ˜ ë§Œí¼ ì€ë‹‰ì¸µì„ ê³¨ë¼ì„œ ë’¤ë¡œ ì „íŒŒí•œë‹¤.</p>

<p>ê¸°ì¡´ì˜ RNN ì´ë¼ë©´, <strong>(ë°°ì¹˜í¬ê¸° $\times$ ë¬¸ì¥ì˜ ìµœëŒ€ ê¸¸ì´ $\times$ ì¸µì˜ ê°¯ìˆ˜)</strong> ë§Œí¼ ì—°ì‚°ì„ í•´ì•¼í•˜ì§€ë§Œ, <strong>(ì‹¤ì œ í† í°ì˜ ê°¯ìˆ˜ $\times$ ì¸µì˜ ê°¯ìˆ˜)</strong> ë§Œí¼ ê³„ì‚°í•˜ë©´ ëœë‹¤. ì´ ì˜ˆì œë¡œ ë§í•˜ë©´ $(5 \times 6 \times 1)=30 \rightarrow (18 \times 1)=18$ ë¡œ í¬ê²Œ ì¤„ì—ˆë‹¤.</p>

<h3 id="ê·¸ë ‡ë‹¤ë©´-hidden-ì–´ë–»ê²Œ-ì¶œë ¥-ë˜ëŠ”ê°€">ê·¸ë ‡ë‹¤ë©´ Hidden ì–´ë–»ê²Œ ì¶œë ¥ ë˜ëŠ”ê°€?</h3>

<p>ê¸°ì¡´ì˜ RNN ì´ë¼ë©´ ë§ˆì§€ë§‰ íƒ€ì„ìŠ¤í… ë•Œ hidden vector ë§Œ ì¶œë ¥í•˜ì§€ë§Œ, packed sequence ëŠ” ì•„ë˜ì˜ ê·¸ë¦¼ ì²˜ëŸ¼ ê³¨ë¼ì„œ ì¶œë ¥í•˜ê²Œ ëœë‹¤.</p>

<p><img src="https://dl.dropbox.com/s/e1kjq4jsehbixiq/0705img5.png" /></p>

<p>ì°¸ê³ ìë£Œ: <a href="https://discuss.pytorch.org/t/lstm-hidden-cell-outputs-and-packed-sequence-for-variable-length-sequence-inputs/1183">https://discuss.pytorch.org/t/lstm-hidden-cell-outputs-and-packed-sequence-for-variable-length-sequence-inputs/1183</a></p>
:ET